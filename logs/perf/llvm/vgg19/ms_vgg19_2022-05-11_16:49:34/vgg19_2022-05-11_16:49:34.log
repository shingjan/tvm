2022-05-11 16:50:06.705 INFO RPCRunner: max_workers = 1
https://storage.cloud.google.com/octoml-aquarium-models/onnx_model_zoo/vision_classification_vgg19.onnx
file existed. Skipping downloading.
/home/ubuntu/cache-workloads/vgg19.onnx
Workload: vgg19
  input_name: data
  input_shape: [1, 3, 224, 224]
  input_dtype: float32
2022-05-11 16:50:23.342 INFO Logging directory: /home/ubuntu/tvm/logs/perf/llvm/vgg19//ms_vgg19_2022-05-11_16:49:34/logs
2022-05-11 16:50:23.342 INFO Working directory: /home/ubuntu/tvm/logs/perf/llvm/vgg19//ms_vgg19_2022-05-11_16:49:34/
2022-05-11 16:50:23.342 INFO Creating JSONDatabase. Workload at: /home/ubuntu/tvm/logs/perf/llvm/vgg19//ms_vgg19_2022-05-11_16:49:34/database_workload.json. Tuning records at: /home/ubuntu/tvm/logs/perf/llvm/vgg19//ms_vgg19_2022-05-11_16:49:34/database_tuning_record.json
2022-05-11 16:50:23.343 INFO LocalBuilder: max_workers = 48
2022-05-11 16:50:34.340 INFO 
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |            N/A |          N/A |                   N/A |      0 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 0
Total latency (us): 0

2022-05-11 16:50:34.340 INFO Scheduler picks Task #0: "fused_layout_transform"
2022-05-11 16:50:37.259 INFO Sending 8 sample(s) to builder
2022-05-11 16:50:38.749 INFO Sending 8 sample(s) to runner
2022-05-11 16:50:38.754 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-11 16:50:58.778 INFO Sending 64 sample(s) to builder
2022-05-11 16:51:32.688 INFO Sending 64 sample(s) to runner
2022-05-11 16:51:34.127 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 16:51:52.273 INFO Sending 64 sample(s) to builder
2022-05-11 16:52:26.783 INFO Sending 64 sample(s) to runner
2022-05-11 16:52:28.218 INFO Scheduler picks Task #3: "fused_nn_max_pool2d"
2022-05-11 16:52:32.695 INFO Sending 8 sample(s) to builder
2022-05-11 16:52:34.439 INFO Sending 8 sample(s) to runner
2022-05-11 16:52:34.443 INFO Scheduler picks Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-11 16:52:51.203 INFO Sending 64 sample(s) to builder
2022-05-11 16:53:23.190 INFO Sending 64 sample(s) to runner
2022-05-11 16:53:24.695 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 16:53:38.280 INFO Sending 64 sample(s) to builder
2022-05-11 16:53:49.473 INFO Sending 64 sample(s) to runner
2022-05-11 16:53:49.597 INFO Scheduler picks Task #6: "fused_nn_max_pool2d_1"
2022-05-11 16:53:53.219 INFO Sending 8 sample(s) to builder
2022-05-11 16:53:54.261 INFO Sending 8 sample(s) to runner
2022-05-11 16:53:54.265 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-11 16:54:07.921 INFO Sending 64 sample(s) to builder
2022-05-11 16:54:36.966 INFO Sending 64 sample(s) to runner
2022-05-11 16:54:37.010 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 16:54:48.893 INFO Sending 64 sample(s) to builder
2022-05-11 16:54:56.963 INFO Sending 64 sample(s) to runner
2022-05-11 16:54:57.008 INFO Scheduler picks Task #9: "fused_nn_max_pool2d_2"
2022-05-11 16:54:59.680 INFO Sending 8 sample(s) to builder
2022-05-11 16:55:01.611 INFO Sending 8 sample(s) to runner
2022-05-11 16:55:01.615 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-11 16:55:13.811 INFO Sending 64 sample(s) to builder
2022-05-11 16:55:42.491 INFO Sending 64 sample(s) to runner
2022-05-11 16:55:42.534 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 16:55:57.818 INFO Sending 64 sample(s) to builder
2022-05-11 16:56:23.872 INFO Sending 64 sample(s) to runner
2022-05-11 16:56:23.984 INFO Scheduler picks Task #12: "fused_nn_max_pool2d_3"
2022-05-11 16:56:27.874 INFO Sending 8 sample(s) to builder
2022-05-11 16:56:28.653 INFO Sending 8 sample(s) to runner
2022-05-11 16:56:28.657 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 16:56:39.561 INFO Sending 64 sample(s) to builder
2022-05-11 16:56:51.846 INFO Sending 64 sample(s) to runner
2022-05-11 16:56:51.928 INFO Scheduler picks Task #14: "fused_nn_max_pool2d_4"
2022-05-11 16:56:55.464 INFO Sending 12 sample(s) to builder
2022-05-11 16:56:56.517 INFO Sending 12 sample(s) to runner
2022-05-11 16:56:56.522 INFO Scheduler picks Task #15: "fused_layout_transform_nn_batch_flatten"
2022-05-11 16:56:58.867 INFO Sending 12 sample(s) to builder
2022-05-11 16:56:59.845 INFO Sending 12 sample(s) to runner
2022-05-11 16:56:59.849 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 16:57:02.381 INFO Sending 64 sample(s) to builder
2022-05-11 16:57:14.237 INFO Sending 64 sample(s) to runner
2022-05-11 16:57:14.315 INFO Scheduler picks Task #17: "fused_nn_dense_add_nn_relu_1"
2022-05-11 16:57:19.031 INFO Sending 64 sample(s) to builder
2022-05-11 16:57:42.162 INFO Sending 64 sample(s) to runner
2022-05-11 16:57:42.192 INFO Scheduler picks Task #18: "fused_nn_batch_flatten"
2022-05-11 16:57:43.147 INFO Sending 4 sample(s) to builder
2022-05-11 16:57:43.792 INFO Sending 4 sample(s) to runner
2022-05-11 16:57:43.793 INFO Scheduler picks Task #19: "fused_nn_dense_add"
2022-05-11 16:57:46.399 INFO Sending 64 sample(s) to builder
2022-05-11 16:57:53.646 INFO Sending 64 sample(s) to runner
/home/ubuntu/anaconda3/lib/python3.9/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)
2022-05-11 16:57:59.356 INFO [Updated] Task #0: "fused_layout_transform"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |            N/A |          N/A |                   N/A |      0 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8
Total latency (us): 3.07633

2022-05-11 16:58:11.817 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |            N/A |          N/A |                   N/A |      0 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 72
Total latency (us): 189.023

2022-05-11 16:58:37.164 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |            N/A |          N/A |                   N/A |      0 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 136
Total latency (us): 6077.89

2022-05-11 16:58:54.673 INFO [Updated] Task #3: "fused_nn_max_pool2d"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |            N/A |          N/A |                   N/A |      0 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 144
Total latency (us): 6095.5

2022-05-11 16:59:02.034 INFO [Updated] Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |            N/A |          N/A |                   N/A |      0 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 208
Total latency (us): 7414.99

2022-05-11 16:59:06.252 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |            N/A |          N/A |                   N/A |      0 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 272
Total latency (us): 11691.4

2022-05-11 16:59:15.070 INFO [Updated] Task #6: "fused_nn_max_pool2d_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |            N/A |          N/A |                   N/A |      0 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 280
Total latency (us): 11697.7

2022-05-11 16:59:25.484 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |            N/A |          N/A |                   N/A |      0 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 344
Total latency (us): 14399.3

2022-05-11 16:59:57.225 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 408
Total latency (us): 20936.8

2022-05-11 17:00:04.222 INFO [Updated] Task #9: "fused_nn_max_pool2d_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 416
Total latency (us): 20941.1

2022-05-11 17:00:14.974 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |            N/A |          N/A |                   N/A |      0 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 480
Total latency (us): 22756.7

2022-05-11 17:00:51.943 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |       687.3721 |    5383.0798 |            16149.2395 |     64 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 544
Total latency (us): 38906

2022-05-11 17:01:08.880 INFO [Updated] Task #12: "fused_nn_max_pool2d_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |       687.3721 |    5383.0798 |            16149.2395 |     64 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |            N/A |          N/A |                   N/A |      0 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 552
Total latency (us): 38909.2

2022-05-11 17:01:35.962 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |       687.3721 |    5383.0798 |            16149.2395 |     64 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 616
Total latency (us): 43865.5

2022-05-11 17:01:59.475 INFO [Updated] Task #14: "fused_nn_max_pool2d_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |       687.3721 |    5383.0798 |            16149.2395 |     64 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 628
Total latency (us): 43868.3

2022-05-11 17:02:29.978 INFO [Updated] Task #15: "fused_layout_transform_nn_batch_flatten"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |       687.3721 |    5383.0798 |            16149.2395 |     64 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 640
Total latency (us): 43871.4

2022-05-11 17:02:48.968 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |       687.3721 |    5383.0798 |            16149.2395 |     64 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 704
Total latency (us): 47576.8

2022-05-11 17:03:08.900 INFO [Updated] Task #17: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |       687.3721 |    5383.0798 |            16149.2395 |     64 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 768
Total latency (us): 48029.6

2022-05-11 17:03:38.535 INFO [Updated] Task #18: "fused_nn_batch_flatten"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |       687.3721 |    5383.0798 |            16149.2395 |     64 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |            N/A |          N/A |                   N/A |      0 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 772
Total latency (us): 48035

2022-05-11 17:03:55.596 INFO [Updated] Task #19: "fused_nn_dense_add"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |       687.3721 |    5383.0798 |            16149.2395 |     64 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 836
Total latency (us): 48102.9

2022-05-11 17:03:55.596 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 17:04:28.971 INFO Sending 64 sample(s) to builder
2022-05-11 17:04:42.553 INFO Sending 64 sample(s) to runner
2022-05-11 17:05:41.710 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2091.3446 |    1769.2823 |             5307.8469 |    128 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 900
Total latency (us): 37261.5

2022-05-11 17:05:41.710 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 17:06:13.459 INFO Sending 64 sample(s) to builder
2022-05-11 17:06:28.952 INFO Sending 64 sample(s) to runner
2022-05-11 17:06:29.024 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 17:06:59.444 INFO Sending 64 sample(s) to builder
2022-05-11 17:07:22.229 INFO Sending 64 sample(s) to runner
2022-05-11 17:07:53.258 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      1698.3478 |    2179.1660 |             6537.4981 |     64 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 964
Total latency (us): 36539.6

2022-05-11 17:08:08.668 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2180.1441 |    1697.5859 |             5092.7576 |    128 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1028
Total latency (us): 35094.9

2022-05-11 17:08:08.668 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 17:08:32.520 INFO Sending 64 sample(s) to builder
2022-05-11 17:08:39.672 INFO Sending 64 sample(s) to runner
2022-05-11 17:08:39.767 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 17:09:07.258 INFO Sending 64 sample(s) to builder
2022-05-11 17:09:26.516 INFO Sending 64 sample(s) to runner
2022-05-11 17:09:55.373 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |       629.2886 |    5888.8700 |             5888.8700 |     64 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1092
Total latency (us): 34837.8

2022-05-11 17:10:12.923 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      1410.1086 |    2628.0235 |             2628.0235 |    128 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1156
Total latency (us): 31577

2022-05-11 17:10:12.923 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 17:10:40.088 INFO Sending 64 sample(s) to builder
2022-05-11 17:10:45.557 INFO Sending 64 sample(s) to runner
2022-05-11 17:10:45.601 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 17:11:15.219 INFO Sending 64 sample(s) to builder
2022-05-11 17:11:29.725 INFO Sending 64 sample(s) to runner
2022-05-11 17:12:10.998 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |       746.5612 |    1239.0742 |             4956.2968 |     64 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1220
Total latency (us): 30781.2

2022-05-11 17:12:41.828 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |       865.8200 |    4276.3939 |             4276.3939 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      1175.6843 |     786.8139 |             3147.2555 |    128 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1284
Total latency (us): 28972.1

2022-05-11 17:12:41.828 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 17:13:12.983 INFO Sending 64 sample(s) to builder
2022-05-11 17:13:21.420 INFO Sending 64 sample(s) to runner
2022-05-11 17:13:59.830 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      1175.1206 |    3150.8148 |             3150.8148 |    128 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      1175.6843 |     786.8139 |             3147.2555 |    128 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1348
Total latency (us): 27846.5

2022-05-11 17:13:59.830 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 17:14:32.740 INFO Sending 64 sample(s) to builder
2022-05-11 17:14:55.606 INFO Sending 64 sample(s) to runner
2022-05-11 17:14:55.782 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 17:15:08.710 INFO Sending 64 sample(s) to builder
2022-05-11 17:15:34.151 INFO Sending 64 sample(s) to runner
2022-05-11 17:16:13.410 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      1175.6843 |     786.8139 |             3147.2555 |    128 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |     64 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1412
Total latency (us): 26340.4

2022-05-11 17:18:07.799 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |       685.2613 |    2701.5881 |             2701.5881 |     64 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      1175.6843 |     786.8139 |             3147.2555 |    128 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    128 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1476
Total latency (us): 26340.4

2022-05-11 17:18:07.799 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 17:18:21.667 INFO Sending 64 sample(s) to builder
2022-05-11 17:18:29.011 INFO Sending 64 sample(s) to runner
2022-05-11 17:18:29.087 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-11 17:19:08.448 INFO Sending 64 sample(s) to builder
2022-05-11 17:19:26.562 INFO Sending 64 sample(s) to runner
2022-05-11 17:21:45.235 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      1659.8238 |    1115.3556 |             1115.3556 |    128 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      1175.6843 |     786.8139 |             3147.2555 |    128 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    128 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1540
Total latency (us): 24754.1

2022-05-11 17:21:45.235 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-11 17:22:24.465 INFO Sending 64 sample(s) to builder
2022-05-11 17:22:51.887 INFO Sending 64 sample(s) to runner
2022-05-11 17:23:11.865 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      1659.8238 |    1115.3556 |             1115.3556 |    128 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      1175.6843 |     786.8139 |             3147.2555 |    128 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1604
Total latency (us): 24754.1

2022-05-11 17:23:11.866 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-11 17:23:50.325 INFO Sending 64 sample(s) to builder
2022-05-11 17:24:05.410 INFO Sending 64 sample(s) to runner
2022-05-11 17:24:24.772 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1019.2022 |    1815.6268 |             1815.6268 |     64 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      1175.6843 |     786.8139 |             3147.2555 |    128 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1668
Total latency (us): 24468.3

2022-05-11 17:24:49.125 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      1888.3971 |     979.9268 |              979.9268 |    128 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      1175.6843 |     786.8139 |             3147.2555 |    128 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1732
Total latency (us): 23632.6

2022-05-11 17:24:49.125 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-11 17:25:28.493 INFO Sending 64 sample(s) to builder
2022-05-11 17:26:03.703 INFO Sending 64 sample(s) to runner
2022-05-11 17:26:03.818 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 17:26:43.810 INFO Sending 64 sample(s) to builder
2022-05-11 17:27:14.286 INFO Sending 64 sample(s) to runner
2022-05-11 17:27:42.025 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    192 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      1175.6843 |     786.8139 |             3147.2555 |    128 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1796
Total latency (us): 23500.7

2022-05-11 17:28:02.243 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2296.0493 |    1611.8913 |             4835.6738 |    256 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      1175.6843 |     786.8139 |             3147.2555 |    128 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1860
Total latency (us): 23500.7

2022-05-11 17:28:02.243 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 17:28:36.965 INFO Sending 64 sample(s) to builder
2022-05-11 17:28:51.279 INFO Sending 64 sample(s) to runner
2022-05-11 17:28:51.395 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 17:29:33.223 INFO Sending 64 sample(s) to builder
2022-05-11 17:29:47.203 INFO Sending 64 sample(s) to runner
2022-05-11 17:30:07.925 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2308.0086 |    1603.5390 |             4810.6170 |    320 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      1175.6843 |     786.8139 |             3147.2555 |    128 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1924
Total latency (us): 23475.7

2022-05-11 17:30:54.115 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2308.0086 |    1603.5390 |             4810.6170 |    320 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2109.9234 |     438.4257 |             1753.7029 |    192 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1988
Total latency (us): 22082.1

2022-05-11 17:30:54.115 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 17:31:10.891 INFO Sending 64 sample(s) to builder
2022-05-11 17:31:16.245 INFO Sending 64 sample(s) to runner
2022-05-11 17:31:16.289 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 17:31:40.073 INFO Sending 64 sample(s) to builder
2022-05-11 17:31:55.704 INFO Sending 64 sample(s) to runner
2022-05-11 17:32:39.638 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2308.0086 |    1603.5390 |             4810.6170 |    320 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2420.5311 |    1528.6641 |             4585.9922 |    192 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2052
Total latency (us): 21701.1

2022-05-11 17:33:16.425 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2308.0086 |    1603.5390 |             4810.6170 |    320 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2432.8844 |    1520.9021 |             4562.7063 |    256 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2116
Total latency (us): 21677.8

2022-05-11 17:33:16.425 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 17:33:50.890 INFO Sending 64 sample(s) to builder
2022-05-11 17:33:57.513 INFO Sending 64 sample(s) to runner
2022-05-11 17:34:35.755 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2308.0086 |    1603.5390 |             4810.6170 |    320 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2510.3607 |    1473.9630 |             4421.8891 |    320 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2180
Total latency (us): 21537

2022-05-11 17:34:35.755 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 17:35:16.550 INFO Sending 64 sample(s) to builder
2022-05-11 17:35:32.518 INFO Sending 64 sample(s) to runner
2022-05-11 17:35:32.645 INFO Scheduler picks Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-11 17:36:07.812 INFO Sending 64 sample(s) to builder
2022-05-11 17:36:26.722 INFO Sending 64 sample(s) to runner
2022-05-11 17:37:02.556 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      1404.2594 |    1319.4851 |             1319.4851 |     64 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2308.0086 |    1603.5390 |             4810.6170 |    320 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    384 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2244
Total latency (us): 21488.7

2022-05-11 17:37:20.760 INFO [Updated] Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2447.3234 |     757.1126 |              757.1126 |    128 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2308.0086 |    1603.5390 |             4810.6170 |    320 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    384 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2308
Total latency (us): 20926.3

2022-05-11 17:37:20.760 INFO Scheduler picks Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-11 17:38:00.485 INFO Sending 64 sample(s) to builder
2022-05-11 17:38:16.612 INFO Sending 64 sample(s) to runner
2022-05-11 17:38:16.701 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 17:38:29.130 INFO Sending 64 sample(s) to builder
2022-05-11 17:38:38.414 INFO Sending 64 sample(s) to runner
2022-05-11 17:41:50.534 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2447.3234 |     757.1126 |              757.1126 |    128 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2308.0086 |    1603.5390 |             4810.6170 |    320 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    384 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    256 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2372
Total latency (us): 20926.3

2022-05-11 17:41:50.534 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 17:42:04.283 INFO Sending 64 sample(s) to builder
2022-05-11 17:42:09.648 INFO Sending 64 sample(s) to runner
2022-05-11 17:42:46.274 INFO [Updated] Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2308.0086 |    1603.5390 |             4810.6170 |    320 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    384 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    256 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2436
Total latency (us): 20898.5

2022-05-11 17:42:46.274 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 17:43:30.306 INFO Sending 64 sample(s) to builder
2022-05-11 17:43:48.181 INFO Sending 64 sample(s) to runner
2022-05-11 17:45:29.332 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2308.0086 |    1603.5390 |             4810.6170 |    384 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    384 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    256 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2500
Total latency (us): 20898.5

2022-05-11 17:45:29.332 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 17:46:12.663 INFO Sending 64 sample(s) to builder
2022-05-11 17:46:28.563 INFO Sending 64 sample(s) to runner
2022-05-11 17:47:00.653 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2308.0086 |    1603.5390 |             4810.6170 |    384 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    384 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2564
Total latency (us): 20898.5

2022-05-11 17:47:32.589 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2568.0928 |    1441.1402 |             4323.4206 |    448 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    384 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2628
Total latency (us): 20411.3

2022-05-11 17:47:32.589 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 17:48:07.980 INFO Sending 64 sample(s) to builder
2022-05-11 17:48:14.742 INFO Sending 64 sample(s) to runner
2022-05-11 17:48:14.811 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 17:48:53.712 INFO Sending 64 sample(s) to builder
2022-05-11 17:49:26.713 INFO Sending 64 sample(s) to runner
2022-05-11 17:49:46.519 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2627.7698 |    1408.4117 |             4225.2351 |    512 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    384 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2692
Total latency (us): 20313.1

2022-05-11 17:50:30.016 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2627.7698 |    1408.4117 |             4225.2351 |    512 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    448 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2756
Total latency (us): 20313.1

2022-05-11 17:50:30.016 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 17:50:57.054 INFO Sending 64 sample(s) to builder
2022-05-11 17:51:17.223 INFO Sending 64 sample(s) to runner
2022-05-11 17:51:17.349 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 17:51:32.817 INFO Sending 64 sample(s) to builder
2022-05-11 17:51:40.883 INFO Sending 64 sample(s) to runner
2022-05-11 17:52:29.372 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2627.7698 |    1408.4117 |             4225.2351 |    512 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    512 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2820
Total latency (us): 20313.1

2022-05-11 17:54:19.163 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2627.7698 |    1408.4117 |             4225.2351 |    512 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    512 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    256 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    384 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2884
Total latency (us): 20313.1

2022-05-11 17:54:19.163 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 17:54:34.842 INFO Sending 64 sample(s) to builder
2022-05-11 17:54:41.563 INFO Sending 64 sample(s) to runner
2022-05-11 17:54:41.932 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 17:55:11.132 INFO Sending 64 sample(s) to builder
2022-05-11 17:55:17.501 INFO Sending 64 sample(s) to runner
2022-05-11 17:58:35.661 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2627.7698 |    1408.4117 |             4225.2351 |    512 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    512 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    320 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    384 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2948
Total latency (us): 20313.1

2022-05-11 17:58:35.661 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 17:59:15.955 INFO Sending 64 sample(s) to builder
2022-05-11 17:59:26.099 INFO Sending 64 sample(s) to runner
2022-05-11 18:00:05.188 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2627.7698 |    1408.4117 |             4225.2351 |    512 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    512 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    320 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    448 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3012
Total latency (us): 20313.1

2022-05-11 18:00:05.189 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 18:00:51.316 INFO Sending 64 sample(s) to builder
2022-05-11 18:01:14.832 INFO Sending 64 sample(s) to runner
2022-05-11 18:01:40.574 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2022.5730 |    1832.2200 |             1832.2200 |    192 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2627.7698 |    1408.4117 |             4225.2351 |    512 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    512 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    448 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3076
Total latency (us): 20313.1

2022-05-11 18:02:29.685 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2211.1168 |    1675.9850 |             1675.9850 |    256 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2627.7698 |    1408.4117 |             4225.2351 |    512 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    512 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    448 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3140
Total latency (us): 20156.9

2022-05-11 18:02:29.685 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 18:03:00.879 INFO Sending 64 sample(s) to builder
2022-05-11 18:03:26.520 INFO Sending 64 sample(s) to runner
2022-05-11 18:04:55.341 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2398.7857 |    1544.8644 |             1544.8644 |    320 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2627.7698 |    1408.4117 |             4225.2351 |    512 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    512 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    448 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3204
Total latency (us): 20025.8

2022-05-11 18:04:55.341 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 18:05:22.356 INFO Sending 64 sample(s) to builder
2022-05-11 18:05:52.584 INFO Sending 64 sample(s) to runner
2022-05-11 18:05:52.659 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 18:06:37.265 INFO Sending 64 sample(s) to builder
2022-05-11 18:06:53.418 INFO Sending 64 sample(s) to runner
2022-05-11 18:07:28.662 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2627.7698 |    1408.4117 |             4225.2351 |    512 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    512 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    448 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3268
Total latency (us): 19914.2

2022-05-11 18:08:15.306 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    576 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    512 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    448 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3332
Total latency (us): 19652.9

2022-05-11 18:08:15.306 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 18:08:48.167 INFO Sending 64 sample(s) to builder
2022-05-11 18:09:01.483 INFO Sending 64 sample(s) to runner
2022-05-11 18:09:01.628 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 18:09:46.306 INFO Sending 64 sample(s) to builder
2022-05-11 18:09:57.419 INFO Sending 64 sample(s) to runner
2022-05-11 18:10:16.309 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2538.1022 |    1457.8526 |             4373.5578 |    512 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    448 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3396
Total latency (us): 19652.9

2022-05-11 18:10:57.671 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2604.9591 |    1420.4365 |             4261.3095 |    576 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    448 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3460
Total latency (us): 19540.6

2022-05-11 18:10:57.671 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 18:11:40.430 INFO Sending 64 sample(s) to builder
2022-05-11 18:11:55.080 INFO Sending 64 sample(s) to runner
2022-05-11 18:11:55.205 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 18:12:33.887 INFO Sending 64 sample(s) to builder
2022-05-11 18:12:58.616 INFO Sending 64 sample(s) to runner
2022-05-11 18:13:54.564 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2251.3151 |    1644.6331 |             1644.6331 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2639.9774 |    1401.5950 |             4204.7849 |    640 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    448 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3524
Total latency (us): 19484.1

2022-05-11 18:14:23.027 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2603.9473 |    1421.9133 |             1421.9133 |    256 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2639.9774 |    1401.5950 |             4204.7849 |    640 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    448 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3588
Total latency (us): 19261.4

2022-05-11 18:14:23.027 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 18:15:05.498 INFO Sending 64 sample(s) to builder
2022-05-11 18:15:24.999 INFO Sending 64 sample(s) to runner
2022-05-11 18:16:16.392 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2626.5678 |    1409.6675 |             1409.6675 |    320 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2639.9774 |    1401.5950 |             4204.7849 |    640 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    448 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3652
Total latency (us): 19249.1

2022-05-11 18:16:16.393 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 18:17:03.376 INFO Sending 64 sample(s) to builder
2022-05-11 18:17:18.610 INFO Sending 64 sample(s) to runner
2022-05-11 18:17:18.716 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 18:17:32.165 INFO Sending 64 sample(s) to builder
2022-05-11 18:17:39.283 INFO Sending 64 sample(s) to runner
2022-05-11 18:20:37.119 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2626.5678 |    1409.6675 |             1409.6675 |    320 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2639.9774 |    1401.5950 |             4204.7849 |    640 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    512 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3716
Total latency (us): 19249.1

2022-05-11 18:20:37.120 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 18:20:45.272 INFO Sending 64 sample(s) to builder
2022-05-11 18:20:49.322 INFO Sending 64 sample(s) to runner
2022-05-11 18:21:11.671 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2639.9774 |    1401.5950 |             4204.7849 |    640 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4678 |    3705.3743 |             3705.3743 |    512 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3780
Total latency (us): 19132.8

2022-05-11 18:23:35.752 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2639.9774 |    1401.5950 |             4204.7849 |    640 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4744 |    3704.9387 |             3704.9387 |    576 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        74.1313 |     452.7456 |              452.7456 |     64 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3844
Total latency (us): 19132.4

2022-05-11 18:23:35.753 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 18:23:49.489 INFO Sending 64 sample(s) to builder
2022-05-11 18:23:58.692 INFO Sending 64 sample(s) to runner
2022-05-11 18:23:58.764 INFO Scheduler picks Task #17: "fused_nn_dense_add_nn_relu_1"
2022-05-11 18:24:13.822 INFO Sending 64 sample(s) to builder
2022-05-11 18:24:19.448 INFO Sending 64 sample(s) to runner
2022-05-11 18:27:42.130 INFO [Updated] Task #17: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2639.9774 |    1401.5950 |             4204.7849 |    640 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4744 |    3704.9387 |             3704.9387 |    576 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.2993 |     445.7230 |              445.7230 |    128 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3908
Total latency (us): 19125.4

2022-05-11 18:27:42.130 INFO Scheduler picks Task #17: "fused_nn_dense_add_nn_relu_1"
2022-05-11 18:27:56.396 INFO Sending 64 sample(s) to builder
2022-05-11 18:28:01.568 INFO Sending 64 sample(s) to runner
2022-05-11 18:29:01.727 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2639.9774 |    1401.5950 |             4204.7849 |    640 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4744 |    3704.9387 |             3704.9387 |    640 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.2993 |     445.7230 |              445.7230 |    128 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3972
Total latency (us): 19125.4

2022-05-11 18:29:26.980 INFO [Updated] Task #17: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2639.9774 |    1401.5950 |             4204.7849 |    640 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4744 |    3704.9387 |             3704.9387 |    640 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4036
Total latency (us): 19123.8

2022-05-11 18:29:26.980 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 18:30:03.771 INFO Sending 64 sample(s) to builder
2022-05-11 18:30:21.756 INFO Sending 64 sample(s) to runner
2022-05-11 18:31:13.992 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2639.9774 |    1401.5950 |             4204.7849 |    704 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4744 |    3704.9387 |             3704.9387 |    640 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4100
Total latency (us): 19123.8

2022-05-11 18:31:13.992 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 18:31:57.349 INFO Sending 64 sample(s) to builder
2022-05-11 18:32:14.214 INFO Sending 64 sample(s) to runner
2022-05-11 18:32:14.373 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 18:32:54.299 INFO Sending 64 sample(s) to builder
2022-05-11 18:33:06.668 INFO Sending 64 sample(s) to runner
2022-05-11 18:33:48.081 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2801.0317 |    1321.2923 |             3963.8770 |    640 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2658.6888 |    1391.7307 |             4175.1922 |    768 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4744 |    3704.9387 |             3704.9387 |    640 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4164
Total latency (us): 19094.2

2022-05-11 18:34:14.811 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2811.9578 |    1316.1584 |             3948.4751 |    704 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2658.6888 |    1391.7307 |             4175.1922 |    768 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4744 |    3704.9387 |             3704.9387 |    640 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4228
Total latency (us): 19078.8

2022-05-11 18:34:14.811 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 18:34:58.308 INFO Sending 64 sample(s) to builder
2022-05-11 18:35:11.854 INFO Sending 64 sample(s) to runner
2022-05-11 18:36:31.760 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2811.9578 |    1316.1584 |             3948.4751 |    768 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2658.6888 |    1391.7307 |             4175.1922 |    768 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4744 |    3704.9387 |             3704.9387 |    640 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4292
Total latency (us): 19078.8

2022-05-11 18:36:31.760 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 18:37:17.486 INFO Sending 64 sample(s) to builder
2022-05-11 18:37:29.276 INFO Sending 64 sample(s) to runner
2022-05-11 18:37:29.359 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 18:37:44.817 INFO Sending 64 sample(s) to builder
2022-05-11 18:37:51.410 INFO Sending 64 sample(s) to runner
2022-05-11 18:38:09.631 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2811.9578 |    1316.1584 |             3948.4751 |    832 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2658.6888 |    1391.7307 |             4175.1922 |    768 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4744 |    3704.9387 |             3704.9387 |    640 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4356
Total latency (us): 19078.8

2022-05-11 18:41:17.401 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2811.9578 |    1316.1584 |             3948.4751 |    832 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2658.6888 |    1391.7307 |             4175.1922 |    768 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4744 |    3704.9387 |             3704.9387 |    704 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4420
Total latency (us): 19078.8

2022-05-11 18:41:17.402 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 18:41:28.391 INFO Sending 64 sample(s) to builder
2022-05-11 18:41:32.127 INFO Sending 64 sample(s) to runner
2022-05-11 18:41:32.171 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 18:42:00.585 INFO Sending 64 sample(s) to builder
2022-05-11 18:42:08.994 INFO Sending 64 sample(s) to runner
2022-05-11 18:44:36.069 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2811.9578 |    1316.1584 |             3948.4751 |    832 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2661.2967 |    1390.3669 |             4171.1008 |    832 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.4744 |    3704.9387 |             3704.9387 |    704 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4484
Total latency (us): 19074.7

2022-05-11 18:44:36.069 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 18:45:12.661 INFO Sending 64 sample(s) to builder
2022-05-11 18:45:44.438 INFO Sending 64 sample(s) to runner
2022-05-11 18:46:13.289 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2811.9578 |    1316.1584 |             3948.4751 |    832 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2661.2967 |    1390.3669 |             4171.1008 |    832 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.7456 |    3686.9102 |             3686.9102 |    768 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4548
Total latency (us): 19056.7

2022-05-11 18:46:54.159 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2811.9578 |    1316.1584 |             3948.4751 |    832 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2675.0870 |    1383.1995 |             4149.5984 |    896 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.7456 |    3686.9102 |             3686.9102 |    768 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4612
Total latency (us): 19035.2

2022-05-11 18:46:54.159 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 18:47:26.846 INFO Sending 64 sample(s) to builder
2022-05-11 18:47:33.597 INFO Sending 64 sample(s) to runner
2022-05-11 18:47:33.674 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 18:47:44.035 INFO Sending 64 sample(s) to builder
2022-05-11 18:47:49.083 INFO Sending 64 sample(s) to runner
2022-05-11 18:51:03.359 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2811.9578 |    1316.1584 |             3948.4751 |    832 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2675.0870 |    1383.1995 |             4149.5984 |    896 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    832 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4676
Total latency (us): 19031.4

2022-05-11 18:51:03.384 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 18:51:18.694 INFO Sending 64 sample(s) to builder
2022-05-11 18:51:24.576 INFO Sending 64 sample(s) to runner
2022-05-11 18:51:47.981 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2811.9578 |    1316.1584 |             3948.4751 |    832 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2675.0870 |    1383.1995 |             4149.5984 |    960 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    832 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4740
Total latency (us): 19031.4

2022-05-11 18:51:47.981 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 18:52:33.058 INFO Sending 64 sample(s) to builder
2022-05-11 18:52:43.148 INFO Sending 64 sample(s) to runner
2022-05-11 18:54:42.027 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    896 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2675.0870 |    1383.1995 |             4149.5984 |    960 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    832 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4804
Total latency (us): 19021

2022-05-11 18:54:42.037 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 18:55:12.278 INFO Sending 64 sample(s) to builder
2022-05-11 18:55:17.368 INFO Sending 64 sample(s) to runner
2022-05-11 18:55:45.471 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    896 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2675.0870 |    1383.1995 |             4149.5984 |    960 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    896 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4868
Total latency (us): 19021

2022-05-11 18:55:45.471 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-11 18:56:28.961 INFO Sending 64 sample(s) to builder
2022-05-11 18:56:46.122 INFO Sending 64 sample(s) to runner
2022-05-11 18:57:10.891 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    960 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2182.1942 |     847.9955 |              847.9955 |    192 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2675.0870 |    1383.1995 |             4149.5984 |    960 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    896 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4932
Total latency (us): 19021

2022-05-11 18:57:42.082 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    960 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2259.6645 |     818.9228 |              818.9228 |    256 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2675.0870 |    1383.1995 |             4149.5984 |    960 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    896 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4996
Total latency (us): 18991.9

2022-05-11 18:57:42.082 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-11 18:58:11.527 INFO Sending 64 sample(s) to builder
2022-05-11 18:58:20.849 INFO Sending 64 sample(s) to runner
2022-05-11 18:59:30.339 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    960 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2508.3805 |     737.7234 |              737.7234 |    320 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2675.0870 |    1383.1995 |             4149.5984 |    960 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    896 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5060
Total latency (us): 18910.7

2022-05-11 18:59:30.339 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-11 19:00:13.173 INFO Sending 64 sample(s) to builder
2022-05-11 19:00:34.315 INFO Sending 64 sample(s) to runner
2022-05-11 19:00:34.479 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 19:01:10.837 INFO Sending 64 sample(s) to builder
2022-05-11 19:01:21.225 INFO Sending 64 sample(s) to runner
2022-05-11 19:01:58.959 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    960 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2675.0870 |    1383.1995 |             4149.5984 |    960 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    896 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5124
Total latency (us): 18824.9

2022-05-11 19:02:29.508 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2231.6269 |     829.5713 |              829.5713 |    192 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    960 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2723.6640 |    1358.5299 |             4075.5897 |   1024 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    896 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5188
Total latency (us): 18750.9

2022-05-11 19:02:29.508 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-11 19:03:05.866 INFO Sending 64 sample(s) to builder
2022-05-11 19:03:30.446 INFO Sending 64 sample(s) to runner
2022-05-11 19:04:21.086 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2792.3168 |     662.9956 |              662.9956 |    256 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    960 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2723.6640 |    1358.5299 |             4075.5897 |   1024 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    896 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5252
Total latency (us): 18584.3

2022-05-11 19:04:21.086 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-11 19:05:08.761 INFO Sending 64 sample(s) to builder
2022-05-11 19:05:28.670 INFO Sending 64 sample(s) to runner
2022-05-11 19:06:31.587 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2874.7564 |     643.9828 |              643.9828 |    320 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    960 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2723.6640 |    1358.5299 |             4075.5897 |   1024 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    896 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5316
Total latency (us): 18565.3

2022-05-11 19:06:31.603 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-11 19:07:10.167 INFO Sending 64 sample(s) to builder
2022-05-11 19:07:19.076 INFO Sending 64 sample(s) to runner
2022-05-11 19:07:19.121 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 19:07:45.564 INFO Sending 64 sample(s) to builder
2022-05-11 19:08:09.362 INFO Sending 64 sample(s) to runner
2022-05-11 19:08:45.600 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2585.5181 |    1433.2906 |             1433.2906 |    384 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    960 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2723.6640 |    1358.5299 |             4075.5897 |   1024 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    896 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5380
Total latency (us): 18541.3

2022-05-11 19:09:37.923 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2682.3746 |    1381.5366 |             1381.5366 |    448 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    960 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2723.6640 |    1358.5299 |             4075.5897 |   1024 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    896 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5444
Total latency (us): 18489.6

2022-05-11 19:09:37.933 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 19:10:13.080 INFO Sending 64 sample(s) to builder
2022-05-11 19:10:24.322 INFO Sending 64 sample(s) to runner
2022-05-11 19:10:24.403 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 19:10:40.596 INFO Sending 64 sample(s) to builder
2022-05-11 19:10:50.355 INFO Sending 64 sample(s) to runner
2022-05-11 19:13:39.724 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2682.3746 |    1381.5366 |             1381.5366 |    448 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    960 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2723.6640 |    1358.5299 |             4075.5897 |   1024 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    960 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5508
Total latency (us): 18489.6

2022-05-11 19:13:39.724 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 19:13:53.544 INFO Sending 64 sample(s) to builder
2022-05-11 19:14:01.636 INFO Sending 64 sample(s) to runner
2022-05-11 19:14:24.207 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2819.3861 |    1312.6906 |             3938.0719 |    960 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2723.6640 |    1358.5299 |             4075.5897 |   1024 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    960 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5572
Total latency (us): 18464.5

2022-05-11 19:14:24.208 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 19:15:03.354 INFO Sending 64 sample(s) to builder
2022-05-11 19:15:15.537 INFO Sending 64 sample(s) to runner
2022-05-11 19:17:12.161 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1024 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2723.6640 |    1358.5299 |             4075.5897 |   1024 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |    960 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5636
Total latency (us): 18445.1

2022-05-11 19:17:12.162 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 19:17:59.495 INFO Sending 64 sample(s) to builder
2022-05-11 19:18:11.554 INFO Sending 64 sample(s) to runner
2022-05-11 19:18:42.678 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1024 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2723.6640 |    1358.5299 |             4075.5897 |   1024 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5700
Total latency (us): 18445.1

2022-05-11 19:18:42.679 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 19:19:24.428 INFO Sending 64 sample(s) to builder
2022-05-11 19:19:38.994 INFO Sending 64 sample(s) to runner
2022-05-11 19:20:34.393 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1088 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2723.6640 |    1358.5299 |             4075.5897 |   1024 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5764
Total latency (us): 18445.1

2022-05-11 19:21:09.245 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1088 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1088 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    384 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5828
Total latency (us): 18415.5

2022-05-11 19:21:09.245 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 19:21:54.093 INFO Sending 64 sample(s) to builder
2022-05-11 19:22:05.283 INFO Sending 64 sample(s) to runner
2022-05-11 19:23:13.454 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1088 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1088 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    448 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5892
Total latency (us): 18415.5

2022-05-11 19:23:13.455 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 19:23:42.396 INFO Sending 64 sample(s) to builder
2022-05-11 19:23:48.683 INFO Sending 64 sample(s) to runner
2022-05-11 19:23:48.768 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 19:24:30.862 INFO Sending 64 sample(s) to builder
2022-05-11 19:24:48.592 INFO Sending 64 sample(s) to runner
2022-05-11 19:25:49.779 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1088 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1088 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5956
Total latency (us): 18415.5

2022-05-11 19:26:34.020 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1088 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1152 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6020
Total latency (us): 18415.5

2022-05-11 19:26:34.020 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 19:27:11.372 INFO Sending 64 sample(s) to builder
2022-05-11 19:27:31.762 INFO Sending 64 sample(s) to runner
2022-05-11 19:27:31.874 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 19:28:16.761 INFO Sending 64 sample(s) to builder
2022-05-11 19:28:31.622 INFO Sending 64 sample(s) to runner
2022-05-11 19:29:31.738 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2862.7594 |    1293.3631 |             1293.3631 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1088 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1216 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6084
Total latency (us): 18415.5

2022-05-11 19:29:47.105 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    448 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1088 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1216 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6148
Total latency (us): 18385.8

2022-05-11 19:29:47.105 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 19:30:06.031 INFO Sending 64 sample(s) to builder
2022-05-11 19:30:10.002 INFO Sending 64 sample(s) to runner
2022-05-11 19:30:10.044 INFO Scheduler picks Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-11 19:30:37.319 INFO Sending 64 sample(s) to builder
2022-05-11 19:30:53.629 INFO Sending 64 sample(s) to runner
2022-05-11 19:31:42.692 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2540.5312 |     729.3354 |              729.3354 |    192 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1088 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1216 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6212
Total latency (us): 18385.8

2022-05-11 19:32:27.734 INFO [Updated] Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2846.9929 |     650.8268 |              650.8268 |    256 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1088 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1216 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6276
Total latency (us): 18307.3

2022-05-11 19:32:27.734 INFO Scheduler picks Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-11 19:33:01.054 INFO Sending 64 sample(s) to builder
2022-05-11 19:33:14.971 INFO Sending 64 sample(s) to runner
2022-05-11 19:33:15.098 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 19:33:51.939 INFO Sending 64 sample(s) to builder
2022-05-11 19:34:06.018 INFO Sending 64 sample(s) to runner
2022-05-11 19:34:56.570 INFO [Updated] Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2833.3202 |    1306.2349 |             3918.7047 |   1088 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1216 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6340
Total latency (us): 18295

2022-05-11 19:35:23.543 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2885.4356 |    1282.6423 |             3847.9269 |   1152 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1216 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1024 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6404
Total latency (us): 18224.2

2022-05-11 19:35:23.544 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 19:35:40.738 INFO Sending 64 sample(s) to builder
2022-05-11 19:35:50.242 INFO Sending 64 sample(s) to runner
2022-05-11 19:38:40.793 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2885.4356 |    1282.6423 |             3847.9269 |   1152 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1216 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1088 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6468
Total latency (us): 18224.2

2022-05-11 19:38:40.793 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 19:38:55.479 INFO Sending 64 sample(s) to builder
2022-05-11 19:39:00.087 INFO Sending 64 sample(s) to runner
2022-05-11 19:39:00.138 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 19:39:40.393 INFO Sending 64 sample(s) to builder
2022-05-11 19:39:50.167 INFO Sending 64 sample(s) to runner
2022-05-11 19:42:23.516 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2885.4356 |    1282.6423 |             3847.9269 |   1216 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1216 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1088 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6532
Total latency (us): 18224.2

2022-05-11 19:42:23.516 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 19:43:03.211 INFO Sending 64 sample(s) to builder
2022-05-11 19:43:40.548 INFO Sending 64 sample(s) to runner
2022-05-11 19:44:35.982 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2885.4356 |    1282.6423 |             3847.9269 |   1216 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1216 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1152 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6596
Total latency (us): 18224.2

2022-05-11 19:44:35.982 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 19:45:10.430 INFO Sending 64 sample(s) to builder
2022-05-11 19:45:23.940 INFO Sending 64 sample(s) to runner
2022-05-11 19:45:50.853 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2885.4356 |    1282.6423 |             3847.9269 |   1280 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1216 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1152 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6660
Total latency (us): 18224.2

2022-05-11 19:46:50.249 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2885.4356 |    1282.6423 |             3847.9269 |   1280 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1280 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1152 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6724
Total latency (us): 18224.2

2022-05-11 19:46:50.249 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 19:47:32.490 INFO Sending 64 sample(s) to builder
2022-05-11 19:47:42.541 INFO Sending 64 sample(s) to runner
2022-05-11 19:47:42.692 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 19:47:56.432 INFO Sending 63 sample(s) to builder
2022-05-11 19:48:01.293 INFO Sending 63 sample(s) to runner
2022-05-11 19:51:02.254 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2885.4356 |    1282.6423 |             3847.9269 |   1280 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1280 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1215 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6787
Total latency (us): 18224.2

2022-05-11 19:51:02.254 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 19:51:13.488 INFO Sending 64 sample(s) to builder
2022-05-11 19:51:19.054 INFO Sending 64 sample(s) to runner
2022-05-11 19:51:42.967 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2885.4356 |    1282.6423 |             3847.9269 |   1280 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1344 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1215 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6851
Total latency (us): 18224.2

2022-05-11 19:51:42.967 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 19:52:14.028 INFO Sending 64 sample(s) to builder
2022-05-11 19:52:39.430 INFO Sending 64 sample(s) to runner
2022-05-11 19:54:33.778 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2911.9881 |    1270.9467 |             3812.8402 |   1344 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1344 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1215 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6915
Total latency (us): 18189.1

2022-05-11 19:54:33.778 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 19:55:20.725 INFO Sending 64 sample(s) to builder
2022-05-11 19:55:33.688 INFO Sending 64 sample(s) to runner
2022-05-11 19:56:03.209 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2911.9881 |    1270.9467 |             3812.8402 |   1344 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1344 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1279 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6979
Total latency (us): 18189.1

2022-05-11 19:56:03.209 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 19:56:47.709 INFO Sending 64 sample(s) to builder
2022-05-11 19:57:00.197 INFO Sending 64 sample(s) to runner
2022-05-11 19:57:39.937 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1408 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2743.5712 |    1348.6725 |             4046.0174 |   1344 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1279 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7043
Total latency (us): 18170.6

2022-05-11 19:58:15.263 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |       967.1090 |     185.9468 |              185.9468 |     64 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1408 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1408 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1279 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7107
Total latency (us): 18142.4

2022-05-11 19:58:15.264 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-11 19:58:49.230 INFO Sending 64 sample(s) to builder
2022-05-11 19:59:14.378 INFO Sending 64 sample(s) to runner
2022-05-11 20:00:20.238 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      1425.3968 |     126.1619 |              126.1619 |    128 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1408 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1408 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1279 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7171
Total latency (us): 18082.6

2022-05-11 20:00:20.238 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-11 20:00:57.160 INFO Sending 64 sample(s) to builder
2022-05-11 20:01:09.876 INFO Sending 64 sample(s) to runner
2022-05-11 20:01:09.966 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 20:01:53.826 INFO Sending 64 sample(s) to builder
2022-05-11 20:02:32.382 INFO Sending 64 sample(s) to runner
2022-05-11 20:03:45.676 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2732.0244 |    1356.4295 |             1356.4295 |    512 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1408 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1408 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1279 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7235
Total latency (us): 18040.2

2022-05-11 20:04:34.736 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1408 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1408 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1279 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7299
Total latency (us): 18014.2

2022-05-11 20:04:34.736 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 20:05:15.499 INFO Sending 64 sample(s) to builder
2022-05-11 20:05:30.549 INFO Sending 64 sample(s) to runner
2022-05-11 20:06:25.235 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1408 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1472 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1279 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7363
Total latency (us): 18014.2

2022-05-11 20:06:25.235 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 20:07:00.571 INFO Sending 64 sample(s) to builder
2022-05-11 20:07:10.549 INFO Sending 64 sample(s) to runner
2022-05-11 20:07:10.647 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 20:07:23.386 INFO Sending 64 sample(s) to builder
2022-05-11 20:07:29.494 INFO Sending 64 sample(s) to runner
2022-05-11 20:10:41.505 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1408 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1472 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1343 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7427
Total latency (us): 18014.2

2022-05-11 20:10:41.505 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 20:10:48.787 INFO Sending 63 sample(s) to builder
2022-05-11 20:11:16.076 INFO Sending 63 sample(s) to runner
2022-05-11 20:12:03.848 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1408 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1536 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1343 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7491
Total latency (us): 18014.2

2022-05-11 20:12:03.849 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 20:12:41.625 INFO Sending 64 sample(s) to builder
2022-05-11 20:12:55.704 INFO Sending 64 sample(s) to runner
2022-05-11 20:15:01.652 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1472 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1536 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1343 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7555
Total latency (us): 18014.2

2022-05-11 20:15:01.652 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 20:15:45.681 INFO Sending 64 sample(s) to builder
2022-05-11 20:15:57.565 INFO Sending 64 sample(s) to runner
2022-05-11 20:16:52.988 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1472 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1536 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1406 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7618
Total latency (us): 18014.2

2022-05-11 20:16:52.988 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 20:17:26.174 INFO Sending 64 sample(s) to builder
2022-05-11 20:17:35.909 INFO Sending 64 sample(s) to runner
2022-05-11 20:18:08.413 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1536 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1536 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    512 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1406 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7682
Total latency (us): 18014.2

2022-05-11 20:18:49.158 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2930.0833 |    1263.6458 |             1263.6458 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1536 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1536 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1406 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7746
Total latency (us): 18014.2

2022-05-11 20:18:49.158 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 20:19:36.257 INFO Sending 64 sample(s) to builder
2022-05-11 20:19:56.594 INFO Sending 64 sample(s) to runner
2022-05-11 20:21:10.553 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    576 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1536 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1536 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1406 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7810
Total latency (us): 17994.5

2022-05-11 20:21:10.553 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 20:21:43.783 INFO Sending 64 sample(s) to builder
2022-05-11 20:22:01.996 INFO Sending 64 sample(s) to runner
2022-05-11 20:22:02.041 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 20:22:40.211 INFO Sending 64 sample(s) to builder
2022-05-11 20:23:00.487 INFO Sending 64 sample(s) to runner
2022-05-11 20:23:52.250 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1536 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1536 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1406 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7874
Total latency (us): 17994.5

2022-05-11 20:24:39.239 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1536 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1600 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1406 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7938
Total latency (us): 17994.5

2022-05-11 20:24:39.240 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 20:24:54.432 INFO Sending 64 sample(s) to builder
2022-05-11 20:24:58.977 INFO Sending 64 sample(s) to runner
2022-05-11 20:28:00.388 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1536 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1600 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1470 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8002
Total latency (us): 17994.5

2022-05-11 20:28:00.388 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 20:28:07.737 INFO Sending 64 sample(s) to builder
2022-05-11 20:28:13.066 INFO Sending 64 sample(s) to runner
2022-05-11 20:28:13.231 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 20:28:54.147 INFO Sending 64 sample(s) to builder
2022-05-11 20:29:05.296 INFO Sending 64 sample(s) to runner
2022-05-11 20:31:40.248 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1536 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1664 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1470 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8066
Total latency (us): 17994.5

2022-05-11 20:31:40.248 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 20:32:22.871 INFO Sending 64 sample(s) to builder
2022-05-11 20:32:41.958 INFO Sending 64 sample(s) to runner
2022-05-11 20:33:36.662 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1536 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1664 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1534 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8130
Total latency (us): 17994.5

2022-05-11 20:33:36.662 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 20:34:11.783 INFO Sending 64 sample(s) to builder
2022-05-11 20:34:25.859 INFO Sending 64 sample(s) to runner
2022-05-11 20:35:06.580 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1536 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1728 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1534 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8194
Total latency (us): 17994.5

2022-05-11 20:36:02.350 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1600 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1728 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1534 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8258
Total latency (us): 17994.5

2022-05-11 20:36:02.350 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 20:36:41.101 INFO Sending 64 sample(s) to builder
2022-05-11 20:36:54.860 INFO Sending 64 sample(s) to runner
2022-05-11 20:36:55.044 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 20:37:38.430 INFO Sending 64 sample(s) to builder
2022-05-11 20:37:56.659 INFO Sending 64 sample(s) to runner
2022-05-11 20:38:38.483 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2785.4360 |    1330.4196 |             1330.4196 |    576 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1664 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1728 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1534 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8322
Total latency (us): 17994.5

2022-05-11 20:39:21.493 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    640 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1664 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1728 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1534 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8386
Total latency (us): 17983.6

2022-05-11 20:39:21.493 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 20:40:01.788 INFO Sending 64 sample(s) to builder
2022-05-11 20:40:12.277 INFO Sending 64 sample(s) to runner
2022-05-11 20:40:12.383 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 20:40:23.262 INFO Sending 64 sample(s) to builder
2022-05-11 20:40:32.138 INFO Sending 64 sample(s) to runner
2022-05-11 20:43:41.163 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    640 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1664 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1728 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1598 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8450
Total latency (us): 17983.6

2022-05-11 20:43:41.163 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 20:43:58.342 INFO Sending 64 sample(s) to builder
2022-05-11 20:44:08.068 INFO Sending 64 sample(s) to runner
2022-05-11 20:45:05.822 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1664 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1728 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    576 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1598 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8514
Total latency (us): 17983.6

2022-05-11 20:45:05.823 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 20:45:28.602 INFO Sending 64 sample(s) to builder
2022-05-11 20:45:32.648 INFO Sending 64 sample(s) to runner
2022-05-11 20:47:56.226 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1664 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1728 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    640 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1598 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8578
Total latency (us): 17983.6

2022-05-11 20:47:56.227 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 20:48:32.324 INFO Sending 64 sample(s) to builder
2022-05-11 20:48:57.145 INFO Sending 64 sample(s) to runner
2022-05-11 20:49:40.734 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1664 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1728 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    640 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1662 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8642
Total latency (us): 17983.6

2022-05-11 20:49:40.734 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 20:50:25.283 INFO Sending 64 sample(s) to builder
2022-05-11 20:50:37.991 INFO Sending 64 sample(s) to runner
2022-05-11 20:51:28.459 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1664 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1728 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1662 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8706
Total latency (us): 17983.6

2022-05-11 20:52:09.847 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1664 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1792 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1662 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.5578 |     444.1981 |              444.1981 |    192 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8770
Total latency (us): 17983.6

2022-05-11 20:52:09.847 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 20:52:41.274 INFO Sending 64 sample(s) to builder
2022-05-11 20:52:55.271 INFO Sending 64 sample(s) to runner
2022-05-11 20:52:55.378 INFO Scheduler picks Task #17: "fused_nn_dense_add_nn_relu_1"
2022-05-11 20:53:11.311 INFO Sending 64 sample(s) to builder
2022-05-11 20:53:27.889 INFO Sending 64 sample(s) to runner
2022-05-11 20:55:15.036 INFO [Updated] Task #17: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1664 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1792 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1662 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    256 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8834
Total latency (us): 17983.3

2022-05-11 20:55:15.037 INFO Scheduler picks Task #17: "fused_nn_dense_add_nn_relu_1"
2022-05-11 20:55:29.480 INFO Sending 64 sample(s) to builder
2022-05-11 20:55:36.181 INFO Sending 64 sample(s) to runner
2022-05-11 20:56:08.501 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1664 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1856 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1662 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    256 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8898
Total latency (us): 17983.3

2022-05-11 20:56:08.501 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 20:56:51.006 INFO Sending 64 sample(s) to builder
2022-05-11 20:57:04.194 INFO Sending 64 sample(s) to runner
2022-05-11 20:57:38.120 INFO [Updated] Task #17: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1664 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1856 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1662 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8962
Total latency (us): 17983.3

2022-05-11 20:58:36.632 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1728 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1856 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1662 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9026
Total latency (us): 17983.3

2022-05-11 20:58:36.632 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 20:59:17.670 INFO Sending 64 sample(s) to builder
2022-05-11 20:59:32.514 INFO Sending 64 sample(s) to runner
2022-05-11 20:59:32.614 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 20:59:47.358 INFO Sending 64 sample(s) to builder
2022-05-11 20:59:59.629 INFO Sending 64 sample(s) to runner
2022-05-11 21:00:53.848 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1792 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1856 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1662 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9090
Total latency (us): 17983.3

2022-05-11 21:02:49.871 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1792 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1856 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1726 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9154
Total latency (us): 17983.3

2022-05-11 21:02:49.871 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 21:03:02.428 INFO Sending 64 sample(s) to builder
2022-05-11 21:03:20.798 INFO Sending 64 sample(s) to runner
2022-05-11 21:03:20.986 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 21:04:05.990 INFO Sending 64 sample(s) to builder
2022-05-11 21:04:20.233 INFO Sending 64 sample(s) to runner
2022-05-11 21:06:54.065 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1792 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1920 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1726 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9218
Total latency (us): 17983.3

2022-05-11 21:06:54.065 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 21:07:35.894 INFO Sending 64 sample(s) to builder
2022-05-11 21:07:54.308 INFO Sending 64 sample(s) to runner
2022-05-11 21:08:38.819 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1792 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1920 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1790 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9282
Total latency (us): 17983.3

2022-05-11 21:08:38.819 INFO Scheduler picks Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-11 21:09:04.469 INFO Sending 64 sample(s) to builder
2022-05-11 21:09:12.103 INFO Sending 64 sample(s) to runner
2022-05-11 21:09:59.981 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2901.9293 |     638.5060 |              638.5060 |    320 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1792 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1984 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1790 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9346
Total latency (us): 17983.3

2022-05-11 21:10:45.513 INFO [Updated] Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2968.4487 |     624.1979 |              624.1979 |    384 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1792 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1984 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1790 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9410
Total latency (us): 17969

2022-05-11 21:10:45.514 INFO Scheduler picks Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-11 21:11:17.168 INFO Sending 64 sample(s) to builder
2022-05-11 21:11:35.880 INFO Sending 64 sample(s) to runner
2022-05-11 21:11:36.023 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 21:12:16.769 INFO Sending 64 sample(s) to builder
2022-05-11 21:12:30.549 INFO Sending 64 sample(s) to runner
2022-05-11 21:13:22.832 INFO [Updated] Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1792 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1984 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1790 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9474
Total latency (us): 17967.3

2022-05-11 21:14:09.404 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1856 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1984 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1790 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9538
Total latency (us): 17967.3

2022-05-11 21:14:09.404 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 21:14:24.210 INFO Sending 64 sample(s) to builder
2022-05-11 21:14:31.278 INFO Sending 64 sample(s) to runner
2022-05-11 21:17:35.711 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1856 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1984 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1854 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9602
Total latency (us): 17967.3

2022-05-11 21:17:35.711 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 21:17:49.571 INFO Sending 64 sample(s) to builder
2022-05-11 21:18:00.007 INFO Sending 64 sample(s) to runner
2022-05-11 21:18:00.106 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 21:18:43.950 INFO Sending 64 sample(s) to builder
2022-05-11 21:18:59.146 INFO Sending 64 sample(s) to runner
2022-05-11 21:21:26.455 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1920 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1984 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1854 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9666
Total latency (us): 17967.3

2022-05-11 21:21:26.466 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 21:22:15.149 INFO Sending 64 sample(s) to builder
2022-05-11 21:22:30.616 INFO Sending 64 sample(s) to runner
2022-05-11 21:23:42.878 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1920 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1984 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1918 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9730
Total latency (us): 17967.3

2022-05-11 21:23:42.878 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 21:24:21.371 INFO Sending 64 sample(s) to builder
2022-05-11 21:24:34.021 INFO Sending 64 sample(s) to runner
2022-05-11 21:25:17.310 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1984 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   1984 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1918 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9794
Total latency (us): 17967.3

2022-05-11 21:26:01.888 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2976.5964 |    1243.8997 |             1243.8997 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1984 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   2048 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1918 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9858
Total latency (us): 17967.3

2022-05-11 21:26:01.888 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 21:26:50.553 INFO Sending 64 sample(s) to builder
2022-05-11 21:27:05.098 INFO Sending 64 sample(s) to runner
2022-05-11 21:28:27.533 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      2979.0011 |    1242.8956 |             1242.8956 |    704 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1984 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   2048 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1918 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9922
Total latency (us): 17966.3

2022-05-11 21:28:27.533 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 21:28:51.190 INFO Sending 64 sample(s) to builder
2022-05-11 21:29:10.192 INFO Sending 64 sample(s) to runner
2022-05-11 21:29:10.334 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 21:29:56.327 INFO Sending 64 sample(s) to builder
2022-05-11 21:30:06.614 INFO Sending 64 sample(s) to runner
2022-05-11 21:31:04.731 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1984 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2762.8065 |    1339.2827 |             4017.8482 |   2048 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1918 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9986
Total latency (us): 17954

2022-05-11 21:32:07.620 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1984 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    384 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2112 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1918 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10050
Total latency (us): 17942.4

2022-05-11 21:32:07.620 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-11 21:32:48.998 INFO Sending 64 sample(s) to builder
2022-05-11 21:33:25.664 INFO Sending 64 sample(s) to runner
2022-05-11 21:34:29.943 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1984 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    448 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2112 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1918 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10114
Total latency (us): 17942.4

2022-05-11 21:34:29.943 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-11 21:35:11.535 INFO Sending 64 sample(s) to builder
2022-05-11 21:35:24.666 INFO Sending 64 sample(s) to runner
2022-05-11 21:35:24.734 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 21:35:57.919 INFO Sending 64 sample(s) to builder
2022-05-11 21:36:06.373 INFO Sending 64 sample(s) to runner
2022-05-11 21:37:01.602 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1984 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2112 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    704 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1918 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10178
Total latency (us): 17942.4

2022-05-11 21:37:45.077 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2808.3290 |    1319.5743 |             1319.5743 |    704 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1984 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2112 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1918 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10242
Total latency (us): 17942.4

2022-05-11 21:37:45.077 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 21:38:21.376 INFO Sending 64 sample(s) to builder
2022-05-11 21:38:34.498 INFO Sending 64 sample(s) to runner
2022-05-11 21:39:56.463 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    768 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1984 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2112 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1918 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10306
Total latency (us): 17898.7

2022-05-11 21:39:56.463 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 21:40:43.938 INFO Sending 64 sample(s) to builder
2022-05-11 21:41:22.930 INFO Sending 64 sample(s) to runner
2022-05-11 21:41:23.056 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 21:41:38.168 INFO Sending 64 sample(s) to builder
2022-05-11 21:41:47.963 INFO Sending 64 sample(s) to runner
2022-05-11 21:45:28.690 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    768 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1984 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2112 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1982 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10370
Total latency (us): 17898.7

2022-05-11 21:45:28.690 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 21:45:42.372 INFO Sending 63 sample(s) to builder
2022-05-11 21:45:53.706 INFO Sending 63 sample(s) to runner
2022-05-11 21:46:46.549 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   1984 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2112 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1982 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10434
Total latency (us): 17898.7

2022-05-11 21:46:46.549 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 21:47:27.568 INFO Sending 64 sample(s) to builder
2022-05-11 21:47:40.905 INFO Sending 64 sample(s) to runner
2022-05-11 21:49:30.438 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2048 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2112 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.8033 |    3683.0978 |             3683.0978 |   1982 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10498
Total latency (us): 17898.7

2022-05-11 21:49:30.438 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 21:50:19.437 INFO Sending 64 sample(s) to builder
2022-05-11 21:50:33.941 INFO Sending 64 sample(s) to runner
2022-05-11 21:51:23.383 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2048 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2112 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2045 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10561
Total latency (us): 17887.6

2022-05-11 21:51:23.383 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 21:52:05.238 INFO Sending 64 sample(s) to builder
2022-05-11 21:52:17.275 INFO Sending 64 sample(s) to runner
2022-05-11 21:53:17.792 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2112 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2112 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2045 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10625
Total latency (us): 17887.6

2022-05-11 21:54:04.268 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    384 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2112 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2176 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2045 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10689
Total latency (us): 17887.6

2022-05-11 21:54:04.268 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-11 21:54:50.933 INFO Sending 64 sample(s) to builder
2022-05-11 21:55:09.741 INFO Sending 64 sample(s) to runner
2022-05-11 21:56:48.676 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    448 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2112 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2176 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2045 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10753
Total latency (us): 17887.6

2022-05-11 21:56:48.676 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-11 21:57:20.625 INFO Sending 64 sample(s) to builder
2022-05-11 21:57:32.435 INFO Sending 64 sample(s) to runner
2022-05-11 21:57:32.583 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 21:58:19.770 INFO Sending 64 sample(s) to builder
2022-05-11 21:58:55.658 INFO Sending 64 sample(s) to runner
2022-05-11 21:59:37.086 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2112 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2770.8529 |    1335.3935 |             4006.1805 |   2176 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2045 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10817
Total latency (us): 17887.6

2022-05-11 22:00:43.038 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2112 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2779.2525 |    1331.3576 |             3994.0728 |   2240 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2045 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10881
Total latency (us): 17875.5

2022-05-11 22:00:43.038 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 22:01:08.754 INFO Sending 64 sample(s) to builder
2022-05-11 22:01:19.374 INFO Sending 64 sample(s) to runner
2022-05-11 22:02:40.533 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2112 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2779.2525 |    1331.3576 |             3994.0728 |   2304 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2045 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10945
Total latency (us): 17875.5

2022-05-11 22:02:40.533 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 22:03:17.732 INFO Sending 64 sample(s) to builder
2022-05-11 22:03:26.399 INFO Sending 64 sample(s) to runner
2022-05-11 22:03:26.566 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 22:03:41.581 INFO Sending 64 sample(s) to builder
2022-05-11 22:03:52.140 INFO Sending 64 sample(s) to runner
2022-05-11 22:04:50.874 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2112 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2368 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2045 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11009
Total latency (us): 17853.2

2022-05-11 22:07:07.055 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2112 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2368 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2109 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11073
Total latency (us): 17853.2

2022-05-11 22:07:07.055 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 22:07:18.185 INFO Sending 63 sample(s) to builder
2022-05-11 22:07:32.880 INFO Sending 63 sample(s) to runner
2022-05-11 22:07:33.015 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 22:08:18.481 INFO Sending 64 sample(s) to builder
2022-05-11 22:08:31.709 INFO Sending 64 sample(s) to runner
2022-05-11 22:11:04.897 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2176 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2368 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2109 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11137
Total latency (us): 17853.2

2022-05-11 22:11:04.897 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 22:11:51.192 INFO Sending 64 sample(s) to builder
2022-05-11 22:12:06.296 INFO Sending 64 sample(s) to runner
2022-05-11 22:13:06.018 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2176 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2368 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2172 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11200
Total latency (us): 17853.2

2022-05-11 22:13:06.019 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 22:13:37.716 INFO Sending 64 sample(s) to builder
2022-05-11 22:13:42.018 INFO Sending 64 sample(s) to runner
2022-05-11 22:14:10.697 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2240 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2368 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2695.5299 |     343.1773 |             1372.7093 |    768 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2172 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11264
Total latency (us): 17853.2

2022-05-11 22:14:46.407 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2240 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2368 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2803.0087 |     330.0185 |             1320.0740 |    832 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2172 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11328
Total latency (us): 17800.6

2022-05-11 22:14:46.408 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 22:15:24.429 INFO Sending 64 sample(s) to builder
2022-05-11 22:15:34.130 INFO Sending 64 sample(s) to runner
2022-05-11 22:15:34.268 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 22:16:10.402 INFO Sending 64 sample(s) to builder
2022-05-11 22:16:22.960 INFO Sending 64 sample(s) to runner
2022-05-11 22:17:19.226 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2240 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2368 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2172 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11392
Total latency (us): 17774.6

2022-05-11 22:18:02.646 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2240 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2432 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2172 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11456
Total latency (us): 17774.6

2022-05-11 22:18:02.646 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 22:18:46.722 INFO Sending 64 sample(s) to builder
2022-05-11 22:19:00.440 INFO Sending 64 sample(s) to runner
2022-05-11 22:19:00.567 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 22:19:18.119 INFO Sending 64 sample(s) to builder
2022-05-11 22:19:30.535 INFO Sending 64 sample(s) to runner
2022-05-11 22:20:45.996 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2240 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2496 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2172 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11520
Total latency (us): 17774.6

2022-05-11 22:22:51.515 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2240 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2496 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2236 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11584
Total latency (us): 17774.6

2022-05-11 22:22:51.515 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 22:23:05.437 INFO Sending 64 sample(s) to builder
2022-05-11 22:23:13.740 INFO Sending 64 sample(s) to runner
2022-05-11 22:23:13.800 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 22:23:45.784 INFO Sending 64 sample(s) to builder
2022-05-11 22:24:21.432 INFO Sending 64 sample(s) to runner
2022-05-11 22:26:54.074 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2304 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2496 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2236 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11648
Total latency (us): 17774.6

2022-05-11 22:26:54.074 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 22:27:43.834 INFO Sending 64 sample(s) to builder
2022-05-11 22:27:58.202 INFO Sending 64 sample(s) to runner
2022-05-11 22:29:13.090 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2304 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2496 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2300 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11712
Total latency (us): 17774.6

2022-05-11 22:30:24.169 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2368 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2496 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2300 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11776
Total latency (us): 17774.6

2022-05-11 22:30:24.170 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 22:31:09.948 INFO Sending 64 sample(s) to builder
2022-05-11 22:31:37.864 INFO Sending 64 sample(s) to runner
2022-05-11 22:31:38.018 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 22:32:17.449 INFO Sending 64 sample(s) to builder
2022-05-11 22:32:36.473 INFO Sending 64 sample(s) to runner
2022-05-11 22:33:26.238 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2432 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2496 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2300 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11840
Total latency (us): 17774.6

2022-05-11 22:34:41.802 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2432 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2560 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2300 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11904
Total latency (us): 17774.6

2022-05-11 22:34:41.803 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 22:35:17.683 INFO Sending 64 sample(s) to builder
2022-05-11 22:35:36.937 INFO Sending 64 sample(s) to runner
2022-05-11 22:36:46.599 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3008.5768 |    1230.6774 |             1230.6774 |    832 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2432 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2560 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2300 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11968
Total latency (us): 17774.6

2022-05-11 22:36:46.599 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 22:37:36.281 INFO Sending 64 sample(s) to builder
2022-05-11 22:37:53.886 INFO Sending 64 sample(s) to runner
2022-05-11 22:37:53.961 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 22:38:08.934 INFO Sending 64 sample(s) to builder
2022-05-11 22:38:18.975 INFO Sending 64 sample(s) to runner
2022-05-11 22:39:08.518 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2432 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2560 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2300 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12032
Total latency (us): 17772

2022-05-11 22:41:18.094 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    832 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2432 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2560 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2364 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12096
Total latency (us): 17772

2022-05-11 22:41:18.094 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 22:41:35.460 INFO Sending 64 sample(s) to builder
2022-05-11 22:41:52.195 INFO Sending 64 sample(s) to runner
2022-05-11 22:41:52.277 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 22:42:31.436 INFO Sending 64 sample(s) to builder
2022-05-11 22:43:00.537 INFO Sending 64 sample(s) to runner
2022-05-11 22:45:23.759 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    896 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2432 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2560 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2364 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12160
Total latency (us): 17772

2022-05-11 22:45:23.759 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-11 22:46:11.542 INFO Sending 64 sample(s) to builder
2022-05-11 22:46:32.296 INFO Sending 64 sample(s) to runner
2022-05-11 22:47:38.673 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2904.4528 |    1275.9025 |             1275.9025 |    896 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2432 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2560 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2428 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12224
Total latency (us): 17772

2022-05-11 22:47:38.674 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 22:48:15.981 INFO Sending 64 sample(s) to builder
2022-05-11 22:48:30.016 INFO Sending 64 sample(s) to runner
2022-05-11 22:49:30.554 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2432 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2560 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2428 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12288
Total latency (us): 17757

2022-05-11 22:50:21.952 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2496 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2560 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2428 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12352
Total latency (us): 17757

2022-05-11 22:50:21.952 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 22:51:01.708 INFO Sending 64 sample(s) to builder
2022-05-11 22:51:08.025 INFO Sending 64 sample(s) to runner
2022-05-11 22:52:30.193 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2496 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2624 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2428 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12416
Total latency (us): 17757

2022-05-11 22:52:30.193 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 22:53:14.593 INFO Sending 64 sample(s) to builder
2022-05-11 22:53:29.989 INFO Sending 64 sample(s) to runner
2022-05-11 22:53:30.135 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 22:54:17.741 INFO Sending 64 sample(s) to builder
2022-05-11 22:54:28.489 INFO Sending 64 sample(s) to runner
2022-05-11 22:55:24.264 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2496 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2688 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2859.2796 |     323.5237 |             1294.0948 |    896 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2428 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12480
Total latency (us): 17757

2022-05-11 22:56:16.552 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2496 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2688 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |    960 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2428 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12544
Total latency (us): 17752.5

2022-05-11 22:56:16.552 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 22:57:03.467 INFO Sending 64 sample(s) to builder
2022-05-11 22:57:24.334 INFO Sending 64 sample(s) to runner
2022-05-11 22:58:55.473 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2560 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2688 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |    960 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2428 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12608
Total latency (us): 17752.5

2022-05-11 22:58:55.473 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 22:59:37.038 INFO Sending 64 sample(s) to builder
2022-05-11 22:59:47.530 INFO Sending 64 sample(s) to runner
2022-05-11 22:59:47.608 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 22:59:58.901 INFO Sending 64 sample(s) to builder
2022-05-11 23:00:05.288 INFO Sending 64 sample(s) to runner
2022-05-11 23:03:45.848 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2926.2007 |    1264.7737 |             3794.3211 |   2560 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2688 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |    960 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2492 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12672
Total latency (us): 17752.5

2022-05-11 23:03:45.848 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 23:04:04.222 INFO Sending 64 sample(s) to builder
2022-05-11 23:04:15.300 INFO Sending 64 sample(s) to runner
2022-05-11 23:05:21.307 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2624 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2688 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |    960 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2492 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12736
Total latency (us): 17689.7

2022-05-11 23:05:21.308 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 23:06:13.339 INFO Sending 64 sample(s) to builder
2022-05-11 23:06:35.160 INFO Sending 64 sample(s) to runner
2022-05-11 23:07:57.457 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2624 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2688 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |    960 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2556 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12800
Total latency (us): 17689.7

2022-05-11 23:08:59.340 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2688 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2688 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |    960 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2556 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12864
Total latency (us): 17689.7

2022-05-11 23:08:59.340 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 23:09:49.130 INFO Sending 64 sample(s) to builder
2022-05-11 23:10:02.091 INFO Sending 64 sample(s) to runner
2022-05-11 23:10:02.165 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 23:10:38.916 INFO Sending 64 sample(s) to builder
2022-05-11 23:10:50.135 INFO Sending 64 sample(s) to runner
2022-05-11 23:11:50.867 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2752 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2688 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |    960 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2556 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12928
Total latency (us): 17689.7

2022-05-11 23:12:44.447 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2752 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2752 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |    960 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2556 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12992
Total latency (us): 17689.7

2022-05-11 23:12:44.448 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 23:13:28.247 INFO Sending 64 sample(s) to builder
2022-05-11 23:13:36.496 INFO Sending 64 sample(s) to runner
2022-05-11 23:15:38.655 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2752 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2752 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1024 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2556 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13056
Total latency (us): 17689.7

2022-05-11 23:15:38.655 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-11 23:16:21.552 INFO Sending 64 sample(s) to builder
2022-05-11 23:16:48.323 INFO Sending 64 sample(s) to runner
2022-05-11 23:16:48.500 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 23:17:29.037 INFO Sending 64 sample(s) to builder
2022-05-11 23:17:41.386 INFO Sending 64 sample(s) to runner
2022-05-11 23:18:37.374 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2752 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2752 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2556 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13120
Total latency (us): 17689.7

2022-05-11 23:19:45.653 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2752 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2816 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2556 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13184
Total latency (us): 17689.7

2022-05-11 23:19:45.653 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 23:20:22.494 INFO Sending 64 sample(s) to builder
2022-05-11 23:21:01.062 INFO Sending 64 sample(s) to runner
2022-05-11 23:21:02.604 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 23:21:50.784 INFO Sending 64 sample(s) to builder
2022-05-11 23:22:17.723 INFO Sending 64 sample(s) to runner
2022-05-11 23:23:29.529 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2752 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2556 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13248
Total latency (us): 17689.7

2022-05-11 23:24:31.736 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2816 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2556 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13312
Total latency (us): 17689.7

2022-05-11 23:24:31.736 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-11 23:25:19.631 INFO Sending 64 sample(s) to builder
2022-05-11 23:25:34.645 INFO Sending 64 sample(s) to runner
2022-05-11 23:25:34.827 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 23:25:53.198 INFO Sending 63 sample(s) to builder
2022-05-11 23:26:08.972 INFO Sending 63 sample(s) to runner
2022-05-11 23:26:56.847 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2556 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13376
Total latency (us): 17689.7

2022-05-11 23:29:27.887 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2976.6191 |     622.4845 |              622.4845 |    448 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2619 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13439
Total latency (us): 17689.7

2022-05-11 23:29:27.887 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 23:29:43.681 INFO Sending 63 sample(s) to builder
2022-05-11 23:29:53.386 INFO Sending 63 sample(s) to runner
2022-05-11 23:29:53.504 INFO Scheduler picks Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-11 23:30:39.570 INFO Sending 64 sample(s) to builder
2022-05-11 23:31:00.173 INFO Sending 64 sample(s) to runner
2022-05-11 23:33:27.426 INFO [Updated] Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    512 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2619 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13503
Total latency (us): 17686.9

2022-05-11 23:33:27.426 INFO Scheduler picks Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-11 23:34:15.927 INFO Sending 64 sample(s) to builder
2022-05-11 23:34:52.725 INFO Sending 64 sample(s) to runner
2022-05-11 23:35:51.743 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    512 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2682 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13566
Total latency (us): 17686.9

2022-05-11 23:35:51.743 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-11 23:36:33.066 INFO Sending 64 sample(s) to builder
2022-05-11 23:36:48.884 INFO Sending 64 sample(s) to runner
2022-05-11 23:37:39.363 INFO [Updated] Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3014.8873 |    1228.1014 |             1228.1014 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2682 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13630
Total latency (us): 17686.9

2022-05-11 23:38:28.935 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2682 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    320 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13694
Total latency (us): 17686.8

2022-05-11 23:38:28.935 INFO Scheduler picks Task #17: "fused_nn_dense_add_nn_relu_1"
2022-05-11 23:38:46.100 INFO Sending 64 sample(s) to builder
2022-05-11 23:38:52.932 INFO Sending 64 sample(s) to runner
2022-05-11 23:40:58.034 INFO [Updated] Task #17: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2682 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    384 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13758
Total latency (us): 17686.8

2022-05-11 23:40:58.034 INFO Scheduler picks Task #17: "fused_nn_dense_add_nn_relu_1"
2022-05-11 23:41:16.519 INFO Sending 64 sample(s) to builder
2022-05-11 23:41:52.206 INFO Sending 64 sample(s) to runner
2022-05-11 23:41:52.842 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-11 23:42:37.550 INFO Sending 64 sample(s) to builder
2022-05-11 23:42:56.165 INFO Sending 64 sample(s) to runner
2022-05-11 23:43:41.935 INFO [Updated] Task #17: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2838.6079 |     651.9008 |              651.9008 |    512 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2682 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13822
Total latency (us): 17686.8

2022-05-11 23:44:52.765 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2864.1179 |     646.0945 |              646.0945 |    576 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2682 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13886
Total latency (us): 17681

2022-05-11 23:44:52.765 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-11 23:45:33.007 INFO Sending 64 sample(s) to builder
2022-05-11 23:45:43.993 INFO Sending 64 sample(s) to runner
2022-05-11 23:45:44.067 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 23:46:25.393 INFO Sending 64 sample(s) to builder
2022-05-11 23:46:44.243 INFO Sending 64 sample(s) to runner
2022-05-11 23:48:19.909 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2880 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2682 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13950
Total latency (us): 17679.1

2022-05-11 23:49:24.884 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2944 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2682 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14014
Total latency (us): 17679.1

2022-05-11 23:49:24.884 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 23:49:42.490 INFO Sending 64 sample(s) to builder
2022-05-11 23:49:56.174 INFO Sending 64 sample(s) to runner
2022-05-11 23:52:53.872 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   2944 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2746 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14078
Total latency (us): 17679.1

2022-05-11 23:52:53.872 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-11 23:53:11.923 INFO Sending 63 sample(s) to builder
2022-05-11 23:53:26.616 INFO Sending 63 sample(s) to runner
2022-05-11 23:53:27.062 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 23:54:10.204 INFO Sending 64 sample(s) to builder
2022-05-11 23:54:22.377 INFO Sending 64 sample(s) to runner
2022-05-11 23:57:17.381 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3008 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2746 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14142
Total latency (us): 17679.1

2022-05-11 23:57:17.381 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-11 23:57:57.540 INFO Sending 64 sample(s) to builder
2022-05-11 23:58:11.116 INFO Sending 64 sample(s) to runner
2022-05-11 23:59:27.957 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3008 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2809 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14205
Total latency (us): 17679.1

2022-05-11 23:59:27.957 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 00:00:14.100 INFO Sending 64 sample(s) to builder
2022-05-12 00:00:53.961 INFO Sending 64 sample(s) to runner
2022-05-12 00:02:13.934 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      2939.0634 |    1260.8774 |             1260.8774 |    960 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3072 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2809 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14269
Total latency (us): 17679.1

2022-05-12 00:03:33.586 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1024 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3072 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2809 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14333
Total latency (us): 17644.4

2022-05-12 00:03:33.586 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 00:04:11.255 INFO Sending 64 sample(s) to builder
2022-05-12 00:04:34.249 INFO Sending 64 sample(s) to runner
2022-05-12 00:04:34.376 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 00:04:50.726 INFO Sending 64 sample(s) to builder
2022-05-12 00:05:07.841 INFO Sending 64 sample(s) to runner
2022-05-12 00:05:53.286 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3072 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2809 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14397
Total latency (us): 17644.4

2022-05-12 00:08:06.382 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2880 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3072 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2873 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14461
Total latency (us): 17644.4

2022-05-12 00:08:06.383 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 00:08:20.712 INFO Sending 64 sample(s) to builder
2022-05-12 00:08:27.413 INFO Sending 64 sample(s) to runner
2022-05-12 00:08:27.486 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 00:09:08.031 INFO Sending 64 sample(s) to builder
2022-05-12 00:09:20.602 INFO Sending 64 sample(s) to runner
2022-05-12 00:11:52.531 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2944 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3072 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2873 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14525
Total latency (us): 17644.4

2022-05-12 00:11:52.531 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 00:12:30.831 INFO Sending 64 sample(s) to builder
2022-05-12 00:12:39.614 INFO Sending 64 sample(s) to runner
2022-05-12 00:13:26.170 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   2944 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3072 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2937 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14589
Total latency (us): 17644.4

2022-05-12 00:13:26.170 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 00:13:55.791 INFO Sending 64 sample(s) to builder
2022-05-12 00:13:59.951 INFO Sending 64 sample(s) to runner
2022-05-12 00:14:34.328 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   3008 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3072 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2937 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14653
Total latency (us): 17644.4

2022-05-12 00:15:21.504 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   3008 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3136 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2937 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14717
Total latency (us): 17644.4

2022-05-12 00:15:21.505 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-12 00:15:48.997 INFO Sending 64 sample(s) to builder
2022-05-12 00:16:00.409 INFO Sending 64 sample(s) to runner
2022-05-12 00:17:05.318 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   3008 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3136 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2937 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14781
Total latency (us): 17644.4

2022-05-12 00:17:05.318 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-12 00:17:39.877 INFO Sending 64 sample(s) to builder
2022-05-12 00:17:52.300 INFO Sending 64 sample(s) to runner
2022-05-12 00:17:52.376 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 00:18:23.775 INFO Sending 64 sample(s) to builder
2022-05-12 00:18:55.635 INFO Sending 64 sample(s) to runner
2022-05-12 00:20:00.605 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   3008 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3136 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2937 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14845
Total latency (us): 17644.4

2022-05-12 00:20:29.332 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   3008 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3200 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   2937 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14909
Total latency (us): 17644.4

2022-05-12 00:20:29.332 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 00:20:40.641 INFO Sending 64 sample(s) to builder
2022-05-12 00:20:49.899 INFO Sending 64 sample(s) to runner
2022-05-12 00:23:40.645 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2986.0039 |     619.9904 |              619.9904 |    512 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   3008 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3200 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3001 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14973
Total latency (us): 17644.4

2022-05-12 00:23:40.645 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 00:23:51.072 INFO Sending 63 sample(s) to builder
2022-05-12 00:23:59.402 INFO Sending 63 sample(s) to runner
2022-05-12 00:23:59.458 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-12 00:24:32.726 INFO Sending 64 sample(s) to builder
2022-05-12 00:24:47.475 INFO Sending 64 sample(s) to runner
2022-05-12 00:27:38.254 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2987.5706 |     619.6653 |              619.6653 |    576 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   3008 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3200 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3001 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15037
Total latency (us): 17644.1

2022-05-12 00:27:38.255 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-12 00:28:01.731 INFO Sending 64 sample(s) to builder
2022-05-12 00:28:08.193 INFO Sending 64 sample(s) to runner
2022-05-12 00:28:46.308 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2987.5706 |     619.6653 |              619.6653 |    576 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   3008 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3200 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3064 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15100
Total latency (us): 17644.1

2022-05-12 00:28:46.308 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 00:29:17.082 INFO Sending 64 sample(s) to builder
2022-05-12 00:29:25.796 INFO Sending 64 sample(s) to runner
2022-05-12 00:30:09.951 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   3008 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3200 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3064 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15164
Total latency (us): 17643.8

2022-05-12 00:30:57.525 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   3008 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3264 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3064 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15228
Total latency (us): 17643.8

2022-05-12 00:30:57.525 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 00:31:19.761 INFO Sending 64 sample(s) to builder
2022-05-12 00:31:31.234 INFO Sending 64 sample(s) to runner
2022-05-12 00:32:33.954 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.4504 |    1243.8392 |             3731.5175 |   3072 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3264 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3064 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15292
Total latency (us): 17643.8

2022-05-12 00:32:33.954 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 00:33:07.947 INFO Sending 64 sample(s) to builder
2022-05-12 00:33:19.337 INFO Sending 64 sample(s) to runner
2022-05-12 00:33:19.450 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 00:33:51.150 INFO Sending 64 sample(s) to builder
2022-05-12 00:34:05.178 INFO Sending 64 sample(s) to runner
2022-05-12 00:35:01.390 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3136 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3264 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3064 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15356
Total latency (us): 17643.5

2022-05-12 00:35:37.441 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3136 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3328 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3064 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15420
Total latency (us): 17643.5

2022-05-12 00:35:37.441 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 00:35:48.943 INFO Sending 64 sample(s) to builder
2022-05-12 00:35:55.229 INFO Sending 64 sample(s) to runner
2022-05-12 00:39:03.787 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3136 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3328 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3128 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15484
Total latency (us): 17643.5

2022-05-12 00:39:03.787 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 00:39:09.807 INFO Sending 64 sample(s) to builder
2022-05-12 00:39:13.232 INFO Sending 64 sample(s) to runner
2022-05-12 00:39:13.316 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 00:39:29.886 INFO Sending 64 sample(s) to builder
2022-05-12 00:39:39.889 INFO Sending 64 sample(s) to runner
2022-05-12 00:42:29.849 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3136 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3392 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3128 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15548
Total latency (us): 17643.5

2022-05-12 00:42:29.849 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 00:42:51.695 INFO Sending 64 sample(s) to builder
2022-05-12 00:42:57.360 INFO Sending 64 sample(s) to runner
2022-05-12 00:43:55.581 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3136 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3392 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15612
Total latency (us): 17643.5

2022-05-12 00:43:55.581 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 00:44:34.330 INFO Sending 64 sample(s) to builder
2022-05-12 00:44:54.371 INFO Sending 64 sample(s) to runner
2022-05-12 00:45:38.493 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1088 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3136 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3456 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15676
Total latency (us): 17643.5

2022-05-12 00:46:29.874 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1152 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3136 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3456 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15740
Total latency (us): 17643.5

2022-05-12 00:46:29.874 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 00:47:02.149 INFO Sending 64 sample(s) to builder
2022-05-12 00:47:11.554 INFO Sending 64 sample(s) to runner
2022-05-12 00:47:11.638 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-12 00:47:45.834 INFO Sending 64 sample(s) to builder
2022-05-12 00:47:54.652 INFO Sending 64 sample(s) to runner
2022-05-12 00:48:53.139 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3136 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3456 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1088 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15804
Total latency (us): 17643.5

2022-05-12 00:49:38.655 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3136 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3456 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15868
Total latency (us): 17643.5

2022-05-12 00:49:38.655 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 00:50:09.524 INFO Sending 64 sample(s) to builder
2022-05-12 00:50:19.358 INFO Sending 64 sample(s) to runner
2022-05-12 00:51:34.965 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3200 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3456 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15932
Total latency (us): 17643.5

2022-05-12 00:51:34.965 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 00:51:58.681 INFO Sending 64 sample(s) to builder
2022-05-12 00:52:12.225 INFO Sending 64 sample(s) to runner
2022-05-12 00:53:03.172 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3264 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3456 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15996
Total latency (us): 17643.5

2022-05-12 00:53:03.173 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 00:53:35.835 INFO Sending 64 sample(s) to builder
2022-05-12 00:53:45.321 INFO Sending 64 sample(s) to runner
2022-05-12 00:53:45.394 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 00:54:10.367 INFO Sending 64 sample(s) to builder
2022-05-12 00:54:20.213 INFO Sending 64 sample(s) to runner
2022-05-12 00:54:47.500 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3328 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3456 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16060
Total latency (us): 17643.5

2022-05-12 00:55:11.826 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3328 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3520 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3192 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16124
Total latency (us): 17643.5

2022-05-12 00:55:11.826 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 00:55:22.366 INFO Sending 64 sample(s) to builder
2022-05-12 00:55:27.787 INFO Sending 64 sample(s) to runner
2022-05-12 00:58:49.299 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3328 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3520 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3256 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16188
Total latency (us): 17643.5

2022-05-12 00:58:49.300 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 00:58:54.739 INFO Sending 64 sample(s) to builder
2022-05-12 00:59:01.323 INFO Sending 64 sample(s) to runner
2022-05-12 00:59:01.379 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-12 00:59:35.186 INFO Sending 64 sample(s) to builder
2022-05-12 00:59:48.757 INFO Sending 64 sample(s) to runner
2022-05-12 01:02:34.133 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3328 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3520 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3256 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16252
Total latency (us): 17643.5

2022-05-12 01:02:34.133 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-12 01:03:00.714 INFO Sending 64 sample(s) to builder
2022-05-12 01:03:24.779 INFO Sending 64 sample(s) to runner
2022-05-12 01:04:08.911 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3328 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3520 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16316
Total latency (us): 17643.5

2022-05-12 01:04:08.911 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 01:04:38.446 INFO Sending 64 sample(s) to builder
2022-05-12 01:04:46.678 INFO Sending 64 sample(s) to runner
2022-05-12 01:05:32.090 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3328 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3520 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16380
Total latency (us): 17643.5

2022-05-12 01:06:23.401 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3328 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3584 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16444
Total latency (us): 17643.5

2022-05-12 01:06:23.402 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 01:06:55.320 INFO Sending 64 sample(s) to builder
2022-05-12 01:07:05.830 INFO Sending 64 sample(s) to runner
2022-05-12 01:07:59.535 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3392 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3584 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16508
Total latency (us): 17643.5

2022-05-12 01:07:59.536 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 01:08:32.357 INFO Sending 64 sample(s) to builder
2022-05-12 01:08:41.517 INFO Sending 64 sample(s) to runner
2022-05-12 01:08:41.603 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-12 01:09:08.504 INFO Sending 64 sample(s) to builder
2022-05-12 01:09:13.208 INFO Sending 64 sample(s) to runner
2022-05-12 01:09:41.585 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3456 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3584 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1152 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16572
Total latency (us): 17643.5

2022-05-12 01:10:21.227 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3456 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3584 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16636
Total latency (us): 17643.5

2022-05-12 01:10:21.227 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 01:10:50.557 INFO Sending 64 sample(s) to builder
2022-05-12 01:10:58.981 INFO Sending 64 sample(s) to runner
2022-05-12 01:12:16.906 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3456 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3648 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3320 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16700
Total latency (us): 17643.5

2022-05-12 01:12:16.906 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 01:12:46.310 INFO Sending 64 sample(s) to builder
2022-05-12 01:12:55.847 INFO Sending 64 sample(s) to runner
2022-05-12 01:12:55.922 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 01:13:06.792 INFO Sending 63 sample(s) to builder
2022-05-12 01:13:12.286 INFO Sending 63 sample(s) to runner
2022-05-12 01:16:11.555 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3456 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3648 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3383 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16763
Total latency (us): 17643.5

2022-05-12 01:16:11.555 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 01:16:22.390 INFO Sending 63 sample(s) to builder
2022-05-12 01:16:27.305 INFO Sending 63 sample(s) to runner
2022-05-12 01:17:03.004 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3456 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3712 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3383 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16827
Total latency (us): 17643.5

2022-05-12 01:19:37.817 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      2990.0273 |     619.6931 |              619.6931 |    576 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3456 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3712 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3446 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16890
Total latency (us): 17643.5

2022-05-12 01:19:37.817 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 01:19:44.782 INFO Sending 64 sample(s) to builder
2022-05-12 01:19:49.075 INFO Sending 64 sample(s) to runner
2022-05-12 01:19:49.105 INFO Scheduler picks Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-12 01:20:19.998 INFO Sending 64 sample(s) to builder
2022-05-12 01:20:37.101 INFO Sending 64 sample(s) to runner
2022-05-12 01:22:59.140 INFO [Updated] Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3022.1365 |     613.1091 |              613.1091 |    640 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3456 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3712 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3446 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16954
Total latency (us): 17636.9

2022-05-12 01:22:59.141 INFO Scheduler picks Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-12 01:23:30.684 INFO Sending 64 sample(s) to builder
2022-05-12 01:23:56.266 INFO Sending 64 sample(s) to runner
2022-05-12 01:24:47.520 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3022.1365 |     613.1091 |              613.1091 |    640 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3456 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3712 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3510 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17018
Total latency (us): 17636.9

2022-05-12 01:24:47.521 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 01:25:06.106 INFO Sending 64 sample(s) to builder
2022-05-12 01:25:20.303 INFO Sending 64 sample(s) to runner
2022-05-12 01:26:00.691 INFO [Updated] Task #4: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2975.7419 |    1243.7173 |             3731.1520 |   3456 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3712 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3510 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17082
Total latency (us): 17632.2

2022-05-12 01:26:49.067 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3520 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3712 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3510 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17146
Total latency (us): 17626

2022-05-12 01:26:49.067 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 01:27:13.158 INFO Sending 64 sample(s) to builder
2022-05-12 01:27:17.228 INFO Sending 64 sample(s) to runner
2022-05-12 01:28:09.876 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3520 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3776 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3510 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17210
Total latency (us): 17626

2022-05-12 01:28:09.876 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 01:28:39.474 INFO Sending 64 sample(s) to builder
2022-05-12 01:28:48.879 INFO Sending 64 sample(s) to runner
2022-05-12 01:28:48.961 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 01:29:20.683 INFO Sending 64 sample(s) to builder
2022-05-12 01:29:29.137 INFO Sending 64 sample(s) to runner
2022-05-12 01:30:07.475 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3520 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3840 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3510 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17274
Total latency (us): 17626

2022-05-12 01:30:39.015 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3584 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3840 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3510 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       120.6507 |      67.9068 |               67.9068 |     64 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17338
Total latency (us): 17626

2022-05-12 01:30:39.015 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 01:31:11.908 INFO Sending 64 sample(s) to builder
2022-05-12 01:31:21.825 INFO Sending 64 sample(s) to runner
2022-05-12 01:31:21.907 INFO Scheduler picks Task #19: "fused_nn_dense_add"
2022-05-12 01:31:32.320 INFO Sending 64 sample(s) to builder
2022-05-12 01:31:40.352 INFO Sending 64 sample(s) to runner
2022-05-12 01:33:05.570 INFO [Updated] Task #19: "fused_nn_dense_add"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3584 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3840 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3510 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       132.6973 |      61.7420 |               61.7420 |    128 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17402
Total latency (us): 17619.8

2022-05-12 01:33:05.570 INFO Scheduler picks Task #19: "fused_nn_dense_add"
2022-05-12 01:33:15.965 INFO Sending 64 sample(s) to builder
2022-05-12 01:33:24.133 INFO Sending 64 sample(s) to runner
2022-05-12 01:34:03.303 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3648 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3840 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3510 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       132.6973 |      61.7420 |               61.7420 |    128 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17466
Total latency (us): 17619.8

2022-05-12 01:34:44.002 INFO [Updated] Task #19: "fused_nn_dense_add"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3648 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3840 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1216 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3510 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17530
Total latency (us): 17619.4

2022-05-12 01:34:44.002 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-12 01:35:09.617 INFO Sending 64 sample(s) to builder
2022-05-12 01:35:15.371 INFO Sending 64 sample(s) to runner
2022-05-12 01:36:14.314 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3648 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3840 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1280 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3510 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17594
Total latency (us): 17619.4

2022-05-12 01:36:14.314 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-12 01:36:44.017 INFO Sending 64 sample(s) to builder
2022-05-12 01:36:51.929 INFO Sending 64 sample(s) to runner
2022-05-12 01:36:51.972 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 01:37:00.495 INFO Sending 64 sample(s) to builder
2022-05-12 01:37:05.001 INFO Sending 64 sample(s) to runner
2022-05-12 01:40:12.798 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3648 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3840 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1280 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3574 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17658
Total latency (us): 17619.4

2022-05-12 01:40:12.798 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 01:40:20.931 INFO Sending 64 sample(s) to builder
2022-05-12 01:40:25.687 INFO Sending 64 sample(s) to runner
2022-05-12 01:41:17.057 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3648 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3840 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3574 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17722
Total latency (us): 17619.4

2022-05-12 01:41:17.057 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 01:41:34.412 INFO Sending 64 sample(s) to builder
2022-05-12 01:41:41.802 INFO Sending 64 sample(s) to runner
2022-05-12 01:43:58.023 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3648 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3904 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3574 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17786
Total latency (us): 17619.4

2022-05-12 01:43:58.023 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 01:44:27.302 INFO Sending 64 sample(s) to builder
2022-05-12 01:44:35.117 INFO Sending 64 sample(s) to runner
2022-05-12 01:45:09.379 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3648 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3904 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3638 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17850
Total latency (us): 17619.4

2022-05-12 01:45:09.380 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 01:45:42.587 INFO Sending 64 sample(s) to builder
2022-05-12 01:45:52.042 INFO Sending 64 sample(s) to runner
2022-05-12 01:46:40.401 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3648 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3968 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3638 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17914
Total latency (us): 17619.4

2022-05-12 01:47:19.383 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3712 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3968 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3638 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17978
Total latency (us): 17619.4

2022-05-12 01:47:19.383 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 01:47:46.071 INFO Sending 64 sample(s) to builder
2022-05-12 01:47:55.323 INFO Sending 64 sample(s) to runner
2022-05-12 01:47:55.399 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-12 01:48:25.746 INFO Sending 64 sample(s) to builder
2022-05-12 01:48:34.603 INFO Sending 64 sample(s) to runner
2022-05-12 01:49:23.621 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3776 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2872.4326 |     644.2243 |              644.2243 |    640 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3968 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3638 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18042
Total latency (us): 17619.4

2022-05-12 01:50:20.390 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3015.0968 |    1228.0161 |             1228.0161 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3776 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3968 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3638 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18106
Total latency (us): 17617.4

2022-05-12 01:50:20.390 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-12 01:50:50.800 INFO Sending 64 sample(s) to builder
2022-05-12 01:51:10.000 INFO Sending 64 sample(s) to runner
2022-05-12 01:52:10.802 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3041.0150 |    1217.5498 |             1217.5498 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3776 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3968 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3638 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18170
Total latency (us): 17606.9

2022-05-12 01:52:10.802 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-12 01:52:40.212 INFO Sending 64 sample(s) to builder
2022-05-12 01:52:52.153 INFO Sending 64 sample(s) to runner
2022-05-12 01:52:52.199 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 01:53:11.100 INFO Sending 64 sample(s) to builder
2022-05-12 01:53:19.008 INFO Sending 64 sample(s) to runner
2022-05-12 01:54:00.341 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1216 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3776 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3968 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3638 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18234
Total latency (us): 17601.2

2022-05-12 01:54:42.337 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1280 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3776 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3968 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3638 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18298
Total latency (us): 17601.2

2022-05-12 01:54:42.337 INFO Scheduler picks Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 01:55:05.358 INFO Sending 64 sample(s) to builder
2022-05-12 01:55:12.388 INFO Sending 64 sample(s) to runner
2022-05-12 01:55:12.431 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 01:55:17.705 INFO Sending 64 sample(s) to builder
2022-05-12 01:55:21.016 INFO Sending 64 sample(s) to runner
2022-05-12 01:58:52.175 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1280 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3776 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3968 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3702 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18362
Total latency (us): 17601.2

2022-05-12 01:58:52.175 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 01:58:58.046 INFO Sending 64 sample(s) to builder
2022-05-12 01:59:02.331 INFO Sending 64 sample(s) to runner
2022-05-12 01:59:41.937 INFO [Updated] Task #2: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3776 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   3968 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3702 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18426
Total latency (us): 17601.2

2022-05-12 01:59:41.938 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 02:00:10.231 INFO Sending 64 sample(s) to builder
2022-05-12 02:00:18.236 INFO Sending 64 sample(s) to runner
2022-05-12 02:02:16.630 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3776 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4032 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3702 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18490
Total latency (us): 17601.2

2022-05-12 02:02:16.630 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 02:02:46.134 INFO Sending 64 sample(s) to builder
2022-05-12 02:02:55.959 INFO Sending 64 sample(s) to runner
2022-05-12 02:03:35.460 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3776 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4032 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3766 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18554
Total latency (us): 17601.2

2022-05-12 02:03:35.461 INFO Scheduler picks Task #17: "fused_nn_dense_add_nn_relu_1"
2022-05-12 02:03:46.775 INFO Sending 64 sample(s) to builder
2022-05-12 02:03:52.824 INFO Sending 64 sample(s) to runner
2022-05-12 02:04:55.976 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3776 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4096 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3766 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    448 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18618
Total latency (us): 17601.2

2022-05-12 02:05:50.445 INFO [Updated] Task #17: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3776 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4096 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3766 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18682
Total latency (us): 17601.2

2022-05-12 02:05:50.445 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 02:06:23.561 INFO Sending 64 sample(s) to builder
2022-05-12 02:06:33.295 INFO Sending 64 sample(s) to runner
2022-05-12 02:07:32.229 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3840 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4096 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3766 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18746
Total latency (us): 17601.2

2022-05-12 02:07:32.229 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 02:08:05.015 INFO Sending 64 sample(s) to builder
2022-05-12 02:08:15.755 INFO Sending 64 sample(s) to runner
2022-05-12 02:08:15.835 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 02:08:24.723 INFO Sending 64 sample(s) to builder
2022-05-12 02:08:29.478 INFO Sending 64 sample(s) to runner
2022-05-12 02:11:29.382 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2980.6830 |    1241.6556 |             3724.9668 |   3840 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4096 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3830 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18810
Total latency (us): 17601.2

2022-05-12 02:11:29.382 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 02:11:40.744 INFO Sending 64 sample(s) to builder
2022-05-12 02:11:45.766 INFO Sending 64 sample(s) to runner
2022-05-12 02:12:41.321 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   3904 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4096 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3830 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18874
Total latency (us): 17600.7

2022-05-12 02:12:41.321 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 02:12:57.704 INFO Sending 64 sample(s) to builder
2022-05-12 02:13:07.480 INFO Sending 64 sample(s) to runner
2022-05-12 02:15:02.013 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   3904 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4160 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3830 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18938
Total latency (us): 17600.7

2022-05-12 02:15:02.015 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 02:15:31.291 INFO Sending 64 sample(s) to builder
2022-05-12 02:15:45.320 INFO Sending 64 sample(s) to runner
2022-05-12 02:16:31.241 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   3904 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4160 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3894 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19002
Total latency (us): 17600.7

2022-05-12 02:16:31.241 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-12 02:17:03.432 INFO Sending 64 sample(s) to builder
2022-05-12 02:17:15.495 INFO Sending 64 sample(s) to runner
2022-05-12 02:18:28.141 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    640 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   3904 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4224 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3894 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19066
Total latency (us): 17600.7

2022-05-12 02:19:13.750 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      2988.9008 |     619.3895 |              619.3895 |    704 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   3904 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4224 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3894 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19130
Total latency (us): 17600.7

2022-05-12 02:19:13.750 INFO Scheduler picks Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-12 02:19:45.790 INFO Sending 64 sample(s) to builder
2022-05-12 02:19:57.566 INFO Sending 64 sample(s) to runner
2022-05-12 02:19:57.647 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
2022-05-12 02:20:27.156 INFO Sending 64 sample(s) to builder
2022-05-12 02:20:33.714 INFO Sending 64 sample(s) to runner
2022-05-12 02:21:15.288 INFO [Updated] Task #7: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   3904 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4224 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1344 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3894 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19194
Total latency (us): 17594.8

2022-05-12 02:22:09.060 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   3904 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4224 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3894 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19258
Total latency (us): 17594.8

2022-05-12 02:22:09.060 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 02:22:27.517 INFO Sending 64 sample(s) to builder
2022-05-12 02:22:32.942 INFO Sending 64 sample(s) to runner
2022-05-12 02:23:42.662 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   3968 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4224 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3894 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19322
Total latency (us): 17594.8

2022-05-12 02:23:42.662 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 02:24:08.124 INFO Sending 64 sample(s) to builder
2022-05-12 02:24:14.734 INFO Sending 64 sample(s) to runner
2022-05-12 02:24:14.777 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 02:24:20.054 INFO Sending 64 sample(s) to builder
2022-05-12 02:24:24.205 INFO Sending 64 sample(s) to runner
2022-05-12 02:27:42.495 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   3968 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4224 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3958 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19386
Total latency (us): 17594.8

2022-05-12 02:27:42.495 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu"
2022-05-12 02:27:47.799 INFO Sending 63 sample(s) to builder
2022-05-12 02:27:52.341 INFO Sending 63 sample(s) to runner
2022-05-12 02:28:16.096 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   4032 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4224 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3958 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19450
Total latency (us): 17594.8

2022-05-12 02:28:16.096 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 02:28:45.433 INFO Sending 64 sample(s) to builder
2022-05-12 02:28:53.130 INFO Sending 64 sample(s) to runner
2022-05-12 02:31:17.602 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   4032 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4288 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   3958 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19514
Total latency (us): 17594.8

2022-05-12 02:31:17.602 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 02:31:34.169 INFO Sending 64 sample(s) to builder
2022-05-12 02:31:37.641 INFO Sending 64 sample(s) to runner
2022-05-12 02:32:19.064 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   4032 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4288 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   4021 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19577
Total latency (us): 17594.8

2022-05-12 02:33:08.501 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   4032 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4352 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   4021 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19641
Total latency (us): 17594.8

2022-05-12 02:33:08.501 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
2022-05-12 02:33:29.018 INFO Sending 64 sample(s) to builder
2022-05-12 02:33:36.229 INFO Sending 64 sample(s) to runner
2022-05-12 02:33:36.272 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-12 02:33:57.147 INFO Sending 64 sample(s) to builder
2022-05-12 02:34:01.848 INFO Sending 64 sample(s) to runner
2022-05-12 02:34:29.164 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   4032 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2881.5634 |     642.1830 |              642.1830 |    704 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4416 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   4021 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19705
Total latency (us): 17594.8

2022-05-12 02:35:15.958 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   4032 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2926.1599 |     632.3957 |              632.3957 |    768 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4416 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   4021 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19769
Total latency (us): 17585

2022-05-12 02:35:15.958 INFO Scheduler picks Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-12 02:35:45.027 INFO Sending 64 sample(s) to builder
2022-05-12 02:36:00.838 INFO Sending 64 sample(s) to runner
2022-05-12 02:36:00.915 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 02:36:34.221 INFO Sending 64 sample(s) to builder
2022-05-12 02:36:49.519 INFO Sending 64 sample(s) to runner
2022-05-12 02:37:30.202 INFO [Updated] Task #10: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   4032 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2926.1599 |     632.3957 |              632.3957 |    832 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4416 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   4021 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19833
Total latency (us): 17585

2022-05-12 02:38:10.931 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |            
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |            
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |            
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |            
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   4096 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2926.1599 |     632.3957 |              632.3957 |    832 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4416 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   4021 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19897
Total latency (us): 17585

2022-05-12 02:38:10.931 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-12 02:38:37.593 INFO Sending 64 sample(s) to builder
2022-05-12 02:38:48.342 INFO Sending 64 sample(s) to runner
2022-05-12 02:38:48.386 INFO Scheduler picks Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-12 02:39:15.410 INFO Sending 64 sample(s) to builder
2022-05-12 02:39:26.273 INFO Sending 64 sample(s) to runner
2022-05-12 02:39:26.349 INFO Task #0 has finished. Remaining task(s): 19
2022-05-12 02:39:26.349 INFO Task #1 has finished. Remaining task(s): 18
2022-05-12 02:39:26.349 INFO Task #2 has finished. Remaining task(s): 17
2022-05-12 02:39:26.349 INFO Task #3 has finished. Remaining task(s): 16
2022-05-12 02:39:26.349 INFO Task #4 has finished. Remaining task(s): 15
2022-05-12 02:40:19.181 INFO [Updated] Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |          Y 
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |          Y 
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |          Y 
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |          Y 
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |          Y 
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |            
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |            
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   4096 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2926.1599 |     632.3957 |              632.3957 |    832 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4416 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   4021 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19961
Total latency (us): 17585

2022-05-12 02:40:19.181 INFO Task #5 has finished. Remaining task(s): 14
2022-05-12 02:40:19.181 INFO Task #6 has finished. Remaining task(s): 13
2022-05-12 02:40:19.181 INFO Task #7 has finished. Remaining task(s): 12
2022-05-12 02:40:43.831 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                        Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |          1 |      1 |         0.0003 |       3.0763 |                3.0763 |      8 |          Y 
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu |  179830784 |      1 |      2147.0218 |      83.7582 |               83.7582 |    192 |          Y 
  2 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 3705798656 |      1 |      3022.1293 |    1226.2211 |             1226.2211 |   1344 |          Y 
  3 |                         fused_nn_max_pool2d |    3211264 |      1 |       182.3546 |      17.6100 |               17.6100 |      8 |          Y 
  4 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 1852899328 |      1 |      3045.6745 |     608.3708 |              608.3708 |    704 |          Y 
  5 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 3702587392 |      1 |      3055.3238 |    1211.8478 |             1211.8478 |   1408 |          Y 
  6 |                       fused_nn_max_pool2d_1 |    1605632 |      1 |       255.4115 |       6.2865 |                6.2865 |      8 |          Y 
  7 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 1851293696 |      1 |      3017.8352 |     613.4509 |              613.4509 |    768 |          Y 
  8 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 3700981760 |      3 |      2981.1105 |    1241.4776 |             3724.4327 |   4160 |            
  9 |                       fused_nn_max_pool2d_2 |     802816 |      1 |       184.0718 |       4.3614 |                4.3614 |      8 |            
 10 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 | 1850490880 |      1 |      2926.1599 |     632.3957 |              632.3957 |    832 |            
 11 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7 | 3700178944 |      3 |      2794.8251 |    1323.9394 |             3971.8181 |   4416 |            
 12 |                       fused_nn_max_pool2d_3 |     401408 |      1 |       125.7816 |       3.1913 |                3.1913 |      8 |            
 13 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8 |  925044736 |      4 |      2869.3751 |     322.3854 |             1289.5418 |   1408 |            
 14 |                       fused_nn_max_pool2d_4 |     100352 |      1 |        35.6605 |       2.8141 |                2.8141 |     12 |            
 15 |     fused_layout_transform_nn_batch_flatten |          1 |      1 |         0.0003 |       3.1604 |                3.1604 |     12 |            
 16 |                  fused_nn_dense_add_nn_relu |  205529088 |      1 |        55.9721 |    3671.9920 |             3671.9920 |   4021 |            
 17 |                fused_nn_dense_add_nn_relu_1 |   33562624 |      1 |        75.6163 |     443.8541 |              443.8541 |    512 |            
 18 |                      fused_nn_batch_flatten |          1 |      2 |         0.0004 |       2.7080 |                5.4160 |      4 |            
 19 |                          fused_nn_dense_add |    8193000 |      1 |       133.4794 |      61.3803 |               61.3803 |    192 |            
------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 20025
Total latency (us): 17585

2022-05-12 02:40:43.831 INFO Task #8 has finished. Remaining task(s): 11
2022-05-12 02:40:43.831 INFO Task #9 has finished. Remaining task(s): 10
2022-05-12 02:40:43.831 INFO Task #10 has finished. Remaining task(s): 9
2022-05-12 02:40:43.831 INFO Task #11 has finished. Remaining task(s): 8
2022-05-12 02:40:43.831 INFO Task #12 has finished. Remaining task(s): 7
2022-05-12 02:40:43.831 INFO Task #13 has finished. Remaining task(s): 6
2022-05-12 02:40:43.832 INFO Task #14 has finished. Remaining task(s): 5
2022-05-12 02:40:43.832 INFO Task #15 has finished. Remaining task(s): 4
2022-05-12 02:40:43.832 INFO Task #16 has finished. Remaining task(s): 3
2022-05-12 02:40:43.832 INFO Task #17 has finished. Remaining task(s): 2
2022-05-12 02:40:43.832 INFO Task #18 has finished. Remaining task(s): 1
2022-05-12 02:40:43.832 INFO Task #19 has finished. Remaining task(s): 0
2022-05-12 02:40:44.526 INFO Saved XGBModel to /home/ubuntu/tvm/logs/perf/llvm/vgg19//ms_vgg19_2022-05-11_16:49:34/cost_model.xgb
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 3, 224, 224), "float32"], T_layout_trans: T.Buffer[(1, 1, 224, 224, 3), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4 in T.grid(1, 1, 224, 224, 3):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[0, ax4, ax2, ax3])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                T_layout_trans[ax0, ax1, ax2, ax3, ax4] = placeholder[0, ax4, ax2, ax3]
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_layout_transform(placeholder: T.Buffer[(1, 3, 224, 224), "float32"], T_layout_trans: T.Buffer[(1, 1, 224, 224, 3), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(224, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3, i4 in T.grid(224, 3):
                with T.block("T_layout_trans"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(1, 0)
                    ax2, ax3, ax4 = T.axis.remap("SSS", [i0_i1_i2_fused, i3, i4])
                    T.reads(placeholder[0, ax4, ax2, ax3])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                    T_layout_trans[ax0, ax1, ax2, ax3, ax4] = placeholder[0, ax4, ax2, ax3]
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7, l8 = sch.get_loops(block=b3)", "l9 = sch.fuse(l4, l5, l6)", "sch.parallel(loop=l9)", "sch.annotate(block_or_loop=l9, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l9, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
2022-05-12 02:40:50.056 WARNING Cannot find workload: tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu
2022-05-12 02:40:50.076 WARNING Cannot find workload: tvmgen_default_fused_layout_transform_1
2022-05-12 02:40:50.115 WARNING Cannot find workload: tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1
2022-05-12 02:40:50.139 WARNING Cannot find workload: tvmgen_default_fused_nn_max_pool2d
2022-05-12 02:40:50.178 WARNING Cannot find workload: tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2
2022-05-12 02:40:50.226 WARNING Cannot find workload: tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3
2022-05-12 02:40:50.248 WARNING Cannot find workload: tvmgen_default_fused_nn_max_pool2d_1
2022-05-12 02:40:50.260 WARNING Cannot find workload: tvmgen_default_fused_layout_transform_2
2022-05-12 02:40:50.299 WARNING Cannot find workload: tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4
2022-05-12 02:40:50.323 WARNING Cannot find workload: tvmgen_default_fused_layout_transform_3
2022-05-12 02:40:50.362 WARNING Cannot find workload: tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5
2022-05-12 02:40:50.385 WARNING Cannot find workload: tvmgen_default_fused_nn_max_pool2d_2
2022-05-12 02:40:50.397 WARNING Cannot find workload: tvmgen_default_fused_layout_transform_4
2022-05-12 02:40:50.435 WARNING Cannot find workload: tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6
2022-05-12 02:40:50.457 WARNING Cannot find workload: tvmgen_default_fused_layout_transform_5
2022-05-12 02:40:50.496 WARNING Cannot find workload: tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_7
2022-05-12 02:40:50.525 WARNING Cannot find workload: tvmgen_default_fused_layout_transform_6
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 28, 28, 16), "float32"], tensor: T.Buffer[(1, 32, 14, 14, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 32, 14, 14, 16, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_max_pool2d_3(placeholder: T.Buffer[(1, 32, 28, 28, 16), "float32"], tensor: T.Buffer[(1, 32, 14, 14, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(448, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i3, i4 in T.grid(14, 16):
                with T.block("tensor_init"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(32, i0_i1_i2_fused // 14)
                    ax2 = T.axis.spatial(14, i0_i1_i2_fused % 14)
                    ax3, ax4 = T.axis.remap("SS", [i3, i4])
                    T.reads()
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                for i5, i6 in T.grid(2, 2):
                    with T.block("tensor_update"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(32, i0_i1_i2_fused // 14)
                        ax2 = T.axis.spatial(14, i0_i1_i2_fused % 14)
                        ax3, ax4, rv0, rv1 = T.axis.remap("SSRR", [i3, i4, i5, i6])
                        T.reads(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                        T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b3)", "l11 = sch.fuse(l4, l5, l6)", "sch.parallel(loop=l11)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b12 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l13, l14, l15, l16, l17 = sch.get_loops(block=b12)", "b18 = sch.decompose_reduction(block=b12, loop=l16)"]
2022-05-12 02:40:50.550 WARNING Cannot find workload: tvmgen_default_fused_layout_transform_7
2022-05-12 02:40:50.588 WARNING Cannot find workload: tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_8
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 14, 14, 16), "float32"], tensor: T.Buffer[(1, 32, 7, 7, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 32, 7, 7, 16, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_max_pool2d_4(placeholder: T.Buffer[(1, 32, 14, 14, 16), "float32"], tensor: T.Buffer[(1, 32, 7, 7, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(32, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i2, i3, i4 in T.grid(7, 7, 16):
                with T.block("tensor_init"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1, ax2, ax3, ax4 = T.axis.remap("SSSS", [i0_i1_fused, i2, i3, i4])
                    T.reads()
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                for i5, i6 in T.grid(2, 2):
                    with T.block("tensor_update"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSRR", [i0_i1_fused, i2, i3, i4, i5, i6])
                        T.reads(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                        T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b3)", "l11 = sch.fuse(l4, l5)", "sch.parallel(loop=l11)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b12 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l13, l14, l15, l16, l17, l18 = sch.get_loops(block=b12)", "b19 = sch.decompose_reduction(block=b12, loop=l17)"]
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 32, 7, 7, 16), "float32"], tensor: T.Buffer[(1, 25088), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_layout_trans = T.alloc_buffer([1, 512, 7, 7], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 512, 7, 7):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, ax1 // 16, ax2, ax3, ax1 % 16])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                T_layout_trans[ax0, ax1, ax2, ax3] = placeholder[0, ax1 // 16, ax2, ax3, ax1 % 16]
        for i0, i1 in T.grid(1, 25088):
            with T.block("tensor"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_layout_trans[0, ax1 // 49, ax1 % 49 // 7, ax1 % 7])
                T.writes(tensor[ax0, ax1])
                tensor[ax0, ax1] = T_layout_trans[0, ax1 // 49, ax1 % 49 // 7, ax1 % 7]
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_layout_transform_nn_batch_flatten(placeholder: T.Buffer[(1, 32, 7, 7, 16), "float32"], tensor: T.Buffer[(1, 25088), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_layout_trans = T.alloc_buffer([1, 512, 7, 7], dtype="float32")
        for i0_i1_fused in T.parallel(25088, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 1):
                with T.block("T_layout_trans"):
                    ax0_1 = T.axis.spatial(1, 0)
                    ax1_1 = T.axis.spatial(512, i0_i1_fused // 49)
                    ax2_1 = T.axis.spatial(7, i0_i1_fused % 49 // 7)
                    ax3_1 = T.axis.spatial(7, i0_i1_fused % 7)
                    T.reads(placeholder[0, ax1_1 // 16, ax2_1, ax3_1, ax1_1 % 16])
                    T.writes(T_layout_trans[ax0_1, ax1_1, ax2_1, ax3_1])
                    T_layout_trans[ax0_1, ax1_1, ax2_1, ax3_1] = placeholder[0, ax1_1 // 16, ax2_1, ax3_1, ax1_1 % 16]
            with T.block("tensor"):
                ax0 = T.axis.spatial(1, 0)
                ax1 = T.axis.spatial(25088, i0_i1_fused)
                T.reads(T_layout_trans[0, ax1 // 49, ax1 % 49 // 7, ax1 % 7])
                T.writes(tensor[ax0, ax1])
                tensor[ax0, ax1] = T_layout_trans[0, ax1 // 49, ax1 % 49 // 7, ax1 % 7]
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_layout_trans\", func_name=\"main\")", "b1 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v2 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v2)", "l3 = sch.sample_compute_location(block=b0, decision=1)", "sch.compute_at(block=b0, loop=l3, preserve_unit_loops=True)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, b6 = sch.get_child_blocks(b4)", "l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b5)", "l13 = sch.fuse(l7, l8)", "sch.parallel(loop=l13)", "sch.annotate(block_or_loop=l13, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l13, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l14, = sch.get_loops(block=b6)", "sch.annotate(block_or_loop=l14, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l14, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 25088), "float32"], placeholder_1: T.Buffer[(4096, 25088), "float32"], placeholder_2: T.Buffer[(1, 4096), "float32"], T_relu: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 4096], dtype="float32")
        T_add = T.alloc_buffer([1, 4096], dtype="float32")
        for i0, i1, i2 in T.grid(1, 4096, 25088):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[0, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
        for i0, i1 in T.grid(1, 4096):
            with T.block("T_add"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                T.writes(T_add[ax0, ax1])
                T_add[ax0, ax1] = T_matmul_NT[0, ax1] + placeholder_2[0, ax1]
        for i0, i1 in T.grid(1, 4096):
            with T.block("T_relu"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_add[0, ax1])
                T.writes(T_relu[ax0, ax1])
                T_relu[ax0, ax1] = T.max(T_add[0, ax1], T.float32(0))
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_dense_add_nn_relu(placeholder: T.Buffer[(1, 25088), "float32"], placeholder_1: T.Buffer[(4096, 25088), "float32"], placeholder_2: T.Buffer[(1, 4096), "float32"], T_relu: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 4096], dtype="float32")
        for i0_0_i1_0_fused in T.parallel(64, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1 in T.grid(1, 16):
                for i1_2_init, i1_3_init in T.grid(2, 2):
                    with T.block("T_matmul_NT_init"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(4096, i0_0_i1_0_fused * 64 + i1_1 * 4 + i1_2_init * 2 + i1_3_init)
                        T.reads()
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T.float32(0)
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(3584, 1, 2, 7, 1, 2):
                    with T.block("T_matmul_NT_update"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(4096, i0_0_i1_0_fused * 64 + i1_1 * 4 + i1_2 * 2 + i1_3)
                        k = T.axis.reduce(25088, i2_0 * 7 + i2_1)
                        T.reads(T_matmul_NT[i, j], placeholder[0, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
                for ax0_ax1_fused in T.vectorized(4):
                    with T.block("T_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(4096, i0_0_i1_0_fused * 64 + i1_1 * 4 + ax0_ax1_fused)
                        T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                        T.writes(T_relu[ax0, ax1])
                        T_relu[ax0, ax1] = T.max(T_matmul_NT[0, ax1] + placeholder_2[0, ax1], T.float32(0))
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5 = sch.get_loops(block=b0)", "v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l10, l11, l12, l13 = sch.split(loop=l3, factors=[v6, v7, v8, v9])", "v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[64, 16, 2, 2])", "l18, l19, l20, l21 = sch.split(loop=l4, factors=[v14, v15, v16, v17])", "v22, v23 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[3584, 7])", "l24, l25 = sch.split(loop=l5, factors=[v22, v23])", "sch.reorder(l10, l18, l11, l19, l24, l12, l20, l25, l13, l21)", "b26, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b26, loop=l19, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v27 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v27)", "sch.enter_postproc()", "b28 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.unroll_explicit\")", "b29, b30 = sch.get_child_blocks(b28)", "l31, l32, l33, l34, l35, l36, l37, l38, l39, l40 = sch.get_loops(block=b29)", "l41 = sch.fuse(l31, l32)", "sch.parallel(loop=l41)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l42, l43, l44, l45, l46 = sch.get_loops(block=b30)", "l47 = sch.fuse(l45, l46)", "sch.vectorize(loop=l47)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b48 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "l49, l50, l51, l52, l53, l54, l55, l56, l57 = sch.get_loops(block=b48)", "b58 = sch.decompose_reduction(block=b48, loop=l52)"]
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4096), "float32"], tensor: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1 in T.grid(1, 4096):
            with T.block("tensor"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(placeholder[0, ax1])
                T.writes(tensor[ax0, ax1])
                tensor[ax0, ax1] = placeholder[0, ax1]
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_batch_flatten(placeholder: T.Buffer[(1, 4096), "float32"], tensor: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(4096):
            with T.block("tensor"):
                ax0 = T.axis.spatial(1, 0)
                ax1 = T.axis.spatial(4096, i0_i1_fused)
                T.reads(placeholder[0, ax1])
                T.writes(tensor[ax0, ax1])
                tensor[ax0, ax1] = placeholder[0, ax1]
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5 = sch.get_loops(block=b3)", "l6 = sch.fuse(l4, l5)", "sch.parallel(loop=l6)"]
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4096), "float32"], placeholder_1: T.Buffer[(4096, 4096), "float32"], placeholder_2: T.Buffer[(1, 4096), "float32"], T_relu: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 4096], dtype="float32")
        T_add = T.alloc_buffer([1, 4096], dtype="float32")
        for i0, i1, i2 in T.grid(1, 4096, 4096):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[0, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
        for i0, i1 in T.grid(1, 4096):
            with T.block("T_add"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                T.writes(T_add[ax0, ax1])
                T_add[ax0, ax1] = T_matmul_NT[0, ax1] + placeholder_2[0, ax1]
        for i0, i1 in T.grid(1, 4096):
            with T.block("T_relu"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_add[0, ax1])
                T.writes(T_relu[ax0, ax1])
                T_relu[ax0, ax1] = T.max(T_add[0, ax1], T.float32(0))
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_dense_add_nn_relu_1(placeholder: T.Buffer[(1, 4096), "float32"], placeholder_1: T.Buffer[(4096, 4096), "float32"], placeholder_2: T.Buffer[(1, 4096), "float32"], T_relu: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 4096], dtype="float32")
        for i0_0_i1_0_i0_1_i1_1_fused in T.parallel(1024, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_2_init in T.serial(4):
                with T.block("T_matmul_NT_init"):
                    i = T.axis.spatial(1, 0)
                    j = T.axis.spatial(4096, i0_0_i1_0_i0_1_i1_1_fused // 64 * 256 + i0_0_i1_0_i0_1_i1_1_fused % 64 * 4 + i1_2_init)
                    T.reads()
                    T.writes(T_matmul_NT[i, j])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                    T_matmul_NT[i, j] = T.float32(0)
            for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(4096, 1, 4, 1, 1, 1):
                with T.block("T_matmul_NT_update"):
                    i = T.axis.spatial(1, 0)
                    j = T.axis.spatial(4096, i0_0_i1_0_i0_1_i1_1_fused // 64 * 256 + i0_0_i1_0_i0_1_i1_1_fused % 64 * 4 + i1_2)
                    k = T.axis.reduce(4096, i2_0)
                    T.reads(T_matmul_NT[i, j], placeholder[0, k], placeholder_1[j, k])
                    T.writes(T_matmul_NT[i, j])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                    T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
            for ax0_ax1_fused in T.vectorized(4):
                with T.block("T_relu"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(4096, i0_0_i1_0_i0_1_i1_1_fused // 64 * 256 + i0_0_i1_0_i0_1_i1_1_fused % 64 * 4 + ax0_ax1_fused)
                    T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                    T.writes(T_relu[ax0, ax1])
                    T_relu[ax0, ax1] = T.max(T_matmul_NT[0, ax1] + placeholder_2[0, ax1], T.float32(0))
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5 = sch.get_loops(block=b0)", "v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l10, l11, l12, l13 = sch.split(loop=l3, factors=[v6, v7, v8, v9])", "v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[16, 64, 4, 1])", "l18, l19, l20, l21 = sch.split(loop=l4, factors=[v14, v15, v16, v17])", "v22, v23 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[4096, 1])", "l24, l25 = sch.split(loop=l5, factors=[v22, v23])", "sch.reorder(l10, l18, l11, l19, l24, l12, l20, l25, l13, l21)", "b26, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b26, loop=l19, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v27 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v27)", "sch.enter_postproc()", "b28 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.unroll_explicit\")", "b29, b30 = sch.get_child_blocks(b28)", "l31, l32, l33, l34, l35, l36, l37, l38, l39, l40 = sch.get_loops(block=b29)", "l41 = sch.fuse(l31, l32, l33, l34)", "sch.parallel(loop=l41)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l42, l43, l44 = sch.get_loops(block=b30)", "l45 = sch.fuse(l43, l44)", "sch.vectorize(loop=l45)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b46 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "l47, l48, l49, l50, l51, l52, l53 = sch.get_loops(block=b46)", "b54 = sch.decompose_reduction(block=b46, loop=l48)"]
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4096), "float32"], placeholder_1: T.Buffer[(1000, 4096), "float32"], placeholder_2: T.Buffer[(1, 1000), "float32"], T_add: T.Buffer[(1, 1000), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 1000], dtype="float32")
        for i0, i1, i2 in T.grid(1, 1000, 4096):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[0, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
        for i0, i1 in T.grid(1, 1000):
            with T.block("T_add"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                T.writes(T_add[ax0, ax1])
                T_add[ax0, ax1] = T_matmul_NT[0, ax1] + placeholder_2[0, ax1]
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_dense_add(placeholder: T.Buffer[(1, 4096), "float32"], placeholder_1: T.Buffer[(1000, 4096), "float32"], placeholder_2: T.Buffer[(1, 1000), "float32"], T_add: T.Buffer[(1, 1000), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 1000], dtype="float32")
        for i0_0_i1_0_i0_1_i1_1_fused in T.parallel(125, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_3_init in T.serial(8):
                with T.block("T_matmul_NT_init"):
                    i = T.axis.spatial(1, 0)
                    j = T.axis.spatial(1000, i0_0_i1_0_i0_1_i1_1_fused // 25 * 200 + i0_0_i1_0_i0_1_i1_1_fused % 25 * 8 + i1_3_init)
                    T.reads()
                    T.writes(T_matmul_NT[i, j])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                    T_matmul_NT[i, j] = T.float32(0)
            for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(128, 1, 1, 32, 1, 8):
                with T.block("T_matmul_NT_update"):
                    i = T.axis.spatial(1, 0)
                    j = T.axis.spatial(1000, i0_0_i1_0_i0_1_i1_1_fused // 25 * 200 + i0_0_i1_0_i0_1_i1_1_fused % 25 * 8 + i1_3)
                    k = T.axis.reduce(4096, i2_0 * 32 + i2_1)
                    T.reads(T_matmul_NT[i, j], placeholder[0, k], placeholder_1[j, k])
                    T.writes(T_matmul_NT[i, j])
                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                    T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
            for ax0_ax1_fused in T.vectorized(8):
                with T.block("T_add"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(1000, i0_0_i1_0_i0_1_i1_1_fused // 25 * 200 + i0_0_i1_0_i0_1_i1_1_fused % 25 * 8 + ax0_ax1_fused)
                    T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                    T.writes(T_add[ax0, ax1])
                    T_add[ax0, ax1] = T_matmul_NT[0, ax1] + placeholder_2[0, ax1]
    

[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[02:40:50] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "b1 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l2, l3, l4 = sch.get_loops(block=b0)", "v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])", "v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[5, 25, 1, 8])", "l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])", "v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[128, 32])", "l23, l24 = sch.split(loop=l4, factors=[v21, v22])", "sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)", "b25, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b25, loop=l18, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v26)", "sch.enter_postproc()", "b27 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.unroll_explicit\")", "b28, b29 = sch.get_child_blocks(b27)", "l30, l31, l32, l33, l34, l35, l36, l37, l38, l39 = sch.get_loops(block=b28)", "l40 = sch.fuse(l30, l31, l32, l33)", "sch.parallel(loop=l40)", "sch.annotate(block_or_loop=l40, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l40, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l41, l42, l43 = sch.get_loops(block=b29)", "l44 = sch.fuse(l42, l43)", "sch.vectorize(loop=l44)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b45 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "l46, l47, l48, l49, l50, l51, l52 = sch.get_loops(block=b45)", "b53 = sch.decompose_reduction(block=b45, loop=l47)"]
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ubuntu/anaconda3/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/tune_relay_meta_schedule.py", line 198, in <module>
    main()
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/tune_relay_meta_schedule.py", line 188, in main
    run_module_via_rpc(
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/custom_builder_runner.py", line 170, in run_module_via_rpc
    return continuation(rt_mod, dev, args)
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/tune_relay_meta_schedule.py", line 177, in f_per_layer
    mod = create(graph, rt_mod, dev)
  File "/home/ubuntu/tvm/python/tvm/contrib/debugger/debug_executor.py", line 73, in create
    gmod = GraphModuleDebug(func_obj, dev, graph_json_str, dump_root)
  File "/home/ubuntu/tvm/python/tvm/contrib/debugger/debug_executor.py", line 116, in __init__
    self._run_individual_node = module["run_individual_node"]
  File "/home/ubuntu/tvm/python/tvm/runtime/module.py", line 169, in __getitem__
    return self.get_function(name)
  File "/home/ubuntu/tvm/python/tvm/runtime/module.py", line 153, in get_function
    raise AttributeError("Module has no function '%s'" % name)
AttributeError: Module has no function 'run_individual_node'
Running time in time_evaluator:  [21.753138173913044, 21.753502826086955, 21.879002864864866]
Avg running time: 21.795214621621625
