2022-05-13 13:29:03.886 INFO RPCRunner: max_workers = 1
Workload: resnet_50
  input_name: input0
  input_shape: [1, 3, 224, 224]
  input_dtype: float32
2022-05-13 13:29:55.498 INFO Logging directory: /home/ubuntu/tvm/logs/perf/llvm/pytorch_resnet_50//ms_resnet_50_2022-05-13_13:28:55/logs
2022-05-13 13:29:55.498 INFO Working directory: /home/ubuntu/tvm/logs/perf/llvm/pytorch_resnet_50//ms_resnet_50_2022-05-13_13:28:55/
2022-05-13 13:29:55.499 INFO Creating JSONDatabase. Workload at: /home/ubuntu/tvm/logs/perf/llvm/pytorch_resnet_50//ms_resnet_50_2022-05-13_13:28:55/database_workload.json. Tuning records at: /home/ubuntu/tvm/logs/perf/llvm/pytorch_resnet_50//ms_resnet_50_2022-05-13_13:28:55/database_tuning_record.json
2022-05-13 13:29:55.499 INFO LocalBuilder: max_workers = 48
2022-05-13 13:30:08.937 INFO 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |            N/A |          N/A |                   N/A |      0 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                                  fused_layout_transform |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 0
Total latency (us): 0

2022-05-13 13:30:08.938 INFO Scheduler picks Task #0: "fused_nn_conv2d_add"
2022-05-13 13:30:13.725 INFO Sending 64 sample(s) to builder
2022-05-13 13:30:17.882 INFO Sending 64 sample(s) to runner
2022-05-13 13:30:17.947 INFO Scheduler picks Task #1: "fused_nn_conv2d_add_1"
2022-05-13 13:30:23.479 INFO Sending 64 sample(s) to builder
2022-05-13 13:30:31.903 INFO Sending 64 sample(s) to runner
2022-05-13 13:30:31.980 INFO Scheduler picks Task #2: "fused_nn_conv2d_add_2"
2022-05-13 13:30:37.588 INFO Sending 64 sample(s) to builder
2022-05-13 13:31:03.518 INFO Sending 64 sample(s) to runner
2022-05-13 13:31:03.576 INFO Scheduler picks Task #3: "fused_nn_conv2d_add_3"
2022-05-13 13:31:09.758 INFO Sending 64 sample(s) to builder
2022-05-13 13:31:41.062 INFO Sending 64 sample(s) to runner
2022-05-13 13:31:41.100 INFO Scheduler picks Task #4: "fused_layout_transform"
2022-05-13 13:31:42.364 INFO Sending 8 sample(s) to builder
2022-05-13 13:31:42.997 INFO Sending 8 sample(s) to runner
2022-05-13 13:31:43.001 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-13 13:31:51.913 INFO Sending 64 sample(s) to builder
2022-05-13 13:32:04.922 INFO Sending 64 sample(s) to runner
2022-05-13 13:32:06.306 INFO Scheduler picks Task #6: "fused_nn_max_pool2d"
2022-05-13 13:32:16.935 INFO Sending 40 sample(s) to builder
2022-05-13 13:32:22.901 INFO Sending 40 sample(s) to runner
2022-05-13 13:32:22.927 INFO Scheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_1"
2022-05-13 13:32:30.085 INFO Sending 64 sample(s) to builder
2022-05-13 13:33:03.182 INFO Sending 64 sample(s) to runner
2022-05-13 13:33:04.253 INFO Scheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_2"
2022-05-13 13:33:13.059 INFO Sending 64 sample(s) to builder
2022-05-13 13:33:45.627 INFO Sending 64 sample(s) to runner
2022-05-13 13:33:45.812 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 13:34:07.592 INFO Sending 64 sample(s) to builder
2022-05-13 13:34:30.058 INFO Sending 64 sample(s) to runner
2022-05-13 13:34:30.119 INFO Scheduler picks Task #10: "fused_nn_conv2d_add_add_nn_relu"
2022-05-13 13:34:38.353 INFO Sending 64 sample(s) to builder
2022-05-13 13:35:10.888 INFO Sending 64 sample(s) to runner
2022-05-13 13:35:13.107 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2022-05-13 13:35:22.042 INFO Sending 64 sample(s) to builder
2022-05-13 13:35:54.808 INFO Sending 64 sample(s) to runner
2022-05-13 13:35:54.912 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2022-05-13 13:36:10.502 INFO Sending 64 sample(s) to builder
2022-05-13 13:36:31.540 INFO Sending 64 sample(s) to runner
2022-05-13 13:36:31.580 INFO Scheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2022-05-13 13:36:43.155 INFO Sending 64 sample(s) to builder
2022-05-13 13:36:58.104 INFO Sending 64 sample(s) to runner
2022-05-13 13:36:58.216 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 13:37:41.191 INFO Sending 63 sample(s) to builder
2022-05-13 13:38:25.072 INFO Sending 63 sample(s) to runner
2022-05-13 13:38:25.230 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 13:38:37.199 INFO Sending 64 sample(s) to builder
2022-05-13 13:39:14.184 INFO Sending 64 sample(s) to runner
2022-05-13 13:39:17.224 INFO Scheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2022-05-13 13:39:25.600 INFO Sending 64 sample(s) to builder
2022-05-13 13:39:54.627 INFO Sending 64 sample(s) to runner
2022-05-13 13:39:54.789 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 13:40:14.176 INFO Sending 64 sample(s) to builder
2022-05-13 13:40:31.484 INFO Sending 64 sample(s) to runner
2022-05-13 13:40:31.551 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 13:40:36.770 INFO Sending 64 sample(s) to builder
2022-05-13 13:40:40.541 INFO Sending 64 sample(s) to runner
2022-05-13 13:40:40.580 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 13:41:03.905 INFO Sending 64 sample(s) to builder
2022-05-13 13:41:38.359 INFO Sending 64 sample(s) to runner
2022-05-13 13:41:38.397 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 13:41:43.526 INFO Sending 64 sample(s) to builder
2022-05-13 13:42:10.070 INFO Sending 64 sample(s) to runner
2022-05-13 13:42:10.153 INFO Scheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_10"
2022-05-13 13:42:20.903 INFO Sending 64 sample(s) to builder
2022-05-13 13:42:38.367 INFO Sending 64 sample(s) to runner
2022-05-13 13:42:38.466 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 13:42:50.207 INFO Sending 64 sample(s) to builder
2022-05-13 13:43:21.265 INFO Sending 64 sample(s) to runner
2022-05-13 13:43:23.151 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 13:43:33.495 INFO Sending 64 sample(s) to builder
2022-05-13 13:43:41.147 INFO Sending 64 sample(s) to runner
2022-05-13 13:43:41.186 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 13:43:49.142 INFO Sending 64 sample(s) to builder
2022-05-13 13:44:26.353 INFO Sending 64 sample(s) to runner
2022-05-13 13:44:27.629 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 13:44:34.679 INFO Sending 64 sample(s) to builder
2022-05-13 13:45:07.659 INFO Sending 64 sample(s) to runner
2022-05-13 13:45:07.742 INFO Scheduler picks Task #26: "fused_nn_adaptive_avg_pool2d"
2022-05-13 13:45:12.910 INFO Sending 63 sample(s) to builder
2022-05-13 13:45:15.816 INFO Sending 63 sample(s) to runner
2022-05-13 13:45:15.850 INFO Scheduler picks Task #27: "fused_layout_transform_reshape_squeeze"
2022-05-13 13:45:17.599 INFO Sending 4 sample(s) to builder
2022-05-13 13:45:18.178 INFO Sending 4 sample(s) to runner
2022-05-13 13:45:18.179 INFO Scheduler picks Task #28: "fused_nn_dense_add"
2022-05-13 13:45:20.786 INFO Sending 64 sample(s) to builder
2022-05-13 13:45:42.658 INFO Sending 64 sample(s) to runner
/home/ubuntu/anaconda3/lib/python3.9/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)
2022-05-13 13:46:00.295 INFO [Updated] Task #0: "fused_nn_conv2d_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                                  fused_layout_transform |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 64
Total latency (us): 212.11

2022-05-13 13:46:04.222 INFO [Updated] Task #1: "fused_nn_conv2d_add_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                                  fused_layout_transform |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 128
Total latency (us): 376.141

2022-05-13 13:46:07.539 INFO [Updated] Task #2: "fused_nn_conv2d_add_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                                  fused_layout_transform |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 192
Total latency (us): 498.745

2022-05-13 13:46:11.532 INFO [Updated] Task #3: "fused_nn_conv2d_add_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 256
Total latency (us): 553.029

2022-05-13 13:46:16.323 INFO [Updated] Task #4: "fused_layout_transform"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 264
Total latency (us): 556.154

2022-05-13 13:46:37.116 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 328
Total latency (us): 718.825

2022-05-13 13:46:49.001 INFO [Updated] Task #6: "fused_nn_max_pool2d"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 368
Total latency (us): 725.523

2022-05-13 13:47:02.535 INFO [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |            N/A |          N/A |                   N/A |      0 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 432
Total latency (us): 748.105

2022-05-13 13:47:25.141 INFO [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 496
Total latency (us): 846.836

2022-05-13 13:47:56.733 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |            N/A |          N/A |                   N/A |      0 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 560
Total latency (us): 1473.49

2022-05-13 13:48:11.066 INFO [Updated] Task #10: "fused_nn_conv2d_add_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 624
Total latency (us): 1611.72

2022-05-13 13:48:25.862 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 688
Total latency (us): 1747.47

2022-05-13 13:48:56.606 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |            N/A |          N/A |                   N/A |      0 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 752
Total latency (us): 1881.87

2022-05-13 13:49:10.629 INFO [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 816
Total latency (us): 2110.56

2022-05-13 13:49:54.706 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |            N/A |          N/A |                   N/A |      0 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 879
Total latency (us): 2804.43

2022-05-13 13:50:03.156 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 943
Total latency (us): 3341.84

2022-05-13 13:50:13.805 INFO [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1007
Total latency (us): 3556.77

2022-05-13 13:50:31.853 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |            N/A |          N/A |                   N/A |      0 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1071
Total latency (us): 3899.1

2022-05-13 13:50:45.065 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |            N/A |          N/A |                   N/A |      0 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1135
Total latency (us): 4261.91

2022-05-13 13:51:09.533 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       405.9806 |     242.8711 |             1214.3556 |     64 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |            N/A |          N/A |                   N/A |      0 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1199
Total latency (us): 5476.26

2022-05-13 13:51:49.483 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       405.9806 |     242.8711 |             1214.3556 |     64 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |       755.8290 |     136.7539 |              820.5233 |     64 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |            N/A |          N/A |                   N/A |      0 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1263
Total latency (us): 6296.79

2022-05-13 13:52:10.302 INFO [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_10"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       405.9806 |     242.8711 |             1214.3556 |     64 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |       755.8290 |     136.7539 |              820.5233 |     64 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |            N/A |          N/A |                   N/A |      0 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1327
Total latency (us): 6531.18

2022-05-13 13:52:25.011 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       405.9806 |     242.8711 |             1214.3556 |     64 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |       755.8290 |     136.7539 |              820.5233 |     64 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |            N/A |          N/A |                   N/A |      0 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1391
Total latency (us): 6901.12

2022-05-13 13:52:43.966 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       405.9806 |     242.8711 |             1214.3556 |     64 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |       755.8290 |     136.7539 |              820.5233 |     64 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |            N/A |          N/A |                   N/A |      0 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1455
Total latency (us): 7177.37

2022-05-13 13:53:23.699 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       405.9806 |     242.8711 |             1214.3556 |     64 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |       755.8290 |     136.7539 |              820.5233 |     64 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |            N/A |          N/A |                   N/A |      0 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1519
Total latency (us): 7743.62

2022-05-13 13:53:44.844 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       405.9806 |     242.8711 |             1214.3556 |     64 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |       755.8290 |     136.7539 |              820.5233 |     64 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |            N/A |          N/A |                   N/A |      0 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1583
Total latency (us): 8097.05

2022-05-13 13:53:57.212 INFO [Updated] Task #26: "fused_nn_adaptive_avg_pool2d"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       405.9806 |     242.8711 |             1214.3556 |     64 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |       755.8290 |     136.7539 |              820.5233 |     64 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1646
Total latency (us): 8100.34

2022-05-13 13:54:11.403 INFO [Updated] Task #27: "fused_layout_transform_reshape_squeeze"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       405.9806 |     242.8711 |             1214.3556 |     64 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |       755.8290 |     136.7539 |              820.5233 |     64 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |            N/A |          N/A |                   N/A |      0 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1650
Total latency (us): 8102.99

2022-05-13 13:54:24.080 INFO [Updated] Task #28: "fused_nn_dense_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       405.9806 |     242.8711 |             1214.3556 |     64 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |       755.8290 |     136.7539 |              820.5233 |     64 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1714
Total latency (us): 8138.99

2022-05-13 13:54:24.080 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 13:55:38.644 INFO Sending 64 sample(s) to builder
2022-05-13 13:56:22.108 INFO Sending 64 sample(s) to runner
2022-05-13 13:57:30.087 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       405.9806 |     242.8711 |             1214.3556 |    128 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |       755.8290 |     136.7539 |              820.5233 |     64 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1778
Total latency (us): 8138.99

2022-05-13 13:57:30.087 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 13:58:54.344 INFO Sending 64 sample(s) to builder
2022-05-13 13:59:25.395 INFO Sending 64 sample(s) to runner
2022-05-13 13:59:25.508 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 13:59:42.530 INFO Sending 64 sample(s) to builder
2022-05-13 14:00:17.234 INFO Sending 64 sample(s) to runner
2022-05-13 14:00:38.561 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |       755.8290 |     136.7539 |              820.5233 |     64 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1842
Total latency (us): 8008.02

2022-05-13 14:01:21.351 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       403.0737 |     231.2902 |              693.8706 |     63 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1906
Total latency (us): 7557.63

2022-05-13 14:01:21.351 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 14:02:44.993 INFO Sending 64 sample(s) to builder
2022-05-13 14:03:22.204 INFO Sending 64 sample(s) to runner
2022-05-13 14:03:46.985 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       452.0155 |     206.2474 |              618.7421 |    127 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1970
Total latency (us): 7482.51

2022-05-13 14:03:46.986 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 14:04:56.428 INFO Sending 64 sample(s) to builder
2022-05-13 14:05:23.104 INFO Sending 64 sample(s) to runner
2022-05-13 14:05:23.157 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 14:06:00.004 INFO Sending 64 sample(s) to builder
2022-05-13 14:06:08.430 INFO Sending 64 sample(s) to runner
2022-05-13 14:06:29.177 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      1108.8115 |     208.8835 |              626.6505 |     64 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2034
Total latency (us): 7374.17

2022-05-13 14:06:57.641 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2189.6565 |     105.7757 |              317.3271 |    128 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2098
Total latency (us): 7064.85

2022-05-13 14:06:57.641 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 14:07:23.406 INFO Sending 64 sample(s) to builder
2022-05-13 14:07:39.146 INFO Sending 64 sample(s) to runner
2022-05-13 14:07:39.268 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 14:08:05.691 INFO Sending 64 sample(s) to builder
2022-05-13 14:08:34.860 INFO Sending 64 sample(s) to runner
2022-05-13 14:08:51.433 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |       816.8067 |     283.1284 |              566.2568 |     64 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2162
Total latency (us): 7048.22

2022-05-13 14:09:14.548 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1343.0765 |     172.1877 |              344.3753 |    128 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2226
Total latency (us): 6826.34

2022-05-13 14:09:14.548 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 14:09:34.654 INFO Sending 64 sample(s) to builder
2022-05-13 14:09:43.684 INFO Sending 64 sample(s) to runner
2022-05-13 14:09:43.723 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 14:09:56.085 INFO Sending 64 sample(s) to builder
2022-05-13 14:10:14.065 INFO Sending 64 sample(s) to runner
2022-05-13 14:10:36.849 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |       773.8268 |     134.3513 |              537.4054 |     64 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2290
Total latency (us): 6797.6

2022-05-13 14:11:02.368 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2274.9627 |      45.6995 |              182.7980 |    128 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |       625.1265 |     369.9430 |              369.9430 |     64 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2354
Total latency (us): 6443

2022-05-13 14:11:02.368 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 14:11:15.707 INFO Sending 64 sample(s) to builder
2022-05-13 14:11:22.957 INFO Sending 64 sample(s) to runner
2022-05-13 14:11:23.004 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 14:11:37.805 INFO Sending 64 sample(s) to builder
2022-05-13 14:11:41.789 INFO Sending 64 sample(s) to runner
2022-05-13 14:12:21.835 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2274.9627 |      45.6995 |              182.7980 |    128 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1314.2656 |     175.9623 |              175.9623 |    128 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2418
Total latency (us): 6249.01

2022-05-13 14:12:21.835 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 14:12:48.667 INFO Sending 64 sample(s) to builder
2022-05-13 14:12:55.664 INFO Sending 64 sample(s) to runner
2022-05-13 14:13:17.694 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1314.2656 |     175.9623 |              175.9623 |    128 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2482
Total latency (us): 6247.27

2022-05-13 14:13:26.714 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1417.5489 |      72.5624 |              362.8122 |     64 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2546
Total latency (us): 6245.34

2022-05-13 14:13:26.715 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 14:13:43.979 INFO Sending 64 sample(s) to builder
2022-05-13 14:13:54.409 INFO Sending 64 sample(s) to runner
2022-05-13 14:14:30.768 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1790.4134 |      57.4509 |              287.2543 |    128 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2610
Total latency (us): 6169.78

2022-05-13 14:14:30.768 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 14:14:39.994 INFO Sending 64 sample(s) to builder
2022-05-13 14:14:54.209 INFO Sending 64 sample(s) to runner
2022-05-13 14:14:54.303 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 14:15:56.717 INFO Sending 64 sample(s) to builder
2022-05-13 14:16:30.025 INFO Sending 64 sample(s) to runner
2022-05-13 14:16:56.622 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    192 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2674
Total latency (us): 6155.94

2022-05-13 14:17:14.421 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    256 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |       874.8189 |     117.8090 |              353.4269 |     64 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2738
Total latency (us): 6155.94

2022-05-13 14:17:14.421 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 14:17:28.203 INFO Sending 64 sample(s) to builder
2022-05-13 14:17:34.842 INFO Sending 64 sample(s) to runner
2022-05-13 14:18:25.210 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    256 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1312.0315 |      78.5511 |              235.6533 |    128 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2802
Total latency (us): 6038.17

2022-05-13 14:18:25.210 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 14:18:34.373 INFO Sending 64 sample(s) to builder
2022-05-13 14:18:40.730 INFO Sending 64 sample(s) to runner
2022-05-13 14:18:40.828 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 14:19:00.642 INFO Sending 64 sample(s) to builder
2022-05-13 14:19:15.489 INFO Sending 64 sample(s) to runner
2022-05-13 14:19:45.102 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |       675.7103 |     342.3233 |              342.3233 |     64 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    256 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2866
Total latency (us): 5987.3

2022-05-13 14:20:00.250 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1629.8174 |     141.9247 |              141.9247 |    128 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    256 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2930
Total latency (us): 5786.9

2022-05-13 14:20:00.250 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 14:20:29.301 INFO Sending 64 sample(s) to builder
2022-05-13 14:20:37.553 INFO Sending 64 sample(s) to runner
2022-05-13 14:20:37.592 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 14:21:31.569 INFO Sending 64 sample(s) to builder
2022-05-13 14:22:00.285 INFO Sending 64 sample(s) to runner
2022-05-13 14:22:39.878 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       455.0594 |     216.6771 |             1083.3856 |    256 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2994
Total latency (us): 5785.15

2022-05-13 14:22:57.749 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       489.1152 |     201.5905 |             1007.9523 |    320 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       744.3342 |     138.1243 |              276.2486 |     64 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3058
Total latency (us): 5709.72

2022-05-13 14:22:57.749 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 14:23:15.511 INFO Sending 64 sample(s) to builder
2022-05-13 14:23:21.342 INFO Sending 64 sample(s) to runner
2022-05-13 14:24:07.004 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       489.1152 |     201.5905 |             1007.9523 |    320 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |       877.6934 |     234.3889 |              234.3889 |     64 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.8802 |     127.5756 |              255.1511 |    128 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3122
Total latency (us): 5688.62

2022-05-13 14:24:07.004 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 14:24:25.627 INFO Sending 64 sample(s) to builder
2022-05-13 14:24:46.399 INFO Sending 64 sample(s) to runner
2022-05-13 14:24:46.437 INFO Scheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_10"
2022-05-13 14:24:55.169 INFO Sending 64 sample(s) to builder
2022-05-13 14:24:59.248 INFO Sending 64 sample(s) to runner
2022-05-13 14:25:50.632 INFO [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_10"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       489.1152 |     201.5905 |             1007.9523 |    320 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1561.3865 |     131.7557 |              131.7557 |    128 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.8802 |     127.5756 |              255.1511 |    128 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3186
Total latency (us): 5585.99

2022-05-13 14:25:50.632 INFO Scheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_10"
2022-05-13 14:26:07.192 INFO Sending 64 sample(s) to builder
2022-05-13 14:26:19.573 INFO Sending 64 sample(s) to runner
2022-05-13 14:26:54.117 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       489.1152 |     201.5905 |             1007.9523 |    320 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1561.3865 |     131.7557 |              131.7557 |    128 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3250
Total latency (us): 5585.98

2022-05-13 14:26:54.117 INFO Scheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2022-05-13 14:27:02.372 INFO Sending 64 sample(s) to builder
2022-05-13 14:27:07.346 INFO Sending 64 sample(s) to runner
2022-05-13 14:27:29.979 INFO [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_10"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      1350.6691 |      76.2297 |              228.6892 |     64 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       489.1152 |     201.5905 |             1007.9523 |    320 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3314
Total latency (us): 5563.55

2022-05-13 14:28:18.289 INFO [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2118.5844 |      48.5990 |              145.7971 |    128 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       489.1152 |     201.5905 |             1007.9523 |    320 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3378
Total latency (us): 5480.66

2022-05-13 14:28:18.290 INFO Scheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2022-05-13 14:28:38.872 INFO Sending 64 sample(s) to builder
2022-05-13 14:28:49.402 INFO Sending 64 sample(s) to runner
2022-05-13 14:28:49.501 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 14:29:51.309 INFO Sending 64 sample(s) to builder
2022-05-13 14:30:07.300 INFO Sending 64 sample(s) to runner
2022-05-13 14:30:16.575 INFO [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       489.1152 |     201.5905 |             1007.9523 |    320 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3442
Total latency (us): 5472.9

2022-05-13 14:31:06.038 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    384 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3506
Total latency (us): 5338.75

2022-05-13 14:31:06.039 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 14:32:10.030 INFO Sending 64 sample(s) to builder
2022-05-13 14:32:45.771 INFO Sending 64 sample(s) to runner
2022-05-13 14:32:45.851 INFO Scheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2022-05-13 14:32:58.673 INFO Sending 64 sample(s) to builder
2022-05-13 14:33:15.621 INFO Sending 64 sample(s) to runner
2022-05-13 14:33:52.106 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |       958.0655 |     214.9355 |              214.9355 |     64 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3570
Total latency (us): 5338.75

2022-05-13 14:34:09.046 INFO [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      1878.3544 |     109.6291 |              109.6291 |    128 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3634
Total latency (us): 5233.44

2022-05-13 14:34:09.046 INFO Scheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2022-05-13 14:34:19.875 INFO Sending 64 sample(s) to builder
2022-05-13 14:34:37.810 INFO Sending 64 sample(s) to runner
2022-05-13 14:34:37.912 INFO Scheduler picks Task #0: "fused_nn_conv2d_add"
2022-05-13 14:34:51.427 INFO Sending 64 sample(s) to builder
2022-05-13 14:34:57.220 INFO Sending 64 sample(s) to runner
2022-05-13 14:35:15.807 INFO [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |       969.4072 |     212.1103 |              212.1103 |     64 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3698
Total latency (us): 5218.81

2022-05-13 14:35:55.697 INFO [Updated] Task #0: "fused_nn_conv2d_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1501.6310 |     136.9319 |              136.9319 |    128 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1675.5097 |      61.6902 |              370.1413 |    128 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3762
Total latency (us): 5143.63

2022-05-13 14:35:55.697 INFO Scheduler picks Task #0: "fused_nn_conv2d_add"
2022-05-13 14:36:09.033 INFO Sending 64 sample(s) to builder
2022-05-13 14:36:18.114 INFO Sending 64 sample(s) to runner
2022-05-13 14:36:18.153 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 14:36:26.748 INFO Sending 64 sample(s) to builder
2022-05-13 14:36:31.174 INFO Sending 64 sample(s) to runner
2022-05-13 14:37:25.666 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1501.6310 |     136.9319 |              136.9319 |    128 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1732.5900 |      59.6578 |              357.9470 |    192 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3826
Total latency (us): 5131.44

2022-05-13 14:37:25.666 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 14:37:47.860 INFO Sending 64 sample(s) to builder
2022-05-13 14:38:22.334 INFO Sending 64 sample(s) to runner
2022-05-13 14:38:53.518 INFO [Updated] Task #0: "fused_nn_conv2d_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1732.5900 |      59.6578 |              357.9470 |    192 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3890
Total latency (us): 5126.82

2022-05-13 14:39:20.331 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    191 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3954
Total latency (us): 5119.62

2022-05-13 14:39:20.331 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 14:40:23.150 INFO Sending 64 sample(s) to builder
2022-05-13 14:41:06.296 INFO Sending 64 sample(s) to runner
2022-05-13 14:41:37.895 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1254.1625 |     164.0311 |              164.0311 |     64 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    255 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4018
Total latency (us): 5119.62

2022-05-13 14:41:37.910 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 14:42:35.054 INFO Sending 64 sample(s) to builder
2022-05-13 14:42:51.415 INFO Sending 64 sample(s) to runner
2022-05-13 14:42:51.455 INFO Scheduler picks Task #1: "fused_nn_conv2d_add_1"
2022-05-13 14:43:01.045 INFO Sending 64 sample(s) to builder
2022-05-13 14:43:07.072 INFO Sending 64 sample(s) to runner
2022-05-13 14:44:09.518 INFO [Updated] Task #1: "fused_nn_conv2d_add_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1688.3859 |     121.8451 |              121.8451 |    128 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       547.9563 |     170.1358 |              510.4075 |    255 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4082
Total latency (us): 5077.44

2022-05-13 14:44:09.518 INFO Scheduler picks Task #1: "fused_nn_conv2d_add_1"
2022-05-13 14:44:22.992 INFO Sending 64 sample(s) to builder
2022-05-13 14:44:35.451 INFO Sending 64 sample(s) to runner
2022-05-13 14:45:01.159 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1688.3859 |     121.8451 |              121.8451 |    128 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4146
Total latency (us): 5060.29

2022-05-13 14:45:01.159 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-13 14:45:32.467 INFO Sending 64 sample(s) to builder
2022-05-13 14:45:39.810 INFO Sending 64 sample(s) to runner
2022-05-13 14:46:06.727 INFO [Updated] Task #1: "fused_nn_conv2d_add_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      1460.8236 |     162.6709 |              162.6709 |     64 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4210
Total latency (us): 5057.05

2022-05-13 14:46:31.301 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       564.2049 |     174.7609 |              873.8046 |    448 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4274
Total latency (us): 5008.2

2022-05-13 14:46:31.301 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 14:47:22.129 INFO Sending 64 sample(s) to builder
2022-05-13 14:47:49.863 INFO Sending 64 sample(s) to runner
2022-05-13 14:48:21.824 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       669.8497 |     147.1986 |              735.9931 |    512 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4338
Total latency (us): 4870.39

2022-05-13 14:48:21.824 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 14:49:16.458 INFO Sending 64 sample(s) to builder
2022-05-13 14:49:54.605 INFO Sending 64 sample(s) to runner
2022-05-13 14:49:54.703 INFO Scheduler picks Task #10: "fused_nn_conv2d_add_add_nn_relu"
2022-05-13 14:50:14.315 INFO Sending 64 sample(s) to builder
2022-05-13 14:50:19.581 INFO Sending 64 sample(s) to runner
2022-05-13 14:50:47.655 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2282.3415 |      46.0794 |              138.2382 |     64 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4402
Total latency (us): 4843.85

2022-05-13 14:51:28.633 INFO [Updated] Task #10: "fused_nn_conv2d_add_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2434.2793 |      43.2033 |              129.6099 |    128 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4466
Total latency (us): 4835.22

2022-05-13 14:51:28.633 INFO Scheduler picks Task #10: "fused_nn_conv2d_add_add_nn_relu"
2022-05-13 14:51:41.900 INFO Sending 64 sample(s) to builder
2022-05-13 14:51:45.399 INFO Sending 64 sample(s) to runner
2022-05-13 14:51:45.447 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2022-05-13 14:51:56.220 INFO Sending 64 sample(s) to builder
2022-05-13 14:52:06.555 INFO Sending 64 sample(s) to runner
2022-05-13 14:52:41.660 INFO [Updated] Task #10: "fused_nn_conv2d_add_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      1519.9446 |     135.7442 |              135.7442 |     64 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4530
Total latency (us): 4828.53

2022-05-13 14:53:07.443 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1721.7813 |     134.4025 |              134.4025 |     64 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4594
Total latency (us): 4767.51

2022-05-13 14:53:07.443 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2022-05-13 14:53:40.508 INFO Sending 64 sample(s) to builder
2022-05-13 14:53:52.197 INFO Sending 64 sample(s) to runner
2022-05-13 14:54:49.082 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      1827.6607 |     126.6163 |              126.6163 |    128 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4658
Total latency (us): 4759.73

2022-05-13 14:54:49.083 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2022-05-13 14:55:18.625 INFO Sending 64 sample(s) to builder
2022-05-13 14:55:29.036 INFO Sending 64 sample(s) to runner
2022-05-13 14:55:29.152 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 14:55:45.926 INFO Sending 64 sample(s) to builder
2022-05-13 14:55:51.333 INFO Sending 64 sample(s) to runner
2022-05-13 14:56:26.888 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1768.1688 |      58.4574 |              350.7444 |    256 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4722
Total latency (us): 4744.85

2022-05-13 14:56:51.817 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      1679.5733 |     122.6039 |              122.6039 |     64 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4786
Total latency (us): 4739.5

2022-05-13 14:56:51.817 INFO Scheduler picks Task #2: "fused_nn_conv2d_add_2"
2022-05-13 14:57:06.657 INFO Sending 64 sample(s) to builder
2022-05-13 14:57:16.410 INFO Sending 64 sample(s) to runner
2022-05-13 14:58:05.420 INFO [Updated] Task #2: "fused_nn_conv2d_add_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    128 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4850
Total latency (us): 4701.95

2022-05-13 14:58:05.420 INFO Scheduler picks Task #2: "fused_nn_conv2d_add_2"
2022-05-13 14:58:21.151 INFO Sending 64 sample(s) to builder
2022-05-13 14:58:48.317 INFO Sending 64 sample(s) to runner
2022-05-13 14:58:48.392 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 14:59:51.814 INFO Sending 64 sample(s) to builder
2022-05-13 15:00:17.262 INFO Sending 64 sample(s) to runner
2022-05-13 15:00:41.516 INFO [Updated] Task #2: "fused_nn_conv2d_add_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       567.0060 |     164.4198 |              493.2594 |    319 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4914
Total latency (us): 4701.95

2022-05-13 15:01:08.039 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1465.3626 |     157.8184 |              315.6368 |    192 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4978
Total latency (us): 4696.75

2022-05-13 15:01:08.039 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 15:01:33.296 INFO Sending 64 sample(s) to builder
2022-05-13 15:01:43.101 INFO Sending 64 sample(s) to runner
2022-05-13 15:02:42.016 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1514.6200 |     152.6859 |              305.3719 |    256 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5042
Total latency (us): 4686.48

2022-05-13 15:02:42.016 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 15:03:00.186 INFO Sending 64 sample(s) to builder
2022-05-13 15:03:04.002 INFO Sending 64 sample(s) to runner
2022-05-13 15:03:04.041 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 15:03:25.785 INFO Sending 64 sample(s) to builder
2022-05-13 15:03:48.907 INFO Sending 64 sample(s) to runner
2022-05-13 15:04:23.130 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2310.7111 |     100.2343 |              300.7028 |    192 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5106
Total latency (us): 4684.66

2022-05-13 15:05:03.660 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2415.2853 |      95.8944 |              287.6833 |    256 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5170
Total latency (us): 4671.64

2022-05-13 15:05:03.660 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 15:05:36.690 INFO Sending 64 sample(s) to builder
2022-05-13 15:05:54.222 INFO Sending 64 sample(s) to runner
2022-05-13 15:06:34.815 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    320 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5234
Total latency (us): 4650.41

2022-05-13 15:06:34.815 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 15:07:02.618 INFO Sending 64 sample(s) to builder
2022-05-13 15:07:12.536 INFO Sending 64 sample(s) to runner
2022-05-13 15:07:12.576 INFO Scheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_2"
2022-05-13 15:07:27.541 INFO Sending 64 sample(s) to builder
2022-05-13 15:07:34.952 INFO Sending 64 sample(s) to runner
2022-05-13 15:08:28.927 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2089.7710 |      49.3651 |               98.7303 |     64 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5298
Total latency (us): 4650.41

2022-05-13 15:09:03.040 INFO [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2814.3768 |      36.6553 |               73.3106 |    128 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5362
Total latency (us): 4624.99

2022-05-13 15:09:03.040 INFO Scheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_2"
2022-05-13 15:09:12.513 INFO Sending 64 sample(s) to builder
2022-05-13 15:09:15.656 INFO Sending 64 sample(s) to runner
2022-05-13 15:09:15.695 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 15:10:15.865 INFO Sending 64 sample(s) to builder
2022-05-13 15:10:30.224 INFO Sending 64 sample(s) to runner
2022-05-13 15:11:00.005 INFO [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    576 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5426
Total latency (us): 4624.93

2022-05-13 15:11:33.961 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1881.0106 |      54.6838 |              273.4190 |    192 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    640 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5490
Total latency (us): 4624.93

2022-05-13 15:11:33.961 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 15:11:47.523 INFO Sending 64 sample(s) to builder
2022-05-13 15:11:51.102 INFO Sending 64 sample(s) to runner
2022-05-13 15:12:37.409 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    256 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    640 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5554
Total latency (us): 4615.01

2022-05-13 15:12:37.421 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 15:12:55.542 INFO Sending 64 sample(s) to builder
2022-05-13 15:13:01.263 INFO Sending 64 sample(s) to runner
2022-05-13 15:13:01.325 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 15:13:21.968 INFO Sending 64 sample(s) to builder
2022-05-13 15:13:32.191 INFO Sending 64 sample(s) to runner
2022-05-13 15:14:05.743 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    640 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       805.9162 |     127.5699 |              255.1397 |    192 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5618
Total latency (us): 4615.01

2022-05-13 15:14:37.416 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    640 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       821.0787 |     125.2141 |              250.4282 |    256 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5682
Total latency (us): 4610.29

2022-05-13 15:14:37.416 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 15:15:39.676 INFO Sending 64 sample(s) to builder
2022-05-13 15:15:51.267 INFO Sending 64 sample(s) to runner
2022-05-13 15:16:41.427 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       694.9079 |     141.8907 |              709.4534 |    704 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       821.0787 |     125.2141 |              250.4282 |    256 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5746
Total latency (us): 4610.29

2022-05-13 15:16:41.427 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 15:17:49.502 INFO Sending 64 sample(s) to builder
2022-05-13 15:18:23.011 INFO Sending 64 sample(s) to runner
2022-05-13 15:18:23.118 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 15:19:21.076 INFO Sending 64 sample(s) to builder
2022-05-13 15:19:53.669 INFO Sending 64 sample(s) to runner
2022-05-13 15:20:27.745 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    383 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       821.0787 |     125.2141 |              250.4282 |    256 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5810
Total latency (us): 4599.54

2022-05-13 15:21:02.512 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       573.0509 |     162.6854 |              488.0561 |    447 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       821.0787 |     125.2141 |              250.4282 |    256 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5874
Total latency (us): 4599.54

2022-05-13 15:21:02.513 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 15:21:58.836 INFO Sending 64 sample(s) to builder
2022-05-13 15:22:35.366 INFO Sending 64 sample(s) to runner
2022-05-13 15:23:45.397 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       681.9521 |     136.7061 |              410.1183 |    511 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1795.5252 |      57.5668 |              345.4005 |    320 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       821.0787 |     125.2141 |              250.4282 |    256 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5938
Total latency (us): 4521.6

2022-05-13 15:23:45.397 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 15:24:59.865 INFO Sending 64 sample(s) to builder
2022-05-13 15:25:17.699 INFO Sending 64 sample(s) to runner
2022-05-13 15:25:17.740 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 15:25:29.982 INFO Sending 64 sample(s) to builder
2022-05-13 15:25:35.778 INFO Sending 64 sample(s) to runner
2022-05-13 15:26:42.251 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       681.9521 |     136.7061 |              410.1183 |    511 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1801.2346 |      57.3843 |              344.3057 |    384 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       821.0787 |     125.2141 |              250.4282 |    256 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6002
Total latency (us): 4520.51

2022-05-13 15:26:42.262 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 15:27:02.163 INFO Sending 64 sample(s) to builder
2022-05-13 15:27:17.404 INFO Sending 64 sample(s) to runner
2022-05-13 15:28:01.375 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1801.2346 |      57.3843 |              344.3057 |    384 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       821.0787 |     125.2141 |              250.4282 |    256 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6066
Total latency (us): 4519.53

2022-05-13 15:28:34.441 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       821.0787 |     125.2141 |              250.4282 |    256 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6130
Total latency (us): 4514.31

2022-05-13 15:28:34.441 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 15:28:53.466 INFO Sending 64 sample(s) to builder
2022-05-13 15:29:01.609 INFO Sending 64 sample(s) to runner
2022-05-13 15:29:51.055 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       833.8756 |     123.2925 |              246.5850 |    320 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6194
Total latency (us): 4510.47

2022-05-13 15:29:51.055 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 15:30:10.507 INFO Sending 64 sample(s) to builder
2022-05-13 15:30:21.117 INFO Sending 64 sample(s) to runner
2022-05-13 15:30:21.194 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 15:30:46.258 INFO Sending 64 sample(s) to builder
2022-05-13 15:30:54.052 INFO Sending 64 sample(s) to runner
2022-05-13 15:31:43.812 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1523.7154 |     151.7745 |              303.5490 |    320 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6258
Total latency (us): 4509.67

2022-05-13 15:32:16.358 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1673.2592 |      61.5933 |              184.7798 |    192 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6322
Total latency (us): 4501.71

2022-05-13 15:32:16.358 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 15:32:33.133 INFO Sending 64 sample(s) to builder
2022-05-13 15:32:39.758 INFO Sending 64 sample(s) to runner
2022-05-13 15:33:34.456 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1680.8591 |      61.3148 |              183.9443 |    256 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6386
Total latency (us): 4500.87

2022-05-13 15:33:34.456 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 15:33:46.568 INFO Sending 64 sample(s) to builder
2022-05-13 15:33:53.471 INFO Sending 64 sample(s) to runner
2022-05-13 15:33:53.518 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 15:34:13.647 INFO Sending 64 sample(s) to builder
2022-05-13 15:34:43.119 INFO Sending 64 sample(s) to runner
2022-05-13 15:35:30.395 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2296.9292 |      45.2625 |              181.0499 |    192 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6450
Total latency (us): 4498.74

2022-05-13 15:36:01.649 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2410.2855 |      43.1338 |              172.5350 |    256 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6514
Total latency (us): 4490.23

2022-05-13 15:36:01.650 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 15:36:18.927 INFO Sending 64 sample(s) to builder
2022-05-13 15:36:23.406 INFO Sending 64 sample(s) to runner
2022-05-13 15:37:04.253 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2420.8231 |      42.9460 |              171.7840 |    320 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6578
Total latency (us): 4489.48

2022-05-13 15:37:04.254 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 15:37:28.075 INFO Sending 64 sample(s) to builder
2022-05-13 15:37:34.479 INFO Sending 64 sample(s) to runner
2022-05-13 15:37:34.550 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 15:38:41.826 INFO Sending 64 sample(s) to builder
2022-05-13 15:39:02.787 INFO Sending 64 sample(s) to runner
2022-05-13 15:39:47.093 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       705.6032 |     139.7399 |              698.6997 |    768 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6642
Total latency (us): 4482.16

2022-05-13 15:40:27.393 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       719.4561 |     137.0493 |              685.2465 |    832 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1328.8315 |     174.0335 |              174.0335 |    192 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6706
Total latency (us): 4468.7

2022-05-13 15:40:27.393 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 15:40:41.470 INFO Sending 64 sample(s) to builder
2022-05-13 15:40:54.699 INFO Sending 64 sample(s) to runner
2022-05-13 15:41:35.355 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       719.4561 |     137.0493 |              685.2465 |    832 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    256 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6770
Total latency (us): 4465.92

2022-05-13 15:41:35.355 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 15:42:06.071 INFO Sending 64 sample(s) to builder
2022-05-13 15:42:25.654 INFO Sending 64 sample(s) to runner
2022-05-13 15:43:37.505 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       719.4561 |     137.0493 |              685.2465 |    832 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    320 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6834
Total latency (us): 4465.92

2022-05-13 15:43:37.506 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 15:44:00.534 INFO Sending 64 sample(s) to builder
2022-05-13 15:44:19.835 INFO Sending 64 sample(s) to runner
2022-05-13 15:44:19.941 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-13 15:44:53.317 INFO Sending 64 sample(s) to builder
2022-05-13 15:45:00.724 INFO Sending 64 sample(s) to runner
2022-05-13 15:45:38.939 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    128 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       719.4561 |     137.0493 |              685.2465 |    832 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6898
Total latency (us): 4465.92

2022-05-13 15:46:13.710 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2087.7602 |     113.8222 |              113.8222 |    192 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       719.4561 |     137.0493 |              685.2465 |    832 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6962
Total latency (us): 4465.92

2022-05-13 15:46:13.710 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-13 15:46:40.400 INFO Sending 64 sample(s) to builder
2022-05-13 15:46:55.045 INFO Sending 64 sample(s) to runner
2022-05-13 15:46:55.160 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 15:47:47.448 INFO Sending 64 sample(s) to builder
2022-05-13 15:48:01.792 INFO Sending 64 sample(s) to runner
2022-05-13 15:48:35.030 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       719.4561 |     137.0493 |              685.2465 |    832 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7026
Total latency (us): 4451.47

2022-05-13 15:49:19.906 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    320 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       731.4837 |     134.7958 |              673.9792 |    896 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7090
Total latency (us): 4440.2

2022-05-13 15:49:19.907 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 15:49:34.582 INFO Sending 64 sample(s) to builder
2022-05-13 15:49:40.978 INFO Sending 64 sample(s) to runner
2022-05-13 15:50:30.437 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      1907.8013 |      54.2841 |               54.2841 |     64 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    384 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       731.4837 |     134.7958 |              673.9792 |    896 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7154
Total latency (us): 4440.2

2022-05-13 15:50:30.438 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 15:50:51.201 INFO Sending 64 sample(s) to builder
2022-05-13 15:51:00.327 INFO Sending 64 sample(s) to runner
2022-05-13 15:51:00.390 INFO Scheduler picks Task #3: "fused_nn_conv2d_add_3"
2022-05-13 15:51:12.715 INFO Sending 64 sample(s) to builder
2022-05-13 15:51:22.065 INFO Sending 64 sample(s) to runner
2022-05-13 15:51:54.719 INFO [Updated] Task #3: "fused_nn_conv2d_add_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2590.1327 |      39.9838 |               39.9838 |    128 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    384 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       731.4837 |     134.7958 |              673.9792 |    896 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7218
Total latency (us): 4425.9

2022-05-13 15:51:54.719 INFO Scheduler picks Task #3: "fused_nn_conv2d_add_3"
2022-05-13 15:52:11.706 INFO Sending 64 sample(s) to builder
2022-05-13 15:52:31.095 INFO Sending 64 sample(s) to runner
2022-05-13 15:53:16.501 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2590.1327 |      39.9838 |               39.9838 |    128 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       731.4837 |     134.7958 |              673.9792 |    896 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7282
Total latency (us): 4425.9

2022-05-13 15:53:16.501 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 15:54:25.531 INFO Sending 64 sample(s) to builder
2022-05-13 15:54:35.704 INFO Sending 64 sample(s) to runner
2022-05-13 15:55:08.463 INFO [Updated] Task #3: "fused_nn_conv2d_add_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       683.5855 |     136.3794 |              409.1383 |    575 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       731.4837 |     134.7958 |              673.9792 |    896 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7346
Total latency (us): 4422.92

2022-05-13 15:56:17.915 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       703.0752 |     132.5989 |              397.7968 |    639 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       731.4837 |     134.7958 |              673.9792 |    896 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7410
Total latency (us): 4411.57

2022-05-13 15:56:17.915 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 15:57:35.346 INFO Sending 64 sample(s) to builder
2022-05-13 15:57:52.294 INFO Sending 64 sample(s) to runner
2022-05-13 15:58:31.912 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       703.0752 |     132.5989 |              397.7968 |    639 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |    960 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7474
Total latency (us): 4406.88

2022-05-13 15:58:31.913 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 15:59:40.402 INFO Sending 64 sample(s) to builder
2022-05-13 16:00:06.187 INFO Sending 64 sample(s) to runner
2022-05-13 16:00:06.259 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 16:00:33.605 INFO Sending 64 sample(s) to builder
2022-05-13 16:00:52.081 INFO Sending 64 sample(s) to runner
2022-05-13 16:01:46.065 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       703.0752 |     132.5989 |              397.7968 |    639 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    384 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7538
Total latency (us): 4406.88

2022-05-13 16:02:32.011 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       703.0752 |     132.5989 |              397.7968 |    639 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1828.9441 |      56.5149 |              339.0893 |    448 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7602
Total latency (us): 4406.88

2022-05-13 16:02:32.011 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 16:02:55.098 INFO Sending 64 sample(s) to builder
2022-05-13 16:03:17.526 INFO Sending 64 sample(s) to runner
2022-05-13 16:04:14.784 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       703.0752 |     132.5989 |              397.7968 |    639 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1839.3747 |      56.1944 |              337.1664 |    512 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7666
Total latency (us): 4404.96

2022-05-13 16:04:14.784 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 16:04:40.086 INFO Sending 64 sample(s) to builder
2022-05-13 16:04:55.167 INFO Sending 64 sample(s) to runner
2022-05-13 16:04:55.338 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 16:06:18.960 INFO Sending 64 sample(s) to builder
2022-05-13 16:06:43.338 INFO Sending 64 sample(s) to runner
2022-05-13 16:07:23.575 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       703.0752 |     132.5989 |              397.7968 |    639 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7730
Total latency (us): 4403.07

2022-05-13 16:08:11.963 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       753.0392 |     123.8010 |              371.4030 |    703 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7794
Total latency (us): 4376.68

2022-05-13 16:08:11.963 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 16:09:20.363 INFO Sending 64 sample(s) to builder
2022-05-13 16:09:57.825 INFO Sending 64 sample(s) to runner
2022-05-13 16:09:57.979 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 16:10:30.619 INFO Sending 64 sample(s) to builder
2022-05-13 16:10:35.657 INFO Sending 64 sample(s) to runner
2022-05-13 16:11:06.622 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2607.7294 |      88.8177 |              266.4530 |    384 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7858
Total latency (us): 4375.33

2022-05-13 16:11:58.835 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2635.2292 |      87.8908 |              263.6724 |    448 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7922
Total latency (us): 4372.55

2022-05-13 16:11:58.835 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 16:12:25.337 INFO Sending 64 sample(s) to builder
2022-05-13 16:12:35.102 INFO Sending 64 sample(s) to runner
2022-05-13 16:12:35.185 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 16:13:02.781 INFO Sending 64 sample(s) to builder
2022-05-13 16:13:09.961 INFO Sending 64 sample(s) to runner
2022-05-13 16:13:47.985 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    192 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7986
Total latency (us): 4364.75

2022-05-13 16:14:40.937 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1650.0949 |     140.1806 |              140.1806 |    256 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8050
Total latency (us): 4364.75

2022-05-13 16:14:40.937 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 16:15:09.135 INFO Sending 64 sample(s) to builder
2022-05-13 16:15:21.139 INFO Sending 64 sample(s) to runner
2022-05-13 16:16:35.627 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1668.1609 |     138.6625 |              138.6625 |    320 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8114
Total latency (us): 4363.23

2022-05-13 16:16:35.628 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 16:17:06.891 INFO Sending 64 sample(s) to builder
2022-05-13 16:17:19.393 INFO Sending 64 sample(s) to runner
2022-05-13 16:17:19.432 INFO Scheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2022-05-13 16:17:38.820 INFO Sending 64 sample(s) to builder
2022-05-13 16:17:55.511 INFO Sending 64 sample(s) to runner
2022-05-13 16:18:54.002 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2237.6990 |      46.0121 |              138.0362 |    192 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8178
Total latency (us): 4362.97

2022-05-13 16:19:40.573 INFO [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1554.0012 |     132.3173 |              132.3173 |    192 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2246.0695 |      45.8406 |              137.5218 |    256 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8242
Total latency (us): 4362.46

2022-05-13 16:19:40.573 INFO Scheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2022-05-13 16:19:57.992 INFO Sending 64 sample(s) to builder
2022-05-13 16:20:05.168 INFO Sending 64 sample(s) to runner
2022-05-13 16:20:05.236 INFO Scheduler picks Task #0: "fused_nn_conv2d_add"
2022-05-13 16:20:16.121 INFO Sending 64 sample(s) to builder
2022-05-13 16:20:24.350 INFO Sending 64 sample(s) to runner
2022-05-13 16:21:53.473 INFO [Updated] Task #0: "fused_nn_conv2d_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1581.9186 |     129.9822 |              129.9822 |    256 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2246.0695 |      45.8406 |              137.5218 |    256 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8306
Total latency (us): 4360.12

2022-05-13 16:21:53.473 INFO Scheduler picks Task #0: "fused_nn_conv2d_add"
2022-05-13 16:22:13.604 INFO Sending 64 sample(s) to builder
2022-05-13 16:22:27.397 INFO Sending 64 sample(s) to runner
2022-05-13 16:23:24.226 INFO [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1581.9186 |     129.9822 |              129.9822 |    256 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8370
Total latency (us): 4339.85

2022-05-13 16:23:24.226 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 16:24:55.251 INFO Sending 64 sample(s) to builder
2022-05-13 16:25:29.380 INFO Sending 64 sample(s) to runner
2022-05-13 16:26:24.696 INFO [Updated] Task #0: "fused_nn_conv2d_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1024 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8434
Total latency (us): 4339.74

2022-05-13 16:26:59.415 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1088 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    448 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8498
Total latency (us): 4339.74

2022-05-13 16:26:59.415 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 16:27:28.570 INFO Sending 64 sample(s) to builder
2022-05-13 16:27:45.043 INFO Sending 64 sample(s) to runner
2022-05-13 16:28:35.023 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1088 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    512 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8562
Total latency (us): 4339.74

2022-05-13 16:28:35.023 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 16:29:02.788 INFO Sending 64 sample(s) to builder
2022-05-13 16:29:19.697 INFO Sending 64 sample(s) to runner
2022-05-13 16:29:19.737 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 16:29:39.993 INFO Sending 64 sample(s) to builder
2022-05-13 16:29:49.188 INFO Sending 64 sample(s) to runner
2022-05-13 16:30:33.453 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1088 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    384 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8626
Total latency (us): 4339.74

2022-05-13 16:31:04.454 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1088 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    448 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8690
Total latency (us): 4339.74

2022-05-13 16:31:04.454 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 16:31:22.299 INFO Sending 64 sample(s) to builder
2022-05-13 16:31:31.362 INFO Sending 64 sample(s) to runner
2022-05-13 16:31:31.438 INFO Scheduler picks Task #10: "fused_nn_conv2d_add_add_nn_relu"
2022-05-13 16:31:56.325 INFO Sending 64 sample(s) to builder
2022-05-13 16:32:09.172 INFO Sending 64 sample(s) to runner
2022-05-13 16:33:04.577 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2566.6900 |      40.9745 |              122.9236 |    192 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1088 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8754
Total latency (us): 4339.74

2022-05-13 16:34:01.733 INFO [Updated] Task #10: "fused_nn_conv2d_add_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    256 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1088 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8818
Total latency (us): 4339.25

2022-05-13 16:34:01.733 INFO Scheduler picks Task #10: "fused_nn_conv2d_add_add_nn_relu"
2022-05-13 16:34:18.309 INFO Sending 64 sample(s) to builder
2022-05-13 16:34:41.941 INFO Sending 64 sample(s) to runner
2022-05-13 16:34:42.031 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 16:35:07.121 INFO Sending 64 sample(s) to builder
2022-05-13 16:35:25.032 INFO Sending 64 sample(s) to runner
2022-05-13 16:36:22.452 INFO [Updated] Task #10: "fused_nn_conv2d_add_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1088 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1700.5430 |      60.6051 |              181.8152 |    320 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8882
Total latency (us): 4339.25

2022-05-13 16:37:03.101 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1088 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8946
Total latency (us): 4338.93

2022-05-13 16:37:03.101 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 16:37:56.242 INFO Sending 64 sample(s) to builder
2022-05-13 16:38:23.603 INFO Sending 64 sample(s) to runner
2022-05-13 16:39:33.190 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       736.6103 |     133.8577 |              669.2885 |   1152 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9010
Total latency (us): 4338.93

2022-05-13 16:39:33.190 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 16:40:50.091 INFO Sending 64 sample(s) to builder
2022-05-13 16:41:17.100 INFO Sending 64 sample(s) to runner
2022-05-13 16:41:17.207 INFO Scheduler picks Task #1: "fused_nn_conv2d_add_1"
2022-05-13 16:41:29.268 INFO Sending 64 sample(s) to builder
2022-05-13 16:41:40.617 INFO Sending 64 sample(s) to runner
2022-05-13 16:42:24.199 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1734.5046 |     118.6054 |              118.6054 |    192 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9074
Total latency (us): 4336.99

2022-05-13 16:43:25.079 INFO [Updated] Task #1: "fused_nn_conv2d_add_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1748.7984 |     117.6360 |              117.6360 |    256 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9138
Total latency (us): 4336.02

2022-05-13 16:43:25.079 INFO Scheduler picks Task #1: "fused_nn_conv2d_add_1"
2022-05-13 16:43:43.253 INFO Sending 64 sample(s) to builder
2022-05-13 16:43:52.976 INFO Sending 64 sample(s) to runner
2022-05-13 16:43:53.068 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 16:44:08.185 INFO Sending 64 sample(s) to builder
2022-05-13 16:44:21.716 INFO Sending 64 sample(s) to runner
2022-05-13 16:44:55.679 INFO [Updated] Task #1: "fused_nn_conv2d_add_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1849.7393 |      55.8795 |              335.2772 |    576 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9202
Total latency (us): 4328.96

2022-05-13 16:45:48.717 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    448 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9266
Total latency (us): 4322.52

2022-05-13 16:45:48.718 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 16:46:10.412 INFO Sending 64 sample(s) to builder
2022-05-13 16:46:21.054 INFO Sending 64 sample(s) to runner
2022-05-13 16:47:22.542 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    512 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9330
Total latency (us): 4322.52

2022-05-13 16:47:22.542 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 16:47:38.068 INFO Sending 64 sample(s) to builder
2022-05-13 16:47:50.557 INFO Sending 64 sample(s) to runner
2022-05-13 16:47:50.597 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2022-05-13 16:48:03.806 INFO Sending 64 sample(s) to builder
2022-05-13 16:48:15.719 INFO Sending 64 sample(s) to runner
2022-05-13 16:48:55.772 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2761.2074 |      74.7223 |               74.7223 |    128 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9394
Total latency (us): 4322.52

2022-05-13 16:49:53.969 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2812.4100 |      73.3619 |               73.3619 |    192 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9458
Total latency (us): 4321.16

2022-05-13 16:49:53.969 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2022-05-13 16:50:14.598 INFO Sending 64 sample(s) to builder
2022-05-13 16:50:23.444 INFO Sending 64 sample(s) to runner
2022-05-13 16:50:23.540 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2022-05-13 16:50:45.557 INFO Sending 64 sample(s) to builder
2022-05-13 16:50:50.855 INFO Sending 64 sample(s) to runner
2022-05-13 16:51:36.033 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2070.9904 |     111.7396 |              111.7396 |    192 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9522
Total latency (us): 4319.32

2022-05-13 16:52:08.398 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1881.7242 |     109.3261 |              109.3261 |    192 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9586
Total latency (us): 4314.02

2022-05-13 16:52:08.398 INFO Scheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_10"
2022-05-13 16:52:24.593 INFO Sending 64 sample(s) to builder
2022-05-13 16:52:51.230 INFO Sending 64 sample(s) to runner
2022-05-13 16:53:37.059 INFO [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_10"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1884.1786 |     109.1837 |              109.1837 |    256 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9650
Total latency (us): 4313.88

2022-05-13 16:53:37.060 INFO Scheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_10"
2022-05-13 16:53:58.417 INFO Sending 64 sample(s) to builder
2022-05-13 16:54:08.313 INFO Sending 64 sample(s) to runner
2022-05-13 16:55:00.736 INFO [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_10"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    320 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9714
Total latency (us): 4313.7

2022-05-13 16:55:00.737 INFO Scheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_10"
2022-05-13 16:55:14.547 INFO Sending 64 sample(s) to builder
2022-05-13 16:55:23.797 INFO Sending 64 sample(s) to runner
2022-05-13 16:55:23.894 INFO Scheduler picks Task #28: "fused_nn_dense_add"
2022-05-13 16:55:37.751 INFO Sending 64 sample(s) to builder
2022-05-13 16:56:13.312 INFO Sending 64 sample(s) to runner
2022-05-13 16:57:05.059 INFO [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_10"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |     64 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9778
Total latency (us): 4313.7

2022-05-13 16:57:53.671 INFO [Updated] Task #28: "fused_nn_dense_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1216 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9842
Total latency (us): 4313.7

2022-05-13 16:57:53.671 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 16:59:10.863 INFO Sending 64 sample(s) to builder
2022-05-13 16:59:40.354 INFO Sending 64 sample(s) to runner
2022-05-13 17:00:57.365 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1280 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9906
Total latency (us): 4313.7

2022-05-13 17:00:57.366 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 17:01:54.851 INFO Sending 64 sample(s) to builder
2022-05-13 17:02:25.435 INFO Sending 64 sample(s) to runner
2022-05-13 17:02:25.534 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 17:03:19.307 INFO Sending 64 sample(s) to builder
2022-05-13 17:03:59.202 INFO Sending 64 sample(s) to runner
2022-05-13 17:04:59.086 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    767 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1344 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9970
Total latency (us): 4313.7

2022-05-13 17:05:40.647 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    831 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1344 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10034
Total latency (us): 4313.7

2022-05-13 17:05:40.647 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 17:06:42.042 INFO Sending 64 sample(s) to builder
2022-05-13 17:07:03.996 INFO Sending 64 sample(s) to runner
2022-05-13 17:07:04.057 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 17:07:22.713 INFO Sending 64 sample(s) to builder
2022-05-13 17:07:35.729 INFO Sending 64 sample(s) to runner
2022-05-13 17:08:38.422 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1344 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    640 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10098
Total latency (us): 4313.7

2022-05-13 17:09:29.255 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2715.5627 |      85.2908 |              255.8723 |    512 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1344 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    704 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10162
Total latency (us): 4313.7

2022-05-13 17:09:29.256 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 17:10:01.551 INFO Sending 64 sample(s) to builder
2022-05-13 17:10:09.667 INFO Sending 64 sample(s) to runner
2022-05-13 17:11:45.216 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    576 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1344 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    704 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10226
Total latency (us): 4300.92

2022-05-13 17:11:45.216 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 17:12:05.799 INFO Sending 64 sample(s) to builder
2022-05-13 17:12:11.771 INFO Sending 64 sample(s) to runner
2022-05-13 17:12:11.812 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 17:12:39.304 INFO Sending 64 sample(s) to builder
2022-05-13 17:12:54.881 INFO Sending 64 sample(s) to runner
2022-05-13 17:13:47.945 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1344 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    704 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    576 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10290
Total latency (us): 4300.92

2022-05-13 17:14:45.219 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1344 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    704 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10354
Total latency (us): 4300.92

2022-05-13 17:14:45.219 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 17:15:39.699 INFO Sending 64 sample(s) to builder
2022-05-13 17:16:06.451 INFO Sending 64 sample(s) to runner
2022-05-13 17:17:21.510 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2167.6570 |      94.9976 |               94.9976 |    192 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1408 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    704 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10418
Total latency (us): 4300.92

2022-05-13 17:17:21.511 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 17:18:43.214 INFO Sending 64 sample(s) to builder
2022-05-13 17:19:22.203 INFO Sending 64 sample(s) to runner
2022-05-13 17:19:22.240 INFO Scheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2022-05-13 17:19:33.198 INFO Sending 64 sample(s) to builder
2022-05-13 17:19:38.628 INFO Sending 64 sample(s) to runner
2022-05-13 17:21:05.017 INFO [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2524.2835 |      81.5765 |               81.5765 |    256 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1408 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    704 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10482
Total latency (us): 4287.5

2022-05-13 17:21:05.017 INFO Scheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2022-05-13 17:21:26.598 INFO Sending 64 sample(s) to builder
2022-05-13 17:21:39.440 INFO Sending 64 sample(s) to runner
2022-05-13 17:22:27.699 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2524.2835 |      81.5765 |               81.5765 |    256 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    704 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10546
Total latency (us): 4287.5

2022-05-13 17:23:09.363 INFO [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2585.9020 |      79.6327 |               79.6327 |    320 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    704 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10610
Total latency (us): 4285.55

2022-05-13 17:23:09.363 INFO Scheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2022-05-13 17:23:27.960 INFO Sending 64 sample(s) to builder
2022-05-13 17:23:38.781 INFO Sending 64 sample(s) to runner
2022-05-13 17:23:38.891 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 17:23:56.971 INFO Sending 64 sample(s) to builder
2022-05-13 17:24:03.924 INFO Sending 64 sample(s) to runner
2022-05-13 17:24:51.817 INFO [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    704 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    512 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10674
Total latency (us): 4283.31

2022-05-13 17:26:00.705 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    704 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10738
Total latency (us): 4283.31

2022-05-13 17:26:00.709 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 17:26:23.912 INFO Sending 64 sample(s) to builder
2022-05-13 17:26:48.564 INFO Sending 64 sample(s) to runner
2022-05-13 17:27:53.593 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    768 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10802
Total latency (us): 4283.31

2022-05-13 17:27:53.593 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 17:28:09.714 INFO Sending 64 sample(s) to builder
2022-05-13 17:28:28.324 INFO Sending 64 sample(s) to runner
2022-05-13 17:28:28.408 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 17:28:45.331 INFO Sending 64 sample(s) to builder
2022-05-13 17:29:05.268 INFO Sending 64 sample(s) to runner
2022-05-13 17:29:56.348 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    384 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10866
Total latency (us): 4283.31

2022-05-13 17:30:30.577 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2391.3751 |      99.3711 |               99.3711 |    256 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10930
Total latency (us): 4283.31

2022-05-13 17:30:30.577 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-13 17:31:07.267 INFO Sending 64 sample(s) to builder
2022-05-13 17:31:24.606 INFO Sending 64 sample(s) to runner
2022-05-13 17:32:40.735 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    320 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10994
Total latency (us): 4281.6

2022-05-13 17:32:40.735 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-13 17:33:17.245 INFO Sending 64 sample(s) to builder
2022-05-13 17:33:35.332 INFO Sending 64 sample(s) to runner
2022-05-13 17:33:35.465 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 17:34:00.055 INFO Sending 64 sample(s) to builder
2022-05-13 17:34:10.121 INFO Sending 64 sample(s) to runner
2022-05-13 17:34:46.595 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    640 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11058
Total latency (us): 4281.6

2022-05-13 17:35:38.857 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    576 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11122
Total latency (us): 4281.6

2022-05-13 17:35:38.857 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 17:35:51.523 INFO Sending 64 sample(s) to builder
2022-05-13 17:36:04.286 INFO Sending 64 sample(s) to runner
2022-05-13 17:37:15.582 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    640 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11186
Total latency (us): 4281.6

2022-05-13 17:37:15.582 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 17:37:34.437 INFO Sending 64 sample(s) to builder
2022-05-13 17:37:46.382 INFO Sending 64 sample(s) to runner
2022-05-13 17:37:46.452 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 17:38:53.986 INFO Sending 64 sample(s) to builder
2022-05-13 17:39:09.408 INFO Sending 64 sample(s) to runner
2022-05-13 17:39:52.919 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1472 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11250
Total latency (us): 4281.6

2022-05-13 17:40:48.001 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2174.1159 |     106.4395 |              106.4395 |    256 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1536 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11314
Total latency (us): 4281.6

2022-05-13 17:40:48.002 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2022-05-13 17:41:23.600 INFO Sending 64 sample(s) to builder
2022-05-13 17:41:37.444 INFO Sending 64 sample(s) to runner
2022-05-13 17:42:57.736 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2348.2089 |      98.5482 |               98.5482 |    320 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1536 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11378
Total latency (us): 4273.71

2022-05-13 17:42:57.736 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2022-05-13 17:43:28.126 INFO Sending 64 sample(s) to builder
2022-05-13 17:43:43.024 INFO Sending 64 sample(s) to runner
2022-05-13 17:43:43.133 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 17:44:07.787 INFO Sending 64 sample(s) to builder
2022-05-13 17:44:17.429 INFO Sending 64 sample(s) to runner
2022-05-13 17:45:16.262 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2528.5599 |      41.1162 |              164.4646 |    384 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1536 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11442
Total latency (us): 4267.44

2022-05-13 17:46:11.605 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1536 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    384 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11506
Total latency (us): 4265.78

2022-05-13 17:46:11.605 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 17:46:27.062 INFO Sending 64 sample(s) to builder
2022-05-13 17:46:34.211 INFO Sending 64 sample(s) to runner
2022-05-13 17:47:53.722 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1536 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    448 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11570
Total latency (us): 4265.78

2022-05-13 17:47:53.722 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 17:48:19.486 INFO Sending 64 sample(s) to builder
2022-05-13 17:48:31.457 INFO Sending 64 sample(s) to runner
2022-05-13 17:48:31.519 INFO Scheduler picks Task #2: "fused_nn_conv2d_add_2"
2022-05-13 17:48:55.967 INFO Sending 64 sample(s) to builder
2022-05-13 17:49:21.590 INFO Sending 64 sample(s) to runner
2022-05-13 17:50:16.753 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2421.1569 |      85.0512 |               85.0512 |    192 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1536 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11634
Total latency (us): 4265.78

2022-05-13 17:51:08.063 INFO [Updated] Task #2: "fused_nn_conv2d_add_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2488.6790 |      82.7436 |               82.7436 |    256 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1536 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11698
Total latency (us): 4263.48

2022-05-13 17:51:08.063 INFO Scheduler picks Task #2: "fused_nn_conv2d_add_2"
2022-05-13 17:51:29.914 INFO Sending 64 sample(s) to builder
2022-05-13 17:51:37.676 INFO Sending 64 sample(s) to runner
2022-05-13 17:51:37.773 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 17:52:33.374 INFO Sending 64 sample(s) to builder
2022-05-13 17:53:00.250 INFO Sending 64 sample(s) to runner
2022-05-13 17:53:52.391 INFO [Updated] Task #2: "fused_nn_conv2d_add_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1536 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11762
Total latency (us): 4262.11

2022-05-13 17:55:00.479 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1600 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    576 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11826
Total latency (us): 4262.11

2022-05-13 17:55:00.479 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 17:55:21.651 INFO Sending 64 sample(s) to builder
2022-05-13 17:55:38.873 INFO Sending 64 sample(s) to runner
2022-05-13 17:56:53.676 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1600 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    640 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11890
Total latency (us): 4262.11

2022-05-13 17:56:53.676 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 17:57:14.992 INFO Sending 64 sample(s) to builder
2022-05-13 17:57:44.610 INFO Sending 64 sample(s) to runner
2022-05-13 17:57:44.684 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 17:58:14.795 INFO Sending 64 sample(s) to builder
2022-05-13 17:58:28.616 INFO Sending 64 sample(s) to runner
2022-05-13 17:59:35.808 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1600 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    704 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11954
Total latency (us): 4262.11

2022-05-13 18:00:16.256 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       738.7496 |     133.4701 |              667.3504 |   1600 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12018
Total latency (us): 4262.11

2022-05-13 18:00:16.256 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 18:01:12.215 INFO Sending 64 sample(s) to builder
2022-05-13 18:01:43.097 INFO Sending 64 sample(s) to runner
2022-05-13 18:02:40.711 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       742.1036 |     132.8668 |              664.3342 |   1664 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12082
Total latency (us): 4259.1

2022-05-13 18:02:40.711 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 18:03:55.711 INFO Sending 64 sample(s) to builder
2022-05-13 18:04:27.194 INFO Sending 64 sample(s) to runner
2022-05-13 18:04:27.234 INFO Scheduler picks Task #0: "fused_nn_conv2d_add"
2022-05-13 18:04:38.495 INFO Sending 64 sample(s) to builder
2022-05-13 18:04:52.786 INFO Sending 64 sample(s) to runner
2022-05-13 18:05:38.762 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    320 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12146
Total latency (us): 4256.13

2022-05-13 18:06:46.941 INFO [Updated] Task #0: "fused_nn_conv2d_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    384 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12210
Total latency (us): 4256.13

2022-05-13 18:06:46.942 INFO Scheduler picks Task #0: "fused_nn_conv2d_add"
2022-05-13 18:07:04.082 INFO Sending 64 sample(s) to builder
2022-05-13 18:07:14.248 INFO Sending 64 sample(s) to runner
2022-05-13 18:07:14.322 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 18:08:31.787 INFO Sending 64 sample(s) to builder
2022-05-13 18:09:14.033 INFO Sending 64 sample(s) to runner
2022-05-13 18:10:22.140 INFO [Updated] Task #0: "fused_nn_conv2d_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       755.7885 |     123.3507 |              370.0520 |    895 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12274
Total latency (us): 4256.13

2022-05-13 18:11:24.920 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       756.2192 |     123.2804 |              369.8412 |    959 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1703.5161 |      60.4993 |              181.4978 |    448 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12338
Total latency (us): 4255.92

2022-05-13 18:11:24.921 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 18:11:46.376 INFO Sending 64 sample(s) to builder
2022-05-13 18:12:00.215 INFO Sending 64 sample(s) to runner
2022-05-13 18:13:13.180 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       756.2192 |     123.2804 |              369.8412 |    959 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1706.5485 |      60.3918 |              181.1753 |    512 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12402
Total latency (us): 4255.59

2022-05-13 18:13:13.181 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 18:13:32.237 INFO Sending 64 sample(s) to builder
2022-05-13 18:13:50.425 INFO Sending 64 sample(s) to runner
2022-05-13 18:13:50.556 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 18:14:25.272 INFO Sending 64 sample(s) to builder
2022-05-13 18:14:32.980 INFO Sending 64 sample(s) to runner
2022-05-13 18:15:19.125 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    640 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       756.2192 |     123.2804 |              369.8412 |    959 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12466
Total latency (us): 4255.42

2022-05-13 18:16:27.468 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2858.2963 |      81.0316 |              243.0949 |    704 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       756.2192 |     123.2804 |              369.8412 |    959 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12530
Total latency (us): 4255.42

2022-05-13 18:16:27.468 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 18:16:46.326 INFO Sending 64 sample(s) to builder
2022-05-13 18:16:54.758 INFO Sending 64 sample(s) to runner
2022-05-13 18:16:54.844 INFO Scheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2022-05-13 18:17:17.033 INFO Sending 64 sample(s) to builder
2022-05-13 18:17:36.901 INFO Sending 64 sample(s) to runner
2022-05-13 18:18:32.429 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2634.5129 |      39.0817 |              117.2450 |    320 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       756.2192 |     123.2804 |              369.8412 |    959 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12594
Total latency (us): 4252.29

2022-05-13 18:19:38.264 INFO [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       756.2192 |     123.2804 |              369.8412 |    959 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    832 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12658
Total latency (us): 4252.15

2022-05-13 18:19:38.265 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 18:19:58.587 INFO Sending 64 sample(s) to builder
2022-05-13 18:20:18.931 INFO Sending 64 sample(s) to runner
2022-05-13 18:21:43.717 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       756.2192 |     123.2804 |              369.8412 |    959 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    896 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12722
Total latency (us): 4252.15

2022-05-13 18:21:43.717 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 18:21:57.055 INFO Sending 64 sample(s) to builder
2022-05-13 18:22:04.212 INFO Sending 64 sample(s) to runner
2022-05-13 18:22:04.298 INFO Scheduler picks Task #10: "fused_nn_conv2d_add_add_nn_relu"
2022-05-13 18:22:24.766 INFO Sending 64 sample(s) to builder
2022-05-13 18:22:35.665 INFO Sending 64 sample(s) to runner
2022-05-13 18:23:43.370 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2577.0711 |      40.8095 |              122.4284 |    320 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       756.2192 |     123.2804 |              369.8412 |    959 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12786
Total latency (us): 4252.15

2022-05-13 18:25:05.571 INFO [Updated] Task #10: "fused_nn_conv2d_add_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    384 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       756.2192 |     123.2804 |              369.8412 |    959 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12850
Total latency (us): 4251.95

2022-05-13 18:25:05.571 INFO Scheduler picks Task #10: "fused_nn_conv2d_add_add_nn_relu"
2022-05-13 18:25:30.478 INFO Sending 64 sample(s) to builder
2022-05-13 18:26:09.282 INFO Sending 64 sample(s) to runner
2022-05-13 18:26:09.329 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 18:27:05.059 INFO Sending 64 sample(s) to builder
2022-05-13 18:27:38.931 INFO Sending 64 sample(s) to runner
2022-05-13 18:28:33.108 INFO [Updated] Task #10: "fused_nn_conv2d_add_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       756.2192 |     123.2804 |              369.8412 |    959 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       745.4369 |     132.2727 |              661.3636 |   1728 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12914
Total latency (us): 4251.95

2022-05-13 18:29:59.311 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       756.2192 |     123.2804 |              369.8412 |    959 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       754.5120 |     130.6818 |              653.4088 |   1792 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12978
Total latency (us): 4244

2022-05-13 18:29:59.311 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 18:31:14.235 INFO Sending 64 sample(s) to builder
2022-05-13 18:31:52.699 INFO Sending 64 sample(s) to runner
2022-05-13 18:33:16.566 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1023 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       754.5120 |     130.6818 |              653.4088 |   1792 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13042
Total latency (us): 4243.06

2022-05-13 18:33:16.566 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 18:34:31.076 INFO Sending 64 sample(s) to builder
2022-05-13 18:35:08.075 INFO Sending 64 sample(s) to runner
2022-05-13 18:35:08.179 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 18:35:38.308 INFO Sending 64 sample(s) to builder
2022-05-13 18:35:49.192 INFO Sending 64 sample(s) to runner
2022-05-13 18:36:53.238 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       754.5120 |     130.6818 |              653.4088 |   1792 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    768 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13106
Total latency (us): 4243.06

2022-05-13 18:38:06.148 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       754.5120 |     130.6818 |              653.4088 |   1792 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13170
Total latency (us): 4243.06

2022-05-13 18:38:06.148 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 18:39:21.217 INFO Sending 64 sample(s) to builder
2022-05-13 18:39:42.989 INFO Sending 64 sample(s) to runner
2022-05-13 18:40:57.634 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       754.5120 |     130.6818 |              653.4088 |   1856 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13234
Total latency (us): 4243.06

2022-05-13 18:40:57.634 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 18:41:52.688 INFO Sending 64 sample(s) to builder
2022-05-13 18:42:28.769 INFO Sending 64 sample(s) to runner
2022-05-13 18:42:28.889 INFO Scheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_2"
2022-05-13 18:42:47.436 INFO Sending 64 sample(s) to builder
2022-05-13 18:42:52.682 INFO Sending 64 sample(s) to runner
2022-05-13 18:44:04.323 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2816.7594 |      36.6243 |               73.2486 |    192 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13298
Total latency (us): 4240.87

2022-05-13 18:44:56.991 INFO [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2826.6798 |      36.4958 |               72.9915 |    256 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2554.3032 |      40.7018 |              162.8071 |    448 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13362
Total latency (us): 4240.61

2022-05-13 18:44:56.991 INFO Scheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_2"
2022-05-13 18:45:11.197 INFO Sending 64 sample(s) to builder
2022-05-13 18:45:14.685 INFO Sending 64 sample(s) to runner
2022-05-13 18:45:14.723 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 18:45:28.786 INFO Sending 64 sample(s) to builder
2022-05-13 18:45:33.908 INFO Sending 64 sample(s) to runner
2022-05-13 18:46:42.094 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2826.6798 |      36.4958 |               72.9915 |    256 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2567.3345 |      40.4952 |              161.9807 |    512 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13426
Total latency (us): 4239.79

2022-05-13 18:46:42.094 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 18:47:01.878 INFO Sending 64 sample(s) to builder
2022-05-13 18:47:36.694 INFO Sending 64 sample(s) to runner
2022-05-13 18:48:48.402 INFO [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2567.3345 |      40.4952 |              161.9807 |    512 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13490
Total latency (us): 4236.97

2022-05-13 18:49:42.975 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    704 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13554
Total latency (us): 4236.12

2022-05-13 18:49:42.975 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 18:50:05.759 INFO Sending 64 sample(s) to builder
2022-05-13 18:50:21.307 INFO Sending 64 sample(s) to runner
2022-05-13 18:51:59.469 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    768 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13618
Total latency (us): 4236.12

2022-05-13 18:51:59.470 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 18:52:21.539 INFO Sending 64 sample(s) to builder
2022-05-13 18:52:40.027 INFO Sending 64 sample(s) to runner
2022-05-13 18:52:40.127 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2022-05-13 18:53:00.264 INFO Sending 64 sample(s) to builder
2022-05-13 18:53:07.609 INFO Sending 64 sample(s) to runner
2022-05-13 18:54:07.238 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    256 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13682
Total latency (us): 4236.12

2022-05-13 18:55:18.013 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2884.6499 |      71.5247 |               71.5247 |    320 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13746
Total latency (us): 4236.12

2022-05-13 18:55:18.013 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2022-05-13 18:55:33.108 INFO Sending 64 sample(s) to builder
2022-05-13 18:55:39.418 INFO Sending 64 sample(s) to runner
2022-05-13 18:55:39.458 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 18:55:58.001 INFO Sending 64 sample(s) to builder
2022-05-13 18:56:03.860 INFO Sending 64 sample(s) to runner
2022-05-13 18:56:56.860 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    384 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13810
Total latency (us): 4235.82

2022-05-13 18:58:15.226 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1860.5367 |     110.5711 |              110.5711 |    320 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13874
Total latency (us): 4235.82

2022-05-13 18:58:15.227 INFO Scheduler picks Task #1: "fused_nn_conv2d_add_1"
2022-05-13 18:58:34.815 INFO Sending 64 sample(s) to builder
2022-05-13 18:58:46.148 INFO Sending 64 sample(s) to runner
2022-05-13 19:00:16.855 INFO [Updated] Task #1: "fused_nn_conv2d_add_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    384 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13938
Total latency (us): 4232.9

2022-05-13 19:00:16.855 INFO Scheduler picks Task #1: "fused_nn_conv2d_add_1"
2022-05-13 19:00:38.734 INFO Sending 64 sample(s) to builder
2022-05-13 19:00:51.256 INFO Sending 64 sample(s) to runner
2022-05-13 19:00:51.320 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 19:01:16.137 INFO Sending 64 sample(s) to builder
2022-05-13 19:01:28.748 INFO Sending 64 sample(s) to runner
2022-05-13 19:02:30.070 INFO [Updated] Task #1: "fused_nn_conv2d_add_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    832 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14002
Total latency (us): 4232.9

2022-05-13 19:03:33.121 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      1155.3994 |      22.5823 |               22.5823 |     64 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14066
Total latency (us): 4232.9

2022-05-13 19:03:33.121 INFO Scheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_1"
2022-05-13 19:03:45.732 INFO Sending 64 sample(s) to builder
2022-05-13 19:03:51.213 INFO Sending 64 sample(s) to runner
2022-05-13 19:05:11.923 INFO [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2448.0655 |      10.6580 |               10.6580 |    128 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14130
Total latency (us): 4220.97

2022-05-13 19:05:11.923 INFO Scheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_1"
2022-05-13 19:05:24.474 INFO Sending 64 sample(s) to builder
2022-05-13 19:05:31.488 INFO Sending 64 sample(s) to runner
2022-05-13 19:05:31.548 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 19:06:47.430 INFO Sending 64 sample(s) to builder
2022-05-13 19:07:12.556 INFO Sending 64 sample(s) to runner
2022-05-13 19:07:57.329 INFO [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       757.0516 |     130.2434 |              651.2169 |   1920 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14194
Total latency (us): 4220.79

2022-05-13 19:08:46.503 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       760.7460 |     129.6109 |              648.0544 |   1984 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    704 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14258
Total latency (us): 4217.63

2022-05-13 19:08:46.503 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 19:09:01.399 INFO Sending 64 sample(s) to builder
2022-05-13 19:09:07.592 INFO Sending 64 sample(s) to runner
2022-05-13 19:10:40.836 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       760.7460 |     129.6109 |              648.0544 |   1984 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    768 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14322
Total latency (us): 4217.63

2022-05-13 19:10:40.836 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 19:10:55.658 INFO Sending 64 sample(s) to builder
2022-05-13 19:11:12.353 INFO Sending 64 sample(s) to runner
2022-05-13 19:11:12.475 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 19:11:38.225 INFO Sending 64 sample(s) to builder
2022-05-13 19:11:58.193 INFO Sending 64 sample(s) to runner
2022-05-13 19:13:21.831 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       760.7460 |     129.6109 |              648.0544 |   1984 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |    960 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14386
Total latency (us): 4217.63

2022-05-13 19:14:18.424 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       760.7460 |     129.6109 |              648.0544 |   1984 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1024 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14450
Total latency (us): 4217.63

2022-05-13 19:14:18.424 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 19:14:34.817 INFO Sending 64 sample(s) to builder
2022-05-13 19:14:45.746 INFO Sending 64 sample(s) to runner
2022-05-13 19:14:45.831 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 19:15:31.455 INFO Sending 64 sample(s) to builder
2022-05-13 19:16:08.240 INFO Sending 64 sample(s) to runner
2022-05-13 19:17:23.891 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1087 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       760.7460 |     129.6109 |              648.0544 |   1984 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14514
Total latency (us): 4217.63

2022-05-13 19:18:43.504 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1151 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       760.7460 |     129.6109 |              648.0544 |   1984 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14578
Total latency (us): 4217.63

2022-05-13 19:18:43.504 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 19:19:36.931 INFO Sending 64 sample(s) to builder
2022-05-13 19:20:13.441 INFO Sending 64 sample(s) to runner
2022-05-13 19:20:13.549 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 19:20:45.071 INFO Sending 64 sample(s) to builder
2022-05-13 19:21:07.437 INFO Sending 64 sample(s) to runner
2022-05-13 19:22:20.385 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       760.7460 |     129.6109 |              648.0544 |   1984 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    512 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14642
Total latency (us): 4217.63

2022-05-13 19:23:27.667 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       760.7460 |     129.6109 |              648.0544 |   1984 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14706
Total latency (us): 4217.63

2022-05-13 19:23:27.667 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 19:24:42.386 INFO Sending 64 sample(s) to builder
2022-05-13 19:25:01.200 INFO Sending 64 sample(s) to runner
2022-05-13 19:26:32.622 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       760.7460 |     129.6109 |              648.0544 |   2048 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14770
Total latency (us): 4217.63

2022-05-13 19:26:32.622 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 19:27:50.509 INFO Sending 64 sample(s) to builder
2022-05-13 19:28:12.670 INFO Sending 64 sample(s) to runner
2022-05-13 19:28:12.709 INFO Scheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2022-05-13 19:28:31.626 INFO Sending 64 sample(s) to builder
2022-05-13 19:28:52.951 INFO Sending 64 sample(s) to runner
2022-05-13 19:30:02.672 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2637.7227 |      39.0341 |              117.1023 |    384 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       772.7086 |     127.6043 |              638.0216 |   2112 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14834
Total latency (us): 4207.6

2022-05-13 19:31:04.697 INFO [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2669.7168 |      38.5663 |              115.6990 |    448 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       772.7086 |     127.6043 |              638.0216 |   2112 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14898
Total latency (us): 4206.2

2022-05-13 19:31:04.697 INFO Scheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2022-05-13 19:31:23.713 INFO Sending 64 sample(s) to builder
2022-05-13 19:31:34.441 INFO Sending 64 sample(s) to runner
2022-05-13 19:31:34.513 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 19:32:01.090 INFO Sending 64 sample(s) to builder
2022-05-13 19:32:20.066 INFO Sending 64 sample(s) to runner
2022-05-13 19:33:25.844 INFO [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       772.7086 |     127.6043 |              638.0216 |   2112 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    896 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14962
Total latency (us): 4205.35

2022-05-13 19:34:25.287 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       772.7086 |     127.6043 |              638.0216 |   2112 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    960 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15026
Total latency (us): 4205.35

2022-05-13 19:34:25.287 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 19:35:22.324 INFO Sending 64 sample(s) to builder
2022-05-13 19:35:51.412 INFO Sending 64 sample(s) to runner
2022-05-13 19:37:03.350 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       772.7086 |     127.6043 |              638.0216 |   2176 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    960 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15090
Total latency (us): 4205.35

2022-05-13 19:37:03.350 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 19:38:08.115 INFO Sending 64 sample(s) to builder
2022-05-13 19:38:38.741 INFO Sending 64 sample(s) to runner
2022-05-13 19:38:38.859 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 19:39:02.158 INFO Sending 64 sample(s) to builder
2022-05-13 19:39:15.468 INFO Sending 64 sample(s) to runner
2022-05-13 19:40:07.511 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    832 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    960 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15154
Total latency (us): 4200.57

2022-05-13 19:41:00.430 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    896 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    960 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15218
Total latency (us): 4200.57

2022-05-13 19:41:00.431 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 19:41:14.750 INFO Sending 64 sample(s) to builder
2022-05-13 19:41:21.558 INFO Sending 64 sample(s) to runner
2022-05-13 19:41:21.596 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 19:41:40.014 INFO Sending 64 sample(s) to builder
2022-05-13 19:41:45.350 INFO Sending 64 sample(s) to runner
2022-05-13 19:42:34.164 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2895.5945 |      79.9879 |              239.9636 |    768 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    960 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15282
Total latency (us): 4200.57

2022-05-13 19:43:14.912 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2938.0452 |      78.8321 |              236.4964 |    832 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    960 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    576 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15346
Total latency (us): 4197.1

2022-05-13 19:43:14.913 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 19:43:34.270 INFO Sending 64 sample(s) to builder
2022-05-13 19:43:40.393 INFO Sending 64 sample(s) to runner
2022-05-13 19:43:40.431 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 19:43:48.880 INFO Sending 64 sample(s) to builder
2022-05-13 19:43:55.805 INFO Sending 64 sample(s) to runner
2022-05-13 19:44:54.016 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2938.0452 |      78.8321 |              236.4964 |    832 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    960 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    640 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15410
Total latency (us): 4197.1

2022-05-13 19:44:54.016 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 19:45:05.669 INFO Sending 64 sample(s) to builder
2022-05-13 19:45:14.596 INFO Sending 64 sample(s) to runner
2022-05-13 19:46:10.284 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    960 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    640 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15474
Total latency (us): 4196.47

2022-05-13 19:46:58.600 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1671.2346 |     138.4075 |              138.4075 |    448 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    960 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15538
Total latency (us): 4196.47

2022-05-13 19:46:58.601 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 19:47:16.944 INFO Sending 64 sample(s) to builder
2022-05-13 19:47:25.489 INFO Sending 64 sample(s) to runner
2022-05-13 19:48:25.258 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    512 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    960 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15602
Total latency (us): 4195.68

2022-05-13 19:48:25.258 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 19:48:40.814 INFO Sending 64 sample(s) to builder
2022-05-13 19:48:45.919 INFO Sending 64 sample(s) to runner
2022-05-13 19:48:45.986 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 19:49:02.526 INFO Sending 64 sample(s) to builder
2022-05-13 19:49:14.084 INFO Sending 64 sample(s) to runner
2022-05-13 19:49:59.448 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |    960 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15666
Total latency (us): 4195.68

2022-05-13 19:50:32.998 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       758.1309 |     122.9695 |              368.9086 |   1215 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15730
Total latency (us): 4195.68

2022-05-13 19:50:32.998 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 19:51:10.219 INFO Sending 64 sample(s) to builder
2022-05-13 19:51:27.265 INFO Sending 64 sample(s) to runner
2022-05-13 19:52:31.619 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1279 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15794
Total latency (us): 4193.25

2022-05-13 19:52:31.619 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 19:53:08.911 INFO Sending 64 sample(s) to builder
2022-05-13 19:53:26.880 INFO Sending 64 sample(s) to runner
2022-05-13 19:53:26.920 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 19:53:39.154 INFO Sending 64 sample(s) to builder
2022-05-13 19:53:48.565 INFO Sending 64 sample(s) to runner
2022-05-13 19:54:37.719 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1088 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15858
Total latency (us): 4193.25

2022-05-13 19:55:26.929 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2240 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1152 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15922
Total latency (us): 4193.25

2022-05-13 19:55:26.929 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 19:56:08.359 INFO Sending 64 sample(s) to builder
2022-05-13 19:56:25.833 INFO Sending 64 sample(s) to runner
2022-05-13 19:57:27.803 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2304 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1152 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1350.4401 |     171.2488 |              171.2488 |    576 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15986
Total latency (us): 4193.25

2022-05-13 19:57:27.803 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 19:58:09.319 INFO Sending 64 sample(s) to builder
2022-05-13 19:58:22.452 INFO Sending 64 sample(s) to runner
2022-05-13 19:58:22.490 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 19:58:34.614 INFO Sending 64 sample(s) to builder
2022-05-13 19:58:40.622 INFO Sending 64 sample(s) to runner
2022-05-13 19:59:46.245 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2304 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1152 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    640 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16050
Total latency (us): 4182.85

2022-05-13 19:59:46.246 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 19:59:58.410 INFO Sending 64 sample(s) to builder
2022-05-13 20:00:05.224 INFO Sending 64 sample(s) to runner
2022-05-13 20:00:39.394 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1152 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    640 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16114
Total latency (us): 4182.85

2022-05-13 20:01:17.558 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1152 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    832 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16178
Total latency (us): 4182.85

2022-05-13 20:01:17.558 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 20:01:25.615 INFO Sending 64 sample(s) to builder
2022-05-13 20:01:29.825 INFO Sending 64 sample(s) to runner
2022-05-13 20:02:23.097 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    448 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1152 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    896 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16242
Total latency (us): 4182.85

2022-05-13 20:02:23.097 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 20:02:30.982 INFO Sending 64 sample(s) to builder
2022-05-13 20:02:34.790 INFO Sending 64 sample(s) to runner
2022-05-13 20:02:34.827 INFO Scheduler picks Task #0: "fused_nn_conv2d_add"
2022-05-13 20:02:42.761 INFO Sending 64 sample(s) to builder
2022-05-13 20:02:48.628 INFO Sending 64 sample(s) to runner
2022-05-13 20:03:45.570 INFO [Updated] Task #0: "fused_nn_conv2d_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    512 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1152 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    896 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16306
Total latency (us): 4182.85

2022-05-13 20:03:45.570 INFO Scheduler picks Task #0: "fused_nn_conv2d_add"
2022-05-13 20:03:53.652 INFO Sending 64 sample(s) to builder
2022-05-13 20:04:00.152 INFO Sending 64 sample(s) to runner
2022-05-13 20:04:41.800 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    512 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1152 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16370
Total latency (us): 4182.85

2022-05-13 20:04:41.800 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 20:04:54.149 INFO Sending 64 sample(s) to builder
2022-05-13 20:05:01.445 INFO Sending 64 sample(s) to runner
2022-05-13 20:05:37.594 INFO [Updated] Task #0: "fused_nn_conv2d_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1152 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1024 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16434
Total latency (us): 4182.85

2022-05-13 20:06:14.899 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1152 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16498
Total latency (us): 4182.85

2022-05-13 20:06:14.899 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 20:06:23.991 INFO Sending 64 sample(s) to builder
2022-05-13 20:06:37.401 INFO Sending 64 sample(s) to runner
2022-05-13 20:07:39.262 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1216 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1887.3152 |     109.0022 |              109.0022 |    384 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16562
Total latency (us): 4182.85

2022-05-13 20:07:39.262 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 20:07:48.388 INFO Sending 64 sample(s) to builder
2022-05-13 20:07:54.598 INFO Sending 64 sample(s) to runner
2022-05-13 20:07:54.643 INFO Scheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_10"
2022-05-13 20:08:03.117 INFO Sending 64 sample(s) to builder
2022-05-13 20:08:07.149 INFO Sending 64 sample(s) to runner
2022-05-13 20:09:12.034 INFO [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_10"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1216 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    448 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16626
Total latency (us): 4182.75

2022-05-13 20:09:12.034 INFO Scheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_10"
2022-05-13 20:09:20.525 INFO Sending 64 sample(s) to builder
2022-05-13 20:09:29.104 INFO Sending 64 sample(s) to runner
2022-05-13 20:10:11.917 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    448 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16690
Total latency (us): 4182.75

2022-05-13 20:10:53.678 INFO [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_10"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2580.8513 |      40.2831 |              161.1324 |    576 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16754
Total latency (us): 4182.75

2022-05-13 20:10:53.678 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 20:11:03.111 INFO Sending 64 sample(s) to builder
2022-05-13 20:11:17.845 INFO Sending 64 sample(s) to runner
2022-05-13 20:12:13.678 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    640 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       113.8228 |      35.9945 |               35.9945 |    128 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16818
Total latency (us): 4182.39

2022-05-13 20:12:13.678 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 20:12:23.256 INFO Sending 64 sample(s) to builder
2022-05-13 20:12:36.085 INFO Sending 64 sample(s) to runner
2022-05-13 20:12:36.130 INFO Scheduler picks Task #28: "fused_nn_dense_add"
2022-05-13 20:12:41.109 INFO Sending 64 sample(s) to builder
2022-05-13 20:12:46.489 INFO Sending 64 sample(s) to runner
2022-05-13 20:13:51.768 INFO [Updated] Task #28: "fused_nn_dense_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    640 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       120.9549 |      33.8721 |               33.8721 |    192 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16882
Total latency (us): 4180.27

2022-05-13 20:13:51.768 INFO Scheduler picks Task #28: "fused_nn_dense_add"
2022-05-13 20:13:56.843 INFO Sending 64 sample(s) to builder
2022-05-13 20:14:00.973 INFO Sending 64 sample(s) to runner
2022-05-13 20:14:35.738 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       120.9549 |      33.8721 |               33.8721 |    192 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16946
Total latency (us): 4180.27

2022-05-13 20:15:06.069 INFO [Updated] Task #28: "fused_nn_dense_add"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1343 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17010
Total latency (us): 4179.94

2022-05-13 20:15:06.070 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 20:15:37.280 INFO Sending 64 sample(s) to builder
2022-05-13 20:15:49.905 INFO Sending 64 sample(s) to runner
2022-05-13 20:16:41.633 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1407 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17074
Total latency (us): 4179.94

2022-05-13 20:16:41.633 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 20:17:12.907 INFO Sending 64 sample(s) to builder
2022-05-13 20:17:25.638 INFO Sending 64 sample(s) to runner
2022-05-13 20:17:25.676 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-13 20:17:40.935 INFO Sending 64 sample(s) to builder
2022-05-13 20:17:46.148 INFO Sending 64 sample(s) to runner
2022-05-13 20:18:32.357 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2433.0880 |      97.6675 |               97.6675 |    384 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17138
Total latency (us): 4179.94

2022-05-13 20:19:10.931 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2479.8874 |      95.8243 |               95.8243 |    448 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |    960 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17202
Total latency (us): 4178.1

2022-05-13 20:19:10.931 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-13 20:19:26.051 INFO Sending 64 sample(s) to builder
2022-05-13 20:19:34.453 INFO Sending 64 sample(s) to runner
2022-05-13 20:19:34.490 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 20:19:43.244 INFO Sending 64 sample(s) to builder
2022-05-13 20:19:48.817 INFO Sending 64 sample(s) to runner
2022-05-13 20:20:48.223 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2479.8874 |      95.8243 |               95.8243 |    448 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1024 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17266
Total latency (us): 4178.1

2022-05-13 20:20:48.223 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 20:20:56.847 INFO Sending 64 sample(s) to builder
2022-05-13 20:21:01.975 INFO Sending 64 sample(s) to runner
2022-05-13 20:21:49.035 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1024 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17330
Total latency (us): 4176.51

2022-05-13 20:22:31.096 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       778.5485 |     126.6472 |              633.2358 |   2368 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17394
Total latency (us): 4176.51

2022-05-13 20:22:31.097 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 20:23:03.268 INFO Sending 64 sample(s) to builder
2022-05-13 20:23:13.133 INFO Sending 64 sample(s) to runner
2022-05-13 20:24:18.374 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2432 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17458
Total latency (us): 4172.76

2022-05-13 20:24:18.374 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 20:24:50.224 INFO Sending 64 sample(s) to builder
2022-05-13 20:25:00.690 INFO Sending 64 sample(s) to runner
2022-05-13 20:25:00.726 INFO Scheduler picks Task #10: "fused_nn_conv2d_add_add_nn_relu"
2022-05-13 20:25:10.014 INFO Sending 64 sample(s) to builder
2022-05-13 20:25:19.400 INFO Sending 64 sample(s) to runner
2022-05-13 20:26:06.543 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    448 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17522
Total latency (us): 4172.76

2022-05-13 20:26:47.473 INFO [Updated] Task #10: "fused_nn_conv2d_add_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2581.1917 |      40.7443 |              122.2330 |    512 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17586
Total latency (us): 4172.76

2022-05-13 20:26:47.473 INFO Scheduler picks Task #10: "fused_nn_conv2d_add_add_nn_relu"
2022-05-13 20:26:56.893 INFO Sending 64 sample(s) to builder
2022-05-13 20:27:05.227 INFO Sending 64 sample(s) to runner
2022-05-13 20:27:05.272 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 20:27:20.089 INFO Sending 64 sample(s) to builder
2022-05-13 20:27:25.941 INFO Sending 64 sample(s) to runner
2022-05-13 20:28:11.399 INFO [Updated] Task #10: "fused_nn_conv2d_add_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    896 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17650
Total latency (us): 4172.32

2022-05-13 20:28:47.335 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    960 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1088 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17714
Total latency (us): 4172.32

2022-05-13 20:28:47.335 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 20:29:02.443 INFO Sending 64 sample(s) to builder
2022-05-13 20:29:08.190 INFO Sending 64 sample(s) to runner
2022-05-13 20:29:08.228 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 20:29:20.156 INFO Sending 64 sample(s) to builder
2022-05-13 20:29:25.179 INFO Sending 64 sample(s) to runner
2022-05-13 20:30:30.607 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |    960 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1152 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17778
Total latency (us): 4172.32

2022-05-13 20:30:30.608 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 20:30:46.557 INFO Sending 64 sample(s) to builder
2022-05-13 20:30:56.845 INFO Sending 64 sample(s) to runner
2022-05-13 20:31:31.750 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1152 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17842
Total latency (us): 4172.32

2022-05-13 20:32:02.941 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2507.7099 |      92.2801 |               92.2801 |    384 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17906
Total latency (us): 4172.32

2022-05-13 20:32:02.942 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2022-05-13 20:32:16.442 INFO Sending 64 sample(s) to builder
2022-05-13 20:32:20.777 INFO Sending 64 sample(s) to runner
2022-05-13 20:33:04.449 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2696.9433 |      85.8052 |               85.8052 |    448 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17970
Total latency (us): 4165.85

2022-05-13 20:33:04.449 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2022-05-13 20:33:18.212 INFO Sending 64 sample(s) to builder
2022-05-13 20:33:22.424 INFO Sending 64 sample(s) to runner
2022-05-13 20:33:22.462 INFO Scheduler picks Task #2: "fused_nn_conv2d_add_2"
2022-05-13 20:33:30.942 INFO Sending 64 sample(s) to builder
2022-05-13 20:33:42.646 INFO Sending 64 sample(s) to runner
2022-05-13 20:34:12.585 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2530.3834 |      81.3799 |               81.3799 |    320 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18034
Total latency (us): 4164.38

2022-05-13 20:34:45.333 INFO [Updated] Task #2: "fused_nn_conv2d_add_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    384 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    704 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18098
Total latency (us): 4163.25

2022-05-13 20:34:45.334 INFO Scheduler picks Task #2: "fused_nn_conv2d_add_2"
2022-05-13 20:34:53.686 INFO Sending 64 sample(s) to builder
2022-05-13 20:35:05.563 INFO Sending 64 sample(s) to runner
2022-05-13 20:35:05.601 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 20:35:13.983 INFO Sending 64 sample(s) to builder
2022-05-13 20:35:21.251 INFO Sending 64 sample(s) to runner
2022-05-13 20:36:12.043 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    384 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    768 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18162
Total latency (us): 4163.25

2022-05-13 20:36:12.043 INFO Scheduler picks Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
2022-05-13 20:36:20.298 INFO Sending 64 sample(s) to builder
2022-05-13 20:36:54.138 INFO Sending 64 sample(s) to runner
2022-05-13 20:37:26.924 INFO [Updated] Task #2: "fused_nn_conv2d_add_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    768 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18226
Total latency (us): 4163.25

2022-05-13 20:37:55.478 INFO [Updated] Task #25: "fused_nn_conv2d_add_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2496 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18290
Total latency (us): 4163.25

2022-05-13 20:37:55.479 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 20:38:26.910 INFO Sending 64 sample(s) to builder
2022-05-13 20:38:35.439 INFO Sending 64 sample(s) to runner
2022-05-13 20:39:26.580 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2560 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1280 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18354
Total latency (us): 4163.25

2022-05-13 20:39:26.581 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 20:39:57.780 INFO Sending 64 sample(s) to builder
2022-05-13 20:40:08.645 INFO Sending 64 sample(s) to runner
2022-05-13 20:40:08.683 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 20:40:17.693 INFO Sending 64 sample(s) to builder
2022-05-13 20:40:24.558 INFO Sending 64 sample(s) to runner
2022-05-13 20:41:16.051 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2560 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1344 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18418
Total latency (us): 4163.25

2022-05-13 20:41:16.051 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 20:41:24.954 INFO Sending 64 sample(s) to builder
2022-05-13 20:41:58.658 INFO Sending 64 sample(s) to runner
2022-05-13 20:42:28.053 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1344 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18482
Total latency (us): 4163.25

2022-05-13 20:42:57.007 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |    960 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18546
Total latency (us): 4163.25

2022-05-13 20:42:57.007 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 20:43:04.971 INFO Sending 64 sample(s) to builder
2022-05-13 20:43:11.390 INFO Sending 64 sample(s) to runner
2022-05-13 20:43:58.990 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1911.1040 |     107.6454 |              107.6454 |    448 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1024 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18610
Total latency (us): 4163.25

2022-05-13 20:43:58.991 INFO Scheduler picks Task #23: "fused_nn_conv2d_add_nn_relu_12"
2022-05-13 20:44:06.795 INFO Sending 64 sample(s) to builder
2022-05-13 20:44:12.588 INFO Sending 64 sample(s) to runner
2022-05-13 20:44:12.626 INFO Scheduler picks Task #1: "fused_nn_conv2d_add_1"
2022-05-13 20:44:20.819 INFO Sending 64 sample(s) to builder
2022-05-13 20:44:26.777 INFO Sending 64 sample(s) to runner
2022-05-13 20:45:25.461 INFO [Updated] Task #1: "fused_nn_conv2d_add_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    512 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1024 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18674
Total latency (us): 4162.13

2022-05-13 20:45:25.461 INFO Scheduler picks Task #1: "fused_nn_conv2d_add_1"
2022-05-13 20:45:33.879 INFO Sending 64 sample(s) to builder
2022-05-13 20:45:39.768 INFO Sending 64 sample(s) to runner
2022-05-13 20:46:13.208 INFO [Updated] Task #23: "fused_nn_conv2d_add_nn_relu_12"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    512 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18738
Total latency (us): 4162.13

2022-05-13 20:46:13.208 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 20:46:43.846 INFO Sending 64 sample(s) to builder
2022-05-13 20:47:03.662 INFO Sending 64 sample(s) to runner
2022-05-13 20:47:33.847 INFO [Updated] Task #1: "fused_nn_conv2d_add_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1471 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18802
Total latency (us): 4162.13

2022-05-13 20:48:03.038 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1535 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1216 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18866
Total latency (us): 4162.13

2022-05-13 20:48:03.039 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 20:48:15.172 INFO Sending 64 sample(s) to builder
2022-05-13 20:48:22.984 INFO Sending 64 sample(s) to runner
2022-05-13 20:49:12.761 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1535 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1088 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1280 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18930
Total latency (us): 4162.13

2022-05-13 20:49:12.761 INFO Scheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2022-05-13 20:49:24.762 INFO Sending 64 sample(s) to builder
2022-05-13 20:49:32.499 INFO Sending 64 sample(s) to runner
2022-05-13 20:49:32.537 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 20:49:41.314 INFO Sending 64 sample(s) to builder
2022-05-13 20:49:46.498 INFO Sending 64 sample(s) to runner
2022-05-13 20:50:45.195 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1535 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1152 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1280 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18994
Total latency (us): 4162.13

2022-05-13 20:50:45.195 INFO Scheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2022-05-13 20:50:53.601 INFO Sending 64 sample(s) to builder
2022-05-13 20:50:59.189 INFO Sending 64 sample(s) to runner
2022-05-13 20:51:33.794 INFO [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1535 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1152 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19058
Total latency (us): 4162.13

2022-05-13 20:51:33.794 INFO Scheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_11"
2022-05-13 20:51:45.540 INFO Sending 64 sample(s) to builder
2022-05-13 20:51:50.365 INFO Sending 64 sample(s) to runner
2022-05-13 20:52:24.866 INFO [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1535 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1437.7302 |     160.8516 |              160.8516 |    704 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19122
Total latency (us): 4162.13

2022-05-13 20:52:54.285 INFO [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_11"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1535 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1680.9029 |     137.6114 |              137.6114 |    576 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19186
Total latency (us): 4161.04

2022-05-13 20:52:54.285 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 20:53:07.168 INFO Sending 64 sample(s) to builder
2022-05-13 20:53:12.138 INFO Sending 64 sample(s) to runner
2022-05-13 20:53:58.446 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1535 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1684.8927 |     137.2855 |              137.2855 |    640 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19250
Total latency (us): 4160.71

2022-05-13 20:53:58.446 INFO Scheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2022-05-13 20:54:11.416 INFO Sending 64 sample(s) to builder
2022-05-13 20:54:17.241 INFO Sending 64 sample(s) to runner
2022-05-13 20:54:17.279 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 20:54:48.519 INFO Sending 64 sample(s) to builder
2022-05-13 20:54:59.774 INFO Sending 64 sample(s) to runner
2022-05-13 20:55:35.275 INFO [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1535 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2624 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19314
Total latency (us): 4159.33

2022-05-13 20:55:59.556 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1535 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2688 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19378
Total latency (us): 4159.33

2022-05-13 20:55:59.557 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 20:56:29.865 INFO Sending 64 sample(s) to builder
2022-05-13 20:56:40.870 INFO Sending 64 sample(s) to runner
2022-05-13 20:57:29.781 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1599 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2688 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19442
Total latency (us): 4159.33

2022-05-13 20:57:29.781 INFO Scheduler picks Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2022-05-13 20:58:00.234 INFO Sending 64 sample(s) to builder
2022-05-13 20:58:15.013 INFO Sending 64 sample(s) to runner
2022-05-13 20:58:15.051 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 20:58:46.985 INFO Sending 64 sample(s) to builder
2022-05-13 20:58:57.595 INFO Sending 64 sample(s) to runner
2022-05-13 20:59:27.196 INFO [Updated] Task #14: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1663 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2688 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19506
Total latency (us): 4159.33

2022-05-13 20:59:53.484 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1663 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2752 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1408 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19570
Total latency (us): 4159.33

2022-05-13 20:59:53.484 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 21:00:02.459 INFO Sending 64 sample(s) to builder
2022-05-13 21:00:09.831 INFO Sending 64 sample(s) to runner
2022-05-13 21:01:06.634 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1663 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2752 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1472 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19634
Total latency (us): 4159.33

2022-05-13 21:01:06.634 INFO Scheduler picks Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
2022-05-13 21:01:15.638 INFO Sending 64 sample(s) to builder
2022-05-13 21:01:23.928 INFO Sending 64 sample(s) to runner
2022-05-13 21:01:23.974 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 21:01:38.650 INFO Sending 64 sample(s) to builder
2022-05-13 21:01:44.927 INFO Sending 64 sample(s) to runner
2022-05-13 21:02:14.853 INFO [Updated] Task #20: "fused_nn_conv2d_add_add_nn_relu_2"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1024 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1663 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2752 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1536 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19698
Total latency (us): 4159.33

2022-05-13 21:02:42.959 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1088 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1663 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    704 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2752 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1536 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19762
Total latency (us): 4159.33

2022-05-13 21:02:42.959 INFO Scheduler picks Task #9: "fused_nn_conv2d_add_nn_relu_3"
2022-05-13 21:02:57.808 INFO Sending 64 sample(s) to builder
2022-05-13 21:03:03.106 INFO Sending 64 sample(s) to runner
2022-05-13 21:03:03.144 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 21:03:12.310 INFO Sending 64 sample(s) to builder
2022-05-13 21:03:16.915 INFO Sending 64 sample(s) to runner
2022-05-13 21:04:11.233 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1088 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1663 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    768 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2752 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1536 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19826
Total latency (us): 4159.33

2022-05-13 21:04:11.233 INFO Scheduler picks Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
2022-05-13 21:04:20.747 INFO Sending 64 sample(s) to builder
2022-05-13 21:04:25.130 INFO Sending 64 sample(s) to runner
2022-05-13 21:05:02.044 INFO [Updated] Task #9: "fused_nn_conv2d_add_nn_relu_3"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1152 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1663 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    768 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2752 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1536 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19890
Total latency (us): 4159.33

2022-05-13 21:05:32.266 INFO [Updated] Task #15: "fused_nn_conv2d_add_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |            
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |            
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |            
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |            
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |            
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |            
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |            
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |            
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |            
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1152 |            
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |            
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |            
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |            
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |            
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1663 |            
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    832 |            
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |            
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |            
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |            
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       783.1782 |     125.8985 |              629.4925 |   2752 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1536 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19954
Total latency (us): 4159.33

2022-05-13 21:05:32.266 INFO Scheduler picks Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2022-05-13 21:06:03.898 INFO Sending 64 sample(s) to builder
2022-05-13 21:06:21.524 INFO Sending 64 sample(s) to runner
2022-05-13 21:06:21.562 INFO Task #0 has finished. Remaining task(s): 28
2022-05-13 21:06:21.562 INFO Task #1 has finished. Remaining task(s): 27
2022-05-13 21:06:21.563 INFO Task #2 has finished. Remaining task(s): 26
2022-05-13 21:06:21.563 INFO Task #3 has finished. Remaining task(s): 25
2022-05-13 21:06:21.563 INFO Task #4 has finished. Remaining task(s): 24
2022-05-13 21:06:21.564 INFO Task #5 has finished. Remaining task(s): 23
2022-05-13 21:06:21.564 INFO Task #6 has finished. Remaining task(s): 22
2022-05-13 21:06:21.564 INFO Task #7 has finished. Remaining task(s): 21
2022-05-13 21:06:21.564 INFO Task #8 has finished. Remaining task(s): 20
2022-05-13 21:06:21.565 INFO Task #9 has finished. Remaining task(s): 19
2022-05-13 21:06:21.565 INFO Task #10 has finished. Remaining task(s): 18
2022-05-13 21:06:21.566 INFO Task #11 has finished. Remaining task(s): 17
2022-05-13 21:06:21.566 INFO Task #12 has finished. Remaining task(s): 16
2022-05-13 21:06:21.566 INFO Task #13 has finished. Remaining task(s): 15
2022-05-13 21:06:21.567 INFO Task #14 has finished. Remaining task(s): 14
2022-05-13 21:06:21.567 INFO Task #15 has finished. Remaining task(s): 13
2022-05-13 21:06:21.567 INFO Task #16 has finished. Remaining task(s): 12
2022-05-13 21:06:21.568 INFO Task #17 has finished. Remaining task(s): 11
2022-05-13 21:06:21.568 INFO Task #18 has finished. Remaining task(s): 10
2022-05-13 21:07:04.287 INFO [Updated] Task #19: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                                                     fused_nn_conv2d_add | 205621248 |      1 |      1583.1843 |     129.8783 |              129.8783 |    576 |          Y 
  1 |                                                   fused_nn_conv2d_add_1 | 205721600 |      1 |      1931.1140 |     106.5300 |              106.5300 |    576 |          Y 
  2 |                                                   fused_nn_conv2d_add_2 | 205922304 |      1 |      2565.9935 |      80.2505 |               80.2505 |    448 |          Y 
  3 |                                                   fused_nn_conv2d_add_3 | 103563264 |      1 |      2799.0189 |      36.9998 |               36.9998 |    192 |          Y 
  4 |                                                  fused_layout_transform |         1 |      1 |         0.0003 |       3.1246 |                3.1246 |      8 |          Y 
  5 |                                             fused_nn_conv2d_add_nn_relu | 237633536 |      1 |      2521.7789 |      94.2325 |               94.2325 |    512 |          Y 
  6 |                                                     fused_nn_max_pool2d |   1806336 |      1 |       269.6729 |       6.6982 |                6.6982 |     40 |          Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_1 |  26091520 |      1 |      2489.3721 |      10.4812 |               10.4812 |    192 |          Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_2 | 103161856 |      2 |      2940.1012 |      35.0879 |               70.1757 |    320 |          Y 
  9 |                                           fused_nn_conv2d_add_nn_relu_3 | 231612416 |      3 |      2945.8619 |      78.6230 |              235.8689 |   1152 |          Y 
 10 |                                         fused_nn_conv2d_add_add_nn_relu | 105168896 |      3 |      2590.5213 |      40.5976 |              121.7927 |    576 |          Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 | 206323712 |      1 |      2896.8702 |      71.2230 |               71.2230 |    384 |          Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 | 231411712 |      1 |      2743.9418 |      84.3355 |               84.3355 |    512 |          Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 | 102961152 |      3 |      2689.3241 |      38.2851 |              114.8554 |    512 |          Y 
 14 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  93227008 |      3 |       763.1470 |     122.1613 |              366.4838 |   1663 |          Y 
 15 |                                       fused_nn_conv2d_add_add_nn_relu_1 | 103964672 |      4 |      2586.5605 |      40.1942 |              160.7767 |    832 |          Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 | 205922304 |      1 |      2661.0417 |      77.3841 |               77.3841 |    384 |          Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 | 231311360 |      1 |      1701.9840 |     135.9069 |              135.9069 |    704 |          Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 | 102860800 |      5 |      1951.8569 |      52.6989 |              263.4947 |   1216 |          Y 
 19 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  98600960 |      5 |       943.1561 |     104.5436 |              522.7181 |   2816 |            
 20 |                                       fused_nn_conv2d_add_add_nn_relu_2 | 103362560 |      6 |      1885.9641 |      54.8062 |              328.8373 |   1536 |            
 21 |                                          fused_nn_conv2d_add_nn_relu_10 | 205721600 |      1 |      1889.1861 |     108.8943 |              108.8943 |    512 |            
 22 |                                          fused_nn_conv2d_add_nn_relu_11 | 231261184 |      1 |      1447.6015 |     159.7547 |              159.7547 |    768 |            
 23 |                                          fused_nn_conv2d_add_nn_relu_12 | 102810624 |      2 |       836.5748 |     122.8947 |              245.7894 |   1088 |            
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 231261184 |      2 |      1564.7781 |     147.7917 |              295.5834 |   1344 |            
 25 |                                       fused_nn_conv2d_add_add_nn_relu_3 | 103061504 |      3 |      1708.1899 |      60.3337 |              181.0012 |    832 |            
 26 |                                            fused_nn_adaptive_avg_pool2d |    102400 |      1 |        31.1621 |       3.2860 |                3.2860 |     63 |            
 27 |                                  fused_layout_transform_reshape_squeeze |         1 |      1 |         0.0004 |       2.6547 |                2.6547 |      4 |            
 28 |                                                      fused_nn_dense_add |   4097000 |      1 |       122.1322 |      33.5456 |               33.5456 |    256 |            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 20018
Total latency (us): 4052.56

2022-05-13 21:07:04.287 INFO Task #19 has finished. Remaining task(s): 9
2022-05-13 21:07:04.287 INFO Task #20 has finished. Remaining task(s): 8
2022-05-13 21:07:04.287 INFO Task #21 has finished. Remaining task(s): 7
2022-05-13 21:07:04.287 INFO Task #22 has finished. Remaining task(s): 6
2022-05-13 21:07:04.287 INFO Task #23 has finished. Remaining task(s): 5
2022-05-13 21:07:04.287 INFO Task #24 has finished. Remaining task(s): 4
2022-05-13 21:07:04.288 INFO Task #25 has finished. Remaining task(s): 3
2022-05-13 21:07:04.288 INFO Task #26 has finished. Remaining task(s): 2
2022-05-13 21:07:04.288 INFO Task #27 has finished. Remaining task(s): 1
2022-05-13 21:07:04.288 INFO Task #28 has finished. Remaining task(s): 0
2022-05-13 21:07:05.222 INFO Saved XGBModel to /home/ubuntu/tvm/logs/perf/llvm/pytorch_resnet_50//ms_resnet_50_2022-05-13_13:28:55/cost_model.xgb
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 3, 224, 224), "float32"], T_layout_trans: T.Buffer[(1, 224, 224, 3), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(1, 224, 224, 3):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, ax3, ax1, ax2])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                T_layout_trans[ax0, ax1, ax2, ax3] = placeholder[0, ax3, ax1, ax2]
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_layout_transform(placeholder: T.Buffer[(1, 3, 224, 224), "float32"], T_layout_trans: T.Buffer[(1, 224, 224, 3), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(224, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i2, i3 in T.grid(224, 3):
                with T.block("T_layout_trans"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1, ax2, ax3 = T.axis.remap("SSS", [i0_i1_fused, i2, i3])
                    T.reads(placeholder[0, ax3, ax1, ax2])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                    T_layout_trans[ax0, ax1, ax2, ax3] = placeholder[0, ax3, ax1, ax2]
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7 = sch.get_loops(block=b3)", "l8 = sch.fuse(l4, l5)", "sch.parallel(loop=l8)", "sch.annotate(block_or_loop=l8, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l8, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 224, 224, 3), "float32"], placeholder_1: T.Buffer[(7, 7, 3, 64), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 64), "float32"], T_relu: T.Buffer[(1, 112, 112, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 230, 230, 3], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 112, 112, 64], dtype="float32")
        T_add = T.alloc_buffer([1, 112, 112, 64], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 230, 230, 3):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1 - 3, i2_1 - 3, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(3 <= i1_1 and i1_1 < 227 and 3 <= i2_1 and i2_1 < 227, placeholder[0, i1_1 - 3, i2_1 - 3, i3_1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 112, 112, 64, 7, 7, 3):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc], placeholder_1[ry, rx, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc] * placeholder_1[ry, rx, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 112, 112, 64):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 112, 112, 64):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu(placeholder: T.Buffer[(1, 224, 224, 3), "float32"], placeholder_1: T.Buffer[(7, 7, 3, 64), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 64), "float32"], T_relu: T.Buffer[(1, 112, 112, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 230, 230, 3], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 112, 112, 64], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused in T.parallel(784, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for ax0, ax1 in T.grid(1, 13):
                for ax2_ax3_fused in T.vectorized(39):
                    with T.block("pad_temp"):
                        i0 = T.axis.spatial(1, ax0)
                        i1 = T.axis.spatial(230, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 28 * 8 + ax1)
                        i2 = T.axis.spatial(230, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 784 // 28 * 8 + ax2_ax3_fused // 3)
                        i3 = T.axis.spatial(3, ax2_ax3_fused % 3)
                        T.reads(placeholder[0, i1 - 3, i2 - 3, i3])
                        T.writes(pad_temp[i0, i1, i2, i3])
                        pad_temp[i0, i1, i2, i3] = T.if_then_else(3 <= i1 and i1 < 227 and 3 <= i2 and i2 < 227, placeholder[0, i1 - 3, i2 - 3, i3], T.float32(0), dtype="float32")
            for i2_1, i3_1 in T.grid(2, 2):
                for i1_3_init, i2_3_init in T.grid(4, 2):
                    for i3_3_fused_init in T.vectorized(32):
                        with T.block("conv2d_nhwc_init"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(112, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 28 * 4 + i1_3_init)
                            xx = T.axis.spatial(112, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 28 * 4 + i2_1 * 2 + i2_3_init)
                            ff = T.axis.spatial(64, i3_1 * 32 + i3_3_fused_init)
                            T.reads()
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                for i4_0, i5_0, i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(7, 1, 1, 1, 1, 1, 1, 1, 7, 3, 1, 4, 2):
                    for i3_3_fused in T.vectorized(32):
                        with T.block("conv2d_nhwc_update"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(112, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 28 * 4 + i1_3)
                            xx = T.axis.spatial(112, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 28 * 4 + i2_1 * 2 + i2_3)
                            ff = T.axis.spatial(64, i3_1 * 32 + i3_3_fused)
                            ry, rx, rc = T.axis.remap("RRR", [i4_0, i5_1, i6_1])
                            T.reads(conv2d_nhwc[nn, yy, xx, ff], pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc], placeholder_1[ry, rx, rc, ff])
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc] * placeholder_1[ry, rx, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 4, 2):
                    for ax3_fused in T.vectorized(32):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(112, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 28 * 4 + ax1)
                            ax2_1 = T.axis.spatial(112, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 28 * 4 + i2_1 * 2 + ax2)
                            ax3 = T.axis.spatial(64, i3_1 * 32 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 28, 1, 4])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[28, 2, 1, 2])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 32])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[7, 1])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 7])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "l57 = sch.sample_compute_location(block=b0, decision=5)", "sch.compute_at(block=b0, loop=l57, preserve_unit_loops=True)", "sch.enter_postproc()", "b58 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.unroll_explicit\")", "b59, b60, b61 = sch.get_child_blocks(b58)", "l62, l63, l64, l65, l66, l67, l68, l69, l70, l71 = sch.get_loops(block=b59)", "l72 = sch.fuse(l62, l63, l64, l65, l66, l67)", "sch.parallel(loop=l72)", "l73 = sch.fuse(l70, l71)", "sch.vectorize(loop=l73)", "sch.annotate(block_or_loop=l72, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l72, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b60)", "l91 = sch.fuse(l90)", "sch.vectorize(loop=l91)", "sch.annotate(block_or_loop=l74, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l74, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l92, l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b61)", "l99 = sch.fuse(l98)", "sch.vectorize(loop=l99)", "sch.annotate(block_or_loop=l92, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l92, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b100 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b100)", "b118 = sch.decompose_reduction(block=b100, loop=l104)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 112, 112, 64), "float32"], tensor: T.Buffer[(1, 56, 56, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 114, 114, 64], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 114, 114, 64):
            with T.block("pad_temp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, ax1 - 1, ax2 - 1, ax3])
                T.writes(pad_temp[ax0, ax1, ax2, ax3])
                pad_temp[ax0, ax1, ax2, ax3] = T.if_then_else(1 <= ax1 and ax1 < 113 and 1 <= ax2 and ax2 < 113, placeholder[0, ax1 - 1, ax2 - 1, ax3], T.float32(-3.4028234663852886e+38), dtype="float32")
        for i0, i1, i2, i3, i4, i5 in T.grid(1, 56, 56, 64, 3, 3):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                T.reads(pad_temp[0, ax1 * 2 + rv0, ax2 * 2 + rv1, ax3])
                T.writes(tensor[ax0, ax1, ax2, ax3])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], pad_temp[0, ax1 * 2 + rv0, ax2 * 2 + rv1, ax3])
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_max_pool2d(placeholder: T.Buffer[(1, 112, 112, 64), "float32"], tensor: T.Buffer[(1, 56, 56, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 114, 114, 64], dtype="float32")
        for i0_i1_i2_fused in T.parallel(3136, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i3 in T.serial(64):
                for ax0, ax1, ax2, ax3 in T.grid(1, 3, 3, 1):
                    with T.block("pad_temp"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(114, i0_i1_i2_fused % 3136 // 56 * 2 + ax1)
                        ax2_1 = T.axis.spatial(114, i0_i1_i2_fused % 56 * 2 + ax2)
                        ax3_1 = T.axis.spatial(64, i3 + ax3)
                        T.reads(placeholder[0, ax1_1 - 1, ax2_1 - 1, ax3_1])
                        T.writes(pad_temp[ax0_1, ax1_1, ax2_1, ax3_1])
                        pad_temp[ax0_1, ax1_1, ax2_1, ax3_1] = T.if_then_else(1 <= ax1_1 and ax1_1 < 113 and 1 <= ax2_1 and ax2_1 < 113, placeholder[0, ax1_1 - 1, ax2_1 - 1, ax3_1], T.float32(-3.4028234663852886e+38), dtype="float32")
                with T.block("tensor_init"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(56, i0_i1_i2_fused // 56)
                    ax2 = T.axis.spatial(56, i0_i1_i2_fused % 56)
                    ax3 = T.axis.spatial(64, i3)
                    T.reads()
                    T.writes(tensor[ax0, ax1, ax2, ax3])
                    tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                for i4, i5 in T.grid(3, 3):
                    with T.block("tensor_update"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(56, i0_i1_i2_fused // 56)
                        ax2 = T.axis.spatial(56, i0_i1_i2_fused % 56)
                        ax3, rv0, rv1 = T.axis.remap("SRR", [i3, i4, i5])
                        T.reads(tensor[ax0, ax1, ax2, ax3], pad_temp[0, ax1 * 2 + rv0, ax2 * 2 + rv1, ax3])
                        T.writes(tensor[ax0, ax1, ax2, ax3])
                        tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], pad_temp[0, ax1 * 2 + rv0, ax2 * 2 + rv1, ax3])
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v2 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v2)", "l3 = sch.sample_compute_location(block=b0, decision=3)", "sch.compute_at(block=b0, loop=l3, preserve_unit_loops=True)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, b6 = sch.get_child_blocks(b4)", "l7, l8, l9, l10, l11, l12, l13, l14 = sch.get_loops(block=b5)", "l15 = sch.fuse(l7, l8, l9)", "sch.parallel(loop=l15)", "sch.annotate(block_or_loop=l15, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l15, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l16, l17, l18, l19 = sch.get_loops(block=b6)", "sch.annotate(block_or_loop=l16, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l16, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b20 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l21, l22, l23, l24 = sch.get_loops(block=b20)", "b25 = sch.decompose_reduction(block=b20, loop=l23)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 56, 56, 64), "float32"], placeholder_1: T.Buffer[(1, 1, 64, 64), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 64), "float32"], T_relu: T.Buffer[(1, 56, 56, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        T_add = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 64):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 56, 56, 64, 1, 1, 64):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 64):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 64):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_1(placeholder: T.Buffer[(1, 56, 56, 64), "float32"], placeholder_1: T.Buffer[(1, 1, 64, 64), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 64), "float32"], T_relu: T.Buffer[(1, 56, 56, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused in T.parallel(448, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i2_1, i3_1 in T.grid(1, 2):
                for i4_0, i5_0 in T.grid(1, 1):
                    for i2_3_init in T.serial(7):
                        for i3_3_fused_init in T.vectorized(32):
                            with T.block("conv2d_nhwc_init"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 16 * 2 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 2)
                                xx = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 16 // 2 * 7 + i2_3_init)
                                ff = T.axis.spatial(64, i3_1 * 32 + i3_3_fused_init)
                                T.reads()
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                    for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(32, 1, 1, 1, 1, 1, 1, 2, 1, 1, 7):
                        for i3_3_fused in T.vectorized(32):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 16 * 2 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 2)
                                xx = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 16 // 2 * 7 + i2_3)
                                ff = T.axis.spatial(64, i3_1 * 32 + i3_3_fused)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                rc = T.axis.reduce(64, i6_0 * 2 + i6_1)
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 1, 7):
                    for ax3_fused in T.vectorized(32):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 16 * 2 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 2)
                            ax2_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 16 // 2 * 7 + ax2)
                            ax3 = T.axis.spatial(64, i3_1 * 32 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 1, 1, 7])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 32])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 2])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "sch.enter_postproc()", "b57 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.unroll_explicit\")", "b58, b59 = sch.get_child_blocks(b57)", "l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b58)", "l82 = sch.fuse(l60, l61, l62, l63, l64, l65)", "sch.parallel(loop=l82)", "l83 = sch.fuse(l81)", "sch.vectorize(loop=l83)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l84, l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b59)", "l91 = sch.fuse(l90)", "sch.vectorize(loop=l91)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b92 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b92)", "b110 = sch.decompose_reduction(block=b92, loop=l98)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 56, 56, 64), "float32"], placeholder_1: T.Buffer[(3, 3, 64, 64), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 64), "float32"], T_relu: T.Buffer[(1, 56, 56, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 58, 58, 64], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        T_add = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 58, 58, 64):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1 - 1, i2_1 - 1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i1_1 and i1_1 < 57 and 1 <= i2_1 and i2_1 < 57, placeholder[0, i1_1 - 1, i2_1 - 1, i3_1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 56, 56, 64, 3, 3, 64):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy + ry, xx + rx, rc], placeholder_1[ry, rx, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy + ry, xx + rx, rc] * placeholder_1[ry, rx, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 64):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 64):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_2(placeholder: T.Buffer[(1, 56, 56, 64), "float32"], placeholder_1: T.Buffer[(3, 3, 64, 64), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 64), "float32"], T_relu: T.Buffer[(1, 56, 56, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 58, 58, 64], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        for i0_0_i1_0_i2_0_fused in T.parallel(196, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i3_0, i0_1, i1_1, i2_1 in T.grid(1, 1, 1, 2):
                for ax0, ax1, ax2 in T.grid(1, 6, 4):
                    for ax3_fused in T.vectorized(64):
                        with T.block("pad_temp"):
                            i0 = T.axis.spatial(1, ax0)
                            i1 = T.axis.spatial(58, i0_0_i1_0_i2_0_fused % 196 // 14 * 4 + ax1)
                            i2 = T.axis.spatial(58, i0_0_i1_0_i2_0_fused % 14 * 4 + i2_1 * 2 + ax2)
                            i3 = T.axis.spatial(64, ax3_fused)
                            T.reads(placeholder[0, i1 - 1, i2 - 1, i3])
                            T.writes(pad_temp[i0, i1, i2, i3])
                            pad_temp[i0, i1, i2, i3] = T.if_then_else(1 <= i1 and i1 < 57 and 1 <= i2 and i2 < 57, placeholder[0, i1 - 1, i2 - 1, i3], T.float32(0), dtype="float32")
                for i3_1 in T.serial(2):
                    for i4_0 in T.serial(1):
                        for i1_3_init, i2_3_init in T.grid(4, 2):
                            for i3_3_fused_init in T.vectorized(32):
                                with T.block("conv2d_nhwc_init"):
                                    nn = T.axis.spatial(1, 0)
                                    yy = T.axis.spatial(56, i0_0_i1_0_i2_0_fused // 14 * 4 + i1_3_init)
                                    xx = T.axis.spatial(56, i0_0_i1_0_i2_0_fused % 14 * 4 + i2_1 * 2 + i2_3_init)
                                    ff = T.axis.spatial(64, i3_1 * 32 + i3_3_fused_init)
                                    T.reads()
                                    T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                        for i5_0, i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(3, 64, 1, 1, 1, 1, 3, 1, 1, 1, 4, 2):
                            for i3_3_fused in T.vectorized(32):
                                with T.block("conv2d_nhwc_update"):
                                    nn = T.axis.spatial(1, 0)
                                    yy = T.axis.spatial(56, i0_0_i1_0_i2_0_fused // 14 * 4 + i1_3)
                                    xx = T.axis.spatial(56, i0_0_i1_0_i2_0_fused % 14 * 4 + i2_1 * 2 + i2_3)
                                    ff = T.axis.spatial(64, i3_1 * 32 + i3_3_fused)
                                    ry, rx, rc = T.axis.remap("RRR", [i4_1, i5_0, i6_0])
                                    T.reads(conv2d_nhwc[nn, yy, xx, ff], pad_temp[0, yy + ry, xx + rx, rc], placeholder_1[ry, rx, rc, ff])
                                    T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                    T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                    conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy + ry, xx + rx, rc] * placeholder_1[ry, rx, rc, ff]
                    for ax0, ax1, ax2 in T.grid(1, 4, 2):
                        for ax3_fused in T.vectorized(32):
                            with T.block("T_relu"):
                                ax0_1 = T.axis.spatial(1, 0)
                                ax1_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_fused // 14 * 4 + ax1)
                                ax2_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_fused % 14 * 4 + i2_1 * 2 + ax2)
                                ax3 = T.axis.spatial(64, i3_1 * 32 + ax3_fused)
                                T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                                T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                                T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[14, 1, 1, 4])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 2, 1, 2])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 32])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 1])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=14)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "l57 = sch.sample_compute_location(block=b0, decision=6)", "sch.compute_at(block=b0, loop=l57, preserve_unit_loops=True)", "sch.enter_postproc()", "b58 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.unroll_explicit\")", "b59, b60, b61 = sch.get_child_blocks(b58)", "l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b59)", "l73 = sch.fuse(l62, l63, l64)", "sch.parallel(loop=l73)", "l74 = sch.fuse(l72)", "sch.vectorize(loop=l74)", "sch.annotate(block_or_loop=l73, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l73, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94 = sch.get_loops(block=b60)", "l95 = sch.fuse(l94)", "sch.vectorize(loop=l95)", "sch.annotate(block_or_loop=l75, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l75, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b61)", "l106 = sch.fuse(l105)", "sch.vectorize(loop=l106)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b107 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b107)", "b128 = sch.decompose_reduction(block=b107, loop=l115)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 56, 56, 64), "float32"], placeholder_1: T.Buffer[(1, 1, 64, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], T_add: T.Buffer[(1, 56, 56, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 256], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 64):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 56, 56, 256, 1, 1, 64):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 256):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add(placeholder: T.Buffer[(1, 56, 56, 64), "float32"], placeholder_1: T.Buffer[(1, 1, 64, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], T_add: T.Buffer[(1, 56, 56, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 256], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused in T.parallel(448, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i2_1, i3_1 in T.grid(1, 8):
                for i4_0, i5_0, i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1 in T.grid(1, 1, 1, 1, 1, 1, 1, 1, 1):
                    for i2_3_init in T.serial(7):
                        for i3_3_fused_init in T.vectorized(32):
                            with T.block("conv2d_nhwc_init"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 16 * 2 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 2)
                                xx = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 16 // 2 * 7 + i2_3_init)
                                ff = T.axis.spatial(256, i3_1 * 32 + i3_3_fused_init)
                                T.reads()
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                    for i6_1, i0_3, i1_3, i2_3 in T.grid(64, 1, 1, 7):
                        for i3_3_fused in T.vectorized(32):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 16 * 2 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 2)
                                xx = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 16 // 2 * 7 + i2_3)
                                ff = T.axis.spatial(256, i3_1 * 32 + i3_3_fused)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                rc = T.axis.reduce(64, i6_1)
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 1, 7):
                    for ax3_fused in T.vectorized(32):
                        with T.block("T_add"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 16 * 2 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 2)
                            ax2_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 16 // 2 * 7 + ax2)
                            ax3 = T.axis.spatial(256, i3_1 * 32 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                            T.writes(T_add[ax0_1, ax1_1, ax2_1, ax3])
                            T_add[ax0_1, ax1_1, ax2_1, ax3] = conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3]
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)", "v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13])", "v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[28, 2, 1, 1])", "l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21])", "v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 1, 7])", "l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29])", "v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 32])", "l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37])", "v42, v43 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[1, 1])", "l44, l45 = sch.split(loop=l7, factors=[v42, v43])", "v46, v47 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l48, l49 = sch.split(loop=l8, factors=[v46, v47])", "v50, v51 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 64])", "l52, l53 = sch.split(loop=l9, factors=[v50, v51])", "sch.reorder(l14, l22, l30, l38, l15, l23, l31, l39, l44, l48, l52, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41)", "b54, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b54, loop=l39, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v55 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v55)", "sch.enter_postproc()", "b56 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.unroll_explicit\")", "b57, b58 = sch.get_child_blocks(b56)", "l59, l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b57)", "l81 = sch.fuse(l59, l60, l61, l62, l63, l64)", "sch.parallel(loop=l81)", "l82 = sch.fuse(l80)", "sch.vectorize(loop=l82)", "sch.annotate(block_or_loop=l81, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l81, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b58)", "l90 = sch.fuse(l89)", "sch.vectorize(loop=l90)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b91 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b91)", "b109 = sch.decompose_reduction(block=b91, loop=l104)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 56, 56, 64), "float32"], placeholder_1: T.Buffer[(1, 1, 64, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], placeholder_3: T.Buffer[(1, 56, 56, 256), "float32"], T_relu: T.Buffer[(1, 56, 56, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 256], dtype="float32")
        T_add = T.alloc_buffer([1, 56, 56, 256], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 56, 56, 256], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 64):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 56, 56, 256, 1, 1, 64):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 256):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 256):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3], placeholder_3[0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = T_add[0, ax1, ax2, ax3] + placeholder_3[0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 256):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add_1[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_add_nn_relu(placeholder: T.Buffer[(1, 56, 56, 64), "float32"], placeholder_1: T.Buffer[(1, 1, 64, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], placeholder_3: T.Buffer[(1, 56, 56, 256), "float32"], T_relu: T.Buffer[(1, 56, 56, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 256], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused in T.parallel(392, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i3_1 in T.serial(8):
                for i4_0, i5_0 in T.grid(1, 1):
                    for i1_3_init, i2_3_init in T.grid(2, 4):
                        for i3_3_fused_init in T.vectorized(32):
                            with T.block("conv2d_nhwc_init"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 14 * 2 + i1_3_init)
                                xx = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 14 // 2 * 8 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 2 * 4 + i2_3_init)
                                ff = T.axis.spatial(256, i3_1 * 32 + i3_3_fused_init)
                                T.reads()
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                    for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(16, 1, 1, 1, 1, 1, 1, 4, 1, 2, 4):
                        for i3_3_fused in T.vectorized(32):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 14 * 2 + i1_3)
                                xx = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 14 // 2 * 8 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 2 * 4 + i2_3)
                                ff = T.axis.spatial(256, i3_1 * 32 + i3_3_fused)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                rc = T.axis.reduce(64, i6_0 * 4 + i6_1)
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 2, 4):
                    for ax3_fused in T.vectorized(32):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 14 * 2 + ax1)
                            ax2_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 14 // 2 * 8 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 2 * 4 + ax2)
                            ax3 = T.axis.spatial(256, i3_1 * 32 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3], placeholder_3[0, ax1_1, ax2_1, ax3])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3] + placeholder_3[0, ax1_1, ax2_1, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"T_add_1\", func_name=\"main\")", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b3)", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)", "v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l16, l17, l18, l19 = sch.split(loop=l5, factors=[v12, v13, v14, v15])", "v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[28, 1, 1, 2])", "l24, l25, l26, l27 = sch.split(loop=l6, factors=[v20, v21, v22, v23])", "v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 4])", "l32, l33, l34, l35 = sch.split(loop=l7, factors=[v28, v29, v30, v31])", "v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 1, 32])", "l40, l41, l42, l43 = sch.split(loop=l8, factors=[v36, v37, v38, v39])", "v44, v45 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l46, l47 = sch.split(loop=l9, factors=[v44, v45])", "v48, v49 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])", "l50, l51 = sch.split(loop=l10, factors=[v48, v49])", "v52, v53 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[16, 4])", "l54, l55 = sch.split(loop=l11, factors=[v52, v53])", "sch.reorder(l16, l24, l32, l40, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42, l47, l51, l55, l19, l27, l35, l43)", "b56, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b56, loop=l41, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v57 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v57)", "sch.enter_postproc()", "b58 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.unroll_explicit\")", "b59, b60 = sch.get_child_blocks(b58)", "l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b59)", "l83 = sch.fuse(l61, l62, l63, l64, l65, l66, l67)", "sch.parallel(loop=l83)", "l84 = sch.fuse(l82)", "sch.vectorize(loop=l84)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b60)", "l91 = sch.fuse(l90)", "sch.vectorize(loop=l91)", "sch.annotate(block_or_loop=l85, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l85, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b92 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b92)", "b109 = sch.decompose_reduction(block=b92, loop=l97)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 56, 56, 256), "float32"], placeholder_1: T.Buffer[(1, 1, 256, 64), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 64), "float32"], T_relu: T.Buffer[(1, 56, 56, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 56, 56, 256], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        T_add = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 256):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 56, 56, 64, 1, 1, 256):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 64):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 64):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_3(placeholder: T.Buffer[(1, 56, 56, 256), "float32"], placeholder_1: T.Buffer[(1, 1, 256, 64), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 64), "float32"], T_relu: T.Buffer[(1, 56, 56, 64), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 64], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused in T.parallel(448, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i3_1 in T.serial(2):
                for i4_0, i5_0 in T.grid(1, 1):
                    for i2_3_init in T.serial(7):
                        for i3_3_fused_init in T.vectorized(32):
                            with T.block("conv2d_nhwc_init"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 64 * 8 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 64 // 8)
                                xx = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 8 * 7 + i2_3_init)
                                ff = T.axis.spatial(64, i3_1 * 32 + i3_3_fused_init)
                                T.reads()
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                    for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(128, 1, 1, 1, 1, 1, 1, 2, 1, 1, 7):
                        for i3_3_fused in T.vectorized(32):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 64 * 8 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 64 // 8)
                                xx = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 8 * 7 + i2_3)
                                ff = T.axis.spatial(64, i3_1 * 32 + i3_3_fused)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                rc = T.axis.reduce(256, i6_0 * 2 + i6_1)
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 1, 7):
                    for ax3_fused in T.vectorized(32):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 64 * 8 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 64 // 8)
                            ax2_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 8 * 7 + ax2)
                            ax3 = T.axis.spatial(64, i3_1 * 32 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[7, 8, 1, 1])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 7])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 32])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 2])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "sch.enter_postproc()", "b57 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.unroll_explicit\")", "b58, b59 = sch.get_child_blocks(b57)", "l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b58)", "l82 = sch.fuse(l60, l61, l62, l63, l64, l65, l66)", "sch.parallel(loop=l82)", "l83 = sch.fuse(l81)", "sch.vectorize(loop=l83)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b59)", "l90 = sch.fuse(l89)", "sch.vectorize(loop=l90)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b91 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b91)", "b108 = sch.decompose_reduction(block=b91, loop=l96)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 56, 56, 256), "float32"], placeholder_1: T.Buffer[(1, 1, 256, 128), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 128), "float32"], T_relu: T.Buffer[(1, 56, 56, 128), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 56, 56, 256], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 128], dtype="float32")
        T_add = T.alloc_buffer([1, 56, 56, 128], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 256):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 56, 56, 128, 1, 1, 256):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 128):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 128):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_4(placeholder: T.Buffer[(1, 56, 56, 256), "float32"], placeholder_1: T.Buffer[(1, 1, 256, 128), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 128), "float32"], T_relu: T.Buffer[(1, 56, 56, 128), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 56, 56, 128], dtype="float32")
        for i0_0_i1_0_i2_0_fused in T.parallel(784, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i3_0, i0_1, i1_1, i2_1, i3_1 in T.grid(2, 1, 1, 1, 1):
                for i4_0, i5_0 in T.grid(1, 1):
                    for i2_3_init in T.serial(4):
                        for i3_3_fused_init in T.vectorized(64):
                            with T.block("conv2d_nhwc_init"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(56, i0_0_i1_0_i2_0_fused // 14)
                                xx = T.axis.spatial(56, i0_0_i1_0_i2_0_fused % 14 * 4 + i2_3_init)
                                ff = T.axis.spatial(128, i3_0 * 64 + i3_3_fused_init)
                                T.reads()
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                    for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(32, 1, 1, 1, 1, 1, 1, 8, 1, 1, 4):
                        for i3_3_fused in T.vectorized(64):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(56, i0_0_i1_0_i2_0_fused // 14)
                                xx = T.axis.spatial(56, i0_0_i1_0_i2_0_fused % 14 * 4 + i2_3)
                                ff = T.axis.spatial(128, i3_0 * 64 + i3_3_fused)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                rc = T.axis.reduce(256, i6_0 * 8 + i6_1)
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 1, 4):
                    for ax3_fused in T.vectorized(64):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_fused // 14)
                            ax2_1 = T.axis.spatial(56, i0_0_i1_0_i2_0_fused % 14 * 4 + ax2)
                            ax3 = T.axis.spatial(128, i3_0 * 64 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 1, 4])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 64])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 8])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "sch.enter_postproc()", "b57 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.unroll_explicit\")", "b58, b59 = sch.get_child_blocks(b57)", "l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b58)", "l82 = sch.fuse(l60, l61, l62)", "sch.parallel(loop=l82)", "l83 = sch.fuse(l81)", "sch.vectorize(loop=l83)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b59)", "l94 = sch.fuse(l93)", "sch.vectorize(loop=l94)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b95 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b95)", "b116 = sch.decompose_reduction(block=b95, loop=l104)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 56, 56, 128), "float32"], placeholder_1: T.Buffer[(3, 3, 128, 128), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 128), "float32"], T_relu: T.Buffer[(1, 28, 28, 128), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 58, 58, 128], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 28, 28, 128], dtype="float32")
        T_add = T.alloc_buffer([1, 28, 28, 128], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 58, 58, 128):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1 - 1, i2_1 - 1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i1_1 and i1_1 < 57 and 1 <= i2_1 and i2_1 < 57, placeholder[0, i1_1 - 1, i2_1 - 1, i3_1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 28, 28, 128, 3, 3, 128):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc], placeholder_1[ry, rx, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc] * placeholder_1[ry, rx, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 128):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 128):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_5(placeholder: T.Buffer[(1, 56, 56, 128), "float32"], placeholder_1: T.Buffer[(3, 3, 128, 128), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 128), "float32"], T_relu: T.Buffer[(1, 28, 28, 128), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 58, 58, 128], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 28, 28, 128], dtype="float32")
        for i0_0_i1_0_i2_0_fused in T.parallel(196, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for ax0, ax1, ax2, ax3 in T.grid(1, 5, 5, 128):
                with T.block("pad_temp"):
                    i0 = T.axis.spatial(1, ax0)
                    i1 = T.axis.spatial(58, i0_0_i1_0_i2_0_fused % 196 // 14 * 4 + ax1)
                    i2 = T.axis.spatial(58, i0_0_i1_0_i2_0_fused % 14 * 4 + ax2)
                    i3 = T.axis.spatial(128, ax3)
                    T.reads(placeholder[0, i1 - 1, i2 - 1, i3])
                    T.writes(pad_temp[i0, i1, i2, i3])
                    pad_temp[i0, i1, i2, i3] = T.if_then_else(1 <= i1 and i1 < 57 and 1 <= i2 and i2 < 57, placeholder[0, i1 - 1, i2 - 1, i3], T.float32(0), dtype="float32")
            for i3_0, i0_1, i1_1, i2_1, i3_1 in T.grid(1, 1, 1, 1, 2):
                for i4_0 in T.serial(1):
                    for i1_3_init, i2_3_init in T.grid(2, 2):
                        for i3_3_fused_init in T.vectorized(64):
                            with T.block("conv2d_nhwc_init"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(28, i0_0_i1_0_i2_0_fused // 14 * 2 + i1_3_init)
                                xx = T.axis.spatial(28, i0_0_i1_0_i2_0_fused % 14 * 2 + i2_3_init)
                                ff = T.axis.spatial(128, i3_1 * 64 + i3_3_fused_init)
                                T.reads()
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                    for i5_0, i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(3, 128, 1, 1, 1, 1, 3, 1, 1, 1, 2, 2):
                        for i3_3_fused in T.vectorized(64):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(28, i0_0_i1_0_i2_0_fused // 14 * 2 + i1_3)
                                xx = T.axis.spatial(28, i0_0_i1_0_i2_0_fused % 14 * 2 + i2_3)
                                ff = T.axis.spatial(128, i3_1 * 64 + i3_3_fused)
                                ry, rx, rc = T.axis.remap("RRR", [i4_1, i5_0, i6_0])
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc], placeholder_1[ry, rx, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc] * placeholder_1[ry, rx, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 2, 2):
                    for ax3_fused in T.vectorized(64):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(28, i0_0_i1_0_i2_0_fused // 14 * 2 + ax1)
                            ax2_1 = T.axis.spatial(28, i0_0_i1_0_i2_0_fused % 14 * 2 + ax2)
                            ax3 = T.axis.spatial(128, i3_1 * 64 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 1, 2])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 64])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 1])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "l57 = sch.sample_compute_location(block=b0, decision=2)", "sch.compute_at(block=b0, loop=l57, preserve_unit_loops=True)", "sch.enter_postproc()", "b58 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.unroll_explicit\")", "b59, b60, b61 = sch.get_child_blocks(b58)", "l62, l63, l64, l65, l66, l67, l68 = sch.get_loops(block=b59)", "l69 = sch.fuse(l62, l63, l64)", "sch.parallel(loop=l69)", "sch.annotate(block_or_loop=l69, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l69, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b60)", "l90 = sch.fuse(l89)", "sch.vectorize(loop=l90)", "sch.annotate(block_or_loop=l70, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l70, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l91, l92, l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b61)", "l101 = sch.fuse(l100)", "sch.vectorize(loop=l101)", "sch.annotate(block_or_loop=l91, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l91, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b102 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b102)", "b123 = sch.decompose_reduction(block=b102, loop=l110)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 56, 56, 256), "float32"], placeholder_1: T.Buffer[(1, 1, 256, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], T_add: T.Buffer[(1, 28, 28, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 56, 56, 256], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 28, 28, 512], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 56, 56, 256):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 28, 28, 512, 1, 1, 256):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy * 2, xx * 2, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy * 2, xx * 2, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 512):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_1(placeholder: T.Buffer[(1, 56, 56, 256), "float32"], placeholder_1: T.Buffer[(1, 1, 256, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], T_add: T.Buffer[(1, 28, 28, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 28, 28, 512], dtype="float32")
        for i0_0_i1_0_i2_0_fused in T.parallel(196, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i3_0, i0_1, i1_1, i2_1, i3_1 in T.grid(1, 1, 1, 1, 8):
                for i4_0, i5_0 in T.grid(1, 1):
                    for i1_3_init in T.serial(4):
                        for i2_3_i3_3_fused_init in T.vectorized(64):
                            with T.block("conv2d_nhwc_init"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(28, i0_0_i1_0_i2_0_fused // 28 * 4 + i1_3_init)
                                xx = T.axis.spatial(28, i0_0_i1_0_i2_0_fused % 28)
                                ff = T.axis.spatial(512, i3_1 * 64 + i2_3_i3_3_fused_init)
                                T.reads()
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                    for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3 in T.grid(16, 1, 1, 1, 1, 1, 1, 16, 1, 4):
                        for i2_3_i3_3_fused in T.vectorized(64):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(28, i0_0_i1_0_i2_0_fused // 28 * 4 + i1_3)
                                xx = T.axis.spatial(28, i0_0_i1_0_i2_0_fused % 28)
                                ff = T.axis.spatial(512, i3_1 * 64 + i2_3_i3_3_fused)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                rc = T.axis.reduce(256, i6_0 * 16 + i6_1)
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy * 2, xx * 2, rc], placeholder_1[0, 0, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy * 2, xx * 2, rc] * placeholder_1[0, 0, rc, ff]
                for ax0, ax1 in T.grid(1, 4):
                    for ax2_ax3_fused in T.vectorized(64):
                        with T.block("T_add"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(28, i0_0_i1_0_i2_0_fused // 28 * 4 + ax1)
                            ax2 = T.axis.spatial(28, i0_0_i1_0_i2_0_fused % 28)
                            ax3 = T.axis.spatial(512, i3_1 * 64 + ax2_ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                            T.writes(T_add[ax0_1, ax1_1, ax2, ax3])
                            T_add[ax0_1, ax1_1, ax2, ax3] = conv2d_nhwc[0, ax1_1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)", "v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13])", "v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[7, 1, 1, 4])", "l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21])", "v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[28, 1, 1, 1])", "l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29])", "v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 64])", "l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37])", "v42, v43 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[1, 1])", "l44, l45 = sch.split(loop=l7, factors=[v42, v43])", "v46, v47 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l48, l49 = sch.split(loop=l8, factors=[v46, v47])", "v50, v51 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 16])", "l52, l53 = sch.split(loop=l9, factors=[v50, v51])", "sch.reorder(l14, l22, l30, l38, l15, l23, l31, l39, l44, l48, l52, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41)", "b54, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b54, loop=l39, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=98)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v55 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v55)", "sch.enter_postproc()", "b56 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.unroll_explicit\")", "b57, b58 = sch.get_child_blocks(b56)", "l59, l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b57)", "l81 = sch.fuse(l59, l60, l61)", "sch.parallel(loop=l81)", "l82 = sch.fuse(l79, l80)", "sch.vectorize(loop=l82)", "sch.annotate(block_or_loop=l81, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l81, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l83, l84, l85, l86, l87, l88, l89, l90, l91, l92 = sch.get_loops(block=b58)", "l93 = sch.fuse(l91, l92)", "sch.vectorize(loop=l93)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b94 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b94)", "b114 = sch.decompose_reduction(block=b94, loop=l103)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 28, 28, 128), "float32"], placeholder_1: T.Buffer[(1, 1, 128, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], placeholder_3: T.Buffer[(1, 28, 28, 512), "float32"], T_relu: T.Buffer[(1, 28, 28, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 28, 28, 128], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 28, 28, 512], dtype="float32")
        T_add = T.alloc_buffer([1, 28, 28, 512], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 28, 28, 512], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 128):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 28, 28, 512, 1, 1, 128):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 512):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 512):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3], placeholder_3[0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = T_add[0, ax1, ax2, ax3] + placeholder_3[0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 512):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add_1[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_add_nn_relu_1(placeholder: T.Buffer[(1, 28, 28, 128), "float32"], placeholder_1: T.Buffer[(1, 1, 128, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], placeholder_3: T.Buffer[(1, 28, 28, 512), "float32"], T_relu: T.Buffer[(1, 28, 28, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 28, 28, 512], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused in T.parallel(196, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i3_1 in T.serial(8):
                for i4_0, i5_0 in T.grid(1, 1):
                    for i2_3_init in T.serial(4):
                        for i3_3_fused_init in T.vectorized(64):
                            with T.block("conv2d_nhwc_init"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 28 * 4 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 28 // 7)
                                xx = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 7 * 4 + i2_3_init)
                                ff = T.axis.spatial(512, i3_1 * 64 + i3_3_fused_init)
                                T.reads()
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                    for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(16, 1, 1, 1, 1, 1, 1, 8, 1, 1, 4):
                        for i3_3_fused in T.vectorized(64):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 28 * 4 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 28 // 7)
                                xx = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 7 * 4 + i2_3)
                                ff = T.axis.spatial(512, i3_1 * 64 + i3_3_fused)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                rc = T.axis.reduce(128, i6_0 * 8 + i6_1)
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 1, 4):
                    for ax3_fused in T.vectorized(64):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 28 * 4 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 28 // 7)
                            ax2_1 = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 7 * 4 + ax2)
                            ax3 = T.axis.spatial(512, i3_1 * 64 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3], placeholder_3[0, ax1_1, ax2_1, ax3])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3] + placeholder_3[0, ax1_1, ax2_1, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"T_add_1\", func_name=\"main\")", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b3)", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)", "v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l16, l17, l18, l19 = sch.split(loop=l5, factors=[v12, v13, v14, v15])", "v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 4, 1, 1])", "l24, l25, l26, l27 = sch.split(loop=l6, factors=[v20, v21, v22, v23])", "v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 4])", "l32, l33, l34, l35 = sch.split(loop=l7, factors=[v28, v29, v30, v31])", "v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 8, 1, 64])", "l40, l41, l42, l43 = sch.split(loop=l8, factors=[v36, v37, v38, v39])", "v44, v45 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l46, l47 = sch.split(loop=l9, factors=[v44, v45])", "v48, v49 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])", "l50, l51 = sch.split(loop=l10, factors=[v48, v49])", "v52, v53 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[16, 8])", "l54, l55 = sch.split(loop=l11, factors=[v52, v53])", "sch.reorder(l16, l24, l32, l40, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42, l47, l51, l55, l19, l27, l35, l43)", "b56, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b56, loop=l41, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\", ann_val=28)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v57 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v57)", "sch.enter_postproc()", "b58 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.unroll_explicit\")", "b59, b60 = sch.get_child_blocks(b58)", "l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b59)", "l83 = sch.fuse(l61, l62, l63, l64, l65, l66, l67)", "sch.parallel(loop=l83)", "l84 = sch.fuse(l82)", "sch.vectorize(loop=l84)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l85, l86, l87, l88, l89, l90 = sch.get_loops(block=b60)", "l91 = sch.fuse(l90)", "sch.vectorize(loop=l91)", "sch.annotate(block_or_loop=l85, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l85, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b92 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b92)", "b109 = sch.decompose_reduction(block=b92, loop=l97)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 28, 28, 512), "float32"], placeholder_1: T.Buffer[(1, 1, 512, 128), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 128), "float32"], T_relu: T.Buffer[(1, 28, 28, 128), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 28, 28, 512], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 28, 28, 128], dtype="float32")
        T_add = T.alloc_buffer([1, 28, 28, 128], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 512):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 28, 28, 128, 1, 1, 512):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 128):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 128):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_6(placeholder: T.Buffer[(1, 28, 28, 512), "float32"], placeholder_1: T.Buffer[(1, 1, 512, 128), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 128), "float32"], T_relu: T.Buffer[(1, 28, 28, 128), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 28, 28, 128], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(392, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i4_0, i5_0 in T.grid(1, 1):
                for i2_3_init in T.serial(4):
                    for i3_3_fused_init in T.vectorized(64):
                        with T.block("conv2d_nhwc_init"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 56 // 2)
                            xx = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 56 * 4 + i2_3_init)
                            ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 64 + i3_3_fused_init)
                            T.reads()
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(128, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4):
                    for i3_3_fused in T.vectorized(64):
                        with T.block("conv2d_nhwc_update"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 56 // 2)
                            xx = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 56 * 4 + i2_3)
                            ff = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 64 + i3_3_fused)
                            ry = T.axis.reduce(1, 0)
                            rx = T.axis.reduce(1, 0)
                            rc = T.axis.reduce(512, i6_0 * 4 + i6_1)
                            T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
            for ax0, ax1, ax2 in T.grid(1, 1, 4):
                for ax3_fused in T.vectorized(64):
                    with T.block("T_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 56 // 2)
                        ax2_1 = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 56 * 4 + ax2)
                        ax3 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 64 + ax3_fused)
                        T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                        T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                        T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 28, 1, 1])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 4])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 64])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 4])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "sch.enter_postproc()", "b57 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.unroll_explicit\")", "b58, b59 = sch.get_child_blocks(b57)", "l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b58)", "l82 = sch.fuse(l60, l61, l62, l63, l64, l65, l66, l67)", "sch.parallel(loop=l82)", "l83 = sch.fuse(l81)", "sch.vectorize(loop=l83)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l84, l85, l86, l87, l88 = sch.get_loops(block=b59)", "l89 = sch.fuse(l88)", "sch.vectorize(loop=l89)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b90 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b90)", "b106 = sch.decompose_reduction(block=b90, loop=l94)"]
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 28, 28, 128), "float32"], placeholder_1: T.Buffer[(6, 6, 128, 128), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 128), "float32"], T_relu: T.Buffer[(1, 28, 28, 128), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 30, 30, 128], dtype="float32")
        input_tile = T.alloc_buffer([6, 6, 49, 128], dtype="float32")
        B = T.alloc_buffer([6, 6], dtype="float32")
        data_pack = T.alloc_buffer([6, 6, 49, 128], dtype="float32")
        bgemm = T.alloc_buffer([6, 6, 49, 128], dtype="float32")
        A = T.alloc_buffer([6, 4], dtype="float32")
        inverse = T.alloc_buffer([4, 4, 49, 128], dtype="float32")
        conv2d_winograd = T.alloc_buffer([1, 28, 28, 128], dtype="float32")
        T_add = T.alloc_buffer([1, 28, 28, 128], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 30, 30, 128):
            with T.block("data_pad"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1 - 1, i2_1 - 1, i3_1])
                T.writes(data_pad[i0_1, i1_1, i2_1, i3_1])
                T.block_attr({"schedule_rule":"None"})
                data_pad[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i1_1 and i1_1 < 29 and 1 <= i2_1 and i2_1 < 29, placeholder[0, i1_1 - 1, i2_1 - 1, i3_1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3 in T.grid(6, 6, 49, 128):
            with T.block("input_tile"):
                eps, nu, p, ci = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(data_pad[0, p // 7 * 4 + eps, p % 7 * 4 + nu, ci])
                T.writes(input_tile[eps, nu, p, ci])
                T.block_attr({"schedule_rule":"None"})
                input_tile[eps, nu, p, ci] = data_pad[0, p // 7 * 4 + eps, p % 7 * 4 + nu, ci]
        for i0, i1 in T.grid(6, 6):
            with T.block("B"):
                i, j = T.axis.remap("SS", [i0, i1])
                T.reads()
                T.writes(B[i, j])
                T.block_attr({"const_matrix":True, "schedule_rule":"meta_schedule.compute_inline"})
                B[i, j] = T.Select(i == 5 and j == 5, T.float32(1), T.Select(i == 5 and j == 4, T.float32(0), T.Select(i == 5 and j == 3, T.float32(0), T.Select(i == 5 and j == 2, T.float32(0), T.Select(i == 5 and j == 1, T.float32(0), T.Select(i == 5 and j == 0, T.float32(0), T.Select(i == 4 and j == 5, T.float32(1.5), T.Select(i == 4 and j == 4, T.float32(1), T.Select(i == 4 and j == 3, T.float32(1), T.Select(i == 4 and j == 2, T.float32(1), T.Select(i == 4 and j == 1, T.float32(1), T.Select(i == 4 and j == 0, T.float32(1), T.Select(i == 3 and j == 5, T.float32(-2), T.Select(i == 3 and j == 4, T.float32(-0.5), T.Select(i == 3 and j == 3, T.float32(2), T.Select(i == 3 and j == 2, T.float32(2.5), T.Select(i == 3 and j == 1, T.float32(0.5), T.Select(i == 3 and j == 0, T.float32(1.5), T.Select(i == 2 and j == 5, T.float32(-1.5), T.Select(i == 2 and j == 4, T.float32(-1), T.Select(i == 2 and j == 3, T.float32(-1), T.Select(i == 2 and j == 2, T.float32(0.5), T.Select(i == 2 and j == 1, T.float32(-2.5), T.Select(i == 2 and j == 0, T.float32(-2), T.Select(i == 1 and j == 5, T.float32(1), T.Select(i == 1 and j == 4, T.float32(0.5), T.Select(i == 1 and j == 3, T.float32(-2), T.Select(i == 1 and j == 2, T.float32(-1), T.Select(i == 1 and j == 1, T.float32(1), T.Select(i == 1 and j == 0, T.float32(-1.5), T.Select(i == 0 and j == 5, T.float32(0), T.Select(i == 0 and j == 4, T.float32(0), T.Select(i == 0 and j == 3, T.float32(0), T.Select(i == 0 and j == 2, T.float32(0), T.Select(i == 0 and j == 1, T.float32(0), T.Select(i == 0 and j == 0, T.float32(1), T.float32(0)))))))))))))))))))))))))))))))))))))
        for i0, i1, i2, i3, i4, i5 in T.grid(6, 6, 49, 128, 6, 6):
            with T.block("data_pack"):
                eps, nu, p, ci, r_a, r_b = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                T.reads(input_tile[r_a, r_b, p, ci], B[T.min(r_a, r_b) : T.max(r_a, r_b) + 1, T.min(eps, nu) : T.max(eps, nu) + 1])
                T.writes(data_pack[eps, nu, p, ci])
                T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["eps", "nu", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_data_pack.llvm"})
                with T.init():
                    data_pack[eps, nu, p, ci] = T.float32(0)
                data_pack[eps, nu, p, ci] = data_pack[eps, nu, p, ci] + input_tile[r_a, r_b, p, ci] * B[r_a, eps] * B[r_b, nu]
        for i0, i1, i2, i3, i4 in T.grid(6, 6, 49, 128, 128):
            with T.block("bgemm"):
                eps, nu, p, co, ci = T.axis.remap("SSSSR", [i0, i1, i2, i3, i4])
                T.reads(data_pack[eps, nu, p, ci], placeholder_1[eps, nu, co, ci])
                T.writes(bgemm[eps, nu, p, co])
                with T.init():
                    bgemm[eps, nu, p, co] = T.float32(0)
                bgemm[eps, nu, p, co] = bgemm[eps, nu, p, co] + data_pack[eps, nu, p, ci] * placeholder_1[eps, nu, co, ci]
        for i0, i1 in T.grid(6, 4):
            with T.block("A"):
                i, j = T.axis.remap("SS", [i0, i1])
                T.reads()
                T.writes(A[i, j])
                T.block_attr({"const_matrix":True, "schedule_rule":"meta_schedule.compute_inline"})
                A[i, j] = T.Select(i == 5 and j == 3, T.float32(1), T.Select(i == 5 and j == 2, T.float32(0), T.Select(i == 5 and j == 1, T.float32(0), T.Select(i == 5 and j == 0, T.float32(0), T.Select(i == 4 and j == 3, T.float32(-8), T.Select(i == 4 and j == 2, T.float32(4), T.Select(i == 4 and j == 1, T.float32(-2), T.Select(i == 4 and j == 0, T.float32(1), T.Select(i == 3 and j == 3, T.float32(0.125), T.Select(i == 3 and j == 2, T.float32(0.25), T.Select(i == 3 and j == 1, T.float32(0.5), T.Select(i == 3 and j == 0, T.float32(1), T.Select(i == 2 and j == 3, T.float32(1), T.Select(i == 2 and j == 2, T.float32(1), T.Select(i == 2 and j == 1, T.float32(1), T.Select(i == 2 and j == 0, T.float32(1), T.Select(i == 1 and j == 3, T.float32(-1), T.Select(i == 1 and j == 2, T.float32(1), T.Select(i == 1 and j == 1, T.float32(-1), T.Select(i == 1 and j == 0, T.float32(1), T.Select(i == 0 and j == 3, T.float32(0), T.Select(i == 0 and j == 2, T.float32(0), T.Select(i == 0 and j == 1, T.float32(0), T.Select(i == 0 and j == 0, T.float32(1), T.float32(0)))))))))))))))))))))))))
        for i0, i1, i2, i3, i4, i5 in T.grid(4, 4, 49, 128, 6, 6):
            with T.block("inverse"):
                vh, vw, p, co, r_a, r_b = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                T.reads(bgemm[r_a, r_b, p, co], A[T.min(r_a, r_b) : T.max(r_a, r_b) + 1, T.min(vh, vw) : T.max(vh, vw) + 1])
                T.writes(inverse[vh, vw, p, co])
                T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["vh", "vw", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_inverse"})
                with T.init():
                    inverse[vh, vw, p, co] = T.float32(0)
                inverse[vh, vw, p, co] = inverse[vh, vw, p, co] + bgemm[r_a, r_b, p, co] * A[r_a, vh] * A[r_b, vw]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 128):
            with T.block("conv2d_winograd"):
                n, h, w, co = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(inverse[h % 4, w % 4, h // 4 * 7 + w // 4, co])
                T.writes(conv2d_winograd[n, h, w, co])
                conv2d_winograd[n, h, w, co] = inverse[h % 4, w % 4, h // 4 * 7 + w // 4, co]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 128):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_winograd[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_winograd[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 128):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu(placeholder: T.Buffer[(1, 28, 28, 128), "float32"], placeholder_1: T.Buffer[(6, 6, 128, 128), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 128), "float32"], T_relu: T.Buffer[(1, 28, 28, 128), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 30, 30, 128], dtype="float32")
        input_tile = T.alloc_buffer([6, 6, 49, 128], dtype="float32")
        data_pack = T.alloc_buffer([6, 6, 49, 128], dtype="float32")
        bgemm = T.alloc_buffer([6, 6, 49, 128], dtype="float32")
        inverse = T.alloc_buffer([4, 4, 49, 128], dtype="float32")
        bgemm_global = T.alloc_buffer([6, 6, 49, 128], dtype="float32")
        for i2_0_i3_0_fused in T.parallel(112, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for ax0 in T.serial(6):
                for ax0_1, ax1, ax2 in T.grid(1, 1, 30):
                    for ax3_fused in T.vectorized(8):
                        with T.block("data_pad"):
                            i0 = T.axis.spatial(1, ax0_1)
                            i1 = T.axis.spatial(30, i2_0_i3_0_fused // 16 * 4 + ax0 + ax1)
                            i2 = T.axis.spatial(30, ax2)
                            i3 = T.axis.spatial(128, i2_0_i3_0_fused % 16 * 8 + ax3_fused)
                            T.reads(placeholder[0, i1 - 1, i2 - 1, i3])
                            T.writes(data_pad[i0, i1, i2, i3])
                            T.block_attr({"schedule_rule":"None"})
                            data_pad[i0, i1, i2, i3] = T.if_then_else(1 <= i1 and i1 < 29 and 1 <= i2 and i2 < 29, placeholder[0, i1 - 1, i2 - 1, i3], T.float32(0), dtype="float32")
                for ax1, ax2 in T.grid(6, 7):
                    for ax3_fused in T.vectorized(8):
                        with T.block("input_tile"):
                            eps, nu = T.axis.remap("SS", [ax0, ax1])
                            p = T.axis.spatial(49, i2_0_i3_0_fused // 16 * 7 + ax2)
                            ci = T.axis.spatial(128, i2_0_i3_0_fused % 16 * 8 + ax3_fused)
                            T.reads(data_pad[0, p // 7 * 4 + eps, p % 7 * 4 + nu, ci])
                            T.writes(input_tile[eps, nu, p, ci])
                            T.block_attr({"schedule_rule":"None"})
                            input_tile[eps, nu, p, ci] = data_pad[0, p // 7 * 4 + eps, p % 7 * 4 + nu, ci]
            for i2_1, i3_1 in T.grid(7, 8):
                for i0 in T.unroll(6):
                    for i1 in T.unroll(6):
                        with T.block("data_pack_init"):
                            eps, nu = T.axis.remap("SS", [i0, i1])
                            p = T.axis.spatial(49, i2_0_i3_0_fused // 16 * 7 + i2_1)
                            ci = T.axis.spatial(128, i2_0_i3_0_fused % 16 * 8 + i3_1)
                            T.reads()
                            T.writes(data_pack[eps, nu, p, ci])
                            T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["eps", "nu", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_data_pack.llvm"})
                            data_pack[eps, nu, p, ci] = T.float32(0)
                        for i4 in T.unroll(6):
                            for i5 in T.unroll(6):
                                with T.block("data_pack_update"):
                                    eps, nu = T.axis.remap("SS", [i0, i1])
                                    p = T.axis.spatial(49, i2_0_i3_0_fused // 16 * 7 + i2_1)
                                    ci = T.axis.spatial(128, i2_0_i3_0_fused % 16 * 8 + i3_1)
                                    r_a, r_b = T.axis.remap("RR", [i4, i5])
                                    T.reads(data_pack[eps, nu, p, ci], input_tile[r_a, r_b, p, ci])
                                    T.writes(data_pack[eps, nu, p, ci])
                                    T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["eps", "nu", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_data_pack.llvm"})
                                    data_pack[eps, nu, p, ci] = data_pack[eps, nu, p, ci] + input_tile[r_a, r_b, p, ci] * T.Select(r_a == 5 and eps == 5, T.float32(1), T.Select(r_a == 5 and eps == 4, T.float32(0), T.Select(r_a == 5 and eps == 3, T.float32(0), T.Select(r_a == 5 and eps == 2, T.float32(0), T.Select(r_a == 5 and eps == 1, T.float32(0), T.Select(r_a == 5 and eps == 0, T.float32(0), T.Select(r_a == 4 and eps == 5, T.float32(1.5), T.Select(r_a == 4 and eps == 4, T.float32(1), T.Select(r_a == 4 and eps == 3, T.float32(1), T.Select(r_a == 4 and eps == 2, T.float32(1), T.Select(r_a == 4 and eps == 1, T.float32(1), T.Select(r_a == 4 and eps == 0, T.float32(1), T.Select(r_a == 3 and eps == 5, T.float32(-2), T.Select(r_a == 3 and eps == 4, T.float32(-0.5), T.Select(r_a == 3 and eps == 3, T.float32(2), T.Select(r_a == 3 and eps == 2, T.float32(2.5), T.Select(r_a == 3 and eps == 1, T.float32(0.5), T.Select(r_a == 3 and eps == 0, T.float32(1.5), T.Select(r_a == 2 and eps == 5, T.float32(-1.5), T.Select(r_a == 2 and eps == 4, T.float32(-1), T.Select(r_a == 2 and eps == 3, T.float32(-1), T.Select(r_a == 2 and eps == 2, T.float32(0.5), T.Select(r_a == 2 and eps == 1, T.float32(-2.5), T.Select(r_a == 2 and eps == 0, T.float32(-2), T.Select(r_a == 1 and eps == 5, T.float32(1), T.Select(r_a == 1 and eps == 4, T.float32(0.5), T.Select(r_a == 1 and eps == 3, T.float32(-2), T.Select(r_a == 1 and eps == 2, T.float32(-1), T.Select(r_a == 1 and eps == 1, T.float32(1), T.Select(r_a == 1 and eps == 0, T.float32(-1.5), T.Select(r_a == 0 and eps == 5, T.float32(0), T.Select(r_a == 0 and eps == 4, T.float32(0), T.Select(r_a == 0 and eps == 3, T.float32(0), T.Select(r_a == 0 and eps == 2, T.float32(0), T.Select(r_a == 0 and eps == 1, T.float32(0), T.Select(r_a == 0 and eps == 0, T.float32(1), T.float32(0))))))))))))))))))))))))))))))))))))) * T.Select(r_b == 5 and nu == 5, T.float32(1), T.Select(r_b == 5 and nu == 4, T.float32(0), T.Select(r_b == 5 and nu == 3, T.float32(0), T.Select(r_b == 5 and nu == 2, T.float32(0), T.Select(r_b == 5 and nu == 1, T.float32(0), T.Select(r_b == 5 and nu == 0, T.float32(0), T.Select(r_b == 4 and nu == 5, T.float32(1.5), T.Select(r_b == 4 and nu == 4, T.float32(1), T.Select(r_b == 4 and nu == 3, T.float32(1), T.Select(r_b == 4 and nu == 2, T.float32(1), T.Select(r_b == 4 and nu == 1, T.float32(1), T.Select(r_b == 4 and nu == 0, T.float32(1), T.Select(r_b == 3 and nu == 5, T.float32(-2), T.Select(r_b == 3 and nu == 4, T.float32(-0.5), T.Select(r_b == 3 and nu == 3, T.float32(2), T.Select(r_b == 3 and nu == 2, T.float32(2.5), T.Select(r_b == 3 and nu == 1, T.float32(0.5), T.Select(r_b == 3 and nu == 0, T.float32(1.5), T.Select(r_b == 2 and nu == 5, T.float32(-1.5), T.Select(r_b == 2 and nu == 4, T.float32(-1), T.Select(r_b == 2 and nu == 3, T.float32(-1), T.Select(r_b == 2 and nu == 2, T.float32(0.5), T.Select(r_b == 2 and nu == 1, T.float32(-2.5), T.Select(r_b == 2 and nu == 0, T.float32(-2), T.Select(r_b == 1 and nu == 5, T.float32(1), T.Select(r_b == 1 and nu == 4, T.float32(0.5), T.Select(r_b == 1 and nu == 3, T.float32(-2), T.Select(r_b == 1 and nu == 2, T.float32(-1), T.Select(r_b == 1 and nu == 1, T.float32(1), T.Select(r_b == 1 and nu == 0, T.float32(-1.5), T.Select(r_b == 0 and nu == 5, T.float32(0), T.Select(r_b == 0 and nu == 4, T.float32(0), T.Select(r_b == 0 and nu == 3, T.float32(0), T.Select(r_b == 0 and nu == 2, T.float32(0), T.Select(r_b == 0 and nu == 1, T.float32(0), T.Select(r_b == 0 and nu == 0, T.float32(1), T.float32(0)))))))))))))))))))))))))))))))))))))
        for i0_0_i1_0_i2_0_i3_0_fused in T.parallel(288, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1 in T.grid(1, 1, 7, 2):
                for i3_2_init, i2_3_init in T.grid(8, 7):
                    with T.block("bgemm_init"):
                        eps = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused // 48)
                        nu = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused % 48 // 8)
                        p = T.axis.spatial(49, i2_1 * 7 + i2_3_init)
                        co = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused % 8 * 16 + i3_1 * 8 + i3_2_init)
                        T.reads()
                        T.writes(bgemm_global[eps, nu, p, co])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        bgemm_global[eps, nu, p, co] = T.float32(0)
                for i4_0, i0_2, i1_2, i2_2, i3_2, i4_1, i0_3, i1_3, i2_3, i3_3 in T.grid(64, 1, 1, 1, 8, 2, 1, 1, 7, 1):
                    with T.block("bgemm_update"):
                        eps = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused // 48)
                        nu = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused % 48 // 8)
                        p = T.axis.spatial(49, i2_1 * 7 + i2_3)
                        co = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused % 8 * 16 + i3_1 * 8 + i3_2)
                        ci = T.axis.reduce(128, i4_0 * 2 + i4_1)
                        T.reads(bgemm_global[eps, nu, p, co], data_pack[eps, nu, p, ci], placeholder_1[eps, nu, co, ci])
                        T.writes(bgemm_global[eps, nu, p, co])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        bgemm_global[eps, nu, p, co] = bgemm_global[eps, nu, p, co] + data_pack[eps, nu, p, ci] * placeholder_1[eps, nu, co, ci]
                for ax0, ax1, ax2 in T.grid(1, 1, 7):
                    for ax3_fused in T.vectorized(8):
                        with T.block("bgemm_global"):
                            v0 = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused // 48)
                            v1 = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused % 48 // 8)
                            v2 = T.axis.spatial(49, i2_1 * 7 + ax2)
                            v3 = T.axis.spatial(128, i0_0_i1_0_i2_0_i3_0_fused % 8 * 16 + i3_1 * 8 + ax3_fused)
                            T.reads(bgemm_global[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_global[v0, v1, v2, v3]
        for i2_0_i3_0_fused in T.parallel(392, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i2_1, i3_1 in T.grid(1, 16):
                for i0 in T.unroll(4):
                    for i1 in T.unroll(4):
                        with T.block("inverse_init"):
                            vh, vw = T.axis.remap("SS", [i0, i1])
                            p = T.axis.spatial(49, i2_0_i3_0_fused // 8)
                            co = T.axis.spatial(128, i2_0_i3_0_fused % 8 * 16 + i3_1)
                            T.reads()
                            T.writes(inverse[vh, vw, p, co])
                            T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["vh", "vw", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_inverse"})
                            inverse[vh, vw, p, co] = T.float32(0)
                        for i4 in T.unroll(6):
                            for i5 in T.unroll(6):
                                with T.block("inverse_update"):
                                    vh, vw = T.axis.remap("SS", [i0, i1])
                                    p = T.axis.spatial(49, i2_0_i3_0_fused // 8)
                                    co = T.axis.spatial(128, i2_0_i3_0_fused % 8 * 16 + i3_1)
                                    r_a, r_b = T.axis.remap("RR", [i4, i5])
                                    T.reads(inverse[vh, vw, p, co], bgemm[r_a, r_b, p, co])
                                    T.writes(inverse[vh, vw, p, co])
                                    T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["vh", "vw", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_inverse"})
                                    inverse[vh, vw, p, co] = inverse[vh, vw, p, co] + bgemm[r_a, r_b, p, co] * T.Select(r_a == 5 and vh == 3, T.float32(1), T.Select(r_a == 5 and vh == 2, T.float32(0), T.Select(r_a == 5 and vh == 1, T.float32(0), T.Select(r_a == 5 and vh == 0, T.float32(0), T.Select(r_a == 4 and vh == 3, T.float32(-8), T.Select(r_a == 4 and vh == 2, T.float32(4), T.Select(r_a == 4 and vh == 1, T.float32(-2), T.Select(r_a == 4 and vh == 0, T.float32(1), T.Select(r_a == 3 and vh == 3, T.float32(0.125), T.Select(r_a == 3 and vh == 2, T.float32(0.25), T.Select(r_a == 3 and vh == 1, T.float32(0.5), T.Select(r_a == 3 and vh == 0, T.float32(1), T.Select(r_a == 2 and vh == 3, T.float32(1), T.Select(r_a == 2 and vh == 2, T.float32(1), T.Select(r_a == 2 and vh == 1, T.float32(1), T.Select(r_a == 2 and vh == 0, T.float32(1), T.Select(r_a == 1 and vh == 3, T.float32(-1), T.Select(r_a == 1 and vh == 2, T.float32(1), T.Select(r_a == 1 and vh == 1, T.float32(-1), T.Select(r_a == 1 and vh == 0, T.float32(1), T.Select(r_a == 0 and vh == 3, T.float32(0), T.Select(r_a == 0 and vh == 2, T.float32(0), T.Select(r_a == 0 and vh == 1, T.float32(0), T.Select(r_a == 0 and vh == 0, T.float32(1), T.float32(0))))))))))))))))))))))))) * T.Select(r_b == 5 and vw == 3, T.float32(1), T.Select(r_b == 5 and vw == 2, T.float32(0), T.Select(r_b == 5 and vw == 1, T.float32(0), T.Select(r_b == 5 and vw == 0, T.float32(0), T.Select(r_b == 4 and vw == 3, T.float32(-8), T.Select(r_b == 4 and vw == 2, T.float32(4), T.Select(r_b == 4 and vw == 1, T.float32(-2), T.Select(r_b == 4 and vw == 0, T.float32(1), T.Select(r_b == 3 and vw == 3, T.float32(0.125), T.Select(r_b == 3 and vw == 2, T.float32(0.25), T.Select(r_b == 3 and vw == 1, T.float32(0.5), T.Select(r_b == 3 and vw == 0, T.float32(1), T.Select(r_b == 2 and vw == 3, T.float32(1), T.Select(r_b == 2 and vw == 2, T.float32(1), T.Select(r_b == 2 and vw == 1, T.float32(1), T.Select(r_b == 2 and vw == 0, T.float32(1), T.Select(r_b == 1 and vw == 3, T.float32(-1), T.Select(r_b == 1 and vw == 2, T.float32(1), T.Select(r_b == 1 and vw == 1, T.float32(-1), T.Select(r_b == 1 and vw == 0, T.float32(1), T.Select(r_b == 0 and vw == 3, T.float32(0), T.Select(r_b == 0 and vw == 2, T.float32(0), T.Select(r_b == 0 and vw == 1, T.float32(0), T.Select(r_b == 0 and vw == 0, T.float32(1), T.float32(0)))))))))))))))))))))))))
        for i0_i1_i2_fused in T.parallel(784, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i3 in T.serial(128):
                with T.block("T_relu"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(28, i0_i1_i2_fused // 28)
                    ax2 = T.axis.spatial(28, i0_i1_i2_fused % 28)
                    ax3 = T.axis.spatial(128, i3)
                    T.reads(inverse[ax1 % 4, ax2 % 4, ax1 // 4 * 7 + ax2 // 4, ax3], placeholder_2[0, 0, 0, ax3])
                    T.writes(T_relu[ax0, ax1, ax2, ax3])
                    T_relu[ax0, ax1, ax2, ax3] = T.max(inverse[ax1 % 4, ax2 % 4, ax1 // 4 * 7 + ax2 // 4, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"B\", func_name=\"main\")", "b1 = sch.get_block(name=\"data_pack\", func_name=\"main\")", "b2 = sch.get_block(name=\"bgemm\", func_name=\"main\")", "b3 = sch.get_block(name=\"A\", func_name=\"main\")", "b4 = sch.get_block(name=\"inverse\", func_name=\"main\")", "b5 = sch.get_block(name=\"conv2d_winograd\", func_name=\"main\")", "b6 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b7 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b0)", "b8, = sch.get_producers(block=b1)", "b9, = sch.get_producers(block=b8)", "l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)", "v16, v17 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[7, 7])", "l18, l19 = sch.split(loop=l12, factors=[v16, v17])", "v20, v21 = sch.sample_perfect_tile(loop=l13, n=2, max_innermost_factor=64, decision=[16, 8])", "l22, l23 = sch.split(loop=l13, factors=[v20, v21])", "sch.unroll(loop=l10)", "sch.unroll(loop=l11)", "sch.unroll(loop=l14)", "sch.unroll(loop=l15)", "sch.reorder(l18, l22, l19, l23, l10, l11, l14, l15)", "l24 = sch.sample_compute_location(block=b8, decision=1)", "sch.compute_at(block=b8, loop=l24, preserve_unit_loops=True)", "l25 = sch.sample_compute_location(block=b9, decision=2)", "sch.compute_at(block=b9, loop=l25, preserve_unit_loops=True)", "sch.compute_inline(block=b3)", "l26, l27, l28, l29, l30, l31 = sch.get_loops(block=b4)", "v32, v33 = sch.sample_perfect_tile(loop=l28, n=2, max_innermost_factor=64, decision=[49, 1])", "l34, l35 = sch.split(loop=l28, factors=[v32, v33])", "v36, v37 = sch.sample_perfect_tile(loop=l29, n=2, max_innermost_factor=64, decision=[8, 16])", "l38, l39 = sch.split(loop=l29, factors=[v36, v37])", "sch.unroll(loop=l26)", "sch.unroll(loop=l27)", "sch.unroll(loop=l30)", "sch.unroll(loop=l31)", "sch.reorder(l34, l38, l35, l39, l26, l27, l30, l31)", "sch.compute_inline(block=b6)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l40, l41, l42, l43, l44 = sch.get_loops(block=b2)", "v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l40, n=4, max_innermost_factor=64, decision=[6, 1, 1, 1])", "l49, l50, l51, l52 = sch.split(loop=l40, factors=[v45, v46, v47, v48])", "v53, v54, v55, v56 = sch.sample_perfect_tile(loop=l41, n=4, max_innermost_factor=64, decision=[6, 1, 1, 1])", "l57, l58, l59, l60 = sch.split(loop=l41, factors=[v53, v54, v55, v56])", "v61, v62, v63, v64 = sch.sample_perfect_tile(loop=l42, n=4, max_innermost_factor=64, decision=[1, 7, 1, 7])", "l65, l66, l67, l68 = sch.split(loop=l42, factors=[v61, v62, v63, v64])", "v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l43, n=4, max_innermost_factor=64, decision=[8, 2, 8, 1])", "l73, l74, l75, l76 = sch.split(loop=l43, factors=[v69, v70, v71, v72])", "v77, v78 = sch.sample_perfect_tile(loop=l44, n=2, max_innermost_factor=64, decision=[64, 2])", "l79, l80 = sch.split(loop=l44, factors=[v77, v78])", "sch.reorder(l49, l57, l65, l73, l50, l58, l66, l74, l79, l51, l59, l67, l75, l80, l52, l60, l68, l76)", "b81 = sch.cache_write(block=b2, write_buffer_index=0, storage_scope=\"global\")", "sch.reverse_compute_at(block=b81, loop=l74, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b7, ann_key=\"meta_schedule.parallel\", ann_val=96)", "sch.annotate(block_or_loop=b7, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v82 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b7, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v82)", "l83 = sch.sample_compute_location(block=b5, decision=-2)", "sch.compute_at(block=b5, loop=l83, preserve_unit_loops=True)", "sch.enter_postproc()", "b84 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b84, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b84, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b84, ann_key=\"meta_schedule.unroll_explicit\")", "b85, b86, b87, b88, b89, b90, b91 = sch.get_child_blocks(b84)", "l92, l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b85)", "l99 = sch.fuse(l92, l93)", "sch.parallel(loop=l99)", "l100 = sch.fuse(l98)", "sch.vectorize(loop=l100)", "sch.annotate(block_or_loop=l99, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l99, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l101, l102, l103, l104, l105 = sch.get_loops(block=b86)", "l106 = sch.fuse(l105)", "sch.vectorize(loop=l106)", "sch.annotate(block_or_loop=l101, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l101, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b87)", "sch.annotate(block_or_loop=l107, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l107, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131 = sch.get_loops(block=b88)", "l132 = sch.fuse(l114, l115, l116, l117)", "sch.parallel(loop=l132)", "sch.annotate(block_or_loop=l132, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l132, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b89)", "l142 = sch.fuse(l141)", "sch.vectorize(loop=l142)", "sch.annotate(block_or_loop=l133, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l133, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l143, l144, l145, l146, l147, l148, l149, l150 = sch.get_loops(block=b90)", "l151 = sch.fuse(l143, l144)", "sch.parallel(loop=l151)", "sch.annotate(block_or_loop=l151, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l151, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l152, l153, l154, l155 = sch.get_loops(block=b91)", "l156 = sch.fuse(l152, l153, l154)", "sch.parallel(loop=l156)", "sch.annotate(block_or_loop=l156, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l156, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b157 = sch.get_block(name=\"data_pack\", func_name=\"main\")", "l158, l159, l160, l161, l162, l163, l164 = sch.get_loops(block=b157)", "b165 = sch.decompose_reduction(block=b157, loop=l163)", "b166 = sch.get_block(name=\"bgemm\", func_name=\"main\")", "l167, l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b166)", "b182 = sch.decompose_reduction(block=b166, loop=l172)", "b183 = sch.get_block(name=\"inverse\", func_name=\"main\")", "l184, l185, l186, l187, l188, l189, l190 = sch.get_loops(block=b183)", "b191 = sch.decompose_reduction(block=b183, loop=l189)"]
[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 28, 28, 512), "float32"], placeholder_1: T.Buffer[(1, 1, 512, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], T_relu: T.Buffer[(1, 28, 28, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 28, 28, 512], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 28, 28, 256], dtype="float32")
        T_add = T.alloc_buffer([1, 28, 28, 256], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 512):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 28, 28, 256, 1, 1, 512):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 256):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 256):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_7(placeholder: T.Buffer[(1, 28, 28, 512), "float32"], placeholder_1: T.Buffer[(1, 1, 512, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], T_relu: T.Buffer[(1, 28, 28, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 28, 28, 256], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused in T.parallel(196, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i3_1 in T.serial(4):
                for i4_0, i5_0 in T.grid(1, 1):
                    for i2_3_init in T.serial(4):
                        for i3_3_fused_init in T.vectorized(64):
                            with T.block("conv2d_nhwc_init"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 14 * 2 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 14 // 7)
                                xx = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 7 * 4 + i2_3_init)
                                ff = T.axis.spatial(256, i3_1 * 64 + i3_3_fused_init)
                                T.reads()
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                    for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(64, 1, 1, 1, 1, 1, 1, 8, 1, 1, 4):
                        for i3_3_fused in T.vectorized(64):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 14 * 2 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 14 // 7)
                                xx = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 7 * 4 + i2_3)
                                ff = T.axis.spatial(256, i3_1 * 64 + i3_3_fused)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                rc = T.axis.reduce(512, i6_0 * 8 + i6_1)
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 1, 4):
                    for ax3_fused in T.vectorized(64):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 14 * 2 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 14 // 7)
                            ax2_1 = T.axis.spatial(28, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 7 * 4 + ax2)
                            ax3 = T.axis.spatial(256, i3_1 * 64 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[14, 2, 1, 1])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 4])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 1, 64])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 8])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=28)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "sch.enter_postproc()", "b57 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.unroll_explicit\")", "b58, b59 = sch.get_child_blocks(b57)", "l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b58)", "l82 = sch.fuse(l60, l61, l62, l63, l64, l65, l66)", "sch.parallel(loop=l82)", "l83 = sch.fuse(l81)", "sch.vectorize(loop=l83)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b59)", "l90 = sch.fuse(l89)", "sch.vectorize(loop=l90)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b91 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b91)", "b108 = sch.decompose_reduction(block=b91, loop=l96)"]
[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 28, 28, 256), "float32"], placeholder_1: T.Buffer[(3, 3, 256, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], T_relu: T.Buffer[(1, 14, 14, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 30, 30, 256], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 14, 14, 256], dtype="float32")
        T_add = T.alloc_buffer([1, 14, 14, 256], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 30, 30, 256):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1 - 1, i2_1 - 1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i1_1 and i1_1 < 29 and 1 <= i2_1 and i2_1 < 29, placeholder[0, i1_1 - 1, i2_1 - 1, i3_1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 14, 14, 256, 3, 3, 256):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc], placeholder_1[ry, rx, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc] * placeholder_1[ry, rx, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 256):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 256):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_8(placeholder: T.Buffer[(1, 28, 28, 256), "float32"], placeholder_1: T.Buffer[(3, 3, 256, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], T_relu: T.Buffer[(1, 14, 14, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 30, 30, 256], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 14, 14, 256], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for ax0, ax1, ax2, ax3 in T.grid(1, 15, 15, 256):
                with T.block("pad_temp"):
                    i0 = T.axis.spatial(1, ax0)
                    i1 = T.axis.spatial(30, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 4 // 2 * 14 + ax1)
                    i2 = T.axis.spatial(30, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 2 * 14 + ax2)
                    i3 = T.axis.spatial(256, ax3)
                    T.reads(placeholder[0, i1 - 1, i2 - 1, i3])
                    T.writes(pad_temp[i0, i1, i2, i3])
                    pad_temp[i0, i1, i2, i3] = T.if_then_else(1 <= i1 and i1 < 29 and 1 <= i2 and i2 < 29, placeholder[0, i1 - 1, i2 - 1, i3], T.float32(0), dtype="float32")
            for i3_1 in T.serial(1):
                for i2_2_init, i3_2_init, i1_3_init in T.grid(7, 2, 7):
                    for i2_3_i3_3_fused_init in T.vectorized(32):
                        with T.block("conv2d_nhwc_init"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 4 // 2 * 7 + i1_3_init)
                            xx = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 2 * 7 + i2_2_init)
                            ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 4 * 64 + i3_2_init * 32 + i2_3_i3_3_fused_init)
                            T.reads()
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                for i4_0, i5_0, i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3 in T.grid(3, 3, 4, 1, 1, 7, 2, 1, 1, 64, 1, 7):
                    for i2_3_i3_3_fused in T.vectorized(32):
                        with T.block("conv2d_nhwc_update"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 4 // 2 * 7 + i1_3)
                            xx = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 2 * 7 + i2_2)
                            ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 4 * 64 + i3_2 * 32 + i2_3_i3_3_fused)
                            ry, rx = T.axis.remap("RR", [i4_0, i5_0])
                            rc = T.axis.reduce(256, i6_0 * 64 + i6_1)
                            T.reads(conv2d_nhwc[nn, yy, xx, ff], pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc], placeholder_1[ry, rx, rc, ff])
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc] * placeholder_1[ry, rx, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 7, 7):
                    for ax3_fused in T.vectorized(64):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 4 // 2 * 7 + ax1)
                            ax2_1 = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused % 2 * 7 + ax2)
                            ax3 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_fused // 4 * 64 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 7, 1])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 2, 32])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=112)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "l57 = sch.sample_compute_location(block=b0, decision=6)", "sch.compute_at(block=b0, loop=l57, preserve_unit_loops=True)", "sch.enter_postproc()", "b58 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.unroll_explicit\")", "b59, b60, b61 = sch.get_child_blocks(b58)", "l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b59)", "l73 = sch.fuse(l62, l63, l64, l65, l66, l67, l68)", "sch.parallel(loop=l73)", "sch.annotate(block_or_loop=l73, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l73, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b60)", "l90 = sch.fuse(l88, l89)", "sch.vectorize(loop=l90)", "sch.annotate(block_or_loop=l74, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l74, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b61)", "l97 = sch.fuse(l96)", "sch.vectorize(loop=l97)", "sch.annotate(block_or_loop=l91, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l91, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b98 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b98)", "b114 = sch.decompose_reduction(block=b98, loop=l101)"]
[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 28, 28, 512), "float32"], placeholder_1: T.Buffer[(1, 1, 512, 1024), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 1024), "float32"], T_add: T.Buffer[(1, 14, 14, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 28, 28, 512], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 14, 14, 1024], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 28, 28, 512):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 14, 14, 1024, 1, 1, 512):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy * 2, xx * 2, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy * 2, xx * 2, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 1024):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
    

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_2(placeholder: T.Buffer[(1, 28, 28, 512), "float32"], placeholder_1: T.Buffer[(1, 1, 512, 1024), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 1024), "float32"], T_add: T.Buffer[(1, 14, 14, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 14, 14, 1024], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2_1, i3_1 in T.grid(1, 4):
                for i4_0, i5_0 in T.grid(1, 1):
                    for i2_2_init, i1_3_init in T.grid(14, 7):
                        for i2_3_i3_3_fused_init in T.vectorized(32):
                            with T.block("conv2d_nhwc_init"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 2 * 7 + i1_3_init)
                                xx = T.axis.spatial(14, i2_2_init)
                                ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 2 * 128 + i3_1 * 32 + i2_3_i3_3_fused_init)
                                T.reads()
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                    for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3 in T.grid(16, 1, 1, 14, 1, 1, 1, 32, 1, 7):
                        for i2_3_i3_3_fused in T.vectorized(32):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 2 * 7 + i1_3)
                                xx = T.axis.spatial(14, i2_2)
                                ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 2 * 128 + i3_1 * 32 + i2_3_i3_3_fused)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                rc = T.axis.reduce(512, i6_0 * 32 + i6_1)
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy * 2, xx * 2, rc], placeholder_1[0, 0, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy * 2, xx * 2, rc] * placeholder_1[0, 0, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 7, 14):
                    for ax3_fused in T.vectorized(32):
                        with T.block("T_add"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused % 2 * 7 + ax1)
                            ax2_1 = T.axis.spatial(14, ax2)
                            ax3 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_fused // 2 * 128 + i3_1 * 32 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                            T.writes(T_add[ax0_1, ax1_1, ax2_1, ax3])
                            T_add[ax0_1, ax1_1, ax2_1, ax3] = conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3]
    

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)", "v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13])", "v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])", "l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21])", "v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])", "l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29])", "v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 4, 1, 32])", "l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37])", "v42, v43 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[1, 1])", "l44, l45 = sch.split(loop=l7, factors=[v42, v43])", "v46, v47 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l48, l49 = sch.split(loop=l8, factors=[v46, v47])", "v50, v51 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 32])", "l52, l53 = sch.split(loop=l9, factors=[v50, v51])", "sch.reorder(l14, l22, l30, l38, l15, l23, l31, l39, l44, l48, l52, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41)", "b54, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b54, loop=l39, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=8)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v55 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v55)", "sch.enter_postproc()", "b56 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.unroll_explicit\")", "b57, b58 = sch.get_child_blocks(b56)", "l59, l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b57)", "l81 = sch.fuse(l59, l60, l61, l62, l63, l64)", "sch.parallel(loop=l81)", "l82 = sch.fuse(l79, l80)", "sch.vectorize(loop=l82)", "sch.annotate(block_or_loop=l81, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l81, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b58)", "l90 = sch.fuse(l89)", "sch.vectorize(loop=l90)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b91 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b91)", "b108 = sch.decompose_reduction(block=b91, loop=l97)"]
[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 14, 14, 256), "float32"], placeholder_1: T.Buffer[(1, 1, 256, 1024), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 1024), "float32"], placeholder_3: T.Buffer[(1, 14, 14, 1024), "float32"], T_relu: T.Buffer[(1, 14, 14, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 14, 14, 256], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 14, 14, 1024], dtype="float32")
        T_add = T.alloc_buffer([1, 14, 14, 1024], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 14, 14, 1024], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 256):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 14, 14, 1024, 1, 1, 256):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 1024):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 1024):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3], placeholder_3[0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = T_add[0, ax1, ax2, ax3] + placeholder_3[0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 1024):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add_1[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_add_nn_relu_2(placeholder: T.Buffer[(1, 14, 14, 256), "float32"], placeholder_1: T.Buffer[(1, 1, 256, 1024), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 1024), "float32"], placeholder_3: T.Buffer[(1, 14, 14, 1024), "float32"], T_relu: T.Buffer[(1, 14, 14, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 14, 14, 1024], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1 in T.grid(1, 1, 1, 2):
                for i4_0, i5_0 in T.grid(1, 1):
                    for i1_2_init, i2_2_init, i1_3_init in T.grid(2, 14, 7):
                        for i2_3_i3_3_fused_init in T.vectorized(32):
                            with T.block("conv2d_nhwc_init"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(14, i1_2_init * 7 + i1_3_init)
                                xx = T.axis.spatial(14, i2_2_init)
                                ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 64 + i3_1 * 32 + i2_3_i3_3_fused_init)
                                T.reads()
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                    for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3 in T.grid(8, 1, 2, 14, 1, 1, 1, 32, 1, 7):
                        for i2_3_i3_3_fused in T.vectorized(32):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy = T.axis.spatial(14, i1_2 * 7 + i1_3)
                                xx = T.axis.spatial(14, i2_2)
                                ff = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 64 + i3_1 * 32 + i2_3_i3_3_fused)
                                ry = T.axis.reduce(1, 0)
                                rx = T.axis.reduce(1, 0)
                                rc = T.axis.reduce(256, i6_0 * 32 + i6_1)
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
                for ax0, ax1, ax2 in T.grid(1, 14, 14):
                    for ax3_fused in T.vectorized(32):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1, ax2_1 = T.axis.remap("SS", [ax1, ax2])
                            ax3 = T.axis.spatial(1024, i0_0_i1_0_i2_0_i3_0_fused * 64 + i3_1 * 32 + ax3_fused)
                            T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3], placeholder_3[0, ax1_1, ax2_1, ax3])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3] + placeholder_3[0, ax1_1, ax2_1, ax3], T.float32(0))
    

[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"T_add_1\", func_name=\"main\")", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b3)", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)", "v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l16, l17, l18, l19 = sch.split(loop=l5, factors=[v12, v13, v14, v15])", "v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])", "l24, l25, l26, l27 = sch.split(loop=l6, factors=[v20, v21, v22, v23])", "v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])", "l32, l33, l34, l35 = sch.split(loop=l7, factors=[v28, v29, v30, v31])", "v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[16, 2, 1, 32])", "l40, l41, l42, l43 = sch.split(loop=l8, factors=[v36, v37, v38, v39])", "v44, v45 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l46, l47 = sch.split(loop=l9, factors=[v44, v45])", "v48, v49 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])", "l50, l51 = sch.split(loop=l10, factors=[v48, v49])", "v52, v53 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[8, 32])", "l54, l55 = sch.split(loop=l11, factors=[v52, v53])", "sch.reorder(l16, l24, l32, l40, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42, l47, l51, l55, l19, l27, l35, l43)", "b56, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b56, loop=l41, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v57 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v57)", "sch.enter_postproc()", "b58 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.unroll_explicit\")", "b59, b60 = sch.get_child_blocks(b58)", "l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b59)", "l83 = sch.fuse(l61, l62, l63, l64)", "sch.parallel(loop=l83)", "l84 = sch.fuse(l81, l82)", "sch.vectorize(loop=l84)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b60)", "l94 = sch.fuse(l93)", "sch.vectorize(loop=l94)", "sch.annotate(block_or_loop=l85, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l85, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b95 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b95)", "b114 = sch.decompose_reduction(block=b95, loop=l103)"]
[21:07:31] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 14, 14, 1024), "float32"], placeholder_1: T.Buffer[(1, 1, 1024, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], T_relu: T.Buffer[(1, 14, 14, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 14, 14, 1024], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 14, 14, 256], dtype="float32")
        T_add = T.alloc_buffer([1, 14, 14, 256], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 1024):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 14, 14, 256, 1, 1, 1024):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 256):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 256):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:31] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:31] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_9(placeholder: T.Buffer[(1, 14, 14, 1024), "float32"], placeholder_1: T.Buffer[(1, 1, 1024, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], T_relu: T.Buffer[(1, 14, 14, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 14, 14, 256], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_0, i5_0 in T.grid(1, 1):
                for i2_2_init, i1_3_init in T.grid(14, 7):
                    for i2_3_i3_3_fused_init in T.vectorized(32):
                        with T.block("conv2d_nhwc_init"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 7 + i1_3_init)
                            xx = T.axis.spatial(14, i2_2_init)
                            ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + i2_3_i3_3_fused_init)
                            T.reads()
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3 in T.grid(32, 1, 1, 14, 1, 1, 1, 32, 1, 7):
                    for i2_3_i3_3_fused in T.vectorized(32):
                        with T.block("conv2d_nhwc_update"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 7 + i1_3)
                            xx = T.axis.spatial(14, i2_2)
                            ff = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + i2_3_i3_3_fused)
                            ry = T.axis.reduce(1, 0)
                            rx = T.axis.reduce(1, 0)
                            rc = T.axis.reduce(1024, i6_0 * 32 + i6_1)
                            T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
            for ax0, ax1, ax2 in T.grid(1, 7, 14):
                for ax3_fused in T.vectorized(32):
                    with T.block("T_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 7 + ax1)
                        ax2_1 = T.axis.spatial(14, ax2)
                        ax3 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 2 * 32 + ax3_fused)
                        T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                        T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                        T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:31] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:31] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 1, 1, 32])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 32])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "sch.enter_postproc()", "b57 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.unroll_explicit\")", "b58, b59 = sch.get_child_blocks(b57)", "l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b58)", "l82 = sch.fuse(l60, l61, l62, l63, l64, l65, l66, l67)", "sch.parallel(loop=l82)", "l83 = sch.fuse(l80, l81)", "sch.vectorize(loop=l83)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l84, l85, l86, l87, l88 = sch.get_loops(block=b59)", "l89 = sch.fuse(l88)", "sch.vectorize(loop=l89)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b90 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b90)", "b105 = sch.decompose_reduction(block=b90, loop=l94)"]
[21:07:31] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 14, 14, 256), "float32"], placeholder_1: T.Buffer[(6, 6, 256, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], T_relu: T.Buffer[(1, 14, 14, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 18, 18, 256], dtype="float32")
        input_tile = T.alloc_buffer([6, 6, 16, 256], dtype="float32")
        B = T.alloc_buffer([6, 6], dtype="float32")
        data_pack = T.alloc_buffer([6, 6, 16, 256], dtype="float32")
        bgemm = T.alloc_buffer([6, 6, 16, 256], dtype="float32")
        A = T.alloc_buffer([6, 4], dtype="float32")
        inverse = T.alloc_buffer([4, 4, 16, 256], dtype="float32")
        conv2d_winograd = T.alloc_buffer([1, 14, 14, 256], dtype="float32")
        T_add = T.alloc_buffer([1, 14, 14, 256], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 18, 18, 256):
            with T.block("data_pad"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1 - 1, i2_1 - 1, i3_1])
                T.writes(data_pad[i0_1, i1_1, i2_1, i3_1])
                T.block_attr({"schedule_rule":"None"})
                data_pad[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i1_1 and i1_1 < 15 and 1 <= i2_1 and i2_1 < 15, placeholder[0, i1_1 - 1, i2_1 - 1, i3_1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3 in T.grid(6, 6, 16, 256):
            with T.block("input_tile"):
                eps, nu, p, ci = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(data_pad[0, p // 4 * 4 + eps, p % 4 * 4 + nu, ci])
                T.writes(input_tile[eps, nu, p, ci])
                T.block_attr({"schedule_rule":"None"})
                input_tile[eps, nu, p, ci] = data_pad[0, p // 4 * 4 + eps, p % 4 * 4 + nu, ci]
        for i0, i1 in T.grid(6, 6):
            with T.block("B"):
                i, j = T.axis.remap("SS", [i0, i1])
                T.reads()
                T.writes(B[i, j])
                T.block_attr({"const_matrix":True, "schedule_rule":"meta_schedule.compute_inline"})
                B[i, j] = T.Select(i == 5 and j == 5, T.float32(1), T.Select(i == 5 and j == 4, T.float32(0), T.Select(i == 5 and j == 3, T.float32(0), T.Select(i == 5 and j == 2, T.float32(0), T.Select(i == 5 and j == 1, T.float32(0), T.Select(i == 5 and j == 0, T.float32(0), T.Select(i == 4 and j == 5, T.float32(1.5), T.Select(i == 4 and j == 4, T.float32(1), T.Select(i == 4 and j == 3, T.float32(1), T.Select(i == 4 and j == 2, T.float32(1), T.Select(i == 4 and j == 1, T.float32(1), T.Select(i == 4 and j == 0, T.float32(1), T.Select(i == 3 and j == 5, T.float32(-2), T.Select(i == 3 and j == 4, T.float32(-0.5), T.Select(i == 3 and j == 3, T.float32(2), T.Select(i == 3 and j == 2, T.float32(2.5), T.Select(i == 3 and j == 1, T.float32(0.5), T.Select(i == 3 and j == 0, T.float32(1.5), T.Select(i == 2 and j == 5, T.float32(-1.5), T.Select(i == 2 and j == 4, T.float32(-1), T.Select(i == 2 and j == 3, T.float32(-1), T.Select(i == 2 and j == 2, T.float32(0.5), T.Select(i == 2 and j == 1, T.float32(-2.5), T.Select(i == 2 and j == 0, T.float32(-2), T.Select(i == 1 and j == 5, T.float32(1), T.Select(i == 1 and j == 4, T.float32(0.5), T.Select(i == 1 and j == 3, T.float32(-2), T.Select(i == 1 and j == 2, T.float32(-1), T.Select(i == 1 and j == 1, T.float32(1), T.Select(i == 1 and j == 0, T.float32(-1.5), T.Select(i == 0 and j == 5, T.float32(0), T.Select(i == 0 and j == 4, T.float32(0), T.Select(i == 0 and j == 3, T.float32(0), T.Select(i == 0 and j == 2, T.float32(0), T.Select(i == 0 and j == 1, T.float32(0), T.Select(i == 0 and j == 0, T.float32(1), T.float32(0)))))))))))))))))))))))))))))))))))))
        for i0, i1, i2, i3, i4, i5 in T.grid(6, 6, 16, 256, 6, 6):
            with T.block("data_pack"):
                eps, nu, p, ci, r_a, r_b = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                T.reads(input_tile[r_a, r_b, p, ci], B[T.min(r_a, r_b) : T.max(r_a, r_b) + 1, T.min(eps, nu) : T.max(eps, nu) + 1])
                T.writes(data_pack[eps, nu, p, ci])
                T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["eps", "nu", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_data_pack.llvm"})
                with T.init():
                    data_pack[eps, nu, p, ci] = T.float32(0)
                data_pack[eps, nu, p, ci] = data_pack[eps, nu, p, ci] + input_tile[r_a, r_b, p, ci] * B[r_a, eps] * B[r_b, nu]
        for i0, i1, i2, i3, i4 in T.grid(6, 6, 16, 256, 256):
            with T.block("bgemm"):
                eps, nu, p, co, ci = T.axis.remap("SSSSR", [i0, i1, i2, i3, i4])
                T.reads(data_pack[eps, nu, p, ci], placeholder_1[eps, nu, co, ci])
                T.writes(bgemm[eps, nu, p, co])
                with T.init():
                    bgemm[eps, nu, p, co] = T.float32(0)
                bgemm[eps, nu, p, co] = bgemm[eps, nu, p, co] + data_pack[eps, nu, p, ci] * placeholder_1[eps, nu, co, ci]
        for i0, i1 in T.grid(6, 4):
            with T.block("A"):
                i, j = T.axis.remap("SS", [i0, i1])
                T.reads()
                T.writes(A[i, j])
                T.block_attr({"const_matrix":True, "schedule_rule":"meta_schedule.compute_inline"})
                A[i, j] = T.Select(i == 5 and j == 3, T.float32(1), T.Select(i == 5 and j == 2, T.float32(0), T.Select(i == 5 and j == 1, T.float32(0), T.Select(i == 5 and j == 0, T.float32(0), T.Select(i == 4 and j == 3, T.float32(-8), T.Select(i == 4 and j == 2, T.float32(4), T.Select(i == 4 and j == 1, T.float32(-2), T.Select(i == 4 and j == 0, T.float32(1), T.Select(i == 3 and j == 3, T.float32(0.125), T.Select(i == 3 and j == 2, T.float32(0.25), T.Select(i == 3 and j == 1, T.float32(0.5), T.Select(i == 3 and j == 0, T.float32(1), T.Select(i == 2 and j == 3, T.float32(1), T.Select(i == 2 and j == 2, T.float32(1), T.Select(i == 2 and j == 1, T.float32(1), T.Select(i == 2 and j == 0, T.float32(1), T.Select(i == 1 and j == 3, T.float32(-1), T.Select(i == 1 and j == 2, T.float32(1), T.Select(i == 1 and j == 1, T.float32(-1), T.Select(i == 1 and j == 0, T.float32(1), T.Select(i == 0 and j == 3, T.float32(0), T.Select(i == 0 and j == 2, T.float32(0), T.Select(i == 0 and j == 1, T.float32(0), T.Select(i == 0 and j == 0, T.float32(1), T.float32(0)))))))))))))))))))))))))
        for i0, i1, i2, i3, i4, i5 in T.grid(4, 4, 16, 256, 6, 6):
            with T.block("inverse"):
                vh, vw, p, co, r_a, r_b = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                T.reads(bgemm[r_a, r_b, p, co], A[T.min(r_a, r_b) : T.max(r_a, r_b) + 1, T.min(vh, vw) : T.max(vh, vw) + 1])
                T.writes(inverse[vh, vw, p, co])
                T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["vh", "vw", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_inverse"})
                with T.init():
                    inverse[vh, vw, p, co] = T.float32(0)
                inverse[vh, vw, p, co] = inverse[vh, vw, p, co] + bgemm[r_a, r_b, p, co] * A[r_a, vh] * A[r_b, vw]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 256):
            with T.block("conv2d_winograd"):
                n, h, w, co = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(inverse[h % 4, w % 4, h // 4 * 4 + w // 4, co])
                T.writes(conv2d_winograd[n, h, w, co])
                conv2d_winograd[n, h, w, co] = inverse[h % 4, w % 4, h // 4 * 4 + w // 4, co]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 256):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_winograd[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_winograd[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 256):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:31] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:31] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1(placeholder: T.Buffer[(1, 14, 14, 256), "float32"], placeholder_1: T.Buffer[(6, 6, 256, 256), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 256), "float32"], T_relu: T.Buffer[(1, 14, 14, 256), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 18, 18, 256], dtype="float32")
        input_tile = T.alloc_buffer([6, 6, 16, 256], dtype="float32")
        data_pack = T.alloc_buffer([6, 6, 16, 256], dtype="float32")
        bgemm = T.alloc_buffer([6, 6, 16, 256], dtype="float32")
        inverse = T.alloc_buffer([4, 4, 16, 256], dtype="float32")
        conv2d_winograd = T.alloc_buffer([1, 14, 14, 256], dtype="float32")
        bgemm_global = T.alloc_buffer([6, 6, 16, 256], dtype="float32")
        for i2_0_i3_0_i2_1_fused in T.parallel(64, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i3_1 in T.serial(64):
                for ax0, ax1, ax2, ax3 in T.grid(1, 6, 6, 1):
                    with T.block("data_pad"):
                        i0 = T.axis.spatial(1, ax0)
                        i1 = T.axis.spatial(18, i2_0_i3_0_i2_1_fused // 32 * 8 + i2_0_i3_0_i2_1_fused % 8 // 4 * 4 + ax1)
                        i2 = T.axis.spatial(18, i2_0_i3_0_i2_1_fused % 8 % 4 * 4 + ax2)
                        i3 = T.axis.spatial(256, i2_0_i3_0_i2_1_fused % 32 // 8 * 64 + i3_1 + ax3)
                        T.reads(placeholder[0, i1 - 1, i2 - 1, i3])
                        T.writes(data_pad[i0, i1, i2, i3])
                        T.block_attr({"schedule_rule":"None"})
                        data_pad[i0, i1, i2, i3] = T.if_then_else(1 <= i1 and i1 < 15 and 1 <= i2 and i2 < 15, placeholder[0, i1 - 1, i2 - 1, i3], T.float32(0), dtype="float32")
                for i0 in T.unroll(6):
                    for i1 in T.unroll(6):
                        for ax0, ax1, ax2, ax3 in T.grid(6, 6, 1, 1):
                            with T.block("input_tile"):
                                eps, nu = T.axis.remap("SS", [ax0, ax1])
                                p = T.axis.spatial(16, i2_0_i3_0_i2_1_fused // 32 * 8 + i2_0_i3_0_i2_1_fused % 8)
                                ci = T.axis.spatial(256, i2_0_i3_0_i2_1_fused % 32 // 8 * 64 + i3_1)
                                T.reads(data_pad[0, p // 4 * 4 + eps, p % 4 * 4 + nu, ci])
                                T.writes(input_tile[eps, nu, p, ci])
                                T.block_attr({"schedule_rule":"None"})
                                input_tile[eps, nu, p, ci] = data_pad[0, p // 4 * 4 + eps, p % 4 * 4 + nu, ci]
                        with T.block("data_pack_init"):
                            eps, nu = T.axis.remap("SS", [i0, i1])
                            p = T.axis.spatial(16, i2_0_i3_0_i2_1_fused // 32 * 8 + i2_0_i3_0_i2_1_fused % 8)
                            ci = T.axis.spatial(256, i2_0_i3_0_i2_1_fused % 32 // 8 * 64 + i3_1)
                            T.reads()
                            T.writes(data_pack[eps, nu, p, ci])
                            T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["eps", "nu", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_data_pack.llvm"})
                            data_pack[eps, nu, p, ci] = T.float32(0)
                        for i4 in T.unroll(6):
                            for i5 in T.unroll(6):
                                with T.block("data_pack_update"):
                                    eps, nu = T.axis.remap("SS", [i0, i1])
                                    p = T.axis.spatial(16, i2_0_i3_0_i2_1_fused // 32 * 8 + i2_0_i3_0_i2_1_fused % 8)
                                    ci = T.axis.spatial(256, i2_0_i3_0_i2_1_fused % 32 // 8 * 64 + i3_1)
                                    r_a, r_b = T.axis.remap("RR", [i4, i5])
                                    T.reads(data_pack[eps, nu, p, ci], input_tile[r_a, r_b, p, ci])
                                    T.writes(data_pack[eps, nu, p, ci])
                                    T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["eps", "nu", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_data_pack.llvm"})
                                    data_pack[eps, nu, p, ci] = data_pack[eps, nu, p, ci] + input_tile[r_a, r_b, p, ci] * T.Select(r_a == 5 and eps == 5, T.float32(1), T.Select(r_a == 5 and eps == 4, T.float32(0), T.Select(r_a == 5 and eps == 3, T.float32(0), T.Select(r_a == 5 and eps == 2, T.float32(0), T.Select(r_a == 5 and eps == 1, T.float32(0), T.Select(r_a == 5 and eps == 0, T.float32(0), T.Select(r_a == 4 and eps == 5, T.float32(1.5), T.Select(r_a == 4 and eps == 4, T.float32(1), T.Select(r_a == 4 and eps == 3, T.float32(1), T.Select(r_a == 4 and eps == 2, T.float32(1), T.Select(r_a == 4 and eps == 1, T.float32(1), T.Select(r_a == 4 and eps == 0, T.float32(1), T.Select(r_a == 3 and eps == 5, T.float32(-2), T.Select(r_a == 3 and eps == 4, T.float32(-0.5), T.Select(r_a == 3 and eps == 3, T.float32(2), T.Select(r_a == 3 and eps == 2, T.float32(2.5), T.Select(r_a == 3 and eps == 1, T.float32(0.5), T.Select(r_a == 3 and eps == 0, T.float32(1.5), T.Select(r_a == 2 and eps == 5, T.float32(-1.5), T.Select(r_a == 2 and eps == 4, T.float32(-1), T.Select(r_a == 2 and eps == 3, T.float32(-1), T.Select(r_a == 2 and eps == 2, T.float32(0.5), T.Select(r_a == 2 and eps == 1, T.float32(-2.5), T.Select(r_a == 2 and eps == 0, T.float32(-2), T.Select(r_a == 1 and eps == 5, T.float32(1), T.Select(r_a == 1 and eps == 4, T.float32(0.5), T.Select(r_a == 1 and eps == 3, T.float32(-2), T.Select(r_a == 1 and eps == 2, T.float32(-1), T.Select(r_a == 1 and eps == 1, T.float32(1), T.Select(r_a == 1 and eps == 0, T.float32(-1.5), T.Select(r_a == 0 and eps == 5, T.float32(0), T.Select(r_a == 0 and eps == 4, T.float32(0), T.Select(r_a == 0 and eps == 3, T.float32(0), T.Select(r_a == 0 and eps == 2, T.float32(0), T.Select(r_a == 0 and eps == 1, T.float32(0), T.Select(r_a == 0 and eps == 0, T.float32(1), T.float32(0))))))))))))))))))))))))))))))))))))) * T.Select(r_b == 5 and nu == 5, T.float32(1), T.Select(r_b == 5 and nu == 4, T.float32(0), T.Select(r_b == 5 and nu == 3, T.float32(0), T.Select(r_b == 5 and nu == 2, T.float32(0), T.Select(r_b == 5 and nu == 1, T.float32(0), T.Select(r_b == 5 and nu == 0, T.float32(0), T.Select(r_b == 4 and nu == 5, T.float32(1.5), T.Select(r_b == 4 and nu == 4, T.float32(1), T.Select(r_b == 4 and nu == 3, T.float32(1), T.Select(r_b == 4 and nu == 2, T.float32(1), T.Select(r_b == 4 and nu == 1, T.float32(1), T.Select(r_b == 4 and nu == 0, T.float32(1), T.Select(r_b == 3 and nu == 5, T.float32(-2), T.Select(r_b == 3 and nu == 4, T.float32(-0.5), T.Select(r_b == 3 and nu == 3, T.float32(2), T.Select(r_b == 3 and nu == 2, T.float32(2.5), T.Select(r_b == 3 and nu == 1, T.float32(0.5), T.Select(r_b == 3 and nu == 0, T.float32(1.5), T.Select(r_b == 2 and nu == 5, T.float32(-1.5), T.Select(r_b == 2 and nu == 4, T.float32(-1), T.Select(r_b == 2 and nu == 3, T.float32(-1), T.Select(r_b == 2 and nu == 2, T.float32(0.5), T.Select(r_b == 2 and nu == 1, T.float32(-2.5), T.Select(r_b == 2 and nu == 0, T.float32(-2), T.Select(r_b == 1 and nu == 5, T.float32(1), T.Select(r_b == 1 and nu == 4, T.float32(0.5), T.Select(r_b == 1 and nu == 3, T.float32(-2), T.Select(r_b == 1 and nu == 2, T.float32(-1), T.Select(r_b == 1 and nu == 1, T.float32(1), T.Select(r_b == 1 and nu == 0, T.float32(-1.5), T.Select(r_b == 0 and nu == 5, T.float32(0), T.Select(r_b == 0 and nu == 4, T.float32(0), T.Select(r_b == 0 and nu == 3, T.float32(0), T.Select(r_b == 0 and nu == 2, T.float32(0), T.Select(r_b == 0 and nu == 1, T.float32(0), T.Select(r_b == 0 and nu == 0, T.float32(1), T.float32(0)))))))))))))))))))))))))))))))))))))
        for i0_0_i1_0_i2_0_i3_0_fused in T.parallel(576, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1 in T.grid(1, 1, 1, 2):
                for i2_2_init, i2_3_init, i3_3_init in T.grid(2, 8, 8):
                    with T.block("bgemm_init"):
                        eps = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused // 96)
                        nu = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused % 96 // 16)
                        p = T.axis.spatial(16, i2_2_init * 8 + i2_3_init)
                        co = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused % 16 * 16 + i3_1 * 8 + i3_3_init)
                        T.reads()
                        T.writes(bgemm_global[eps, nu, p, co])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        bgemm_global[eps, nu, p, co] = T.float32(0)
                for i4_0, i0_2, i1_2, i2_2, i3_2, i4_1, i0_3, i1_3, i2_3, i3_3 in T.grid(256, 1, 1, 2, 1, 1, 1, 1, 8, 8):
                    with T.block("bgemm_update"):
                        eps = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused // 96)
                        nu = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused % 96 // 16)
                        p = T.axis.spatial(16, i2_2 * 8 + i2_3)
                        co = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused % 16 * 16 + i3_1 * 8 + i3_3)
                        ci = T.axis.reduce(256, i4_0)
                        T.reads(bgemm_global[eps, nu, p, co], data_pack[eps, nu, p, ci], placeholder_1[eps, nu, co, ci])
                        T.writes(bgemm_global[eps, nu, p, co])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        bgemm_global[eps, nu, p, co] = bgemm_global[eps, nu, p, co] + data_pack[eps, nu, p, ci] * placeholder_1[eps, nu, co, ci]
                for ax0, ax1, ax2 in T.grid(1, 1, 16):
                    for ax3_fused in T.vectorized(8):
                        with T.block("bgemm_global"):
                            v0 = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused // 96)
                            v1 = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_fused % 96 // 16)
                            v2 = T.axis.spatial(16, ax2)
                            v3 = T.axis.spatial(256, i0_0_i1_0_i2_0_i3_0_fused % 16 * 16 + i3_1 * 8 + ax3_fused)
                            T.reads(bgemm_global[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_global[v0, v1, v2, v3]
        for i2_0_i3_0_i2_1_fused in T.parallel(64, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i3_1 in T.serial(64):
                for i0 in T.unroll(4):
                    for i1 in T.unroll(4):
                        with T.block("inverse_init"):
                            vh, vw = T.axis.remap("SS", [i0, i1])
                            p = T.axis.spatial(16, i2_0_i3_0_i2_1_fused // 8 * 2 + i2_0_i3_0_i2_1_fused % 2)
                            co = T.axis.spatial(256, i2_0_i3_0_i2_1_fused % 8 // 2 * 64 + i3_1)
                            T.reads()
                            T.writes(inverse[vh, vw, p, co])
                            T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["vh", "vw", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_inverse"})
                            inverse[vh, vw, p, co] = T.float32(0)
                        for i4 in T.unroll(6):
                            for i5 in T.unroll(6):
                                with T.block("inverse_update"):
                                    vh, vw = T.axis.remap("SS", [i0, i1])
                                    p = T.axis.spatial(16, i2_0_i3_0_i2_1_fused // 8 * 2 + i2_0_i3_0_i2_1_fused % 2)
                                    co = T.axis.spatial(256, i2_0_i3_0_i2_1_fused % 8 // 2 * 64 + i3_1)
                                    r_a, r_b = T.axis.remap("RR", [i4, i5])
                                    T.reads(inverse[vh, vw, p, co], bgemm[r_a, r_b, p, co])
                                    T.writes(inverse[vh, vw, p, co])
                                    T.block_attr({"auto_scheduler_simplify_const_tensor_indices":["vh", "vw", "r_a", "r_b"], "schedule_rule":"meta_schedule.winograd_inverse"})
                                    inverse[vh, vw, p, co] = inverse[vh, vw, p, co] + bgemm[r_a, r_b, p, co] * T.Select(r_a == 5 and vh == 3, T.float32(1), T.Select(r_a == 5 and vh == 2, T.float32(0), T.Select(r_a == 5 and vh == 1, T.float32(0), T.Select(r_a == 5 and vh == 0, T.float32(0), T.Select(r_a == 4 and vh == 3, T.float32(-8), T.Select(r_a == 4 and vh == 2, T.float32(4), T.Select(r_a == 4 and vh == 1, T.float32(-2), T.Select(r_a == 4 and vh == 0, T.float32(1), T.Select(r_a == 3 and vh == 3, T.float32(0.125), T.Select(r_a == 3 and vh == 2, T.float32(0.25), T.Select(r_a == 3 and vh == 1, T.float32(0.5), T.Select(r_a == 3 and vh == 0, T.float32(1), T.Select(r_a == 2 and vh == 3, T.float32(1), T.Select(r_a == 2 and vh == 2, T.float32(1), T.Select(r_a == 2 and vh == 1, T.float32(1), T.Select(r_a == 2 and vh == 0, T.float32(1), T.Select(r_a == 1 and vh == 3, T.float32(-1), T.Select(r_a == 1 and vh == 2, T.float32(1), T.Select(r_a == 1 and vh == 1, T.float32(-1), T.Select(r_a == 1 and vh == 0, T.float32(1), T.Select(r_a == 0 and vh == 3, T.float32(0), T.Select(r_a == 0 and vh == 2, T.float32(0), T.Select(r_a == 0 and vh == 1, T.float32(0), T.Select(r_a == 0 and vh == 0, T.float32(1), T.float32(0))))))))))))))))))))))))) * T.Select(r_b == 5 and vw == 3, T.float32(1), T.Select(r_b == 5 and vw == 2, T.float32(0), T.Select(r_b == 5 and vw == 1, T.float32(0), T.Select(r_b == 5 and vw == 0, T.float32(0), T.Select(r_b == 4 and vw == 3, T.float32(-8), T.Select(r_b == 4 and vw == 2, T.float32(4), T.Select(r_b == 4 and vw == 1, T.float32(-2), T.Select(r_b == 4 and vw == 0, T.float32(1), T.Select(r_b == 3 and vw == 3, T.float32(0.125), T.Select(r_b == 3 and vw == 2, T.float32(0.25), T.Select(r_b == 3 and vw == 1, T.float32(0.5), T.Select(r_b == 3 and vw == 0, T.float32(1), T.Select(r_b == 2 and vw == 3, T.float32(1), T.Select(r_b == 2 and vw == 2, T.float32(1), T.Select(r_b == 2 and vw == 1, T.float32(1), T.Select(r_b == 2 and vw == 0, T.float32(1), T.Select(r_b == 1 and vw == 3, T.float32(-1), T.Select(r_b == 1 and vw == 2, T.float32(1), T.Select(r_b == 1 and vw == 1, T.float32(-1), T.Select(r_b == 1 and vw == 0, T.float32(1), T.Select(r_b == 0 and vw == 3, T.float32(0), T.Select(r_b == 0 and vw == 2, T.float32(0), T.Select(r_b == 0 and vw == 1, T.float32(0), T.Select(r_b == 0 and vw == 0, T.float32(1), T.float32(0)))))))))))))))))))))))))
        for i0_i1_i2_fused in T.parallel(196, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i3 in T.serial(256):
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 1):
                    with T.block("conv2d_winograd"):
                        n = T.axis.spatial(1, 0)
                        h = T.axis.spatial(14, i0_i1_i2_fused // 14)
                        w = T.axis.spatial(14, i0_i1_i2_fused % 14)
                        co = T.axis.spatial(256, i3)
                        T.reads(inverse[h % 4, w % 4, h // 4 * 4 + w // 4, co])
                        T.writes(conv2d_winograd[n, h, w, co])
                        conv2d_winograd[n, h, w, co] = inverse[h % 4, w % 4, h // 4 * 4 + w // 4, co]
                with T.block("T_relu"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(14, i0_i1_i2_fused // 14)
                    ax2 = T.axis.spatial(14, i0_i1_i2_fused % 14)
                    ax3 = T.axis.spatial(256, i3)
                    T.reads(conv2d_winograd[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                    T.writes(T_relu[ax0, ax1, ax2, ax3])
                    T_relu[ax0, ax1, ax2, ax3] = T.max(conv2d_winograd[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:31] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:31] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"B\", func_name=\"main\")", "b1 = sch.get_block(name=\"data_pack\", func_name=\"main\")", "b2 = sch.get_block(name=\"bgemm\", func_name=\"main\")", "b3 = sch.get_block(name=\"A\", func_name=\"main\")", "b4 = sch.get_block(name=\"inverse\", func_name=\"main\")", "b5 = sch.get_block(name=\"conv2d_winograd\", func_name=\"main\")", "b6 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b7 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b0)", "b8, = sch.get_producers(block=b1)", "b9, = sch.get_producers(block=b8)", "l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b1)", "v16, v17 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[2, 8])", "l18, l19 = sch.split(loop=l12, factors=[v16, v17])", "v20, v21 = sch.sample_perfect_tile(loop=l13, n=2, max_innermost_factor=64, decision=[4, 64])", "l22, l23 = sch.split(loop=l13, factors=[v20, v21])", "sch.unroll(loop=l10)", "sch.unroll(loop=l11)", "sch.unroll(loop=l14)", "sch.unroll(loop=l15)", "sch.reorder(l18, l22, l19, l23, l10, l11, l14, l15)", "l24 = sch.sample_compute_location(block=b8, decision=5)", "sch.compute_at(block=b8, loop=l24, preserve_unit_loops=True)", "l25 = sch.sample_compute_location(block=b9, decision=3)", "sch.compute_at(block=b9, loop=l25, preserve_unit_loops=True)", "sch.compute_inline(block=b3)", "l26, l27, l28, l29, l30, l31 = sch.get_loops(block=b4)", "v32, v33 = sch.sample_perfect_tile(loop=l28, n=2, max_innermost_factor=64, decision=[8, 2])", "l34, l35 = sch.split(loop=l28, factors=[v32, v33])", "v36, v37 = sch.sample_perfect_tile(loop=l29, n=2, max_innermost_factor=64, decision=[4, 64])", "l38, l39 = sch.split(loop=l29, factors=[v36, v37])", "sch.unroll(loop=l26)", "sch.unroll(loop=l27)", "sch.unroll(loop=l30)", "sch.unroll(loop=l31)", "sch.reorder(l34, l38, l35, l39, l26, l27, l30, l31)", "sch.compute_inline(block=b6)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l40, l41, l42, l43, l44 = sch.get_loops(block=b2)", "v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l40, n=4, max_innermost_factor=64, decision=[6, 1, 1, 1])", "l49, l50, l51, l52 = sch.split(loop=l40, factors=[v45, v46, v47, v48])", "v53, v54, v55, v56 = sch.sample_perfect_tile(loop=l41, n=4, max_innermost_factor=64, decision=[6, 1, 1, 1])", "l57, l58, l59, l60 = sch.split(loop=l41, factors=[v53, v54, v55, v56])", "v61, v62, v63, v64 = sch.sample_perfect_tile(loop=l42, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])", "l65, l66, l67, l68 = sch.split(loop=l42, factors=[v61, v62, v63, v64])", "v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l43, n=4, max_innermost_factor=64, decision=[16, 2, 1, 8])", "l73, l74, l75, l76 = sch.split(loop=l43, factors=[v69, v70, v71, v72])", "v77, v78 = sch.sample_perfect_tile(loop=l44, n=2, max_innermost_factor=64, decision=[256, 1])", "l79, l80 = sch.split(loop=l44, factors=[v77, v78])", "sch.reorder(l49, l57, l65, l73, l50, l58, l66, l74, l79, l51, l59, l67, l75, l80, l52, l60, l68, l76)", "b81 = sch.cache_write(block=b2, write_buffer_index=0, storage_scope=\"global\")", "sch.reverse_compute_at(block=b81, loop=l74, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b7, ann_key=\"meta_schedule.parallel\", ann_val=36)", "sch.annotate(block_or_loop=b7, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v82 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b7, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v82)", "l83 = sch.sample_compute_location(block=b5, decision=3)", "sch.compute_at(block=b5, loop=l83, preserve_unit_loops=True)", "sch.enter_postproc()", "b84 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b84, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b84, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b84, ann_key=\"meta_schedule.unroll_explicit\")", "b85, b86, b87, b88, b89, b90, b91, b92 = sch.get_child_blocks(b84)", "l93, l94, l95, l96, l97, l98, l99, l100 = sch.get_loops(block=b85)", "l101 = sch.fuse(l93, l94, l95)", "sch.parallel(loop=l101)", "sch.annotate(block_or_loop=l101, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l101, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b86)", "sch.annotate(block_or_loop=l102, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l102, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b87)", "sch.annotate(block_or_loop=l110, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l110, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b88)", "l134 = sch.fuse(l116, l117, l118, l119)", "sch.parallel(loop=l134)", "sch.annotate(block_or_loop=l134, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l134, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b89)", "l144 = sch.fuse(l143)", "sch.vectorize(loop=l144)", "sch.annotate(block_or_loop=l135, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l135, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l145, l146, l147, l148, l149, l150, l151, l152 = sch.get_loops(block=b90)", "l153 = sch.fuse(l145, l146, l147)", "sch.parallel(loop=l153)", "sch.annotate(block_or_loop=l153, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l153, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l154, l155, l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b91)", "l162 = sch.fuse(l154, l155, l156)", "sch.parallel(loop=l162)", "sch.annotate(block_or_loop=l162, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l162, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l163, l164 = sch.get_loops(block=b92)", "sch.annotate(block_or_loop=l163, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l163, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b165 = sch.get_block(name=\"data_pack\", func_name=\"main\")", "l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b165)", "b172 = sch.decompose_reduction(block=b165, loop=l170)", "b173 = sch.get_block(name=\"bgemm\", func_name=\"main\")", "l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188 = sch.get_loops(block=b173)", "b189 = sch.decompose_reduction(block=b173, loop=l179)", "b190 = sch.get_block(name=\"inverse\", func_name=\"main\")", "l191, l192, l193, l194, l195, l196 = sch.get_loops(block=b190)", "b197 = sch.decompose_reduction(block=b190, loop=l195)"]
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 14, 14, 1024), "float32"], placeholder_1: T.Buffer[(1, 1, 1024, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], T_relu: T.Buffer[(1, 14, 14, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 14, 14, 1024], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 14, 14, 512], dtype="float32")
        T_add = T.alloc_buffer([1, 14, 14, 512], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 1024):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 14, 14, 512, 1, 1, 1024):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 512):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 512):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_10(placeholder: T.Buffer[(1, 14, 14, 1024), "float32"], placeholder_1: T.Buffer[(1, 1, 1024, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], T_relu: T.Buffer[(1, 14, 14, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 14, 14, 512], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i4_0, i5_0 in T.grid(1, 1):
                for i1_2_init, i3_2_init, i2_3_init in T.grid(14, 2, 7):
                    for i3_3_fused_init in T.vectorized(32):
                        with T.block("conv2d_nhwc_init"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(14, i1_2_init)
                            xx = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 8 // 4 * 7 + i2_3_init)
                            ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 8 * 256 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 4 * 64 + i3_2_init * 32 + i3_3_fused_init)
                            T.reads()
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(16, 1, 14, 1, 2, 1, 1, 64, 1, 1, 7):
                    for i3_3_fused in T.vectorized(32):
                        with T.block("conv2d_nhwc_update"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(14, i1_2)
                            xx = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 8 // 4 * 7 + i2_3)
                            ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 8 * 256 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 4 * 64 + i3_2 * 32 + i3_3_fused)
                            ry = T.axis.reduce(1, 0)
                            rx = T.axis.reduce(1, 0)
                            rc = T.axis.reduce(1024, i6_0 * 64 + i6_1)
                            T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
            for ax0, ax1, ax2 in T.grid(1, 14, 7):
                for ax3_fused in T.vectorized(64):
                    with T.block("T_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(14, ax1)
                        ax2_1 = T.axis.spatial(14, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 8 // 4 * 7 + ax2)
                        ax3 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 8 * 256 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 4 * 64 + ax3_fused)
                        T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                        T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                        T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 4, 2, 32])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 64])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "sch.enter_postproc()", "b57 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.unroll_explicit\")", "b58, b59 = sch.get_child_blocks(b57)", "l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b58)", "l82 = sch.fuse(l60, l61, l62, l63, l64, l65, l66, l67)", "sch.parallel(loop=l82)", "l83 = sch.fuse(l81)", "sch.vectorize(loop=l83)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l84, l85, l86, l87, l88 = sch.get_loops(block=b59)", "l89 = sch.fuse(l88)", "sch.vectorize(loop=l89)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b90 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b90)", "b106 = sch.decompose_reduction(block=b90, loop=l94)"]
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 14, 14, 512), "float32"], placeholder_1: T.Buffer[(3, 3, 512, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], T_relu: T.Buffer[(1, 7, 7, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 16, 16, 512], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 7, 7, 512], dtype="float32")
        T_add = T.alloc_buffer([1, 7, 7, 512], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 16, 16, 512):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1 - 1, i2_1 - 1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i1_1 and i1_1 < 15 and 1 <= i2_1 and i2_1 < 15, placeholder[0, i1_1 - 1, i2_1 - 1, i3_1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 7, 7, 512, 3, 3, 512):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc], placeholder_1[ry, rx, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc] * placeholder_1[ry, rx, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 512):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 512):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_11(placeholder: T.Buffer[(1, 14, 14, 512), "float32"], placeholder_1: T.Buffer[(3, 3, 512, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], T_relu: T.Buffer[(1, 7, 7, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 16, 16, 512], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 7, 7, 512], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_0, i5_0 in T.grid(1, 1):
                for i1_2_init, i2_3_init in T.grid(7, 7):
                    for i3_3_fused_init in T.vectorized(32):
                        with T.block("conv2d_nhwc_init"):
                            nn = T.axis.spatial(1, 0)
                            yy, xx = T.axis.remap("SS", [i1_2_init, i2_3_init])
                            ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 2 * 64 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 32 + i3_3_fused_init)
                            T.reads()
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                for i6_0 in T.serial(16):
                    for ax0, ax1, ax2 in T.grid(1, 15, 15):
                        for ax3_fused in T.vectorized(32):
                            with T.block("pad_temp"):
                                i0 = T.axis.spatial(1, 0)
                                i1 = T.axis.spatial(16, ax1)
                                i2 = T.axis.spatial(16, ax2)
                                i3 = T.axis.spatial(512, i6_0 * 32 + ax3_fused)
                                T.reads(placeholder[0, i1 - 1, i2 - 1, i3])
                                T.writes(pad_temp[i0, i1, i2, i3])
                                pad_temp[i0, i1, i2, i3] = T.if_then_else(1 <= i1 and i1 < 15 and 1 <= i2 and i2 < 15, placeholder[0, i1 - 1, i2 - 1, i3], T.float32(0), dtype="float32")
                    for i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(1, 7, 1, 1, 3, 3, 32, 1, 1, 7):
                        for i3_3_fused in T.vectorized(32):
                            with T.block("conv2d_nhwc_update"):
                                nn = T.axis.spatial(1, 0)
                                yy, xx = T.axis.remap("SS", [i1_2, i2_3])
                                ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 2 * 64 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 32 + i3_3_fused)
                                ry, rx = T.axis.remap("RR", [i4_1, i5_1])
                                rc = T.axis.reduce(512, i6_0 * 32 + i6_1)
                                T.reads(conv2d_nhwc[nn, yy, xx, ff], pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc], placeholder_1[ry, rx, rc, ff])
                                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                                T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy * 2 + ry, xx * 2 + rx, rc] * placeholder_1[ry, rx, rc, ff]
            for ax0, ax1, ax2 in T.grid(1, 7, 7):
                for ax3_fused in T.vectorized(32):
                    with T.block("T_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1, ax2_1 = T.axis.remap("SS", [ax1, ax2])
                        ax3 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 2 * 64 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 32 + ax3_fused)
                        T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                        T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                        T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 2, 1, 32])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 32])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "l57 = sch.sample_compute_location(block=b0, decision=10)", "sch.compute_at(block=b0, loop=l57, preserve_unit_loops=True)", "sch.enter_postproc()", "b58 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.unroll_explicit\")", "b59, b60, b61 = sch.get_child_blocks(b58)", "l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b59)", "l77 = sch.fuse(l62, l63, l64, l65, l66, l67, l68, l69)", "sch.parallel(loop=l77)", "l78 = sch.fuse(l76)", "sch.vectorize(loop=l78)", "sch.annotate(block_or_loop=l77, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l77, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b60)", "l94 = sch.fuse(l93)", "sch.vectorize(loop=l94)", "sch.annotate(block_or_loop=l79, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l79, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l95, l96, l97, l98, l99 = sch.get_loops(block=b61)", "l100 = sch.fuse(l99)", "sch.vectorize(loop=l100)", "sch.annotate(block_or_loop=l95, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l95, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b101 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b101)", "b117 = sch.decompose_reduction(block=b101, loop=l105)"]
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 14, 14, 1024), "float32"], placeholder_1: T.Buffer[(1, 1, 1024, 2048), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 2048), "float32"], T_add: T.Buffer[(1, 7, 7, 2048), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 14, 14, 1024], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 7, 7, 2048], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 14, 14, 1024):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 7, 7, 2048, 1, 1, 1024):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy * 2, xx * 2, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy * 2, xx * 2, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 2048):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_3(placeholder: T.Buffer[(1, 14, 14, 1024), "float32"], placeholder_1: T.Buffer[(1, 1, 1024, 2048), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 2048), "float32"], T_add: T.Buffer[(1, 7, 7, 2048), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 7, 7, 2048], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(64, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_0, i5_0 in T.grid(1, 1):
                for i1_2_init, i2_3_init in T.grid(7, 7):
                    for i3_3_fused_init in T.vectorized(32):
                        with T.block("conv2d_nhwc_init"):
                            nn = T.axis.spatial(1, 0)
                            yy, xx = T.axis.remap("SS", [i1_2_init, i2_3_init])
                            ff = T.axis.spatial(2048, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 32 * 1024 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 32 * 32 + i3_3_fused_init)
                            T.reads()
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(64, 1, 7, 1, 1, 1, 1, 16, 1, 1, 7):
                    for i3_3_fused in T.vectorized(32):
                        with T.block("conv2d_nhwc_update"):
                            nn = T.axis.spatial(1, 0)
                            yy, xx = T.axis.remap("SS", [i1_2, i2_3])
                            ff = T.axis.spatial(2048, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 32 * 1024 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 32 * 32 + i3_3_fused)
                            ry = T.axis.reduce(1, 0)
                            rx = T.axis.reduce(1, 0)
                            rc = T.axis.reduce(1024, i6_0 * 16 + i6_1)
                            T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy * 2, xx * 2, rc], placeholder_1[0, 0, rc, ff])
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy * 2, xx * 2, rc] * placeholder_1[0, 0, rc, ff]
            for ax0, ax1, ax2 in T.grid(1, 7, 7):
                for ax3_fused in T.vectorized(32):
                    with T.block("T_add"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1, ax2_1 = T.axis.remap("SS", [ax1, ax2])
                        ax3 = T.axis.spatial(2048, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 32 * 1024 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 32 * 32 + ax3_fused)
                        T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                        T.writes(T_add[ax0_1, ax1_1, ax2_1, ax3])
                        T_add[ax0_1, ax1_1, ax2_1, ax3] = conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3]
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)", "v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13])", "v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])", "l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21])", "v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])", "l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29])", "v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 32, 1, 32])", "l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37])", "v42, v43 = sch.sample_perfect_tile(loop=l7, n=2, max_innermost_factor=64, decision=[1, 1])", "l44, l45 = sch.split(loop=l7, factors=[v42, v43])", "v46, v47 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l48, l49 = sch.split(loop=l8, factors=[v46, v47])", "v50, v51 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 16])", "l52, l53 = sch.split(loop=l9, factors=[v50, v51])", "sch.reorder(l14, l22, l30, l38, l15, l23, l31, l39, l44, l48, l52, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41)", "b54, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b54, loop=l39, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v55 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v55)", "sch.enter_postproc()", "b56 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b56, ann_key=\"meta_schedule.unroll_explicit\")", "b57, b58 = sch.get_child_blocks(b56)", "l59, l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b57)", "l81 = sch.fuse(l59, l60, l61, l62, l63, l64, l65, l66)", "sch.parallel(loop=l81)", "l82 = sch.fuse(l80)", "sch.vectorize(loop=l82)", "sch.annotate(block_or_loop=l81, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l81, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l83, l84, l85, l86, l87 = sch.get_loops(block=b58)", "l88 = sch.fuse(l87)", "sch.vectorize(loop=l88)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b89 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b89)", "b105 = sch.decompose_reduction(block=b89, loop=l93)"]
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 7, 7, 512), "float32"], placeholder_1: T.Buffer[(1, 1, 512, 2048), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 2048), "float32"], placeholder_3: T.Buffer[(1, 7, 7, 2048), "float32"], T_relu: T.Buffer[(1, 7, 7, 2048), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 7, 7, 512], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 7, 7, 2048], dtype="float32")
        T_add = T.alloc_buffer([1, 7, 7, 2048], dtype="float32")
        T_add_1 = T.alloc_buffer([1, 7, 7, 2048], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 512):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 7, 7, 2048, 1, 1, 512):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 2048):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 2048):
            with T.block("T_add_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3], placeholder_3[0, ax1, ax2, ax3])
                T.writes(T_add_1[ax0, ax1, ax2, ax3])
                T_add_1[ax0, ax1, ax2, ax3] = T_add[0, ax1, ax2, ax3] + placeholder_3[0, ax1, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 2048):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add_1[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add_1[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_add_nn_relu_3(placeholder: T.Buffer[(1, 7, 7, 512), "float32"], placeholder_1: T.Buffer[(1, 1, 512, 2048), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 2048), "float32"], placeholder_3: T.Buffer[(1, 7, 7, 2048), "float32"], T_relu: T.Buffer[(1, 7, 7, 2048), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 7, 7, 2048], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_fused in T.parallel(32, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_0, i5_0 in T.grid(1, 1, 1, 2, 1, 1):
                for i2_2_init, i1_3_init in T.grid(7, 7):
                    for i2_3_i3_3_fused_init in T.vectorized(32):
                        with T.block("conv2d_nhwc_init"):
                            nn = T.axis.spatial(1, 0)
                            yy, xx = T.axis.remap("SS", [i1_3_init, i2_2_init])
                            ff = T.axis.spatial(2048, i0_0_i1_0_i2_0_i3_0_fused * 64 + i3_1 * 32 + i2_3_i3_3_fused_init)
                            T.reads()
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3 in T.grid(32, 1, 1, 7, 1, 1, 1, 16, 1, 7):
                    for i2_3_i3_3_fused in T.vectorized(32):
                        with T.block("conv2d_nhwc_update"):
                            nn = T.axis.spatial(1, 0)
                            yy, xx = T.axis.remap("SS", [i1_3, i2_2])
                            ff = T.axis.spatial(2048, i0_0_i1_0_i2_0_i3_0_fused * 64 + i3_1 * 32 + i2_3_i3_3_fused)
                            ry = T.axis.reduce(1, 0)
                            rx = T.axis.reduce(1, 0)
                            rc = T.axis.reduce(512, i6_0 * 16 + i6_1)
                            T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
            for ax0, ax1, ax2 in T.grid(1, 7, 7):
                for ax3_fused in T.vectorized(64):
                    with T.block("T_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1, ax2_1 = T.axis.remap("SS", [ax1, ax2])
                        ax3 = T.axis.spatial(2048, i0_0_i1_0_i2_0_i3_0_fused * 64 + ax3_fused)
                        T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3], placeholder_3[0, ax1_1, ax2_1, ax3])
                        T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                        T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3] + placeholder_3[0, ax1_1, ax2_1, ax3], T.float32(0))
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"T_add_1\", func_name=\"main\")", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b3)", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)", "v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l16, l17, l18, l19 = sch.split(loop=l5, factors=[v12, v13, v14, v15])", "v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])", "l24, l25, l26, l27 = sch.split(loop=l6, factors=[v20, v21, v22, v23])", "v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])", "l32, l33, l34, l35 = sch.split(loop=l7, factors=[v28, v29, v30, v31])", "v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[32, 2, 1, 32])", "l40, l41, l42, l43 = sch.split(loop=l8, factors=[v36, v37, v38, v39])", "v44, v45 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l46, l47 = sch.split(loop=l9, factors=[v44, v45])", "v48, v49 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])", "l50, l51 = sch.split(loop=l10, factors=[v48, v49])", "v52, v53 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[32, 16])", "l54, l55 = sch.split(loop=l11, factors=[v52, v53])", "sch.reorder(l16, l24, l32, l40, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42, l47, l51, l55, l19, l27, l35, l43)", "b56, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b56, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v57 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v57)", "sch.enter_postproc()", "b58 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.unroll_explicit\")", "b59, b60 = sch.get_child_blocks(b58)", "l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b59)", "l83 = sch.fuse(l61, l62, l63, l64)", "sch.parallel(loop=l83)", "l84 = sch.fuse(l81, l82)", "sch.vectorize(loop=l84)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l83, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l85, l86, l87, l88, l89 = sch.get_loops(block=b60)", "l90 = sch.fuse(l89)", "sch.vectorize(loop=l90)", "sch.annotate(block_or_loop=l85, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l85, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b91 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b91)", "b110 = sch.decompose_reduction(block=b91, loop=l99)"]
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 7, 7, 2048), "float32"], placeholder_1: T.Buffer[(1, 1, 2048, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], T_relu: T.Buffer[(1, 7, 7, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 7, 7, 2048], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 7, 7, 512], dtype="float32")
        T_add = T.alloc_buffer([1, 7, 7, 512], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 2048):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = placeholder[0, i1_1, i2_1, i3_1]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 7, 7, 512, 1, 1, 2048):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 512):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 512):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_12(placeholder: T.Buffer[(1, 7, 7, 2048), "float32"], placeholder_1: T.Buffer[(1, 1, 2048, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], T_relu: T.Buffer[(1, 7, 7, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        conv2d_nhwc = T.alloc_buffer([1, 7, 7, 512], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(56, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i4_0, i5_0 in T.grid(1, 1):
                for i2_3_init in T.serial(7):
                    for i3_3_fused_init in T.vectorized(64):
                        with T.block("conv2d_nhwc_init"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(7, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 7)
                            xx = T.axis.spatial(7, i2_3_init)
                            ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 7 * 64 + i3_3_fused_init)
                            T.reads()
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                for i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1, i0_3, i1_3, i2_3 in T.grid(256, 1, 1, 1, 1, 1, 1, 8, 1, 1, 7):
                    for i3_3_fused in T.vectorized(64):
                        with T.block("conv2d_nhwc_update"):
                            nn = T.axis.spatial(1, 0)
                            yy = T.axis.spatial(7, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 7)
                            xx = T.axis.spatial(7, i2_3)
                            ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 7 * 64 + i3_3_fused)
                            ry = T.axis.reduce(1, 0)
                            rx = T.axis.reduce(1, 0)
                            rc = T.axis.reduce(2048, i6_0 * 8 + i6_1)
                            T.reads(conv2d_nhwc[nn, yy, xx, ff], placeholder[0, yy, xx, rc], placeholder_1[0, 0, rc, ff])
                            T.writes(conv2d_nhwc[nn, yy, xx, ff])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + placeholder[0, yy, xx, rc] * placeholder_1[0, 0, rc, ff]
            for ax0, ax1, ax2 in T.grid(1, 1, 7):
                for ax3_fused in T.vectorized(64):
                    with T.block("T_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(7, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 7)
                        ax2_1 = T.axis.spatial(7, ax2)
                        ax3 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 7 * 64 + ax3_fused)
                        T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                        T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                        T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 7, 1, 1])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 7])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 1, 1, 64])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 1])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 8])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "sch.enter_postproc()", "b57 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b57, ann_key=\"meta_schedule.unroll_explicit\")", "b58, b59 = sch.get_child_blocks(b57)", "l60, l61, l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b58)", "l82 = sch.fuse(l60, l61, l62, l63, l64, l65, l66, l67)", "sch.parallel(loop=l82)", "l83 = sch.fuse(l81)", "sch.vectorize(loop=l83)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l82, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l84, l85, l86, l87, l88 = sch.get_loops(block=b59)", "l89 = sch.fuse(l88)", "sch.vectorize(loop=l89)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l84, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b90 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b90)", "b106 = sch.decompose_reduction(block=b90, loop=l94)"]
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 7, 7, 512), "float32"], placeholder_1: T.Buffer[(3, 3, 512, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], T_relu: T.Buffer[(1, 7, 7, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 9, 9, 512], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 7, 7, 512], dtype="float32")
        T_add = T.alloc_buffer([1, 7, 7, 512], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 9, 9, 512):
            with T.block("pad_temp"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1 - 1, i2_1 - 1, i3_1])
                T.writes(pad_temp[i0_1, i1_1, i2_1, i3_1])
                pad_temp[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i1_1 and i1_1 < 8 and 1 <= i2_1 and i2_1 < 8, placeholder[0, i1_1 - 1, i2_1 - 1, i3_1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 7, 7, 512, 3, 3, 512):
            with T.block("conv2d_nhwc"):
                nn, yy, xx, ff, ry, rx, rc = T.axis.remap("SSSSRRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, yy + ry, xx + rx, rc], placeholder_1[ry, rx, rc, ff])
                T.writes(conv2d_nhwc[nn, yy, xx, ff])
                with T.init():
                    conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
                conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy + ry, xx + rx, rc] * placeholder_1[ry, rx, rc, ff]
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 512):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv2d_nhwc[0, ax1, ax2, ax3], placeholder_2[0, 0, 0, ax3])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = conv2d_nhwc[0, ax1, ax2, ax3] + placeholder_2[0, 0, 0, ax3]
        for i0, i1, i2, i3 in T.grid(1, 7, 7, 512):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_13(placeholder: T.Buffer[(1, 7, 7, 512), "float32"], placeholder_1: T.Buffer[(3, 3, 512, 512), "float32"], placeholder_2: T.Buffer[(1, 1, 1, 512), "float32"], T_relu: T.Buffer[(1, 7, 7, 512), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 9, 9, 512], dtype="float32")
        conv2d_nhwc = T.alloc_buffer([1, 7, 7, 512], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for ax0, ax1, ax2, ax3 in T.grid(1, 9, 9, 512):
                with T.block("pad_temp"):
                    i0 = T.axis.spatial(1, 0)
                    i1, i2, i3 = T.axis.remap("SSS", [ax1, ax2, ax3])
                    T.reads(placeholder[0, i1 - 1, i2 - 1, i3])
                    T.writes(pad_temp[i0, i1, i2, i3])
                    pad_temp[i0, i1, i2, i3] = T.if_then_else(1 <= i1 and i1 < 8 and 1 <= i2 and i2 < 8, placeholder[0, i1 - 1, i2 - 1, i3], T.float32(0), dtype="float32")
            for i1_2_init, i2_2_init in T.grid(7, 7):
                for i0_3_i1_3_i2_3_i3_3_fused_init in T.vectorized(32):
                    with T.block("conv2d_nhwc_init"):
                        nn = T.axis.spatial(1, 0)
                        yy, xx = T.axis.remap("SS", [i1_2_init, i2_2_init])
                        ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 4 * 128 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 4 * 32 + i0_3_i1_3_i2_3_i3_3_fused_init)
                        T.reads()
                        T.writes(conv2d_nhwc[nn, yy, xx, ff])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        conv2d_nhwc[nn, yy, xx, ff] = T.float32(0)
            for i4_0, i5_0, i6_0, i0_2, i1_2, i2_2, i3_2, i4_1, i5_1, i6_1 in T.grid(3, 1, 256, 1, 7, 7, 1, 1, 3, 2):
                for i0_3_i1_3_i2_3_i3_3_fused in T.vectorized(32):
                    with T.block("conv2d_nhwc_update"):
                        nn = T.axis.spatial(1, 0)
                        yy, xx = T.axis.remap("SS", [i1_2, i2_2])
                        ff = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 4 * 128 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 4 * 32 + i0_3_i1_3_i2_3_i3_3_fused)
                        ry, rx = T.axis.remap("RR", [i4_0, i5_1])
                        rc = T.axis.reduce(512, i6_0 * 2 + i6_1)
                        T.reads(conv2d_nhwc[nn, yy, xx, ff], pad_temp[0, yy + ry, xx + rx, rc], placeholder_1[ry, rx, rc, ff])
                        T.writes(conv2d_nhwc[nn, yy, xx, ff])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        conv2d_nhwc[nn, yy, xx, ff] = conv2d_nhwc[nn, yy, xx, ff] + pad_temp[0, yy + ry, xx + rx, rc] * placeholder_1[ry, rx, rc, ff]
            for ax0, ax1, ax2 in T.grid(1, 7, 7):
                for ax3_fused in T.vectorized(32):
                    with T.block("T_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1, ax2_1 = T.axis.remap("SS", [ax1, ax2])
                        ax3 = T.axis.spatial(512, i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused // 4 * 128 + i0_0_i1_0_i2_0_i3_0_i0_1_i1_1_i2_1_i3_1_fused % 4 * 32 + ax3_fused)
                        T.reads(conv2d_nhwc[0, ax1_1, ax2_1, ax3], placeholder_2[0, 0, 0, ax3])
                        T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3])
                        T_relu[ax0_1, ax1_1, ax2_1, ax3] = T.max(conv2d_nhwc[0, ax1_1, ax2_1, ax3] + placeholder_2[0, 0, 0, ax3], T.float32(0))
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b1)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l4, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])", "l23, l24, l25, l26 = sch.split(loop=l5, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 7, 1])", "l31, l32, l33, l34 = sch.split(loop=l6, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 4, 1, 32])", "l39, l40, l41, l42 = sch.split(loop=l7, factors=[v35, v36, v37, v38])", "v43, v44 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])", "l45, l46 = sch.split(loop=l8, factors=[v43, v44])", "v47, v48 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])", "l49, l50 = sch.split(loop=l9, factors=[v47, v48])", "v51, v52 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[256, 2])", "l53, l54 = sch.split(loop=l10, factors=[v51, v52])", "sch.reorder(l15, l23, l31, l39, l16, l24, l32, l40, l45, l49, l53, l17, l25, l33, l41, l46, l50, l54, l18, l26, l34, l42)", "b55, = sch.get_consumers(block=b1)", "sch.reverse_compute_at(block=b55, loop=l40, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v56 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v56)", "l57 = sch.sample_compute_location(block=b0, decision=7)", "sch.compute_at(block=b0, loop=l57, preserve_unit_loops=True)", "sch.enter_postproc()", "b58 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.unroll_explicit\")", "b59, b60, b61 = sch.get_child_blocks(b58)", "l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73 = sch.get_loops(block=b59)", "l74 = sch.fuse(l62, l63, l64, l65, l66, l67, l68, l69)", "sch.parallel(loop=l74)", "sch.annotate(block_or_loop=l74, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l74, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89 = sch.get_loops(block=b60)", "l90 = sch.fuse(l86, l87, l88, l89)", "sch.vectorize(loop=l90)", "sch.annotate(block_or_loop=l75, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l75, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l91, l92, l93, l94, l95 = sch.get_loops(block=b61)", "l96 = sch.fuse(l95)", "sch.vectorize(loop=l96)", "sch.annotate(block_or_loop=l91, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l91, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b97 = sch.get_block(name=\"conv2d_nhwc\", func_name=\"main\")", "l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b97)", "b110 = sch.decompose_reduction(block=b97, loop=l99)"]
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 7, 7, 2048), "float32"], tensor: T.Buffer[(1, 1, 1, 2048), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        tensor_1 = T.alloc_buffer([1, 1, 1, 2048], dtype="float32")
        for i0, i1, i2, i3, i4, i5 in T.grid(1, 1, 1, 2048, 7, 7):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                T.reads(placeholder[0, rv0, rv1, ax3])
                T.writes(tensor_1[ax0, ax1, ax2, ax3])
                with T.init():
                    tensor_1[ax0, ax1, ax2, ax3] = T.float32(0)
                tensor_1[ax0, ax1, ax2, ax3] = tensor_1[ax0, ax1, ax2, ax3] + placeholder[0, rv0, rv1, ax3]
        for i0, i1, i2, i3 in T.grid(1, 1, 1, 2048):
            with T.block("tensor_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(tensor_1[0, 0, 0, ax3])
                T.writes(tensor[ax0, ax1, ax2, ax3])
                tensor[ax0, ax1, ax2, ax3] = tensor_1[0, 0, 0, ax3] * T.float32(0.020408163265306121)
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_adaptive_avg_pool2d(placeholder: T.Buffer[(1, 7, 7, 2048), "float32"], tensor: T.Buffer[(1, 1, 1, 2048), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        tensor_1 = T.alloc_buffer([1, 1, 1, 2048], dtype="float32")
        tensor_rf = T.alloc_buffer([1, 1, 1, 2048, 7], dtype="float32")
        for i0_i1_i2_i3_fused in T.parallel(2048, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for ax0_init in T.serial(7):
                with T.block("tensor_rf_init"):
                    vi4_i5_fused_0 = T.axis.spatial(7, ax0_init)
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(1, 0)
                    ax2 = T.axis.spatial(1, 0)
                    ax3 = T.axis.spatial(2048, i0_i1_i2_i3_fused)
                    T.reads()
                    T.writes(tensor_rf[ax0, ax1, ax2, ax3, vi4_i5_fused_0])
                    tensor_rf[ax0, ax1, ax2, ax3, vi4_i5_fused_0] = T.float32(0)
            with T.block("tensor_init"):
                ax0 = T.axis.spatial(1, 0)
                ax1 = T.axis.spatial(1, 0)
                ax2 = T.axis.spatial(1, 0)
                ax3 = T.axis.spatial(2048, i0_i1_i2_i3_fused)
                T.reads()
                T.writes(tensor_1[ax0, ax1, ax2, ax3])
                tensor_1[ax0, ax1, ax2, ax3] = T.float32(0)
            for ax0 in T.serial(7):
                for ax0_1, ax1, ax2, ax3, ax4, ax5 in T.grid(1, 1, 1, 1, 1, 7):
                    with T.block("tensor_rf_update"):
                        vi4_i5_fused_0 = T.axis.spatial(7, ax0)
                        ax0_2 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(1, 0)
                        ax2_1 = T.axis.spatial(1, 0)
                        ax3_1, vi4_i5_fused_1 = T.axis.remap("SR", [i0_i1_i2_i3_fused, ax5])
                        T.reads(tensor_rf[ax0_2, ax1_1, ax2_1, ax3_1, vi4_i5_fused_0], placeholder[0, (vi4_i5_fused_0 * 7 + vi4_i5_fused_1) // 7, (vi4_i5_fused_0 * 7 + vi4_i5_fused_1) % 7, ax3_1])
                        T.writes(tensor_rf[ax0_2, ax1_1, ax2_1, ax3_1, vi4_i5_fused_0])
                        tensor_rf[ax0_2, ax1_1, ax2_1, ax3_1, vi4_i5_fused_0] = tensor_rf[ax0_2, ax1_1, ax2_1, ax3_1, vi4_i5_fused_0] + placeholder[0, (vi4_i5_fused_0 * 7 + vi4_i5_fused_1) // 7, (vi4_i5_fused_0 * 7 + vi4_i5_fused_1) % 7, ax3_1]
                for ax1, ax2, ax3, ax4 in T.grid(1, 1, 1, 1):
                    with T.block("tensor_update"):
                        vi4_i5_fused_0 = T.axis.reduce(7, ax0)
                        ax0_3 = T.axis.spatial(1, 0)
                        ax1_2 = T.axis.spatial(1, 0)
                        ax2_2 = T.axis.spatial(1, 0)
                        ax3_2 = T.axis.spatial(2048, i0_i1_i2_i3_fused)
                        T.reads(tensor_1[ax0_3, ax1_2, ax2_2, ax3_2], tensor_rf[ax0_3, ax1_2, ax2_2, ax3_2, vi4_i5_fused_0])
                        T.writes(tensor_1[ax0_3, ax1_2, ax2_2, ax3_2])
                        tensor_1[ax0_3, ax1_2, ax2_2, ax3_2] = tensor_1[ax0_3, ax1_2, ax2_2, ax3_2] + tensor_rf[ax0_3, ax1_2, ax2_2, ax3_2, vi4_i5_fused_0]
            with T.block("tensor_1"):
                ax0_4 = T.axis.spatial(1, 0)
                ax1_3 = T.axis.spatial(1, 0)
                ax2_3 = T.axis.spatial(1, 0)
                ax3_3 = T.axis.spatial(2048, i0_i1_i2_i3_fused)
                T.reads(tensor_1[0, 0, 0, ax3_3])
                T.writes(tensor[ax0_4, ax1_3, ax2_3, ax3_3])
                tensor[ax0_4, ax1_3, ax2_3, ax3_3] = tensor_1[0, 0, 0, ax3_3] * T.float32(0.020408163265306121)
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"tensor\", func_name=\"main\")", "b1 = sch.get_block(name=\"root\", func_name=\"main\")", "l2, l3, l4, l5, l6, l7 = sch.get_loops(block=b0)", "l8 = sch.fuse(l6, l7)", "v9, v10 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[7, 7])", "l11, l12 = sch.split(loop=l8, factors=[v9, v10])", "b13 = sch.rfactor(loop=l11, factor_axis=4)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.random_compute_producer\", ann_val=1)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v14 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v14)", "b15, = sch.get_producers(block=b0)", "sch.unannotate(block_or_loop=b0, ann_key=\"meta_schedule.random_compute_producer\")", "l16 = sch.sample_compute_location(block=b0, decision=3)", "sch.compute_at(block=b0, loop=l16, preserve_unit_loops=True)", "l17 = sch.sample_compute_location(block=b15, decision=4)", "sch.compute_at(block=b15, loop=l17, preserve_unit_loops=True)", "sch.enter_postproc()", "b18 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b18, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b18, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b18, ann_key=\"meta_schedule.unroll_explicit\")", "b19, b20, b21 = sch.get_child_blocks(b18)", "l22, l23, l24, l25, l26, l27, l28, l29, l30, l31, l32 = sch.get_loops(block=b19)", "l33 = sch.fuse(l22, l23, l24, l25)", "sch.parallel(loop=l33)", "sch.annotate(block_or_loop=l33, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l33, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l34, l35, l36, l37, l38, l39 = sch.get_loops(block=b20)", "sch.annotate(block_or_loop=l34, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l34, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l40, = sch.get_loops(block=b21)", "sch.annotate(block_or_loop=l40, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l40, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b41 = sch.get_block(name=\"tensor_rf\", func_name=\"main\")", "l42, l43, l44, l45, l46, l47, l48, l49 = sch.get_loops(block=b41)", "b50 = sch.decompose_reduction(block=b41, loop=l43)", "b51 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l52, l53, l54, l55, l56, l57 = sch.get_loops(block=b51)", "b58 = sch.decompose_reduction(block=b51, loop=l53)"]
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 1, 2048), "float32"], T_squeeze: T.Buffer[(1, 2048), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_layout_trans = T.alloc_buffer([1, 2048, 1, 1], dtype="float32")
        T_reshape = T.alloc_buffer([1, 2048, 1, 1], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 2048, 1, 1):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, 0, 0, ax1])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                T_layout_trans[ax0, ax1, ax2, ax3] = placeholder[0, 0, 0, ax1]
        for i0, i1, i2, i3 in T.grid(1, 2048, 1, 1):
            with T.block("T_reshape"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_layout_trans[0, ax1, 0, 0])
                T.writes(T_reshape[ax0, ax1, ax2, ax3])
                T_reshape[ax0, ax1, ax2, ax3] = T_layout_trans[0, ax1, 0, 0]
        for i0, i1 in T.grid(1, 2048):
            with T.block("T_squeeze"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_reshape[0, ax1, 0, 0])
                T.writes(T_squeeze[ax0, ax1])
                T_squeeze[ax0, ax1] = T_reshape[0, ax1, 0, 0]
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_layout_transform_reshape_squeeze(placeholder: T.Buffer[(1, 1, 1, 2048), "float32"], T_squeeze: T.Buffer[(1, 2048), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(2048):
            with T.block("T_squeeze"):
                ax0 = T.axis.spatial(1, 0)
                ax1 = T.axis.spatial(2048, i0_i1_fused)
                T.reads(placeholder[0, 0, 0, ax1])
                T.writes(T_squeeze[ax0, ax1])
                T_squeeze[ax0, ax1] = placeholder[0, 0, 0, ax1]
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_layout_trans\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_reshape\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v3)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, = sch.get_child_blocks(b4)", "l6, l7 = sch.get_loops(block=b5)", "l8 = sch.fuse(l6, l7)", "sch.parallel(loop=l8)"]
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 2048), "float32"], placeholder_1: T.Buffer[(1000, 2048), "float32"], placeholder_2: T.Buffer[(1, 1000), "float32"], T_add: T.Buffer[(1, 1000), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 1000], dtype="float32")
        for i0, i1, i2 in T.grid(1, 1000, 2048):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[0, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
        for i0, i1 in T.grid(1, 1000):
            with T.block("T_add"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                T.writes(T_add[ax0, ax1])
                T_add[ax0, ax1] = T_matmul_NT[0, ax1] + placeholder_2[0, ax1]
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_dense_add(placeholder: T.Buffer[(1, 2048), "float32"], placeholder_1: T.Buffer[(1000, 2048), "float32"], placeholder_2: T.Buffer[(1, 1000), "float32"], T_add: T.Buffer[(1, 1000), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 1000], dtype="float32")
        for i0_0_i1_0_fused in T.parallel(50, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1 in T.grid(1, 2):
                for i1_2_init, i1_3_init in T.grid(2, 5):
                    with T.block("T_matmul_NT_init"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(1000, i0_0_i1_0_fused * 20 + i1_1 * 10 + i1_2_init * 5 + i1_3_init)
                        T.reads()
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T.float32(0)
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(64, 1, 2, 32, 1, 5):
                    with T.block("T_matmul_NT_update"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(1000, i0_0_i1_0_fused * 20 + i1_1 * 10 + i1_2 * 5 + i1_3)
                        k = T.axis.reduce(2048, i2_0 * 32 + i2_1)
                        T.reads(T_matmul_NT[i, j], placeholder[0, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
            for ax0_ax1_fused in T.vectorized(20):
                with T.block("T_add"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(1000, i0_0_i1_0_fused * 20 + ax0_ax1_fused)
                    T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                    T.writes(T_add[ax0, ax1])
                    T_add[ax0, ax1] = T_matmul_NT[0, ax1] + placeholder_2[0, ax1]
    

[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[21:07:33] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "b1 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l2, l3, l4 = sch.get_loops(block=b0)", "v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])", "v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[50, 2, 2, 5])", "l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])", "v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[64, 32])", "l23, l24 = sch.split(loop=l4, factors=[v21, v22])", "sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)", "b25, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b25, loop=l17, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v26)", "sch.enter_postproc()", "b27 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.unroll_explicit\")", "b28, b29 = sch.get_child_blocks(b27)", "l30, l31, l32, l33, l34, l35, l36, l37, l38, l39 = sch.get_loops(block=b28)", "l40 = sch.fuse(l30, l31)", "sch.parallel(loop=l40)", "sch.annotate(block_or_loop=l40, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l40, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l41, l42, l43 = sch.get_loops(block=b29)", "l44 = sch.fuse(l42, l43)", "sch.vectorize(loop=l44)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b45 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "l46, l47, l48, l49, l50, l51, l52, l53, l54 = sch.get_loops(block=b45)", "b55 = sch.decompose_reduction(block=b45, loop=l49)"]
Running time in time_evaluator:  [7.319959536231885, 7.373444144927537, 7.378627884057971]
Avg running time: 7.357343855072464
|graph_nodes| =  167
|graph_time| =  167
input0 : 0.000
tvmgen_default_fused_layout_transform : 0.000
p0 : 0.000
p1 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu : 0.000
tvmgen_default_fused_nn_max_pool2d : 0.000
p2 : 0.000
p3 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_1 : 0.000
p4 : 0.000
p5 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_2 : 0.000
p6 : 0.000
p7 : 0.000
p8 : 0.000
p9 : 0.000
tvmgen_default_fused_nn_conv2d_add : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu : 0.000
p10 : 0.000
p11 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_3 : 0.000
p12 : 0.000
p13 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_21 : 0.000
p14 : 0.000
p15 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu1 : 0.000
p16 : 0.000
p17 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_31 : 0.000
p18 : 0.000
p19 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_22 : 0.000
p20 : 0.000
p21 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu2 : 0.000
p22 : 0.000
p23 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_4 : 0.000
p24 : 0.000
p25 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_5 : 0.000
p26 : 0.000
p27 : 0.000
p28 : 0.000
p29 : 0.000
tvmgen_default_fused_nn_conv2d_add_1 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_1 : 0.000
p30 : 0.000
p31 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_6 : 0.000
p32 : 0.000
p33 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu : 0.000
p34 : 0.000
p35 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_11 : 0.000
p36 : 0.000
p37 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_61 : 0.000
p38 : 0.000
p39 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu1 : 0.000
p40 : 0.000
p41 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_12 : 0.000
p42 : 0.000
p43 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_62 : 0.000
p44 : 0.000
p45 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu2 : 0.000
p46 : 0.000
p47 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_13 : 0.000
p48 : 0.000
p49 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_7 : 0.000
p50 : 0.000
p51 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_8 : 0.000
p52 : 0.000
p53 : 0.000
p54 : 0.000
p55 : 0.000
tvmgen_default_fused_nn_conv2d_add_2 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_2 : 0.000
p56 : 0.000
p57 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_9 : 0.000
p58 : 0.000
p59 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 : 0.000
p60 : 0.000
p61 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_21 : 0.000
p62 : 0.000
p63 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_91 : 0.000
p64 : 0.000
p65 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_11 : 0.000
p66 : 0.000
p67 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_22 : 0.000
p68 : 0.000
p69 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_92 : 0.000
p70 : 0.000
p71 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_12 : 0.000
p72 : 0.000
p73 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_23 : 0.000
p74 : 0.000
p75 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_93 : 0.000
p76 : 0.000
p77 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_13 : 0.000
p78 : 0.000
p79 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_24 : 0.000
p80 : 0.000
p81 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_94 : 0.000
p82 : 0.000
p83 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_14 : 0.000
p84 : 0.000
p85 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_25 : 0.000
p86 : 0.000
p87 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_10 : 0.000
p88 : 0.000
p89 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_11 : 0.000
p90 : 0.000
p91 : 0.000
p92 : 0.000
p93 : 0.000
tvmgen_default_fused_nn_conv2d_add_3 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_3 : 0.000
p94 : 0.000
p95 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_12 : 0.000
p96 : 0.000
p97 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_13 : 0.000
p98 : 0.000
p99 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_31 : 0.000
p100 : 0.000
p101 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_121 : 0.000
p102 : 0.000
p103 : 0.000
tvmgen_default_fused_nn_conv2d_add_nn_relu_131 : 0.000
p104 : 0.000
p105 : 0.000
tvmgen_default_fused_nn_conv2d_add_add_nn_relu_32 : 0.000
tvmgen_default_fused_nn_adaptive_avg_pool2d : 0.000
tvmgen_default_fused_layout_transform_reshape_squeeze : 0.000
p106 : 0.000
p107 : 0.000
tvmgen_default_fused_nn_dense_add : 0.000
