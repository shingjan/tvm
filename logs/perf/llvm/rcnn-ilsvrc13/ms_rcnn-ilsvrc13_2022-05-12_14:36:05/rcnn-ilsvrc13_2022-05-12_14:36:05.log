2022-05-12 14:36:08.478 INFO RPCRunner: max_workers = 1
https://storage.cloud.google.com/octoml-aquarium-models/onnx_model_zoo/vision_classification_rcnn-ilsvrc13.onnx
file existed. Skipping downloading.
/home/ubuntu/cache-workloads/rcnn-ilsvrc13.onnx
Workload: rcnn-ilsvrc13
  input_name: data_0
  input_shape: [1, 3, 224, 224]
  input_dtype: float32
2022-05-12 14:36:10.623 INFO Logging directory: /home/ubuntu/tvm/logs/perf/llvm/rcnn-ilsvrc13//ms_rcnn-ilsvrc13_2022-05-12_14:36:05/logs
2022-05-12 14:36:10.623 INFO Working directory: /home/ubuntu/tvm/logs/perf/llvm/rcnn-ilsvrc13//ms_rcnn-ilsvrc13_2022-05-12_14:36:05/
2022-05-12 14:36:10.623 INFO Creating JSONDatabase. Workload at: /home/ubuntu/tvm/logs/perf/llvm/rcnn-ilsvrc13//ms_rcnn-ilsvrc13_2022-05-12_14:36:05/database_workload.json. Tuning records at: /home/ubuntu/tvm/logs/perf/llvm/rcnn-ilsvrc13//ms_rcnn-ilsvrc13_2022-05-12_14:36:05/database_tuning_record.json
2022-05-12 14:36:10.624 INFO LocalBuilder: max_workers = 48
2022-05-12 14:36:14.188 INFO 
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                fused_nn_lrn |    979776 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 0
Total latency (us): 0

2022-05-12 14:36:14.188 INFO Scheduler picks Task #0: "fused_layout_transform"
2022-05-12 14:36:15.125 INFO Sending 8 sample(s) to builder
2022-05-12 14:36:15.587 INFO Sending 8 sample(s) to runner
2022-05-12 14:36:15.590 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-12 14:36:21.228 INFO Sending 64 sample(s) to builder
2022-05-12 14:36:32.391 INFO Sending 64 sample(s) to runner
2022-05-12 14:36:32.435 INFO Scheduler picks Task #2: "fused_nn_max_pool2d"
2022-05-12 14:36:40.221 INFO Sending 60 sample(s) to builder
2022-05-12 14:36:44.728 INFO Sending 60 sample(s) to runner
2022-05-12 14:36:44.767 INFO Scheduler picks Task #3: "fused_layout_transform_1"
2022-05-12 14:36:46.461 INFO Sending 8 sample(s) to builder
2022-05-12 14:36:47.652 INFO Sending 8 sample(s) to runner
2022-05-12 14:36:47.655 INFO Scheduler picks Task #4: "fused_nn_lrn"
2022-05-12 14:36:53.688 INFO Sending 64 sample(s) to builder
2022-05-12 14:36:56.004 INFO Sending 64 sample(s) to runner
2022-05-12 14:36:56.026 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 14:37:17.202 INFO Sending 64 sample(s) to builder
2022-05-12 14:37:36.060 INFO Sending 64 sample(s) to runner
2022-05-12 14:37:36.097 INFO Scheduler picks Task #6: "fused_nn_max_pool2d_1"
2022-05-12 14:37:39.074 INFO Sending 36 sample(s) to builder
2022-05-12 14:37:40.435 INFO Sending 36 sample(s) to runner
2022-05-12 14:37:40.449 INFO Scheduler picks Task #7: "fused_nn_lrn_1"
2022-05-12 14:37:45.257 INFO Sending 62 sample(s) to builder
2022-05-12 14:37:47.093 INFO Sending 62 sample(s) to runner
2022-05-12 14:37:47.156 INFO Scheduler picks Task #8: "fused_layout_transform_2"
2022-05-12 14:37:48.140 INFO Sending 12 sample(s) to builder
2022-05-12 14:37:49.412 INFO Sending 12 sample(s) to runner
2022-05-12 14:37:49.417 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 14:37:59.000 INFO Sending 64 sample(s) to builder
2022-05-12 14:38:04.505 INFO Sending 64 sample(s) to runner
2022-05-12 14:38:04.549 INFO Scheduler picks Task #10: "fused_layout_transform_3"
2022-05-12 14:38:05.499 INFO Sending 4 sample(s) to builder
2022-05-12 14:38:06.143 INFO Sending 4 sample(s) to runner
2022-05-12 14:38:06.145 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 14:38:26.766 INFO Sending 64 sample(s) to builder
2022-05-12 14:38:40.946 INFO Sending 64 sample(s) to runner
2022-05-12 14:38:40.984 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 14:39:08.220 INFO Sending 64 sample(s) to builder
2022-05-12 14:39:29.494 INFO Sending 64 sample(s) to runner
2022-05-12 14:39:29.532 INFO Scheduler picks Task #13: "fused_nn_max_pool2d_2"
2022-05-12 14:39:33.167 INFO Sending 36 sample(s) to builder
2022-05-12 14:39:36.158 INFO Sending 36 sample(s) to runner
2022-05-12 14:39:36.171 INFO Scheduler picks Task #14: "fused_reshape"
2022-05-12 14:39:36.963 INFO Sending 4 sample(s) to builder
2022-05-12 14:39:37.405 INFO Sending 4 sample(s) to runner
2022-05-12 14:39:37.407 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 14:39:39.580 INFO Sending 64 sample(s) to builder
2022-05-12 14:40:09.357 INFO Sending 64 sample(s) to runner
2022-05-12 14:40:09.388 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 14:40:11.605 INFO Sending 64 sample(s) to builder
2022-05-12 14:40:17.373 INFO Sending 64 sample(s) to runner
2022-05-12 14:40:17.403 INFO Scheduler picks Task #17: "fused_nn_dense_add"
2022-05-12 14:40:19.961 INFO Sending 64 sample(s) to builder
2022-05-12 14:40:22.245 INFO Sending 64 sample(s) to runner
/home/ubuntu/anaconda3/lib/python3.9/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)
2022-05-12 14:40:25.482 INFO [Updated] Task #0: "fused_layout_transform"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                fused_nn_lrn |    979776 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8
Total latency (us): 3.1586

2022-05-12 14:40:28.904 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                fused_nn_lrn |    979776 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 72
Total latency (us): 171.183

2022-05-12 14:40:32.088 INFO [Updated] Task #2: "fused_nn_max_pool2d"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                                fused_nn_lrn |    979776 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 132
Total latency (us): 175.097

2022-05-12 14:40:35.339 INFO [Updated] Task #3: "fused_layout_transform_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 140
Total latency (us): 180.259

2022-05-12 14:40:38.008 INFO [Updated] Task #4: "fused_nn_lrn"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 204
Total latency (us): 221.565

2022-05-12 14:40:40.642 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 268
Total latency (us): 1009.25

2022-05-12 14:40:46.338 INFO [Updated] Task #6: "fused_nn_max_pool2d_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 304
Total latency (us): 1013.5

2022-05-12 14:41:03.007 INFO [Updated] Task #7: "fused_nn_lrn_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 366
Total latency (us): 1043.13

2022-05-12 14:41:24.810 INFO [Updated] Task #8: "fused_layout_transform_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 378
Total latency (us): 1045.97

2022-05-12 14:41:28.545 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 442
Total latency (us): 1661.18

2022-05-12 14:41:31.600 INFO [Updated] Task #10: "fused_layout_transform_3"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 446
Total latency (us): 1664.38

2022-05-12 14:41:35.609 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       360.0127 |     623.3402 |              623.3402 |     64 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |            N/A |          N/A |                   N/A |      0 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 510
Total latency (us): 2287.72

2022-05-12 14:41:39.626 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       360.0127 |     623.3402 |              623.3402 |     64 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |            N/A |          N/A |                   N/A |      0 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 574
Total latency (us): 2680.35

2022-05-12 14:41:54.989 INFO [Updated] Task #13: "fused_nn_max_pool2d_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       360.0127 |     623.3402 |              623.3402 |     64 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 610
Total latency (us): 2683.29

2022-05-12 14:42:15.136 INFO [Updated] Task #14: "fused_reshape"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       360.0127 |     623.3402 |              623.3402 |     64 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |            N/A |          N/A |                   N/A |      0 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 614
Total latency (us): 2685.9

2022-05-12 14:43:00.729 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       360.0127 |     623.3402 |              623.3402 |     64 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.6914 |    1264.9339 |             1264.9339 |     64 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |            N/A |          N/A |                   N/A |      0 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 678
Total latency (us): 3950.84

2022-05-12 14:43:53.596 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       360.0127 |     623.3402 |              623.3402 |     64 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.6914 |    1264.9339 |             1264.9339 |     64 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        74.0011 |     453.5424 |              453.5424 |     64 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |            N/A |          N/A |                   N/A |      0 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 742
Total latency (us): 4404.38

2022-05-12 14:44:13.464 INFO [Updated] Task #17: "fused_nn_dense_add"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       360.0127 |     623.3402 |              623.3402 |     64 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.6914 |    1264.9339 |             1264.9339 |     64 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        74.0011 |     453.5424 |              453.5424 |     64 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 806
Total latency (us): 4419.58

2022-05-12 14:44:13.464 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 14:44:25.240 INFO Sending 64 sample(s) to builder
2022-05-12 14:44:31.453 INFO Sending 64 sample(s) to runner
2022-05-12 14:46:18.237 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       360.0127 |     623.3402 |              623.3402 |     64 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    128 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        74.0011 |     453.5424 |              453.5424 |     64 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 870
Total latency (us): 4413.45

2022-05-12 14:46:18.238 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 14:46:24.649 INFO Sending 64 sample(s) to builder
2022-05-12 14:46:28.132 INFO Sending 64 sample(s) to runner
2022-05-12 14:46:28.194 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 14:47:30.729 INFO Sending 64 sample(s) to builder
2022-05-12 14:47:58.167 INFO Sending 64 sample(s) to runner
2022-05-12 14:48:12.616 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |       569.1014 |     787.6818 |              787.6818 |     64 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       360.0127 |     623.3402 |              623.3402 |     64 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    192 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        74.0011 |     453.5424 |              453.5424 |     64 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 934
Total latency (us): 4413.45

2022-05-12 14:48:52.064 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    128 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       360.0127 |     623.3402 |              623.3402 |     64 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    192 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        74.0011 |     453.5424 |              453.5424 |     64 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 998
Total latency (us): 3915.42

2022-05-12 14:48:52.064 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 14:49:47.906 INFO Sending 64 sample(s) to builder
2022-05-12 14:50:05.372 INFO Sending 64 sample(s) to runner
2022-05-12 14:50:05.410 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 14:50:54.772 INFO Sending 64 sample(s) to builder
2022-05-12 14:51:29.480 INFO Sending 64 sample(s) to runner
2022-05-12 14:51:39.047 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       360.0127 |     623.3402 |              623.3402 |     64 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    192 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        74.0011 |     453.5424 |              453.5424 |     64 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1062
Total latency (us): 3915.42

2022-05-12 14:53:21.836 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       806.7985 |     278.1492 |              278.1492 |    128 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    192 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        74.0011 |     453.5424 |              453.5424 |     64 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1126
Total latency (us): 3570.23

2022-05-12 14:53:21.837 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 14:53:47.613 INFO Sending 64 sample(s) to builder
2022-05-12 14:54:03.441 INFO Sending 64 sample(s) to runner
2022-05-12 14:54:03.509 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 14:54:36.759 INFO Sending 64 sample(s) to builder
2022-05-12 14:54:54.537 INFO Sending 64 sample(s) to runner
2022-05-12 14:55:04.602 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |       486.2866 |     615.2144 |              615.2144 |     64 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    192 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        74.0011 |     453.5424 |              453.5424 |     64 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1190
Total latency (us): 3561.18

2022-05-12 14:56:10.912 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1066.4431 |     280.5312 |              280.5312 |    128 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    192 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        74.0011 |     453.5424 |              453.5424 |     64 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1254
Total latency (us): 3226.5

2022-05-12 14:56:10.912 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 14:56:26.579 INFO Sending 64 sample(s) to builder
2022-05-12 14:56:30.194 INFO Sending 64 sample(s) to runner
2022-05-12 14:56:30.239 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 14:56:38.380 INFO Sending 64 sample(s) to builder
2022-05-12 14:56:42.417 INFO Sending 64 sample(s) to runner
2022-05-12 14:58:03.771 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1066.4431 |     280.5312 |              280.5312 |    128 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    192 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    128 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1318
Total latency (us): 3215.34

2022-05-12 14:58:03.771 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 14:58:08.688 INFO Sending 64 sample(s) to builder
2022-05-12 14:58:12.619 INFO Sending 64 sample(s) to runner
2022-05-12 14:58:17.415 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    192 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    128 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1382
Total latency (us): 3189.98

2022-05-12 14:58:17.415 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 14:58:22.137 INFO Sending 64 sample(s) to builder
2022-05-12 14:58:25.433 INFO Sending 64 sample(s) to runner
2022-05-12 15:01:45.651 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    256 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    128 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1446
Total latency (us): 3189.98

2022-05-12 15:01:45.651 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:01:54.276 INFO Sending 64 sample(s) to builder
2022-05-12 15:01:58.321 INFO Sending 64 sample(s) to runner
2022-05-12 15:02:16.739 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       381.0387 |     392.6291 |              392.6291 |     64 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    256 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    192 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1510
Total latency (us): 3189.98

2022-05-12 15:02:16.740 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 15:02:50.073 INFO Sending 64 sample(s) to builder
2022-05-12 15:03:01.314 INFO Sending 64 sample(s) to runner
2022-05-12 15:04:33.048 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       517.2621 |     289.2284 |              289.2284 |    128 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    256 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    192 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1574
Total latency (us): 3086.58

2022-05-12 15:04:33.048 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 15:05:08.738 INFO Sending 64 sample(s) to builder
2022-05-12 15:05:16.317 INFO Sending 64 sample(s) to runner
2022-05-12 15:05:20.646 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       517.2621 |     289.2284 |              289.2284 |    128 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    320 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    192 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1638
Total latency (us): 3086.58

2022-05-12 15:05:20.646 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:05:25.485 INFO Sending 64 sample(s) to builder
2022-05-12 15:05:27.546 INFO Sending 64 sample(s) to runner
2022-05-12 15:08:21.873 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       517.2621 |     289.2284 |              289.2284 |    128 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    384 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    192 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1702
Total latency (us): 3086.58

2022-05-12 15:08:21.873 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:08:26.784 INFO Sending 64 sample(s) to builder
2022-05-12 15:08:30.248 INFO Sending 64 sample(s) to runner
2022-05-12 15:08:42.534 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    384 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    192 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1766
Total latency (us): 3002.58

2022-05-12 15:10:51.071 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    448 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    192 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1830
Total latency (us): 3002.58

2022-05-12 15:10:51.072 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:10:57.897 INFO Sending 64 sample(s) to builder
2022-05-12 15:11:01.211 INFO Sending 64 sample(s) to runner
2022-05-12 15:12:39.331 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1212.8790 |     168.0245 |              168.0245 |     64 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    512 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    192 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1894
Total latency (us): 3002.58

2022-05-12 15:12:39.331 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:12:44.241 INFO Sending 64 sample(s) to builder
2022-05-12 15:12:47.386 INFO Sending 64 sample(s) to runner
2022-05-12 15:12:47.416 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-12 15:12:57.222 INFO Sending 64 sample(s) to builder
2022-05-12 15:13:00.599 INFO Sending 64 sample(s) to runner
2022-05-12 15:15:07.429 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    128 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    512 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    192 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1958
Total latency (us): 2976.08

2022-05-12 15:15:07.429 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-12 15:15:23.527 INFO Sending 64 sample(s) to builder
2022-05-12 15:15:30.229 INFO Sending 64 sample(s) to runner
2022-05-12 15:15:45.797 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    128 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    576 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    192 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2022
Total latency (us): 2976.08

2022-05-12 15:15:45.798 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 15:15:50.787 INFO Sending 64 sample(s) to builder
2022-05-12 15:15:53.653 INFO Sending 64 sample(s) to runner
2022-05-12 15:17:33.100 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    128 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    576 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    256 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2086
Total latency (us): 2976.08

2022-05-12 15:17:33.100 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 15:17:39.573 INFO Sending 64 sample(s) to builder
2022-05-12 15:17:42.296 INFO Sending 64 sample(s) to runner
2022-05-12 15:17:54.210 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    576 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    256 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2150
Total latency (us): 2976.08

2022-05-12 15:17:54.210 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:17:59.158 INFO Sending 64 sample(s) to builder
2022-05-12 15:18:02.513 INFO Sending 64 sample(s) to runner
2022-05-12 15:21:31.333 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    640 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    256 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2214
Total latency (us): 2976.08

2022-05-12 15:21:31.333 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:21:38.432 INFO Sending 64 sample(s) to builder
2022-05-12 15:21:41.414 INFO Sending 64 sample(s) to runner
2022-05-12 15:21:54.723 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    640 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    320 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2278
Total latency (us): 2976.08

2022-05-12 15:23:58.736 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    704 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    320 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2342
Total latency (us): 2976.08

2022-05-12 15:23:58.736 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:24:09.564 INFO Sending 64 sample(s) to builder
2022-05-12 15:24:29.327 INFO Sending 64 sample(s) to runner
2022-05-12 15:26:26.755 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    768 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    320 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2406
Total latency (us): 2976.08

2022-05-12 15:26:26.755 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:26:36.196 INFO Sending 64 sample(s) to builder
2022-05-12 15:26:39.477 INFO Sending 64 sample(s) to runner
2022-05-12 15:28:59.007 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        59.9821 |    1258.8039 |             1258.8039 |    832 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    320 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2470
Total latency (us): 2976.08

2022-05-12 15:28:59.007 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:29:05.700 INFO Sending 64 sample(s) to builder
2022-05-12 15:29:08.391 INFO Sending 64 sample(s) to runner
2022-05-12 15:31:00.706 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1547.6075 |     289.6541 |              289.6541 |    192 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0081 |    1258.2575 |             1258.2575 |    896 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    320 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2534
Total latency (us): 2975.54

2022-05-12 15:31:00.706 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:31:15.795 INFO Sending 64 sample(s) to builder
2022-05-12 15:31:20.247 INFO Sending 64 sample(s) to runner
2022-05-12 15:31:20.279 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 15:32:00.683 INFO Sending 64 sample(s) to builder
2022-05-12 15:32:13.745 INFO Sending 64 sample(s) to runner
2022-05-12 15:33:40.149 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1711.5012 |     261.9168 |              261.9168 |    256 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0081 |    1258.2575 |             1258.2575 |    896 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    320 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2598
Total latency (us): 2947.8

2022-05-12 15:33:40.149 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 15:34:30.762 INFO Sending 64 sample(s) to builder
2022-05-12 15:34:54.464 INFO Sending 64 sample(s) to runner
2022-05-12 15:35:12.670 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1711.5012 |     261.9168 |              261.9168 |    256 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0081 |    1258.2575 |             1258.2575 |    960 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    320 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2662
Total latency (us): 2947.8

2022-05-12 15:35:29.263 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    320 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0081 |    1258.2575 |             1258.2575 |    960 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    320 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2726
Total latency (us): 2934.21

2022-05-12 15:35:29.263 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 15:36:00.072 INFO Sending 64 sample(s) to builder
2022-05-12 15:36:19.334 INFO Sending 64 sample(s) to runner
2022-05-12 15:36:19.408 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 15:37:03.119 INFO Sending 64 sample(s) to builder
2022-05-12 15:37:16.698 INFO Sending 64 sample(s) to runner
2022-05-12 15:37:36.733 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |       833.9299 |     269.0998 |              269.0998 |    192 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0081 |    1258.2575 |             1258.2575 |    960 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    320 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2790
Total latency (us): 2934.21

2022-05-12 15:39:03.421 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1020.0091 |     220.0082 |              220.0082 |    256 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0081 |    1258.2575 |             1258.2575 |    960 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    320 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2854
Total latency (us): 2885.12

2022-05-12 15:39:03.421 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 15:39:35.231 INFO Sending 64 sample(s) to builder
2022-05-12 15:39:44.069 INFO Sending 64 sample(s) to runner
2022-05-12 15:41:18.859 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1020.0091 |     220.0082 |              220.0082 |    320 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0081 |    1258.2575 |             1258.2575 |    960 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    320 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2918
Total latency (us): 2885.12

2022-05-12 15:41:18.859 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 15:41:48.094 INFO Sending 64 sample(s) to builder
2022-05-12 15:41:52.791 INFO Sending 64 sample(s) to runner
2022-05-12 15:41:52.863 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 15:41:59.855 INFO Sending 64 sample(s) to builder
2022-05-12 15:42:02.943 INFO Sending 64 sample(s) to runner
2022-05-12 15:44:25.782 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1020.0091 |     220.0082 |              220.0082 |    320 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0081 |    1258.2575 |             1258.2575 |    960 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    384 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2982
Total latency (us): 2885.12

2022-05-12 15:44:25.782 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 15:44:35.633 INFO Sending 64 sample(s) to builder
2022-05-12 15:44:41.433 INFO Sending 64 sample(s) to runner
2022-05-12 15:45:16.033 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0081 |    1258.2575 |             1258.2575 |    960 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    384 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3046
Total latency (us): 2875.11

2022-05-12 15:45:16.034 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 15:45:44.869 INFO Sending 64 sample(s) to builder
2022-05-12 15:45:49.572 INFO Sending 64 sample(s) to runner
2022-05-12 15:45:58.302 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1172.4030 |     255.1772 |              255.1772 |    192 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0081 |    1258.2575 |             1258.2575 |    960 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    448 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3110
Total latency (us): 2875.11

2022-05-12 15:47:06.972 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1935.7216 |     154.5525 |              154.5525 |    256 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0081 |    1258.2575 |             1258.2575 |    960 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    448 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3174
Total latency (us): 2774.49

2022-05-12 15:47:06.972 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 15:47:25.625 INFO Sending 64 sample(s) to builder
2022-05-12 15:47:32.911 INFO Sending 64 sample(s) to runner
2022-05-12 15:47:32.981 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:47:41.305 INFO Sending 64 sample(s) to builder
2022-05-12 15:47:44.159 INFO Sending 64 sample(s) to runner
2022-05-12 15:50:03.813 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      1935.7216 |     154.5525 |              154.5525 |    256 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1024 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    448 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3238
Total latency (us): 2773.61

2022-05-12 15:50:03.814 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:50:08.765 INFO Sending 64 sample(s) to builder
2022-05-12 15:50:10.890 INFO Sending 64 sample(s) to runner
2022-05-12 15:50:17.956 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1024 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    448 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3302
Total latency (us): 2764.25

2022-05-12 15:51:41.321 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1088 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    448 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3366
Total latency (us): 2764.25

2022-05-12 15:51:41.321 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:51:46.315 INFO Sending 64 sample(s) to builder
2022-05-12 15:51:48.528 INFO Sending 64 sample(s) to runner
2022-05-12 15:54:26.419 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1152 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    448 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3430
Total latency (us): 2764.25

2022-05-12 15:54:26.419 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:54:36.918 INFO Sending 63 sample(s) to builder
2022-05-12 15:54:42.468 INFO Sending 63 sample(s) to runner
2022-05-12 15:56:47.335 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1215 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    448 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3493
Total latency (us): 2764.25

2022-05-12 15:56:47.335 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 15:56:57.588 INFO Sending 64 sample(s) to builder
2022-05-12 15:57:03.655 INFO Sending 64 sample(s) to runner
2022-05-12 15:57:03.698 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 15:58:01.343 INFO Sending 64 sample(s) to builder
2022-05-12 15:58:38.118 INFO Sending 64 sample(s) to runner
2022-05-12 15:59:03.804 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       728.9843 |     205.2265 |              205.2265 |    192 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1279 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    448 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3557
Total latency (us): 2764.25

2022-05-12 15:59:32.261 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       806.8358 |     185.4242 |              185.4242 |    256 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1279 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    448 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3621
Total latency (us): 2744.44

2022-05-12 15:59:32.262 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 16:00:12.633 INFO Sending 64 sample(s) to builder
2022-05-12 16:00:23.527 INFO Sending 64 sample(s) to runner
2022-05-12 16:01:37.198 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       807.6277 |     185.2424 |              185.2424 |    320 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1279 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    448 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3685
Total latency (us): 2744.26

2022-05-12 16:01:37.198 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 16:02:15.493 INFO Sending 64 sample(s) to builder
2022-05-12 16:02:28.660 INFO Sending 64 sample(s) to runner
2022-05-12 16:02:28.722 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 16:02:36.653 INFO Sending 64 sample(s) to builder
2022-05-12 16:02:51.236 INFO Sending 64 sample(s) to runner
2022-05-12 16:04:48.406 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       807.6277 |     185.2424 |              185.2424 |    320 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1279 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    512 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3749
Total latency (us): 2744.26

2022-05-12 16:04:48.407 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 16:05:04.069 INFO Sending 64 sample(s) to builder
2022-05-12 16:05:11.735 INFO Sending 64 sample(s) to runner
2022-05-12 16:05:38.752 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1279 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    512 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3813
Total latency (us): 2725.69

2022-05-12 16:05:38.753 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:05:53.162 INFO Sending 64 sample(s) to builder
2022-05-12 16:05:58.864 INFO Sending 64 sample(s) to runner
2022-05-12 16:07:58.708 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1343 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    512 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3877
Total latency (us): 2725.69

2022-05-12 16:07:58.708 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:08:03.695 INFO Sending 63 sample(s) to builder
2022-05-12 16:08:07.550 INFO Sending 63 sample(s) to runner
2022-05-12 16:08:13.536 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1343 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    576 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3941
Total latency (us): 2725.69

2022-05-12 16:10:00.887 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1406 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    576 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4004
Total latency (us): 2725.69

2022-05-12 16:10:00.888 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:10:07.903 INFO Sending 64 sample(s) to builder
2022-05-12 16:10:11.376 INFO Sending 64 sample(s) to runner
2022-05-12 16:12:29.497 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1470 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    576 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4068
Total latency (us): 2725.69

2022-05-12 16:12:29.497 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:12:44.113 INFO Sending 64 sample(s) to builder
2022-05-12 16:12:49.402 INFO Sending 64 sample(s) to runner
2022-05-12 16:14:45.661 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1534 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    576 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4132
Total latency (us): 2725.69

2022-05-12 16:14:45.661 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:14:53.152 INFO Sending 64 sample(s) to builder
2022-05-12 16:14:57.438 INFO Sending 64 sample(s) to runner
2022-05-12 16:17:17.595 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1598 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    576 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4196
Total latency (us): 2725.69

2022-05-12 16:17:17.595 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:17:28.049 INFO Sending 64 sample(s) to builder
2022-05-12 16:17:32.916 INFO Sending 64 sample(s) to runner
2022-05-12 16:19:17.639 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1662 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    576 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4260
Total latency (us): 2725.69

2022-05-12 16:19:17.640 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:19:24.617 INFO Sending 64 sample(s) to builder
2022-05-12 16:19:36.075 INFO Sending 64 sample(s) to runner
2022-05-12 16:19:36.104 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 16:19:41.018 INFO Sending 64 sample(s) to builder
2022-05-12 16:19:43.524 INFO Sending 64 sample(s) to runner
2022-05-12 16:23:30.939 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1662 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    640 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4324
Total latency (us): 2725.69

2022-05-12 16:23:30.939 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 16:23:41.419 INFO Sending 64 sample(s) to builder
2022-05-12 16:23:46.538 INFO Sending 64 sample(s) to runner
2022-05-12 16:24:16.783 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1726 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    640 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4388
Total latency (us): 2725.69

2022-05-12 16:24:16.783 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-12 16:24:30.790 INFO Sending 64 sample(s) to builder
2022-05-12 16:24:37.230 INFO Sending 64 sample(s) to runner
2022-05-12 16:24:53.108 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1439.9493 |     141.5282 |              141.5282 |    192 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1726 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4452
Total latency (us): 2725.69

2022-05-12 16:25:43.261 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1712.8474 |     118.9793 |              118.9793 |    256 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1726 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4516
Total latency (us): 2703.14

2022-05-12 16:25:43.261 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-12 16:26:06.574 INFO Sending 64 sample(s) to builder
2022-05-12 16:26:26.961 INFO Sending 64 sample(s) to runner
2022-05-12 16:26:27.043 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:26:34.373 INFO Sending 64 sample(s) to builder
2022-05-12 16:26:38.510 INFO Sending 64 sample(s) to runner
2022-05-12 16:28:44.967 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      1712.8474 |     118.9793 |              118.9793 |    256 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1790 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4580
Total latency (us): 2703.14

2022-05-12 16:28:44.967 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:29:00.892 INFO Sending 64 sample(s) to builder
2022-05-12 16:29:08.814 INFO Sending 64 sample(s) to runner
2022-05-12 16:29:56.932 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0501 |    1257.3773 |             1257.3773 |   1790 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4644
Total latency (us): 2663.06

2022-05-12 16:30:57.478 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1805.1716 |     248.3259 |              248.3259 |    384 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   1854 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4708
Total latency (us): 2662.97

2022-05-12 16:30:57.478 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:31:07.198 INFO Sending 63 sample(s) to builder
2022-05-12 16:31:10.796 INFO Sending 63 sample(s) to runner
2022-05-12 16:31:10.826 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 16:31:41.638 INFO Sending 64 sample(s) to builder
2022-05-12 16:31:46.424 INFO Sending 64 sample(s) to runner
2022-05-12 16:34:17.269 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    448 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   1854 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4772
Total latency (us): 2655.35

2022-05-12 16:34:17.270 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 16:35:01.734 INFO Sending 64 sample(s) to builder
2022-05-12 16:35:10.064 INFO Sending 64 sample(s) to runner
2022-05-12 16:35:26.985 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    448 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   1917 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4835
Total latency (us): 2655.35

2022-05-12 16:35:26.985 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:35:34.073 INFO Sending 64 sample(s) to builder
2022-05-12 16:35:37.352 INFO Sending 64 sample(s) to runner
2022-05-12 16:37:42.914 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    448 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   1981 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4899
Total latency (us): 2655.35

2022-05-12 16:37:42.915 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:37:48.964 INFO Sending 64 sample(s) to builder
2022-05-12 16:37:51.322 INFO Sending 64 sample(s) to runner
2022-05-12 16:38:02.699 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7199 |      41.3060 |               41.3060 |     64 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   1981 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4963
Total latency (us): 2655.35

2022-05-12 16:38:02.699 INFO Scheduler picks Task #4: "fused_nn_lrn"
2022-05-12 16:38:13.593 INFO Sending 61 sample(s) to builder
2022-05-12 16:38:16.600 INFO Sending 61 sample(s) to runner
2022-05-12 16:41:07.539 INFO [Updated] Task #4: "fused_nn_lrn"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    125 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   1981 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5024
Total latency (us): 2655.25

2022-05-12 16:41:07.539 INFO Scheduler picks Task #4: "fused_nn_lrn"
2022-05-12 16:41:18.146 INFO Sending 23 sample(s) to builder
2022-05-12 16:41:20.532 INFO Sending 23 sample(s) to runner
2022-05-12 16:41:30.465 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    125 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2045 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5088
Total latency (us): 2655.25

2022-05-12 16:41:30.465 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 16:41:51.072 INFO Sending 64 sample(s) to builder
2022-05-12 16:42:01.650 INFO Sending 64 sample(s) to runner
2022-05-12 16:42:26.823 INFO [Updated] Task #4: "fused_nn_lrn"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2060.5143 |     145.1922 |              145.1922 |    320 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2045 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5111
Total latency (us): 2655.25

2022-05-12 16:42:52.786 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2045 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.8677 |     442.3833 |              442.3833 |    704 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5175
Total latency (us): 2643.62

2022-05-12 16:42:52.787 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 16:42:59.658 INFO Sending 64 sample(s) to builder
2022-05-12 16:43:04.731 INFO Sending 64 sample(s) to runner
2022-05-12 16:44:08.803 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2045 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9283 |     442.0308 |              442.0308 |    768 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5239
Total latency (us): 2643.27

2022-05-12 16:44:08.804 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 16:44:18.958 INFO Sending 64 sample(s) to builder
2022-05-12 16:44:32.570 INFO Sending 64 sample(s) to runner
2022-05-12 16:44:32.626 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 16:45:21.468 INFO Sending 64 sample(s) to builder
2022-05-12 16:45:44.367 INFO Sending 64 sample(s) to runner
2022-05-12 16:45:59.102 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1068.6122 |     210.0017 |              210.0017 |    384 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2045 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    832 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5303
Total latency (us): 2643.25

2022-05-12 16:46:52.394 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    448 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2045 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    832 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5367
Total latency (us): 2623.18

2022-05-12 16:46:52.394 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 16:47:31.880 INFO Sending 64 sample(s) to builder
2022-05-12 16:47:52.692 INFO Sending 64 sample(s) to runner
2022-05-12 16:47:52.749 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:48:02.952 INFO Sending 63 sample(s) to builder
2022-05-12 16:48:09.442 INFO Sending 63 sample(s) to runner
2022-05-12 16:48:37.830 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2045 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    832 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5431
Total latency (us): 2623.18

2022-05-12 16:49:40.045 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2108 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    832 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5494
Total latency (us): 2623.18

2022-05-12 16:49:40.045 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:49:45.056 INFO Sending 64 sample(s) to builder
2022-05-12 16:49:49.484 INFO Sending 64 sample(s) to runner
2022-05-12 16:51:27.869 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2172 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    832 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5558
Total latency (us): 2623.18

2022-05-12 16:51:27.869 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:51:32.901 INFO Sending 64 sample(s) to builder
2022-05-12 16:51:42.363 INFO Sending 64 sample(s) to runner
2022-05-12 16:53:43.971 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2236 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    832 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5622
Total latency (us): 2623.18

2022-05-12 16:53:43.972 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:53:50.966 INFO Sending 64 sample(s) to builder
2022-05-12 16:53:55.054 INFO Sending 64 sample(s) to runner
2022-05-12 16:55:51.858 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2300 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    832 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5686
Total latency (us): 2623.18

2022-05-12 16:55:51.858 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:55:59.065 INFO Sending 64 sample(s) to builder
2022-05-12 16:56:02.814 INFO Sending 64 sample(s) to runner
2022-05-12 16:58:13.760 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2364 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    832 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5750
Total latency (us): 2623.18

2022-05-12 16:58:13.761 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 16:58:25.792 INFO Sending 64 sample(s) to builder
2022-05-12 16:58:35.148 INFO Sending 64 sample(s) to runner
2022-05-12 16:58:35.192 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 16:58:49.658 INFO Sending 63 sample(s) to builder
2022-05-12 16:58:55.206 INFO Sending 63 sample(s) to runner
2022-05-12 17:01:30.213 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2364 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    895 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5813
Total latency (us): 2623.18

2022-05-12 17:01:30.213 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 17:01:37.513 INFO Sending 64 sample(s) to builder
2022-05-12 17:01:42.273 INFO Sending 64 sample(s) to runner
2022-05-12 17:01:55.697 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0544 |    1257.2887 |             1257.2887 |   2428 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    895 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5877
Total latency (us): 2623.18

2022-05-12 17:01:55.698 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:02:02.796 INFO Sending 64 sample(s) to builder
2022-05-12 17:02:05.964 INFO Sending 64 sample(s) to runner
2022-05-12 17:05:30.960 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0648 |    1257.0704 |             1257.0704 |   2492 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    895 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5941
Total latency (us): 2622.96

2022-05-12 17:05:30.960 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:05:36.003 INFO Sending 64 sample(s) to builder
2022-05-12 17:05:38.744 INFO Sending 64 sample(s) to runner
2022-05-12 17:05:53.844 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2239.9094 |     133.5637 |              133.5637 |    384 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0648 |    1257.0704 |             1257.0704 |   2492 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6005
Total latency (us): 2622.96

2022-05-12 17:05:53.844 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 17:06:19.567 INFO Sending 64 sample(s) to builder
2022-05-12 17:06:24.480 INFO Sending 64 sample(s) to runner
2022-05-12 17:08:00.000 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2262.2227 |     132.2463 |              132.2463 |    448 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0648 |    1257.0704 |             1257.0704 |   2492 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6069
Total latency (us): 2621.64

2022-05-12 17:08:00.000 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 17:08:34.306 INFO Sending 64 sample(s) to builder
2022-05-12 17:08:45.242 INFO Sending 64 sample(s) to runner
2022-05-12 17:09:32.618 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2262.2227 |     132.2463 |              132.2463 |    448 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0648 |    1257.0704 |             1257.0704 |   2556 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6133
Total latency (us): 2621.64

2022-05-12 17:09:32.618 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:09:44.249 INFO Sending 64 sample(s) to builder
2022-05-12 17:09:50.124 INFO Sending 64 sample(s) to runner
2022-05-12 17:10:08.933 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0648 |    1257.0704 |             1257.0704 |   2556 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6197
Total latency (us): 2619.41

2022-05-12 17:11:34.353 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    384 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0648 |    1257.0704 |             1257.0704 |   2620 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6261
Total latency (us): 2619.41

2022-05-12 17:11:34.353 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:11:41.934 INFO Sending 64 sample(s) to builder
2022-05-12 17:11:44.892 INFO Sending 64 sample(s) to runner
2022-05-12 17:11:44.922 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 17:12:10.967 INFO Sending 64 sample(s) to builder
2022-05-12 17:12:18.113 INFO Sending 64 sample(s) to runner
2022-05-12 17:14:48.838 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    448 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.0648 |    1257.0704 |             1257.0704 |   2620 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6325
Total latency (us): 2619.41

2022-05-12 17:14:48.838 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 17:15:17.335 INFO Sending 64 sample(s) to builder
2022-05-12 17:15:33.002 INFO Sending 64 sample(s) to runner
2022-05-12 17:15:56.813 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    448 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2684 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6389
Total latency (us): 2616.96

2022-05-12 17:15:56.813 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 17:16:36.842 INFO Sending 64 sample(s) to builder
2022-05-12 17:17:18.774 INFO Sending 64 sample(s) to runner
2022-05-12 17:17:48.534 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1862.3271 |     240.7047 |              240.7047 |    512 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2684 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6453
Total latency (us): 2616.96

2022-05-12 17:18:35.300 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    576 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2684 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6517
Total latency (us): 2612.03

2022-05-12 17:18:35.300 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 17:19:09.774 INFO Sending 64 sample(s) to builder
2022-05-12 17:19:49.186 INFO Sending 64 sample(s) to runner
2022-05-12 17:19:49.296 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:20:07.312 INFO Sending 64 sample(s) to builder
2022-05-12 17:20:13.261 INFO Sending 64 sample(s) to runner
2022-05-12 17:20:27.160 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2684 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6581
Total latency (us): 2612.03

2022-05-12 17:21:58.491 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        20.4430 |      29.6285 |               29.6285 |     62 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2748 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6645
Total latency (us): 2612.03

2022-05-12 17:21:58.491 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:22:03.611 INFO Sending 64 sample(s) to builder
2022-05-12 17:22:32.653 INFO Sending 64 sample(s) to runner
2022-05-12 17:22:32.720 INFO Scheduler picks Task #7: "fused_nn_lrn_1"
2022-05-12 17:22:44.065 INFO Sending 62 sample(s) to builder
2022-05-12 17:22:46.991 INFO Sending 62 sample(s) to runner
2022-05-12 17:25:22.947 INFO [Updated] Task #7: "fused_nn_lrn_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    124 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2748 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6707
Total latency (us): 2610.85

2022-05-12 17:25:22.961 INFO Scheduler picks Task #7: "fused_nn_lrn_1"
2022-05-12 17:25:41.942 INFO Sending 24 sample(s) to builder
2022-05-12 17:25:44.676 INFO Sending 24 sample(s) to runner
2022-05-12 17:26:05.951 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    124 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2812 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6771
Total latency (us): 2610.85

2022-05-12 17:26:05.951 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 17:26:16.487 INFO Sending 64 sample(s) to builder
2022-05-12 17:26:38.265 INFO Sending 64 sample(s) to runner
2022-05-12 17:26:51.340 INFO [Updated] Task #7: "fused_nn_lrn_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2812 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |    959 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6795
Total latency (us): 2610.85

2022-05-12 17:28:58.763 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2812 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1023 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6859
Total latency (us): 2610.85

2022-05-12 17:28:58.777 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 17:29:11.075 INFO Sending 64 sample(s) to builder
2022-05-12 17:29:15.865 INFO Sending 64 sample(s) to runner
2022-05-12 17:29:15.931 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:29:25.588 INFO Sending 64 sample(s) to builder
2022-05-12 17:29:28.694 INFO Sending 64 sample(s) to runner
2022-05-12 17:32:12.484 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2876 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1023 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6923
Total latency (us): 2610.85

2022-05-12 17:32:12.484 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:32:17.615 INFO Sending 64 sample(s) to builder
2022-05-12 17:32:20.716 INFO Sending 64 sample(s) to runner
2022-05-12 17:32:30.407 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2876 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1087 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6987
Total latency (us): 2610.85

2022-05-12 17:34:20.290 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   2940 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1087 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7051
Total latency (us): 2610.85

2022-05-12 17:34:20.290 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:34:30.238 INFO Sending 64 sample(s) to builder
2022-05-12 17:34:38.080 INFO Sending 64 sample(s) to runner
2022-05-12 17:36:29.208 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3004 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1087 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7115
Total latency (us): 2610.85

2022-05-12 17:36:29.208 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:36:38.653 INFO Sending 64 sample(s) to builder
2022-05-12 17:36:44.751 INFO Sending 64 sample(s) to runner
2022-05-12 17:38:13.572 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    512 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3068 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1087 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7179
Total latency (us): 2610.85

2022-05-12 17:38:13.572 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:38:18.516 INFO Sending 63 sample(s) to builder
2022-05-12 17:38:23.924 INFO Sending 63 sample(s) to runner
2022-05-12 17:38:23.954 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 17:39:01.244 INFO Sending 64 sample(s) to builder
2022-05-12 17:39:11.808 INFO Sending 64 sample(s) to runner
2022-05-12 17:40:50.537 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    576 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3068 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1087 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7243
Total latency (us): 2610.85

2022-05-12 17:40:50.538 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 17:41:32.478 INFO Sending 64 sample(s) to builder
2022-05-12 17:41:41.617 INFO Sending 64 sample(s) to runner
2022-05-12 17:41:58.294 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    576 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3131 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1087 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7306
Total latency (us): 2610.85

2022-05-12 17:41:58.294 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 17:42:03.331 INFO Sending 64 sample(s) to builder
2022-05-12 17:42:07.398 INFO Sending 64 sample(s) to runner
2022-05-12 17:44:07.991 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1181.5088 |     189.9354 |              189.9354 |    576 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3131 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1151 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7370
Total latency (us): 2610.85

2022-05-12 17:44:07.991 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 17:44:21.072 INFO Sending 64 sample(s) to builder
2022-05-12 17:44:36.163 INFO Sending 64 sample(s) to runner
2022-05-12 17:45:16.285 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3131 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1151 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7434
Total latency (us): 2599.67

2022-05-12 17:45:16.286 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:45:21.306 INFO Sending 63 sample(s) to builder
2022-05-12 17:45:24.302 INFO Sending 63 sample(s) to runner
2022-05-12 17:47:43.907 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3194 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1151 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7497
Total latency (us): 2599.67

2022-05-12 17:47:43.907 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:47:54.390 INFO Sending 64 sample(s) to builder
2022-05-12 17:48:01.177 INFO Sending 64 sample(s) to runner
2022-05-12 17:48:24.625 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3194 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1215 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7561
Total latency (us): 2599.67

2022-05-12 17:49:54.847 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3258 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1215 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7625
Total latency (us): 2599.67

2022-05-12 17:49:54.847 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:50:00.568 INFO Sending 64 sample(s) to builder
2022-05-12 17:50:05.394 INFO Sending 64 sample(s) to runner
2022-05-12 17:52:05.251 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3322 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1215 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7689
Total latency (us): 2599.67

2022-05-12 17:52:05.251 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:52:18.133 INFO Sending 64 sample(s) to builder
2022-05-12 17:52:25.821 INFO Sending 64 sample(s) to runner
2022-05-12 17:54:00.471 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3386 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1215 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7753
Total latency (us): 2599.67

2022-05-12 17:54:00.471 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 17:54:05.530 INFO Sending 64 sample(s) to builder
2022-05-12 17:54:08.418 INFO Sending 64 sample(s) to runner
2022-05-12 17:54:08.448 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 17:54:55.557 INFO Sending 64 sample(s) to builder
2022-05-12 17:55:25.780 INFO Sending 64 sample(s) to runner
2022-05-12 17:55:50.787 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1901.2502 |     235.7769 |              235.7769 |    640 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3450 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1215 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7817
Total latency (us): 2599.67

2022-05-12 17:56:47.373 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1977.2648 |     226.7126 |              226.7126 |    704 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3450 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1215 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7881
Total latency (us): 2590.6

2022-05-12 17:56:47.373 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 17:57:16.975 INFO Sending 64 sample(s) to builder
2022-05-12 17:57:23.264 INFO Sending 64 sample(s) to runner
2022-05-12 17:57:23.337 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 17:57:30.461 INFO Sending 64 sample(s) to builder
2022-05-12 17:57:37.100 INFO Sending 64 sample(s) to runner
2022-05-12 17:58:58.705 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      1977.2648 |     226.7126 |              226.7126 |    704 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3450 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1279 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7945
Total latency (us): 2590.6

2022-05-12 17:58:58.706 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 17:59:14.160 INFO Sending 64 sample(s) to builder
2022-05-12 17:59:20.905 INFO Sending 64 sample(s) to runner
2022-05-12 18:00:12.888 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3450 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1279 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8009
Total latency (us): 2585.18

2022-05-12 18:00:45.794 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3450 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1343 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8073
Total latency (us): 2585.18

2022-05-12 18:00:45.794 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:01:01.793 INFO Sending 64 sample(s) to builder
2022-05-12 18:01:10.005 INFO Sending 64 sample(s) to runner
2022-05-12 18:03:12.571 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3514 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1343 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8137
Total latency (us): 2585.18

2022-05-12 18:03:12.571 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:03:23.340 INFO Sending 64 sample(s) to builder
2022-05-12 18:03:31.460 INFO Sending 64 sample(s) to runner
2022-05-12 18:05:33.952 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3578 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1343 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8201
Total latency (us): 2585.18

2022-05-12 18:05:33.952 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:05:51.406 INFO Sending 64 sample(s) to builder
2022-05-12 18:06:15.012 INFO Sending 64 sample(s) to runner
2022-05-12 18:08:51.893 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       897.6344 |     166.6680 |              166.6680 |    512 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3642 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1343 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8265
Total latency (us): 2585.18

2022-05-12 18:08:51.894 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:09:08.808 INFO Sending 64 sample(s) to builder
2022-05-12 18:09:39.938 INFO Sending 64 sample(s) to runner
2022-05-12 18:09:39.994 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 18:10:08.004 INFO Sending 64 sample(s) to builder
2022-05-12 18:10:20.989 INFO Sending 64 sample(s) to runner
2022-05-12 18:12:39.759 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    576 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3642 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1343 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8329
Total latency (us): 2584.61

2022-05-12 18:12:39.759 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 18:13:19.688 INFO Sending 64 sample(s) to builder
2022-05-12 18:13:26.876 INFO Sending 64 sample(s) to runner
2022-05-12 18:13:47.415 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    576 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3706 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1343 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8393
Total latency (us): 2584.61

2022-05-12 18:13:47.415 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:13:57.572 INFO Sending 64 sample(s) to builder
2022-05-12 18:14:02.620 INFO Sending 64 sample(s) to runner
2022-05-12 18:14:30.142 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3706 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1343 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8457
Total latency (us): 2584.61

2022-05-12 18:15:41.109 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3770 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1343 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8521
Total latency (us): 2584.61

2022-05-12 18:15:41.109 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:15:50.999 INFO Sending 64 sample(s) to builder
2022-05-12 18:15:56.089 INFO Sending 64 sample(s) to runner
2022-05-12 18:18:43.401 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3834 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1343 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8585
Total latency (us): 2584.61

2022-05-12 18:18:43.402 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:18:52.645 INFO Sending 64 sample(s) to builder
2022-05-12 18:18:58.171 INFO Sending 64 sample(s) to runner
2022-05-12 18:18:58.201 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 18:19:03.956 INFO Sending 64 sample(s) to builder
2022-05-12 18:19:09.006 INFO Sending 64 sample(s) to runner
2022-05-12 18:22:38.530 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3834 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1407 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8649
Total latency (us): 2584.61

2022-05-12 18:22:38.530 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 18:22:45.359 INFO Sending 64 sample(s) to builder
2022-05-12 18:22:55.967 INFO Sending 64 sample(s) to runner
2022-05-12 18:23:08.845 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2582.8657 |      78.9021 |               78.9021 |    320 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3898 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1407 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8713
Total latency (us): 2584.61

2022-05-12 18:23:08.845 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-12 18:23:19.278 INFO Sending 64 sample(s) to builder
2022-05-12 18:23:25.100 INFO Sending 64 sample(s) to runner
2022-05-12 18:25:27.469 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2656.3842 |      76.7183 |               76.7183 |    384 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3898 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1407 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8777
Total latency (us): 2582.42

2022-05-12 18:25:27.469 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-12 18:25:45.052 INFO Sending 64 sample(s) to builder
2022-05-12 18:25:55.462 INFO Sending 64 sample(s) to runner
2022-05-12 18:26:27.021 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2656.3842 |      76.7183 |               76.7183 |    384 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3898 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1471 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8841
Total latency (us): 2582.42

2022-05-12 18:26:27.021 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:26:34.641 INFO Sending 64 sample(s) to builder
2022-05-12 18:26:48.064 INFO Sending 64 sample(s) to runner
2022-05-12 18:27:45.684 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3898 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1471 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8905
Total latency (us): 2581.8

2022-05-12 18:28:22.294 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   3962 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1471 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8969
Total latency (us): 2581.8

2022-05-12 18:28:22.294 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:28:29.925 INFO Sending 64 sample(s) to builder
2022-05-12 18:28:34.729 INFO Sending 64 sample(s) to runner
2022-05-12 18:31:11.051 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4026 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1471 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9033
Total latency (us): 2581.8

2022-05-12 18:31:11.051 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:31:20.725 INFO Sending 64 sample(s) to builder
2022-05-12 18:31:23.937 INFO Sending 64 sample(s) to runner
2022-05-12 18:33:51.366 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2025.7492 |     221.2864 |              221.2864 |    768 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4090 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1471 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9097
Total latency (us): 2581.8

2022-05-12 18:33:51.366 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:33:58.221 INFO Sending 64 sample(s) to builder
2022-05-12 18:34:01.379 INFO Sending 64 sample(s) to runner
2022-05-12 18:34:01.410 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 18:34:38.420 INFO Sending 64 sample(s) to builder
2022-05-12 18:34:55.427 INFO Sending 64 sample(s) to runner
2022-05-12 18:36:29.442 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2052.0497 |     218.4503 |              218.4503 |    832 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4090 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1471 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9161
Total latency (us): 2578.97

2022-05-12 18:36:29.442 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 18:37:04.928 INFO Sending 64 sample(s) to builder
2022-05-12 18:37:19.045 INFO Sending 64 sample(s) to runner
2022-05-12 18:37:37.234 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2052.0497 |     218.4503 |              218.4503 |    832 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4154 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1471 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9225
Total latency (us): 2578.97

2022-05-12 18:37:37.234 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:37:45.076 INFO Sending 63 sample(s) to builder
2022-05-12 18:37:48.984 INFO Sending 63 sample(s) to runner
2022-05-12 18:39:23.274 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2052.0497 |     218.4503 |              218.4503 |    832 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4217 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1471 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9288
Total latency (us): 2578.97

2022-05-12 18:39:23.274 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:39:29.922 INFO Sending 64 sample(s) to builder
2022-05-12 18:39:40.347 INFO Sending 64 sample(s) to runner
2022-05-12 18:40:13.702 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4217 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1471 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9352
Total latency (us): 2564.43

2022-05-12 18:40:13.702 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 18:40:20.863 INFO Sending 64 sample(s) to builder
2022-05-12 18:40:25.737 INFO Sending 64 sample(s) to runner
2022-05-12 18:42:20.708 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4217 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1535 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9416
Total latency (us): 2564.43

2022-05-12 18:42:20.709 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 18:42:25.837 INFO Sending 63 sample(s) to builder
2022-05-12 18:42:28.965 INFO Sending 63 sample(s) to runner
2022-05-12 18:42:48.246 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4281 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9322 |     442.0075 |              442.0075 |   1535 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9480
Total latency (us): 2564.43

2022-05-12 18:42:48.246 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 18:43:22.902 INFO Sending 64 sample(s) to builder
2022-05-12 18:43:32.287 INFO Sending 64 sample(s) to runner
2022-05-12 18:43:46.411 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1255.4080 |     178.7549 |              178.7549 |    640 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4281 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9561 |     441.8685 |              441.8685 |   1598 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9543
Total latency (us): 2564.3

2022-05-12 18:45:21.751 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    704 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4281 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9561 |     441.8685 |              441.8685 |   1598 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9607
Total latency (us): 2561.78

2022-05-12 18:45:21.751 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 18:45:50.934 INFO Sending 64 sample(s) to builder
2022-05-12 18:45:56.398 INFO Sending 64 sample(s) to runner
2022-05-12 18:45:56.436 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:46:01.671 INFO Sending 64 sample(s) to builder
2022-05-12 18:46:05.062 INFO Sending 64 sample(s) to runner
2022-05-12 18:48:36.327 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    704 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4345 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9561 |     441.8685 |              441.8685 |   1598 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9671
Total latency (us): 2561.78

2022-05-12 18:48:36.327 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:48:49.287 INFO Sending 64 sample(s) to builder
2022-05-12 18:48:55.413 INFO Sending 64 sample(s) to runner
2022-05-12 18:49:30.169 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4345 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9561 |     441.8685 |              441.8685 |   1598 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9735
Total latency (us): 2561.78

2022-05-12 18:50:45.573 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.1822 |    1254.6176 |             1254.6176 |   4409 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9561 |     441.8685 |              441.8685 |   1598 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9799
Total latency (us): 2561.78

2022-05-12 18:50:45.573 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:50:52.725 INFO Sending 64 sample(s) to builder
2022-05-12 18:50:58.853 INFO Sending 64 sample(s) to runner
2022-05-12 18:52:49.637 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.2075 |    1254.0906 |             1254.0906 |   4473 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9561 |     441.8685 |              441.8685 |   1598 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9863
Total latency (us): 2561.25

2022-05-12 18:52:49.638 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:52:55.879 INFO Sending 64 sample(s) to builder
2022-05-12 18:53:00.020 INFO Sending 64 sample(s) to runner
2022-05-12 18:55:16.588 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.2075 |    1254.0906 |             1254.0906 |   4537 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9561 |     441.8685 |              441.8685 |   1598 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9927
Total latency (us): 2561.25

2022-05-12 18:55:16.589 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:55:29.596 INFO Sending 63 sample(s) to builder
2022-05-12 18:55:42.250 INFO Sending 63 sample(s) to runner
2022-05-12 18:57:44.690 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.2075 |    1254.0906 |             1254.0906 |   4600 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9561 |     441.8685 |              441.8685 |   1598 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9990
Total latency (us): 2561.25

2022-05-12 18:57:44.691 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 18:57:55.245 INFO Sending 64 sample(s) to builder
2022-05-12 18:58:02.904 INFO Sending 64 sample(s) to runner
2022-05-12 18:58:02.961 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 18:58:13.045 INFO Sending 64 sample(s) to builder
2022-05-12 18:58:16.861 INFO Sending 64 sample(s) to runner
2022-05-12 19:00:59.494 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.2075 |    1254.0906 |             1254.0906 |   4600 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9561 |     441.8685 |              441.8685 |   1662 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10054
Total latency (us): 2561.25

2022-05-12 19:00:59.495 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 19:01:04.783 INFO Sending 64 sample(s) to builder
2022-05-12 19:01:15.601 INFO Sending 64 sample(s) to runner
2022-05-12 19:01:40.434 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.3235 |    1251.6790 |             1251.6790 |   4664 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        75.9561 |     441.8685 |              441.8685 |   1662 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10118
Total latency (us): 2558.84

2022-05-12 19:01:40.435 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 19:02:13.725 INFO Sending 64 sample(s) to builder
2022-05-12 19:02:27.751 INFO Sending 64 sample(s) to runner
2022-05-12 19:03:01.268 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    512 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.3235 |    1251.6790 |             1251.6790 |   4664 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10182
Total latency (us): 2558.25

2022-05-12 19:03:36.616 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    576 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.3235 |    1251.6790 |             1251.6790 |   4664 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10246
Total latency (us): 2558.25

2022-05-12 19:03:36.616 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 19:04:01.207 INFO Sending 64 sample(s) to builder
2022-05-12 19:04:07.656 INFO Sending 64 sample(s) to runner
2022-05-12 19:04:07.703 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:04:13.985 INFO Sending 64 sample(s) to builder
2022-05-12 19:04:17.910 INFO Sending 64 sample(s) to runner
2022-05-12 19:07:33.381 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    576 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.3235 |    1251.6790 |             1251.6790 |   4728 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10310
Total latency (us): 2558.25

2022-05-12 19:07:33.381 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:07:44.140 INFO Sending 64 sample(s) to builder
2022-05-12 19:08:01.546 INFO Sending 64 sample(s) to runner
2022-05-12 19:08:50.339 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.3235 |    1251.6790 |             1251.6790 |   4728 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10374
Total latency (us): 2558.25

2022-05-12 19:09:43.078 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.3235 |    1251.6790 |             1251.6790 |   4792 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10438
Total latency (us): 2558.25

2022-05-12 19:09:43.079 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:09:49.447 INFO Sending 64 sample(s) to builder
2022-05-12 19:10:01.432 INFO Sending 64 sample(s) to runner
2022-05-12 19:12:05.469 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |       900.7137 |     166.0982 |              166.0982 |    640 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.3296 |    1251.5517 |             1251.5517 |   4856 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10502
Total latency (us): 2558.12

2022-05-12 19:12:05.469 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:12:12.399 INFO Sending 63 sample(s) to builder
2022-05-12 19:12:17.270 INFO Sending 63 sample(s) to runner
2022-05-12 19:12:17.315 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 19:12:56.319 INFO Sending 64 sample(s) to builder
2022-05-12 19:13:07.096 INFO Sending 64 sample(s) to runner
2022-05-12 19:15:03.124 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    704 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.3296 |    1251.5517 |             1251.5517 |   4856 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10566
Total latency (us): 2535.42

2022-05-12 19:15:03.125 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 19:15:42.559 INFO Sending 64 sample(s) to builder
2022-05-12 19:15:56.175 INFO Sending 64 sample(s) to runner
2022-05-12 19:16:23.473 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    704 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.4534 |    1248.9892 |             1248.9892 |   4919 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10629
Total latency (us): 2532.86

2022-05-12 19:16:23.474 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 19:16:53.422 INFO Sending 64 sample(s) to builder
2022-05-12 19:17:19.912 INFO Sending 64 sample(s) to runner
2022-05-12 19:18:10.899 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    896 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.4534 |    1248.9892 |             1248.9892 |   4919 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10693
Total latency (us): 2532.86

2022-05-12 19:18:26.781 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |    960 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.4534 |    1248.9892 |             1248.9892 |   4919 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10757
Total latency (us): 2532.86

2022-05-12 19:18:26.782 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 19:18:58.519 INFO Sending 64 sample(s) to builder
2022-05-12 19:19:18.065 INFO Sending 64 sample(s) to runner
2022-05-12 19:19:18.131 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:19:28.820 INFO Sending 64 sample(s) to builder
2022-05-12 19:19:36.831 INFO Sending 64 sample(s) to runner
2022-05-12 19:20:20.867 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.4534 |    1248.9892 |             1248.9892 |   4919 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10821
Total latency (us): 2532.86

2022-05-12 19:21:16.614 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.4534 |    1248.9892 |             1248.9892 |   4983 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.0576 |     441.2792 |              441.2792 |   1726 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10885
Total latency (us): 2532.86

2022-05-12 19:21:16.614 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:21:26.029 INFO Sending 64 sample(s) to builder
2022-05-12 19:21:31.392 INFO Sending 64 sample(s) to runner
2022-05-12 19:21:31.423 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 19:21:36.833 INFO Sending 64 sample(s) to builder
2022-05-12 19:21:39.498 INFO Sending 64 sample(s) to runner
2022-05-12 19:24:49.756 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.4534 |    1248.9892 |             1248.9892 |   4983 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1790 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10949
Total latency (us): 2532.59

2022-05-12 19:24:49.756 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 19:24:57.226 INFO Sending 64 sample(s) to builder
2022-05-12 19:25:00.773 INFO Sending 64 sample(s) to runner
2022-05-12 19:25:31.833 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.4534 |    1248.9892 |             1248.9892 |   5047 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1790 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11013
Total latency (us): 2532.59

2022-05-12 19:25:31.834 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:25:46.065 INFO Sending 64 sample(s) to builder
2022-05-12 19:25:58.527 INFO Sending 64 sample(s) to runner
2022-05-12 19:26:49.065 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.4534 |    1248.9892 |             1248.9892 |   5047 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1854 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11077
Total latency (us): 2532.59

2022-05-12 19:27:42.821 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    768 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5111 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1854 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11141
Total latency (us): 2530.35

2022-05-12 19:27:42.821 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:27:50.136 INFO Sending 64 sample(s) to builder
2022-05-12 19:27:58.458 INFO Sending 64 sample(s) to runner
2022-05-12 19:27:58.519 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 19:28:35.225 INFO Sending 64 sample(s) to builder
2022-05-12 19:28:43.365 INFO Sending 64 sample(s) to runner
2022-05-12 19:30:38.363 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    832 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5111 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1854 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11205
Total latency (us): 2530.35

2022-05-12 19:30:38.363 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 19:31:37.651 INFO Sending 64 sample(s) to builder
2022-05-12 19:31:55.585 INFO Sending 64 sample(s) to runner
2022-05-12 19:32:40.976 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    832 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5175 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1854 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11269
Total latency (us): 2530.35

2022-05-12 19:32:40.976 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:32:54.277 INFO Sending 64 sample(s) to builder
2022-05-12 19:33:04.465 INFO Sending 64 sample(s) to runner
2022-05-12 19:33:56.941 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5175 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1854 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11333
Total latency (us): 2530.35

2022-05-12 19:34:38.502 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5239 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1854 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11397
Total latency (us): 2530.35

2022-05-12 19:34:38.502 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:34:45.964 INFO Sending 64 sample(s) to builder
2022-05-12 19:34:51.184 INFO Sending 64 sample(s) to runner
2022-05-12 19:36:54.397 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5303 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1854 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11461
Total latency (us): 2530.35

2022-05-12 19:36:54.397 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:37:04.672 INFO Sending 64 sample(s) to builder
2022-05-12 19:37:09.791 INFO Sending 64 sample(s) to runner
2022-05-12 19:37:09.852 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 19:37:17.442 INFO Sending 64 sample(s) to builder
2022-05-12 19:37:21.025 INFO Sending 64 sample(s) to runner
2022-05-12 19:40:05.870 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5303 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1918 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11525
Total latency (us): 2530.35

2022-05-12 19:40:05.871 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 19:40:11.171 INFO Sending 63 sample(s) to builder
2022-05-12 19:40:15.611 INFO Sending 63 sample(s) to runner
2022-05-12 19:40:44.297 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5367 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1918 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11589
Total latency (us): 2530.35

2022-05-12 19:40:44.298 INFO Scheduler picks Task #17: "fused_nn_dense_add"
2022-05-12 19:40:49.865 INFO Sending 64 sample(s) to builder
2022-05-12 19:40:53.458 INFO Sending 64 sample(s) to runner
2022-05-12 19:41:43.148 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5367 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1981 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       107.8149 |      15.1983 |               15.1983 |     64 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11652
Total latency (us): 2530.35

2022-05-12 19:42:07.310 INFO [Updated] Task #17: "fused_nn_dense_add"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5367 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1981 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11716
Total latency (us): 2522.51

2022-05-12 19:42:07.310 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:42:12.568 INFO Sending 63 sample(s) to builder
2022-05-12 19:42:17.157 INFO Sending 63 sample(s) to runner
2022-05-12 19:43:34.099 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5430 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1981 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11779
Total latency (us): 2522.51

2022-05-12 19:43:34.099 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:43:44.930 INFO Sending 64 sample(s) to builder
2022-05-12 19:43:50.649 INFO Sending 64 sample(s) to runner
2022-05-12 19:45:06.399 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5494 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1981 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11843
Total latency (us): 2522.51

2022-05-12 19:45:06.399 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:45:11.274 INFO Sending 64 sample(s) to builder
2022-05-12 19:45:14.271 INFO Sending 64 sample(s) to runner
2022-05-12 19:46:39.816 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2677.9978 |      76.0992 |               76.0992 |    448 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5558 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1981 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11907
Total latency (us): 2522.51

2022-05-12 19:46:39.816 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:46:44.935 INFO Sending 64 sample(s) to builder
2022-05-12 19:46:47.842 INFO Sending 64 sample(s) to runner
2022-05-12 19:46:47.872 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-12 19:46:58.255 INFO Sending 64 sample(s) to builder
2022-05-12 19:47:03.797 INFO Sending 64 sample(s) to runner
2022-05-12 19:48:48.544 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    512 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5558 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1981 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11971
Total latency (us): 2522.32

2022-05-12 19:48:48.544 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-12 19:49:00.188 INFO Sending 64 sample(s) to builder
2022-05-12 19:49:08.373 INFO Sending 64 sample(s) to runner
2022-05-12 19:49:41.905 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    512 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5622 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1981 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12035
Total latency (us): 2522.32

2022-05-12 19:49:41.905 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 19:49:50.267 INFO Sending 64 sample(s) to builder
2022-05-12 19:49:57.794 INFO Sending 64 sample(s) to runner
2022-05-12 19:50:16.981 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5622 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   1981 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12099
Total latency (us): 2522.32

2022-05-12 19:50:52.927 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5622 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2045 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12163
Total latency (us): 2522.32

2022-05-12 19:50:52.927 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 19:50:58.090 INFO Sending 63 sample(s) to builder
2022-05-12 19:51:02.605 INFO Sending 63 sample(s) to runner
2022-05-12 19:51:02.635 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:51:07.892 INFO Sending 64 sample(s) to builder
2022-05-12 19:51:11.514 INFO Sending 64 sample(s) to runner
2022-05-12 19:52:58.616 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5686 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2045 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12227
Total latency (us): 2522.32

2022-05-12 19:52:58.616 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:53:03.569 INFO Sending 64 sample(s) to builder
2022-05-12 19:53:07.406 INFO Sending 64 sample(s) to runner
2022-05-12 19:53:21.815 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5686 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2108 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12290
Total latency (us): 2522.32

2022-05-12 19:54:23.866 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2198.2895 |     203.9180 |              203.9180 |   1024 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5750 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2108 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12354
Total latency (us): 2522.32

2022-05-12 19:54:23.866 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 19:54:28.917 INFO Sending 64 sample(s) to builder
2022-05-12 19:54:34.079 INFO Sending 64 sample(s) to runner
2022-05-12 19:54:34.109 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 19:55:02.708 INFO Sending 64 sample(s) to builder
2022-05-12 19:55:27.694 INFO Sending 64 sample(s) to runner
2022-05-12 19:56:39.028 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2203.4894 |     203.4368 |              203.4368 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5750 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2108 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12418
Total latency (us): 2521.84

2022-05-12 19:56:39.028 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 19:57:18.392 INFO Sending 64 sample(s) to builder
2022-05-12 19:57:52.025 INFO Sending 64 sample(s) to runner
2022-05-12 19:58:08.011 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2203.4894 |     203.4368 |              203.4368 |   1088 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5814 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2108 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12482
Total latency (us): 2521.84

2022-05-12 19:58:08.011 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 19:58:33.705 INFO Sending 64 sample(s) to builder
2022-05-12 19:58:39.335 INFO Sending 64 sample(s) to runner
2022-05-12 19:58:56.216 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    768 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5814 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2108 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12546
Total latency (us): 2519.87

2022-05-12 19:59:20.967 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    832 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5814 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2108 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12610
Total latency (us): 2519.87

2022-05-12 19:59:20.967 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 19:59:52.248 INFO Sending 64 sample(s) to builder
2022-05-12 19:59:57.875 INFO Sending 64 sample(s) to runner
2022-05-12 19:59:57.913 INFO Scheduler picks Task #4: "fused_nn_lrn"
2022-05-12 20:00:06.432 INFO Sending 0 sample(s) to builder
2022-05-12 20:00:06.434 INFO Sending 0 sample(s) to runner
2022-05-12 20:00:06.435 INFO [Updated] Task #4: "fused_nn_lrn"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    832 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5814 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2108 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12610
Total latency (us): 2519.87

2022-05-12 20:00:06.435 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:00:11.595 INFO Sending 64 sample(s) to builder
2022-05-12 20:00:15.180 INFO Sending 64 sample(s) to runner
2022-05-12 20:01:32.811 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    832 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5878 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2108 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12674
Total latency (us): 2519.87

2022-05-12 20:01:32.811 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:01:38.041 INFO Sending 64 sample(s) to builder
2022-05-12 20:01:41.759 INFO Sending 64 sample(s) to runner
2022-05-12 20:02:17.062 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5878 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2108 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12738
Total latency (us): 2519.87

2022-05-12 20:02:58.137 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   5942 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2108 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12802
Total latency (us): 2519.87

2022-05-12 20:02:58.137 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:03:03.198 INFO Sending 64 sample(s) to builder
2022-05-12 20:03:07.180 INFO Sending 64 sample(s) to runner
2022-05-12 20:04:37.554 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6006 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2108 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12866
Total latency (us): 2519.87

2022-05-12 20:04:37.554 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:04:42.629 INFO Sending 64 sample(s) to builder
2022-05-12 20:04:46.453 INFO Sending 64 sample(s) to runner
2022-05-12 20:04:46.484 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 20:04:51.579 INFO Sending 64 sample(s) to builder
2022-05-12 20:04:55.140 INFO Sending 64 sample(s) to runner
2022-05-12 20:06:45.860 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6006 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2172 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12930
Total latency (us): 2519.87

2022-05-12 20:06:45.860 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 20:06:50.822 INFO Sending 64 sample(s) to builder
2022-05-12 20:06:54.363 INFO Sending 64 sample(s) to runner
2022-05-12 20:07:10.117 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2301.1085 |     130.0115 |              130.0115 |    640 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6070 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2172 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12994
Total latency (us): 2519.87

2022-05-12 20:07:10.118 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 20:07:25.423 INFO Sending 64 sample(s) to builder
2022-05-12 20:07:30.624 INFO Sending 64 sample(s) to runner
2022-05-12 20:08:03.195 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2318.9511 |     129.0112 |              129.0112 |    704 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6070 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2172 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13058
Total latency (us): 2518.87

2022-05-12 20:08:03.195 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 20:08:24.199 INFO Sending 64 sample(s) to builder
2022-05-12 20:08:30.840 INFO Sending 64 sample(s) to runner
2022-05-12 20:09:02.355 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2318.9511 |     129.0112 |              129.0112 |    704 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6070 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2236 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13122
Total latency (us): 2518.87

2022-05-12 20:09:02.355 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:09:07.614 INFO Sending 64 sample(s) to builder
2022-05-12 20:09:11.944 INFO Sending 64 sample(s) to runner
2022-05-12 20:09:27.683 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6070 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2236 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13186
Total latency (us): 2518.61

2022-05-12 20:10:27.575 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6134 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2236 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13250
Total latency (us): 2518.61

2022-05-12 20:10:27.575 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:10:32.643 INFO Sending 62 sample(s) to builder
2022-05-12 20:10:36.614 INFO Sending 62 sample(s) to runner
2022-05-12 20:11:51.609 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6196 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2236 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13312
Total latency (us): 2518.61

2022-05-12 20:11:51.609 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:11:56.491 INFO Sending 64 sample(s) to builder
2022-05-12 20:12:01.042 INFO Sending 64 sample(s) to runner
2022-05-12 20:13:42.358 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6260 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2236 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13376
Total latency (us): 2518.61

2022-05-12 20:13:42.358 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:13:47.628 INFO Sending 64 sample(s) to builder
2022-05-12 20:13:51.358 INFO Sending 64 sample(s) to runner
2022-05-12 20:15:15.918 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6324 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2236 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13440
Total latency (us): 2518.61

2022-05-12 20:15:15.919 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:15:25.952 INFO Sending 63 sample(s) to builder
2022-05-12 20:15:33.214 INFO Sending 63 sample(s) to runner
2022-05-12 20:15:33.263 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 20:15:41.551 INFO Sending 64 sample(s) to builder
2022-05-12 20:15:45.379 INFO Sending 64 sample(s) to runner
2022-05-12 20:17:29.126 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6324 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2300 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13504
Total latency (us): 2518.61

2022-05-12 20:17:29.127 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 20:17:34.438 INFO Sending 64 sample(s) to builder
2022-05-12 20:17:37.334 INFO Sending 64 sample(s) to runner
2022-05-12 20:17:55.276 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6387 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2300 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13567
Total latency (us): 2518.61

2022-05-12 20:17:55.276 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 20:18:34.737 INFO Sending 64 sample(s) to builder
2022-05-12 20:18:47.665 INFO Sending 64 sample(s) to runner
2022-05-12 20:19:12.518 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    896 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6387 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2364 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13631
Total latency (us): 2518.61

2022-05-12 20:19:28.719 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    960 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6387 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2364 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13695
Total latency (us): 2518.61

2022-05-12 20:19:28.719 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 20:19:57.096 INFO Sending 64 sample(s) to builder
2022-05-12 20:20:06.865 INFO Sending 64 sample(s) to runner
2022-05-12 20:20:06.903 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:20:12.043 INFO Sending 64 sample(s) to builder
2022-05-12 20:20:16.613 INFO Sending 64 sample(s) to runner
2022-05-12 20:21:40.748 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |    960 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6451 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2364 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13759
Total latency (us): 2518.61

2022-05-12 20:21:40.748 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:21:46.007 INFO Sending 63 sample(s) to builder
2022-05-12 20:21:50.564 INFO Sending 63 sample(s) to runner
2022-05-12 20:22:06.543 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6451 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2364 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13823
Total latency (us): 2518.61

2022-05-12 20:23:28.124 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6514 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2364 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13886
Total latency (us): 2518.61

2022-05-12 20:23:28.125 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:23:33.309 INFO Sending 64 sample(s) to builder
2022-05-12 20:23:37.461 INFO Sending 64 sample(s) to runner
2022-05-12 20:24:58.438 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6578 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2364 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13950
Total latency (us): 2518.61

2022-05-12 20:24:58.438 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:25:03.538 INFO Sending 64 sample(s) to builder
2022-05-12 20:25:06.888 INFO Sending 64 sample(s) to runner
2022-05-12 20:26:25.387 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6642 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2364 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14014
Total latency (us): 2518.61

2022-05-12 20:26:25.387 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:26:30.479 INFO Sending 64 sample(s) to builder
2022-05-12 20:26:42.825 INFO Sending 64 sample(s) to runner
2022-05-12 20:28:03.689 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6706 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2364 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14078
Total latency (us): 2518.61

2022-05-12 20:28:03.689 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:28:08.786 INFO Sending 63 sample(s) to builder
2022-05-12 20:28:13.275 INFO Sending 63 sample(s) to runner
2022-05-12 20:28:13.306 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 20:28:18.488 INFO Sending 64 sample(s) to builder
2022-05-12 20:28:26.007 INFO Sending 64 sample(s) to runner
2022-05-12 20:30:08.281 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6706 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2428 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14142
Total latency (us): 2518.61

2022-05-12 20:30:08.281 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 20:30:13.489 INFO Sending 64 sample(s) to builder
2022-05-12 20:30:16.989 INFO Sending 64 sample(s) to runner
2022-05-12 20:30:33.352 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6769 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2428 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14205
Total latency (us): 2518.61

2022-05-12 20:30:33.352 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:30:38.436 INFO Sending 64 sample(s) to builder
2022-05-12 20:30:42.619 INFO Sending 64 sample(s) to runner
2022-05-12 20:32:17.042 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6833 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2428 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14269
Total latency (us): 2518.61

2022-05-12 20:32:17.043 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:32:21.993 INFO Sending 64 sample(s) to builder
2022-05-12 20:32:25.904 INFO Sending 64 sample(s) to runner
2022-05-12 20:32:45.212 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6833 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2492 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14333
Total latency (us): 2518.61

2022-05-12 20:33:55.843 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6897 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2492 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14397
Total latency (us): 2518.61

2022-05-12 20:33:55.843 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:34:01.189 INFO Sending 64 sample(s) to builder
2022-05-12 20:34:05.473 INFO Sending 64 sample(s) to runner
2022-05-12 20:35:26.656 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   6961 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2492 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14461
Total latency (us): 2518.61

2022-05-12 20:35:26.656 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:35:31.857 INFO Sending 64 sample(s) to builder
2022-05-12 20:35:36.011 INFO Sending 64 sample(s) to runner
2022-05-12 20:36:55.429 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2224.9688 |     201.4729 |              201.4729 |   1152 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7025 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2492 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14525
Total latency (us): 2518.61

2022-05-12 20:36:55.429 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:37:00.617 INFO Sending 63 sample(s) to builder
2022-05-12 20:37:04.652 INFO Sending 63 sample(s) to runner
2022-05-12 20:37:04.682 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 20:37:33.179 INFO Sending 64 sample(s) to builder
2022-05-12 20:37:45.242 INFO Sending 64 sample(s) to runner
2022-05-12 20:39:15.947 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7025 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2492 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14589
Total latency (us): 2516.54

2022-05-12 20:39:15.948 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 20:39:54.954 INFO Sending 64 sample(s) to builder
2022-05-12 20:40:19.436 INFO Sending 64 sample(s) to runner
2022-05-12 20:40:54.602 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1216 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7088 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2492 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14652
Total latency (us): 2516.54

2022-05-12 20:40:54.602 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 20:41:01.881 INFO Sending 64 sample(s) to builder
2022-05-12 20:41:05.579 INFO Sending 64 sample(s) to runner
2022-05-12 20:41:34.337 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7088 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2492 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14716
Total latency (us): 2516.54

2022-05-12 20:41:58.719 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7088 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2556 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14780
Total latency (us): 2516.54

2022-05-12 20:41:58.719 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 20:42:03.864 INFO Sending 64 sample(s) to builder
2022-05-12 20:42:07.341 INFO Sending 64 sample(s) to runner
2022-05-12 20:42:07.371 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:42:12.486 INFO Sending 64 sample(s) to builder
2022-05-12 20:42:16.726 INFO Sending 64 sample(s) to runner
2022-05-12 20:44:07.138 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7152 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2556 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14844
Total latency (us): 2516.54

2022-05-12 20:44:07.138 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:44:12.311 INFO Sending 63 sample(s) to builder
2022-05-12 20:44:18.181 INFO Sending 63 sample(s) to runner
2022-05-12 20:44:35.961 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7152 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2620 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14908
Total latency (us): 2516.54

2022-05-12 20:45:52.217 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7215 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2620 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14971
Total latency (us): 2516.54

2022-05-12 20:45:52.218 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:45:58.370 INFO Sending 63 sample(s) to builder
2022-05-12 20:46:03.909 INFO Sending 63 sample(s) to runner
2022-05-12 20:47:20.952 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1024 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7278 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2620 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15034
Total latency (us): 2516.54

2022-05-12 20:47:20.952 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:47:26.102 INFO Sending 64 sample(s) to builder
2022-05-12 20:47:30.163 INFO Sending 64 sample(s) to runner
2022-05-12 20:47:30.194 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 20:47:57.939 INFO Sending 64 sample(s) to builder
2022-05-12 20:48:13.187 INFO Sending 64 sample(s) to runner
2022-05-12 20:49:18.372 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1088 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7278 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2620 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15098
Total latency (us): 2516.54

2022-05-12 20:49:18.372 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 20:49:45.995 INFO Sending 64 sample(s) to builder
2022-05-12 20:49:56.074 INFO Sending 64 sample(s) to runner
2022-05-12 20:50:09.264 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1273.3395 |     176.2377 |              176.2377 |   1088 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7342 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2620 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15162
Total latency (us): 2516.54

2022-05-12 20:50:09.264 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:50:14.321 INFO Sending 64 sample(s) to builder
2022-05-12 20:50:25.912 INFO Sending 64 sample(s) to runner
2022-05-12 20:50:59.187 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7342 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2620 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15226
Total latency (us): 2516.33

2022-05-12 20:51:50.086 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    768 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7406 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2620 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15290
Total latency (us): 2516.33

2022-05-12 20:51:50.086 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:51:55.324 INFO Sending 64 sample(s) to builder
2022-05-12 20:51:59.796 INFO Sending 64 sample(s) to runner
2022-05-12 20:51:59.891 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 20:52:15.517 INFO Sending 64 sample(s) to builder
2022-05-12 20:52:19.749 INFO Sending 64 sample(s) to runner
2022-05-12 20:53:38.254 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    832 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7406 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2620 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15354
Total latency (us): 2516.33

2022-05-12 20:53:38.254 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 20:53:53.536 INFO Sending 64 sample(s) to builder
2022-05-12 20:53:57.708 INFO Sending 64 sample(s) to runner
2022-05-12 20:54:18.130 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    832 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7470 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2620 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15418
Total latency (us): 2516.33

2022-05-12 20:54:18.131 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 20:54:23.491 INFO Sending 64 sample(s) to builder
2022-05-12 20:54:28.446 INFO Sending 64 sample(s) to runner
2022-05-12 20:54:48.011 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7470 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2620 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15482
Total latency (us): 2516.33

2022-05-12 20:55:31.877 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7470 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2684 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15546
Total latency (us): 2516.33

2022-05-12 20:55:31.877 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 20:55:37.250 INFO Sending 64 sample(s) to builder
2022-05-12 20:55:47.946 INFO Sending 64 sample(s) to runner
2022-05-12 20:55:47.977 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:55:53.150 INFO Sending 64 sample(s) to builder
2022-05-12 20:55:56.278 INFO Sending 64 sample(s) to runner
2022-05-12 20:57:46.637 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7534 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2684 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15610
Total latency (us): 2516.33

2022-05-12 20:57:46.637 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:57:51.799 INFO Sending 64 sample(s) to builder
2022-05-12 20:57:55.966 INFO Sending 64 sample(s) to runner
2022-05-12 20:58:14.751 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7534 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2748 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15674
Total latency (us): 2516.33

2022-05-12 20:59:21.889 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7598 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2748 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15738
Total latency (us): 2516.33

2022-05-12 20:59:21.889 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 20:59:30.522 INFO Sending 64 sample(s) to builder
2022-05-12 20:59:34.368 INFO Sending 64 sample(s) to runner
2022-05-12 21:00:57.406 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7662 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2748 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15802
Total latency (us): 2516.33

2022-05-12 21:00:57.407 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:01:02.524 INFO Sending 64 sample(s) to builder
2022-05-12 21:01:06.044 INFO Sending 64 sample(s) to runner
2022-05-12 21:02:54.626 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7726 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2748 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15866
Total latency (us): 2516.33

2022-05-12 21:02:54.626 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:03:02.462 INFO Sending 63 sample(s) to builder
2022-05-12 21:03:10.448 INFO Sending 63 sample(s) to runner
2022-05-12 21:03:10.495 INFO Scheduler picks Task #4: "fused_nn_lrn"
2022-05-12 21:03:27.267 INFO Sending 0 sample(s) to builder
2022-05-12 21:03:27.269 INFO Sending 0 sample(s) to runner
2022-05-12 21:03:27.270 INFO [Updated] Task #4: "fused_nn_lrn"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7726 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2748 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15866
Total latency (us): 2516.33

2022-05-12 21:03:27.270 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 21:04:12.390 INFO Sending 64 sample(s) to builder
2022-05-12 21:04:35.287 INFO Sending 64 sample(s) to runner
2022-05-12 21:05:03.939 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1280 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7789 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2748 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15929
Total latency (us): 2516.33

2022-05-12 21:05:22.149 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7789 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2748 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15993
Total latency (us): 2516.33

2022-05-12 21:05:22.150 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 21:05:50.358 INFO Sending 64 sample(s) to builder
2022-05-12 21:05:59.350 INFO Sending 64 sample(s) to runner
2022-05-12 21:05:59.388 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 21:06:04.754 INFO Sending 64 sample(s) to builder
2022-05-12 21:06:07.980 INFO Sending 64 sample(s) to runner
2022-05-12 21:07:13.622 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2248.1721 |     199.3935 |              199.3935 |   1344 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7789 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2812 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16057
Total latency (us): 2516.33

2022-05-12 21:07:13.622 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 21:07:18.847 INFO Sending 63 sample(s) to builder
2022-05-12 21:07:23.185 INFO Sending 63 sample(s) to runner
2022-05-12 21:07:43.112 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7789 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2812 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16121
Total latency (us): 2515.72

2022-05-12 21:07:43.113 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 21:08:09.214 INFO Sending 64 sample(s) to builder
2022-05-12 21:08:17.318 INFO Sending 64 sample(s) to runner
2022-05-12 21:08:36.287 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1043.3091 |     143.3965 |              143.3965 |    896 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7789 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2875 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16184
Total latency (us): 2515.72

2022-05-12 21:09:14.561 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |    960 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7789 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2875 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16248
Total latency (us): 2508.43

2022-05-12 21:09:14.561 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 21:09:47.986 INFO Sending 64 sample(s) to builder
2022-05-12 21:09:56.489 INFO Sending 64 sample(s) to runner
2022-05-12 21:09:56.528 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:10:01.654 INFO Sending 64 sample(s) to builder
2022-05-12 21:10:04.606 INFO Sending 64 sample(s) to runner
2022-05-12 21:11:42.501 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |    960 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7853 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2875 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16312
Total latency (us): 2508.43

2022-05-12 21:11:42.501 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:11:53.171 INFO Sending 64 sample(s) to builder
2022-05-12 21:11:58.892 INFO Sending 64 sample(s) to runner
2022-05-12 21:12:52.223 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7853 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2875 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16376
Total latency (us): 2508.43

2022-05-12 21:13:40.219 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7917 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2875 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16440
Total latency (us): 2508.43

2022-05-12 21:13:40.232 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:13:50.945 INFO Sending 64 sample(s) to builder
2022-05-12 21:13:58.702 INFO Sending 64 sample(s) to runner
2022-05-12 21:15:22.588 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   7981 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2875 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16504
Total latency (us): 2508.43

2022-05-12 21:15:22.588 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:15:27.781 INFO Sending 64 sample(s) to builder
2022-05-12 21:15:31.589 INFO Sending 64 sample(s) to runner
2022-05-12 21:17:14.111 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8045 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2875 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16568
Total latency (us): 2508.43

2022-05-12 21:17:14.111 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:17:19.305 INFO Sending 64 sample(s) to builder
2022-05-12 21:17:22.795 INFO Sending 64 sample(s) to runner
2022-05-12 21:18:53.222 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8109 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2875 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16632
Total latency (us): 2508.43

2022-05-12 21:18:53.222 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:19:01.368 INFO Sending 64 sample(s) to builder
2022-05-12 21:19:05.590 INFO Sending 64 sample(s) to runner
2022-05-12 21:20:23.992 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8173 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2875 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16696
Total latency (us): 2508.43

2022-05-12 21:20:23.992 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:20:29.249 INFO Sending 64 sample(s) to builder
2022-05-12 21:20:32.547 INFO Sending 64 sample(s) to runner
2022-05-12 21:20:32.578 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 21:20:38.007 INFO Sending 64 sample(s) to builder
2022-05-12 21:20:41.818 INFO Sending 64 sample(s) to runner
2022-05-12 21:22:30.196 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8173 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2939 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16760
Total latency (us): 2508.43

2022-05-12 21:22:30.196 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 21:22:35.510 INFO Sending 64 sample(s) to builder
2022-05-12 21:22:45.530 INFO Sending 64 sample(s) to runner
2022-05-12 21:23:08.676 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8237 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   2939 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16824
Total latency (us): 2508.43

2022-05-12 21:23:08.676 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 21:23:47.723 INFO Sending 64 sample(s) to builder
2022-05-12 21:23:53.572 INFO Sending 64 sample(s) to runner
2022-05-12 21:24:16.329 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1152 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8237 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3003 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16888
Total latency (us): 2508.43

2022-05-12 21:24:34.229 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1216 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8237 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3003 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16952
Total latency (us): 2508.43

2022-05-12 21:24:34.229 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 21:25:03.055 INFO Sending 64 sample(s) to builder
2022-05-12 21:25:08.779 INFO Sending 64 sample(s) to runner
2022-05-12 21:25:08.817 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:25:14.030 INFO Sending 64 sample(s) to builder
2022-05-12 21:25:18.038 INFO Sending 64 sample(s) to runner
2022-05-12 21:26:50.467 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1216 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8301 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3003 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17016
Total latency (us): 2508.43

2022-05-12 21:26:50.467 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:26:55.677 INFO Sending 64 sample(s) to builder
2022-05-12 21:27:00.323 INFO Sending 64 sample(s) to runner
2022-05-12 21:27:21.370 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8301 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3003 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17080
Total latency (us): 2508.43

2022-05-12 21:28:18.673 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8365 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3003 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17144
Total latency (us): 2508.43

2022-05-12 21:28:18.673 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:28:23.853 INFO Sending 64 sample(s) to builder
2022-05-12 21:28:27.722 INFO Sending 64 sample(s) to runner
2022-05-12 21:29:58.495 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8429 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3003 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17208
Total latency (us): 2508.43

2022-05-12 21:29:58.495 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:30:07.918 INFO Sending 64 sample(s) to builder
2022-05-12 21:30:12.802 INFO Sending 64 sample(s) to runner
2022-05-12 21:30:12.834 INFO Scheduler picks Task #7: "fused_nn_lrn_1"
2022-05-12 21:30:22.090 INFO Sending 0 sample(s) to builder
2022-05-12 21:30:22.093 INFO Sending 0 sample(s) to runner
2022-05-12 21:30:22.093 INFO [Updated] Task #7: "fused_nn_lrn_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8429 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3003 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17208
Total latency (us): 2508.43

2022-05-12 21:31:34.815 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8493 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3003 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17272
Total latency (us): 2508.43

2022-05-12 21:31:34.815 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:31:39.953 INFO Sending 64 sample(s) to builder
2022-05-12 21:31:43.451 INFO Sending 64 sample(s) to runner
2022-05-12 21:31:43.482 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 21:31:48.857 INFO Sending 64 sample(s) to builder
2022-05-12 21:31:53.009 INFO Sending 64 sample(s) to runner
2022-05-12 21:33:42.238 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8493 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3067 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17336
Total latency (us): 2508.43

2022-05-12 21:33:42.239 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 21:33:47.522 INFO Sending 64 sample(s) to builder
2022-05-12 21:33:50.457 INFO Sending 64 sample(s) to runner
2022-05-12 21:34:14.277 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8557 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3067 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17400
Total latency (us): 2508.43

2022-05-12 21:34:14.278 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:34:19.513 INFO Sending 64 sample(s) to builder
2022-05-12 21:34:22.991 INFO Sending 64 sample(s) to runner
2022-05-12 21:36:17.020 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8621 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3067 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17464
Total latency (us): 2508.43

2022-05-12 21:36:17.020 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:36:23.960 INFO Sending 64 sample(s) to builder
2022-05-12 21:36:27.189 INFO Sending 64 sample(s) to runner
2022-05-12 21:36:44.808 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8621 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3131 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17528
Total latency (us): 2508.43

2022-05-12 21:37:49.140 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2323.5780 |     128.7543 |              128.7543 |    896 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8685 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3131 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17592
Total latency (us): 2508.43

2022-05-12 21:37:49.140 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:37:54.400 INFO Sending 64 sample(s) to builder
2022-05-12 21:37:58.802 INFO Sending 64 sample(s) to runner
2022-05-12 21:37:58.833 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 21:38:17.315 INFO Sending 64 sample(s) to builder
2022-05-12 21:38:26.496 INFO Sending 64 sample(s) to runner
2022-05-12 21:39:43.279 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2504.3268 |     119.4615 |              119.4615 |    960 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8685 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3131 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17656
Total latency (us): 2499.14

2022-05-12 21:39:43.279 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 21:39:58.909 INFO Sending 64 sample(s) to builder
2022-05-12 21:40:04.674 INFO Sending 64 sample(s) to runner
2022-05-12 21:40:23.287 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2504.3268 |     119.4615 |              119.4615 |    960 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8749 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3131 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17720
Total latency (us): 2499.14

2022-05-12 21:40:23.287 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 21:41:05.196 INFO Sending 64 sample(s) to builder
2022-05-12 21:41:17.414 INFO Sending 64 sample(s) to runner
2022-05-12 21:41:46.755 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1099.2035 |     136.1048 |              136.1048 |   1024 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8749 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3131 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17784
Total latency (us): 2496.04

2022-05-12 21:42:07.973 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8749 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3131 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17848
Total latency (us): 2493.09

2022-05-12 21:42:07.973 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:42:13.059 INFO Sending 64 sample(s) to builder
2022-05-12 21:42:18.258 INFO Sending 64 sample(s) to runner
2022-05-12 21:44:04.104 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2255.0018 |     198.7896 |              198.7896 |   1408 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8813 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3131 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17912
Total latency (us): 2493.09

2022-05-12 21:44:04.105 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:44:09.285 INFO Sending 64 sample(s) to builder
2022-05-12 21:44:13.333 INFO Sending 64 sample(s) to runner
2022-05-12 21:44:13.365 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 21:44:42.244 INFO Sending 64 sample(s) to builder
2022-05-12 21:44:51.415 INFO Sending 64 sample(s) to runner
2022-05-12 21:46:03.154 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2261.0558 |     198.2573 |              198.2573 |   1472 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8813 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3131 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17976
Total latency (us): 2492.56

2022-05-12 21:46:03.154 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 21:46:32.740 INFO Sending 64 sample(s) to builder
2022-05-12 21:46:42.347 INFO Sending 64 sample(s) to runner
2022-05-12 21:47:04.146 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2261.0558 |     198.2573 |              198.2573 |   1472 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8877 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3131 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18040
Total latency (us): 2492.56

2022-05-12 21:47:04.147 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 21:47:09.424 INFO Sending 64 sample(s) to builder
2022-05-12 21:47:17.389 INFO Sending 64 sample(s) to runner
2022-05-12 21:47:39.386 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8877 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3131 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18104
Total latency (us): 2490.68

2022-05-12 21:48:28.953 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8877 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3195 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18168
Total latency (us): 2490.68

2022-05-12 21:48:28.953 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 21:48:35.973 INFO Sending 64 sample(s) to builder
2022-05-12 21:48:41.091 INFO Sending 64 sample(s) to runner
2022-05-12 21:48:41.121 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:48:49.571 INFO Sending 64 sample(s) to builder
2022-05-12 21:48:54.164 INFO Sending 64 sample(s) to runner
2022-05-12 21:50:41.683 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8941 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3195 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18232
Total latency (us): 2490.68

2022-05-12 21:50:41.683 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:50:52.335 INFO Sending 64 sample(s) to builder
2022-05-12 21:50:58.881 INFO Sending 64 sample(s) to runner
2022-05-12 21:52:02.638 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   8941 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3259 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18296
Total latency (us): 2490.68

2022-05-12 21:52:40.715 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9005 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3259 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18360
Total latency (us): 2490.68

2022-05-12 21:52:40.715 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:52:46.932 INFO Sending 64 sample(s) to builder
2022-05-12 21:52:55.061 INFO Sending 64 sample(s) to runner
2022-05-12 21:54:18.273 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1280 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9069 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3259 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18424
Total latency (us): 2490.68

2022-05-12 21:54:18.274 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:54:23.509 INFO Sending 63 sample(s) to builder
2022-05-12 21:54:27.606 INFO Sending 63 sample(s) to runner
2022-05-12 21:54:27.637 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 21:55:13.454 INFO Sending 64 sample(s) to builder
2022-05-12 21:55:25.705 INFO Sending 64 sample(s) to runner
2022-05-12 21:56:06.668 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1344 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9069 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3259 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18488
Total latency (us): 2490.68

2022-05-12 21:56:06.669 INFO Scheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_1"
2022-05-12 21:56:35.072 INFO Sending 64 sample(s) to builder
2022-05-12 21:56:44.645 INFO Sending 64 sample(s) to runner
2022-05-12 21:57:07.751 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1344 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9132 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3259 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18551
Total latency (us): 2490.68

2022-05-12 21:57:07.751 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:57:16.702 INFO Sending 63 sample(s) to builder
2022-05-12 21:57:23.914 INFO Sending 63 sample(s) to runner
2022-05-12 21:58:04.711 INFO [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9132 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3259 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18615
Total latency (us): 2490.68

2022-05-12 21:58:43.019 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1123.5200 |     133.1591 |              133.1591 |   1088 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9195 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3259 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18678
Total latency (us): 2490.68

2022-05-12 21:58:43.019 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 21:58:48.335 INFO Sending 64 sample(s) to builder
2022-05-12 21:58:51.829 INFO Sending 64 sample(s) to runner
2022-05-12 21:58:51.860 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 21:59:18.825 INFO Sending 64 sample(s) to builder
2022-05-12 21:59:27.384 INFO Sending 64 sample(s) to runner
2022-05-12 22:00:33.767 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1152 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9195 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3259 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18742
Total latency (us): 2490.18

2022-05-12 22:00:33.767 INFO Scheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_2"
2022-05-12 22:01:00.239 INFO Sending 64 sample(s) to builder
2022-05-12 22:01:08.951 INFO Sending 64 sample(s) to runner
2022-05-12 22:01:27.127 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1152 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9259 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3259 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18806
Total latency (us): 2490.18

2022-05-12 22:01:27.127 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 22:01:32.493 INFO Sending 64 sample(s) to builder
2022-05-12 22:01:44.577 INFO Sending 64 sample(s) to runner
2022-05-12 22:02:20.402 INFO [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_2"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9259 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3259 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18870
Total latency (us): 2490.18

2022-05-12 22:02:46.527 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9259 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3323 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18934
Total latency (us): 2490.18

2022-05-12 22:02:46.527 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 22:02:51.731 INFO Sending 64 sample(s) to builder
2022-05-12 22:03:01.481 INFO Sending 64 sample(s) to runner
2022-05-12 22:03:01.512 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 22:03:06.871 INFO Sending 63 sample(s) to builder
2022-05-12 22:03:10.938 INFO Sending 63 sample(s) to runner
2022-05-12 22:05:25.367 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9322 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3323 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18997
Total latency (us): 2490.18

2022-05-12 22:05:25.367 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 22:05:30.589 INFO Sending 63 sample(s) to builder
2022-05-12 22:05:34.549 INFO Sending 63 sample(s) to runner
2022-05-12 22:05:56.380 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9322 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3387 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19061
Total latency (us): 2490.18

2022-05-12 22:07:06.710 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    576 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9385 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3387 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19124
Total latency (us): 2490.18

2022-05-12 22:07:06.710 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 22:07:16.870 INFO Sending 64 sample(s) to builder
2022-05-12 22:07:22.891 INFO Sending 64 sample(s) to runner
2022-05-12 22:07:22.935 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-12 22:07:37.684 INFO Sending 64 sample(s) to builder
2022-05-12 22:07:44.157 INFO Sending 64 sample(s) to runner
2022-05-12 22:09:04.253 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    640 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9385 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3387 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19188
Total latency (us): 2490.18

2022-05-12 22:09:04.253 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-12 22:09:14.642 INFO Sending 64 sample(s) to builder
2022-05-12 22:09:22.400 INFO Sending 64 sample(s) to runner
2022-05-12 22:09:44.188 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2684.8737 |      75.9043 |               75.9043 |    640 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9449 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3387 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19252
Total latency (us): 2490.18

2022-05-12 22:09:44.189 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 22:10:25.208 INFO Sending 64 sample(s) to builder
2022-05-12 22:10:44.663 INFO Sending 64 sample(s) to runner
2022-05-12 22:11:17.387 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2282.6832 |     196.3789 |              196.3789 |   1536 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9449 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3387 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19316
Total latency (us): 2490

2022-05-12 22:11:37.215 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1600 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9449 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3387 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19380
Total latency (us): 2486.31

2022-05-12 22:11:37.215 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 22:11:42.416 INFO Sending 63 sample(s) to builder
2022-05-12 22:11:45.880 INFO Sending 63 sample(s) to runner
2022-05-12 22:13:36.307 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1600 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9512 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3387 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19443
Total latency (us): 2486.31

2022-05-12 22:13:36.307 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 22:13:42.337 INFO Sending 63 sample(s) to builder
2022-05-12 22:13:45.398 INFO Sending 63 sample(s) to runner
2022-05-12 22:15:10.382 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1600 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9575 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3387 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19506
Total latency (us): 2486.31

2022-05-12 22:15:10.382 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 22:15:20.648 INFO Sending 64 sample(s) to builder
2022-05-12 22:15:42.401 INFO Sending 64 sample(s) to runner
2022-05-12 22:15:42.433 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 22:15:49.018 INFO Sending 64 sample(s) to builder
2022-05-12 22:15:52.142 INFO Sending 64 sample(s) to runner
2022-05-12 22:17:47.056 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1600 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9575 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3451 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19570
Total latency (us): 2486.31

2022-05-12 22:17:47.057 INFO Scheduler picks Task #16: "fused_nn_dense_add_nn_relu_1"
2022-05-12 22:17:58.368 INFO Sending 64 sample(s) to builder
2022-05-12 22:18:06.379 INFO Sending 64 sample(s) to runner
2022-05-12 22:19:11.939 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1600 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9639 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3451 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19634
Total latency (us): 2486.31

2022-05-12 22:19:33.131 INFO [Updated] Task #16: "fused_nn_dense_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1600 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1024 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9639 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3515 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19698
Total latency (us): 2486.31

2022-05-12 22:19:33.131 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 22:19:49.169 INFO Sending 64 sample(s) to builder
2022-05-12 22:19:53.927 INFO Sending 64 sample(s) to runner
2022-05-12 22:20:37.172 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1600 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1088 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9639 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3515 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19762
Total latency (us): 2486.31

2022-05-12 22:20:37.172 INFO Scheduler picks Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-12 22:21:04.145 INFO Sending 64 sample(s) to builder
2022-05-12 22:21:14.455 INFO Sending 64 sample(s) to runner
2022-05-12 22:21:14.538 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 22:21:24.411 INFO Sending 64 sample(s) to builder
2022-05-12 22:21:30.222 INFO Sending 64 sample(s) to runner
2022-05-12 22:23:00.379 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1600 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2571.1331 |     116.3575 |              116.3575 |   1088 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9703 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3515 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19826
Total latency (us): 2486.31

2022-05-12 22:23:00.379 INFO Scheduler picks Task #15: "fused_nn_dense_add_nn_relu"
2022-05-12 22:23:05.657 INFO Sending 64 sample(s) to builder
2022-05-12 22:23:11.687 INFO Sending 64 sample(s) to runner
2022-05-12 22:23:33.915 INFO [Updated] Task #9: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1600 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2579.0980 |     115.9981 |              115.9981 |   1152 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9703 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3515 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19890
Total latency (us): 2485.95

2022-05-12 22:23:33.915 INFO Scheduler picks Task #4: "fused_nn_lrn"
2022-05-12 22:23:42.524 INFO Sending 0 sample(s) to builder
2022-05-12 22:23:42.526 INFO Sending 0 sample(s) to runner
2022-05-12 22:23:42.527 INFO [Updated] Task #4: "fused_nn_lrn"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |            
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |            
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |            
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |            
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |            
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1600 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2579.0980 |     115.9981 |              115.9981 |   1152 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9703 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3515 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19890
Total latency (us): 2485.95

2022-05-12 22:23:42.527 INFO Scheduler picks Task #5: "fused_nn_conv2d_add_nn_relu"
2022-05-12 22:24:22.486 INFO Sending 64 sample(s) to builder
2022-05-12 22:24:48.219 INFO Sending 64 sample(s) to runner
2022-05-12 22:24:48.257 INFO Task #0 has finished. Remaining task(s): 17
2022-05-12 22:24:48.257 INFO Task #1 has finished. Remaining task(s): 16
2022-05-12 22:24:48.257 INFO Task #2 has finished. Remaining task(s): 15
2022-05-12 22:24:48.257 INFO Task #3 has finished. Remaining task(s): 14
2022-05-12 22:24:48.257 INFO Task #4 has finished. Remaining task(s): 13
2022-05-12 22:25:33.597 INFO [Updated] Task #5: "fused_nn_conv2d_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |          Y 
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |          Y 
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |          Y 
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |          Y 
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |          Y 
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1664 |            
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |            
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |            
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |            
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2579.0980 |     115.9981 |              115.9981 |   1152 |            
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |            
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |            
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |            
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |            
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |            
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9703 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3515 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19954
Total latency (us): 2485.95

2022-05-12 22:25:33.597 INFO Task #5 has finished. Remaining task(s): 12
2022-05-12 22:25:33.598 INFO Task #6 has finished. Remaining task(s): 11
2022-05-12 22:25:33.598 INFO Task #7 has finished. Remaining task(s): 10
2022-05-12 22:25:33.598 INFO Task #8 has finished. Remaining task(s): 9
2022-05-12 22:25:33.598 INFO Task #9 has finished. Remaining task(s): 8
2022-05-12 22:25:33.598 INFO Task #10 has finished. Remaining task(s): 7
2022-05-12 22:25:33.598 INFO Task #11 has finished. Remaining task(s): 6
2022-05-12 22:25:33.598 INFO Task #12 has finished. Remaining task(s): 5
2022-05-12 22:25:33.598 INFO Task #13 has finished. Remaining task(s): 4
2022-05-12 22:25:33.599 INFO Task #14 has finished. Remaining task(s): 3
2022-05-12 22:25:58.328 INFO [Updated] Task #15: "fused_nn_dense_add_nn_relu"
 ID |                                        Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-----------------------------------------------------------------------------------------------------------------------------------------------------
  0 |                      fused_layout_transform |         1 |      1 |         0.0003 |       3.1586 |                3.1586 |      8 |          Y 
  1 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu | 203793408 |      1 |      2691.4088 |      75.7200 |               75.7200 |    704 |          Y 
  2 |                         fused_nn_max_pool2d |    629856 |      1 |       160.9408 |       3.9136 |                3.9136 |     60 |          Y 
  3 |                    fused_layout_transform_1 |         1 |      1 |         0.0002 |       5.1626 |                5.1626 |      8 |          Y 
  4 |                                fused_nn_lrn |    979776 |      1 |        23.7784 |      41.2045 |               41.2045 |    148 |          Y 
  5 |                 fused_nn_conv2d_add_nn_relu | 448270848 |      1 |      2326.4455 |     192.6849 |              192.6849 |   1664 |          Y 
  6 |                       fused_nn_max_pool2d_1 |    389376 |      1 |        91.5087 |       4.2551 |                4.2551 |     36 |          Y 
  7 |                              fused_nn_lrn_1 |    605696 |      1 |        21.2927 |      28.4462 |               28.4462 |    148 |          Y 
  8 |                    fused_layout_transform_2 |         1 |      1 |         0.0004 |       2.8353 |                2.8353 |     12 |          Y 
  9 | fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 299170560 |      1 |      2579.0980 |     115.9981 |              115.9981 |   1152 |          Y 
 10 |                    fused_layout_transform_3 |         1 |      1 |         0.0003 |       3.2017 |                3.2017 |      4 |          Y 
 11 |               fused_nn_conv2d_add_nn_relu_1 | 224410368 |      1 |      1274.8396 |     176.0303 |              176.0303 |   1408 |          Y 
 12 |               fused_nn_conv2d_add_nn_relu_2 | 149606912 |      1 |      1127.7058 |     132.6648 |              132.6648 |   1216 |          Y 
 13 |                       fused_nn_max_pool2d_2 |     82944 |      1 |        28.2155 |       2.9397 |                2.9397 |     36 |          Y 
 14 |                               fused_reshape |         1 |      1 |         0.0004 |       2.6116 |                2.6116 |      4 |          Y 
 15 |                  fused_nn_dense_add_nn_relu |  75505664 |      1 |        60.5624 |    1246.7416 |             1246.7416 |   9767 |            
 16 |                fused_nn_dense_add_nn_relu_1 |  33562624 |      1 |        76.1034 |     441.0135 |              441.0135 |   3515 |            
 17 |                          fused_nn_dense_add |   1638600 |      1 |       222.4805 |       7.3651 |                7.3651 |    128 |            
-----------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 20018
Total latency (us): 2485.95

2022-05-12 22:25:58.328 INFO Task #15 has finished. Remaining task(s): 2
2022-05-12 22:25:58.328 INFO Task #16 has finished. Remaining task(s): 1
2022-05-12 22:25:58.328 INFO Task #17 has finished. Remaining task(s): 0
2022-05-12 22:25:59.090 INFO Saved XGBModel to /home/ubuntu/tvm/logs/perf/llvm/rcnn-ilsvrc13//ms_rcnn-ilsvrc13_2022-05-12_14:36:05/cost_model.xgb
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 3, 224, 224), "float32"], T_layout_trans: T.Buffer[(1, 1, 224, 224, 3), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4 in T.grid(1, 1, 224, 224, 3):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[0, ax4, ax2, ax3])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                T_layout_trans[ax0, ax1, ax2, ax3, ax4] = placeholder[0, ax4, ax2, ax3]
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_layout_transform(placeholder: T.Buffer[(1, 3, 224, 224), "float32"], T_layout_trans: T.Buffer[(1, 1, 224, 224, 3), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(224, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i3, i4 in T.grid(224, 3):
                with T.block("T_layout_trans"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(1, 0)
                    ax2, ax3, ax4 = T.axis.remap("SSS", [i0_i1_i2_fused, i3, i4])
                    T.reads(placeholder[0, ax4, ax2, ax3])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                    T_layout_trans[ax0, ax1, ax2, ax3, ax4] = placeholder[0, ax4, ax2, ax3]
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7, l8 = sch.get_loops(block=b3)", "l9 = sch.fuse(l4, l5, l6)", "sch.parallel(loop=l9)", "sch.annotate(block_or_loop=l9, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l9, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 224, 224, 3), "float32"], placeholder_1: T.Buffer[(6, 1, 11, 11, 3, 16), "float32"], placeholder_2: T.Buffer[(1, 6, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 6, 54, 54, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 6, 54, 54, 16], dtype="float32")
        T_add = T.alloc_buffer([1, 6, 54, 54, 16], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 6, 54, 54, 16, 3, 11, 11):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[0, 0, oh * 4 + kh, ow * 4 + kw, ic], placeholder_1[oc_chunk, 0, kh, kw, ic, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 224, 224, 3], "float32"], ["TENSOR", [6, 1, 11, 11, 3, 16], "float32"], [4, 4], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW16c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[0, 0, oh * 4 + kh, ow * 4 + kw, ic] * placeholder_1[oc_chunk, 0, kh, kw, ic, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 6, 54, 54, 16):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[0, ax1, ax2, ax3, ax4], placeholder_2[0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[0, ax1, ax2, ax3, ax4] + placeholder_2[0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 6, 54, 54, 16):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[0, ax1, ax2, ax3, ax4])
                T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(T_add[0, ax1, ax2, ax3, ax4], T.float32(0))
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu(placeholder: T.Buffer[(1, 1, 224, 224, 3), "float32"], placeholder_1: T.Buffer[(6, 1, 11, 11, 3, 16), "float32"], placeholder_2: T.Buffer[(1, 6, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 6, 54, 54, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 6, 54, 54, 16], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(108, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 1, 1, 1):
                for i3_2_init, i2_3_init, i3_3_init in T.grid(18, 3, 3):
                    for i4_3_fused_init in T.vectorized(16):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 18)
                            oh = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 18 * 3 + i2_3_init)
                            ow = T.axis.spatial(54, i3_2_init * 3 + i3_3_init)
                            oc_block = T.axis.spatial(16, i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 224, 224, 3], "float32"], ["TENSOR", [6, 1, 11, 11, 3, 16], "float32"], [4, 4], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(3, 11, 1, 1, 1, 1, 18, 1, 1, 1, 11, 1, 1, 3, 3):
                    for i4_3_fused in T.vectorized(16):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 18)
                            oh = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 18 * 3 + i2_3)
                            ow = T.axis.spatial(54, i3_2 * 3 + i3_3)
                            oc_block, ic, kh, kw = T.axis.remap("SRRR", [i4_3_fused, i5_0, i6_0, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[0, 0, oh * 4 + kh, ow * 4 + kw, ic], placeholder_1[oc_chunk, 0, kh, kw, ic, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 224, 224, 3], "float32"], ["TENSOR", [6, 1, 11, 11, 3, 16], "float32"], [4, 4], [0, 0, 0, 0], [1, 1], "NCHW3c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[0, 0, oh * 4 + kh, ow * 4 + kw, ic] * placeholder_1[oc_chunk, 0, kh, kw, ic, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 1, 3, 54):
                for ax4_fused in T.vectorized(16):
                    with T.block("T_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(6, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 18)
                        ax2_1 = T.axis.spatial(54, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 18 * 3 + ax2)
                        ax3_1, ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[0, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[0, ax1_1, 0, 0, ax4])
                        T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.max(conv2d_NCHWc[0, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[0, ax1_1, 0, 0, ax4], T.float32(0))
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[6, 1, 1, 1])", "l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[18, 1, 1, 3])", "l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 18, 3])", "l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])", "v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])", "l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])", "v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])", "l53, l54 = sch.split(loop=l8, factors=[v51, v52])", "v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[11, 1])", "l57, l58 = sch.split(loop=l9, factors=[v55, v56])", "v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 11])", "l61, l62 = sch.split(loop=l10, factors=[v59, v60])", "sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)", "b63, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v64)", "sch.enter_postproc()", "b65 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.unroll_explicit\")", "b66, b67 = sch.get_child_blocks(b65)", "l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)", "l94 = sch.fuse(l68, l69, l70, l71, l72)", "sch.parallel(loop=l94)", "l95 = sch.fuse(l93)", "sch.vectorize(loop=l95)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)", "l102 = sch.fuse(l101)", "sch.vectorize(loop=l102)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b103 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b103)", "b126 = sch.decompose_reduction(block=b103, loop=l110)"]
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 6, 54, 54, 16), "float32"], tensor: T.Buffer[(1, 6, 27, 27, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 6, 56, 56, 16], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 6, 56, 56, 16):
            with T.block("pad_temp"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[0, ax1, ax2, ax3, ax4])
                T.writes(pad_temp[ax0, ax1, ax2, ax3, ax4])
                pad_temp[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax2 < 54 and ax3 < 54, placeholder[0, ax1, ax2, ax3, ax4], T.float32(-3.4028234663852886e+38), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 6, 27, 27, 16, 3, 3):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_max_pool2d(placeholder: T.Buffer[(1, 6, 54, 54, 16), "float32"], tensor: T.Buffer[(1, 6, 27, 27, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 6, 56, 56, 16], dtype="float32")
        for i0_i1_i2_fused in T.parallel(162, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i3, i4 in T.grid(27, 16):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 1, 3, 3, 1):
                    with T.block("pad_temp"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(6, i0_i1_i2_fused % 162 // 27 + ax1)
                        ax2_1 = T.axis.spatial(56, i0_i1_i2_fused % 27 * 2 + ax2)
                        ax3_1 = T.axis.spatial(56, i3 * 2 + ax3)
                        ax4_1 = T.axis.spatial(16, i4 + ax4)
                        T.reads(placeholder[0, ax1_1, ax2_1, ax3_1, ax4_1])
                        T.writes(pad_temp[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1])
                        pad_temp[ax0_1, ax1_1, ax2_1, ax3_1, ax4_1] = T.if_then_else(ax2_1 < 54 and ax3_1 < 54, placeholder[0, ax1_1, ax2_1, ax3_1, ax4_1], T.float32(-3.4028234663852886e+38), dtype="float32")
                with T.block("tensor_init"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(6, i0_i1_i2_fused // 27)
                    ax2 = T.axis.spatial(27, i0_i1_i2_fused % 27)
                    ax3, ax4 = T.axis.remap("SS", [i3, i4])
                    T.reads()
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                for i5, i6 in T.grid(3, 3):
                    with T.block("tensor_update"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(6, i0_i1_i2_fused // 27)
                        ax2 = T.axis.spatial(27, i0_i1_i2_fused % 27)
                        ax3, ax4, rv0, rv1 = T.axis.remap("SSRR", [i3, i4, i5, i6])
                        T.reads(tensor[ax0, ax1, ax2, ax3, ax4], pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                        T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=6)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v2 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v2)", "l3 = sch.sample_compute_location(block=b0, decision=4)", "sch.compute_at(block=b0, loop=l3, preserve_unit_loops=True)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, b6 = sch.get_child_blocks(b4)", "l7, l8, l9, l10, l11, l12, l13, l14, l15, l16 = sch.get_loops(block=b5)", "l17 = sch.fuse(l7, l8, l9)", "sch.parallel(loop=l17)", "sch.annotate(block_or_loop=l17, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l17, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l18, l19, l20, l21, l22 = sch.get_loops(block=b6)", "sch.annotate(block_or_loop=l18, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l18, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b23 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l24, l25, l26, l27, l28 = sch.get_loops(block=b23)", "b29 = sch.decompose_reduction(block=b23, loop=l27)"]
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 6, 27, 27, 16), "float32"], T_layout_trans: T.Buffer[(1, 96, 27, 27), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(1, 96, 27, 27):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, ax1 // 16, ax2, ax3, ax1 % 16])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                T_layout_trans[ax0, ax1, ax2, ax3] = placeholder[0, ax1 // 16, ax2, ax3, ax1 % 16]
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_layout_transform_1(placeholder: T.Buffer[(1, 6, 27, 27, 16), "float32"], T_layout_trans: T.Buffer[(1, 96, 27, 27), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(2592, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i3 in T.serial(27):
                with T.block("T_layout_trans"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(96, i0_i1_i2_fused // 27)
                    ax2 = T.axis.spatial(27, i0_i1_i2_fused % 27)
                    ax3 = T.axis.spatial(27, i3)
                    T.reads(placeholder[0, ax1 // 16, ax2, ax3, ax1 % 16])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                    T_layout_trans[ax0, ax1, ax2, ax3] = placeholder[0, ax1 // 16, ax2, ax3, ax1 % 16]
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7 = sch.get_loops(block=b3)", "l8 = sch.fuse(l4, l5, l6)", "sch.parallel(loop=l8)", "sch.annotate(block_or_loop=l8, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l8, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 96, 27, 27), "float32"], T_divide: T.Buffer[(1, 96, 27, 27), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_data = T.alloc_buffer([1, 100, 27, 27], dtype="float32")
        tensor = T.alloc_buffer([1, 96, 27, 27], dtype="float32")
        tensor_1 = T.alloc_buffer([1, 96, 27, 27], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 100, 27, 27):
            with T.block("pad_data"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, ax1 - 2, ax2, ax3])
                T.writes(pad_data[ax0, ax1, ax2, ax3])
                pad_data[ax0, ax1, ax2, ax3] = T.if_then_else(2 <= ax1 and ax1 < 98, placeholder[0, ax1 - 2, ax2, ax3], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 96, 27, 27, 5):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, rxs = T.axis.remap("SSSSR", [i0, i1, i2, i3, i4])
                T.reads(pad_data[0, ax1 + rxs, ax2, ax3])
                T.writes(tensor[ax0, ax1, ax2, ax3])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3] = T.float32(0)
                tensor[ax0, ax1, ax2, ax3] = tensor[ax0, ax1, ax2, ax3] + pad_data[0, ax1 + rxs, ax2, ax3] * pad_data[0, ax1 + rxs, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 96, 27, 27):
            with T.block("tensor_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(tensor[0, ax1, ax2, ax3])
                T.writes(tensor_1[ax0, ax1, ax2, ax3])
                tensor_1[ax0, ax1, ax2, ax3] = T.pow(T.float32(1) + T.float32(9.9999997473787516e-05) * tensor[0, ax1, ax2, ax3] * T.float32(0.20000000000000001), T.float32(0.75), dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 96, 27, 27):
            with T.block("T_divide"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, ax1, ax2, ax3], tensor_1[0, ax1, ax2, ax3])
                T.writes(T_divide[ax0, ax1, ax2, ax3])
                T_divide[ax0, ax1, ax2, ax3] = placeholder[0, ax1, ax2, ax3] / tensor_1[0, ax1, ax2, ax3]
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_lrn(placeholder: T.Buffer[(1, 96, 27, 27), "float32"], T_divide: T.Buffer[(1, 96, 27, 27), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_data = T.alloc_buffer([1, 100, 27, 27], dtype="float32")
        tensor = T.alloc_buffer([1, 96, 27, 27], dtype="float32")
        for i0_i1_i2_fused in T.parallel(2592, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i3 in T.serial(27):
                for ax0, ax1, ax2, ax3 in T.grid(1, 5, 1, 1):
                    with T.block("pad_data"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(100, i0_i1_i2_fused % 2592 // 27 + ax1)
                        ax2_1 = T.axis.spatial(27, i0_i1_i2_fused % 27 + ax2)
                        ax3_1 = T.axis.spatial(27, i3 + ax3)
                        T.reads(placeholder[0, ax1_1 - 2, ax2_1, ax3_1])
                        T.writes(pad_data[ax0_1, ax1_1, ax2_1, ax3_1])
                        pad_data[ax0_1, ax1_1, ax2_1, ax3_1] = T.if_then_else(2 <= ax1_1 and ax1_1 < 98, placeholder[0, ax1_1 - 2, ax2_1, ax3_1], T.float32(0), dtype="float32")
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 1):
                    with T.block("tensor_init"):
                        ax0_2 = T.axis.spatial(1, 0)
                        ax1_2 = T.axis.spatial(96, i0_i1_i2_fused // 27)
                        ax2_2 = T.axis.spatial(27, i0_i1_i2_fused % 27)
                        ax3_2 = T.axis.spatial(27, i3)
                        T.reads()
                        T.writes(tensor[ax0_2, ax1_2, ax2_2, ax3_2])
                        tensor[ax0_2, ax1_2, ax2_2, ax3_2] = T.float32(0)
                    for ax4 in T.serial(5):
                        with T.block("tensor_update"):
                            ax0_3 = T.axis.spatial(1, 0)
                            ax1_3 = T.axis.spatial(96, i0_i1_i2_fused // 27)
                            ax2_3 = T.axis.spatial(27, i0_i1_i2_fused % 27)
                            ax3_3, rxs = T.axis.remap("SR", [i3, ax4])
                            T.reads(tensor[ax0_3, ax1_3, ax2_3, ax3_3], pad_data[0, ax1_3 + rxs, ax2_3, ax3_3])
                            T.writes(tensor[ax0_3, ax1_3, ax2_3, ax3_3])
                            tensor[ax0_3, ax1_3, ax2_3, ax3_3] = tensor[ax0_3, ax1_3, ax2_3, ax3_3] + pad_data[0, ax1_3 + rxs, ax2_3, ax3_3] * pad_data[0, ax1_3 + rxs, ax2_3, ax3_3]
                with T.block("T_divide"):
                    ax0_4 = T.axis.spatial(1, 0)
                    ax1_4 = T.axis.spatial(96, i0_i1_i2_fused // 27)
                    ax2_4 = T.axis.spatial(27, i0_i1_i2_fused % 27)
                    ax3_4 = T.axis.spatial(27, i3)
                    T.reads(placeholder[0, ax1_4, ax2_4, ax3_4], tensor[0, ax1_4, ax2_4, ax3_4])
                    T.writes(T_divide[ax0_4, ax1_4, ax2_4, ax3_4])
                    T_divide[ax0_4, ax1_4, ax2_4, ax3_4] = placeholder[0, ax1_4, ax2_4, ax3_4] / T.pow(T.float32(1) + T.float32(9.9999997473787516e-05) * tensor[0, ax1_4, ax2_4, ax3_4] * T.float32(0.20000000000000001), T.float32(0.75), dtype="float32")
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_data\", func_name=\"main\")", "b1 = sch.get_block(name=\"tensor\", func_name=\"main\")", "b2 = sch.get_block(name=\"tensor_1\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v4 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v4)", "l5 = sch.sample_compute_location(block=b1, decision=3)", "sch.compute_at(block=b1, loop=l5, preserve_unit_loops=True)", "l6 = sch.sample_compute_location(block=b0, decision=3)", "sch.compute_at(block=b0, loop=l6, preserve_unit_loops=True)", "sch.enter_postproc()", "b7 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b7, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b7, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b7, ann_key=\"meta_schedule.unroll_explicit\")", "b8, b9, b10 = sch.get_child_blocks(b7)", "l11, l12, l13, l14, l15, l16, l17, l18 = sch.get_loops(block=b8)", "l19 = sch.fuse(l11, l12, l13)", "sch.parallel(loop=l19)", "sch.annotate(block_or_loop=l19, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l19, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b9)", "sch.annotate(block_or_loop=l20, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l20, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l27, l28 = sch.get_loops(block=b10)", "sch.annotate(block_or_loop=l27, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l27, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b29 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l30, l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b29)", "b37 = sch.decompose_reduction(block=b29, loop=l36)"]
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 96, 27, 27), "float32"], placeholder_1: T.Buffer[(256, 48, 5, 5), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_relu: T.Buffer[(1, 256, 27, 27), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 96, 31, 31], dtype="float32")
        data_vec = T.alloc_buffer([2, 1, 3, 31, 16, 31], dtype="float32")
        kernel_vec = T.alloc_buffer([2, 8, 3, 5, 5, 16, 16], dtype="float32")
        conv = T.alloc_buffer([2, 1, 8, 27, 27, 16], dtype="float32")
        output_unpack = T.alloc_buffer([1, 256, 27, 27], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 27, 27], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 96, 31, 31):
            with T.block("data_pad"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1 - 2, i3_1 - 2])
                T.writes(data_pad[i0_1, i1_1, i2_1, i3_1])
                data_pad[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(2 <= i2_1 and i2_1 < 29 and 2 <= i3_1 and i3_1 < 29, placeholder[0, i1_1, i2_1 - 2, i3_1 - 2], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5 in T.grid(2, 1, 3, 31, 16, 31):
            with T.block("data_vec"):
                g, n, C, h, c, w = T.axis.remap("SSSSSS", [i0, i1, i2, i3, i4, i5])
                T.reads(data_pad[0, g * 48 + C * 16 + c, h, w])
                T.writes(data_vec[g, n, C, h, c, w])
                data_vec[g, n, C, h, c, w] = data_pad[0, g * 48 + C * 16 + c, h, w]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(2, 8, 3, 5, 5, 16, 16):
            with T.block("kernel_vec"):
                g, out_channel, in_channel, h, w, ci, co = T.axis.remap("SSSSSSS", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder_1[g * 128 + out_channel * 16 + co, in_channel * 16 + ci, h, w])
                T.writes(kernel_vec[g, out_channel, in_channel, h, w, ci, co])
                kernel_vec[g, out_channel, in_channel, h, w, ci, co] = placeholder_1[g * 128 + out_channel * 16 + co, in_channel * 16 + ci, h, w]
        for i0, i1, i2, i3, i4, i5, i6, i7, i8 in T.grid(2, 1, 8, 27, 27, 16, 48, 5, 5):
            with T.block("conv"):
                g, n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7, i8])
                T.reads(data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw], kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                T.writes(conv[g, n, oc_chunk, oh, ow, oc_block])
                with T.init():
                    conv[g, n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv[g, n, oc_chunk, oh, ow, oc_block] = conv[g, n, oc_chunk, oh, ow, oc_block] + data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw] * kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
        for i0, i1, i2, i3 in T.grid(1, 256, 27, 27):
            with T.block("output_unpack"):
                n, c, h, w = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv[c // 128, 0, c % 128 // 16, h, w, c % 16])
                T.writes(output_unpack[n, c, h, w])
                T.block_attr({"workload":["group_conv2d_nchw.x86", ["TENSOR", [1, 96, 27, 27], "float32"], ["TENSOR", [256, 48, 5, 5], "float32"], [1, 1], [2, 2, 2, 2], [1, 1], 2, "float32"]})
                output_unpack[n, c, h, w] = conv[c // 128, 0, c % 128 // 16, h, w, c % 16]
        for i0, i1, i2, i3 in T.grid(1, 256, 27, 27):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(output_unpack[0, ax1, ax2, ax3], placeholder_2[0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = output_unpack[0, ax1, ax2, ax3] + placeholder_2[0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 256, 27, 27):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu(placeholder: T.Buffer[(1, 96, 27, 27), "float32"], placeholder_1: T.Buffer[(256, 48, 5, 5), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_relu: T.Buffer[(1, 256, 27, 27), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 96, 31, 31], dtype="float32")
        data_vec = T.alloc_buffer([2, 1, 3, 31, 16, 31], dtype="float32")
        kernel_vec = T.alloc_buffer([2, 8, 3, 5, 5, 16, 16], dtype="float32")
        conv = T.alloc_buffer([2, 1, 8, 27, 27, 16], dtype="float32")
        output_unpack = T.alloc_buffer([1, 256, 27, 27], dtype="float32")
        conv_global = T.alloc_buffer([2, 1, 8, 27, 27, 16], dtype="float32")
        for i0_i1_i2_i3_fused in T.parallel(186, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4, i5 in T.grid(16, 31):
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 1):
                    with T.block("data_pad"):
                        i0 = T.axis.spatial(1, 0)
                        i1 = T.axis.spatial(96, i0_i1_i2_i3_fused // 93 * 48 + i0_i1_i2_i3_fused % 93 // 31 * 16 + i4)
                        i2 = T.axis.spatial(31, i0_i1_i2_i3_fused % 31)
                        i3 = T.axis.spatial(31, i5)
                        T.reads(placeholder[0, i1, i2 - 2, i3 - 2])
                        T.writes(data_pad[i0, i1, i2, i3])
                        data_pad[i0, i1, i2, i3] = T.if_then_else(2 <= i2 and i2 < 29 and 2 <= i3 and i3 < 29, placeholder[0, i1, i2 - 2, i3 - 2], T.float32(0), dtype="float32")
                with T.block("data_vec"):
                    g = T.axis.spatial(2, i0_i1_i2_i3_fused // 93)
                    n = T.axis.spatial(1, 0)
                    C = T.axis.spatial(3, i0_i1_i2_i3_fused % 93 // 31)
                    h = T.axis.spatial(31, i0_i1_i2_i3_fused % 31)
                    c, w = T.axis.remap("SS", [i4, i5])
                    T.reads(data_pad[0, g * 48 + C * 16 + c, h, w])
                    T.writes(data_vec[g, n, C, h, c, w])
                    data_vec[g, n, C, h, c, w] = data_pad[0, g * 48 + C * 16 + c, h, w]
        for i0_i1_i2_i3_fused in T.parallel(240, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4, i5, i6 in T.grid(5, 16, 16):
                with T.block("kernel_vec"):
                    g = T.axis.spatial(2, i0_i1_i2_i3_fused // 120)
                    out_channel = T.axis.spatial(8, i0_i1_i2_i3_fused % 120 // 15)
                    in_channel = T.axis.spatial(3, i0_i1_i2_i3_fused % 15 // 5)
                    h = T.axis.spatial(5, i0_i1_i2_i3_fused % 5)
                    w, ci, co = T.axis.remap("SSS", [i4, i5, i6])
                    T.reads(placeholder_1[g * 128 + out_channel * 16 + co, in_channel * 16 + ci, h, w])
                    T.writes(kernel_vec[g, out_channel, in_channel, h, w, ci, co])
                    kernel_vec[g, out_channel, in_channel, h, w, ci, co] = placeholder_1[g * 128 + out_channel * 16 + co, in_channel * 16 + ci, h, w]
        for i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(216, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_1, i5_1 in T.grid(3, 1):
                for i2_3_init, i4_3_init in T.grid(2, 9):
                    for i5_3_fused_init in T.vectorized(16):
                        with T.block("conv_init"):
                            g = T.axis.spatial(2, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_i1_1_i2_1_i3_1_fused % 54 // 27)
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_i1_1_i2_1_i3_1_fused // 54 * 2 + i2_3_init)
                            oh = T.axis.spatial(27, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_i1_1_i2_1_i3_1_fused % 27)
                            ow = T.axis.spatial(27, i4_1 * 9 + i4_3_init)
                            oc_block = T.axis.spatial(16, i5_3_fused_init)
                            T.reads()
                            T.writes(conv_global[g, n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv_global[g, n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i6_0, i7_0, i8_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_2, i6_1, i7_1, i8_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(3, 5, 1, 1, 1, 1, 1, 1, 1, 16, 1, 5, 1, 1, 2, 1, 9):
                    for i5_3_fused in T.vectorized(16):
                        with T.block("conv_update"):
                            g = T.axis.spatial(2, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_i1_1_i2_1_i3_1_fused % 54 // 27)
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_i1_1_i2_1_i3_1_fused // 54 * 2 + i2_3)
                            oh = T.axis.spatial(27, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_i1_1_i2_1_i3_1_fused % 27)
                            ow = T.axis.spatial(27, i4_1 * 9 + i4_3)
                            oc_block = T.axis.spatial(16, i5_3_fused)
                            ic = T.axis.reduce(48, i6_0 * 16 + i6_1)
                            kh, kw = T.axis.remap("RR", [i7_0, i8_1])
                            T.reads(conv_global[g, n, oc_chunk, oh, ow, oc_block], data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw], kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                            T.writes(conv_global[g, n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv_global[g, n, oc_chunk, oh, ow, oc_block] = conv_global[g, n, oc_chunk, oh, ow, oc_block] + data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw] * kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 1, 2, 1, 9):
                    for ax5_fused in T.vectorized(16):
                        with T.block("conv_global"):
                            v0 = T.axis.spatial(2, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_i1_1_i2_1_i3_1_fused % 54 // 27)
                            v1 = T.axis.spatial(1, 0)
                            v2 = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_i1_1_i2_1_i3_1_fused // 54 * 2 + ax2)
                            v3 = T.axis.spatial(27, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_i1_1_i2_1_i3_1_fused % 27)
                            v4 = T.axis.spatial(27, i4_1 * 9 + ax4)
                            v5 = T.axis.spatial(16, ax5_fused)
                            T.reads(conv_global[v0, v1, v2, v3, v4, v5])
                            T.writes(conv[v0, v1, v2, v3, v4, v5])
                            conv[v0, v1, v2, v3, v4, v5] = conv_global[v0, v1, v2, v3, v4, v5]
        for i0_i1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2 in T.serial(27):
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 27):
                    with T.block("output_unpack"):
                        n = T.axis.spatial(1, 0)
                        c, h, w = T.axis.remap("SSS", [i0_i1_fused, i2, ax3])
                        T.reads(conv[c // 128, 0, c % 128 // 16, h, w, c % 16])
                        T.writes(output_unpack[n, c, h, w])
                        T.block_attr({"workload":["group_conv2d_nchw.x86", ["TENSOR", [1, 96, 27, 27], "float32"], ["TENSOR", [256, 48, 5, 5], "float32"], [1, 1], [2, 2, 2, 2], [1, 1], 2, "float32"]})
                        output_unpack[n, c, h, w] = conv[c // 128, 0, c % 128 // 16, h, w, c % 16]
                for i3_fused in T.vectorized(27):
                    with T.block("T_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3 = T.axis.remap("SSS", [i0_i1_fused, i2, i3_fused])
                        T.reads(output_unpack[0, ax1, ax2, ax3], placeholder_2[0, ax1, 0, 0])
                        T.writes(T_relu[ax0, ax1, ax2, ax3])
                        T_relu[ax0, ax1, ax2, ax3] = T.max(output_unpack[0, ax1, ax2, ax3] + placeholder_2[0, ax1, 0, 0], T.float32(0))
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"data_pad\", func_name=\"main\")", "b1 = sch.get_block(name=\"data_vec\", func_name=\"main\")", "b2 = sch.get_block(name=\"kernel_vec\", func_name=\"main\")", "b3 = sch.get_block(name=\"conv\", func_name=\"main\")", "b4 = sch.get_block(name=\"output_unpack\", func_name=\"main\")", "b5 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b6 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b5)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l7, l8, l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b3)", "v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])", "l20, l21, l22, l23 = sch.split(loop=l7, factors=[v16, v17, v18, v19])", "v24, v25, v26, v27 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l28, l29, l30, l31 = sch.split(loop=l8, factors=[v24, v25, v26, v27])", "v32, v33, v34, v35 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 1, 1, 2])", "l36, l37, l38, l39 = sch.split(loop=l9, factors=[v32, v33, v34, v35])", "v40, v41, v42, v43 = sch.sample_perfect_tile(loop=l10, n=4, max_innermost_factor=64, decision=[1, 27, 1, 1])", "l44, l45, l46, l47 = sch.split(loop=l10, factors=[v40, v41, v42, v43])", "v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l11, n=4, max_innermost_factor=64, decision=[1, 3, 1, 9])", "l52, l53, l54, l55 = sch.split(loop=l11, factors=[v48, v49, v50, v51])", "v56, v57, v58, v59 = sch.sample_perfect_tile(loop=l12, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])", "l60, l61, l62, l63 = sch.split(loop=l12, factors=[v56, v57, v58, v59])", "v64, v65 = sch.sample_perfect_tile(loop=l13, n=2, max_innermost_factor=64, decision=[3, 16])", "l66, l67 = sch.split(loop=l13, factors=[v64, v65])", "v68, v69 = sch.sample_perfect_tile(loop=l14, n=2, max_innermost_factor=64, decision=[5, 1])", "l70, l71 = sch.split(loop=l14, factors=[v68, v69])", "v72, v73 = sch.sample_perfect_tile(loop=l15, n=2, max_innermost_factor=64, decision=[1, 5])", "l74, l75 = sch.split(loop=l15, factors=[v72, v73])", "sch.reorder(l20, l28, l36, l44, l52, l60, l21, l29, l37, l45, l53, l61, l66, l70, l74, l22, l30, l38, l46, l54, l62, l67, l71, l75, l23, l31, l39, l47, l55, l63)", "b76 = sch.cache_write(block=b3, write_buffer_index=0, storage_scope=\"global\")", "sch.reverse_compute_at(block=b76, loop=l61, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b6, ann_key=\"meta_schedule.parallel\", ann_val=48)", "sch.annotate(block_or_loop=b6, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v77 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b6, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v77)", "l78 = sch.sample_compute_location(block=b4, decision=2)", "sch.compute_at(block=b4, loop=l78, preserve_unit_loops=True)", "l79 = sch.sample_compute_location(block=b2, decision=-1)", "sch.compute_at(block=b2, loop=l79, preserve_unit_loops=True)", "l80 = sch.sample_compute_location(block=b1, decision=-1)", "sch.compute_at(block=b1, loop=l80, preserve_unit_loops=True)", "l81 = sch.sample_compute_location(block=b0, decision=5)", "sch.compute_at(block=b0, loop=l81, preserve_unit_loops=True)", "sch.enter_postproc()", "b82 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b82, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b82, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b82, ann_key=\"meta_schedule.unroll_explicit\")", "b83, b84, b85, b86, b87, b88, b89 = sch.get_child_blocks(b82)", "l90, l91, l92, l93, l94, l95, l96, l97, l98, l99 = sch.get_loops(block=b83)", "l100 = sch.fuse(l90, l91, l92, l93)", "sch.parallel(loop=l100)", "sch.annotate(block_or_loop=l100, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l100, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l101, l102, l103 = sch.get_loops(block=b84)", "sch.annotate(block_or_loop=l101, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l101, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b85)", "l111 = sch.fuse(l104, l105, l106, l107)", "sch.parallel(loop=l111)", "sch.annotate(block_or_loop=l111, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l111, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b86)", "l142 = sch.fuse(l112, l113, l114, l115, l116, l117, l118, l119, l120, l121)", "sch.parallel(loop=l142)", "l143 = sch.fuse(l141)", "sch.vectorize(loop=l143)", "sch.annotate(block_or_loop=l142, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l142, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l144, l145, l146, l147, l148, l149, l150, l151, l152 = sch.get_loops(block=b87)", "l153 = sch.fuse(l152)", "sch.vectorize(loop=l153)", "sch.annotate(block_or_loop=l144, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l144, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l154, l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b88)", "l161 = sch.fuse(l154, l155)", "sch.parallel(loop=l161)", "sch.annotate(block_or_loop=l161, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l161, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l162, l163, l164 = sch.get_loops(block=b89)", "l165 = sch.fuse(l164)", "sch.vectorize(loop=l165)", "sch.annotate(block_or_loop=l162, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l162, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b166 = sch.get_block(name=\"conv\", func_name=\"main\")", "l167, l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b166)", "b188 = sch.decompose_reduction(block=b166, loop=l170)"]
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 27, 27), "float32"], tensor: T.Buffer[(1, 256, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 28, 28], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 28, 28):
            with T.block("pad_temp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, ax1, ax2, ax3])
                T.writes(pad_temp[ax0, ax1, ax2, ax3])
                pad_temp[ax0, ax1, ax2, ax3] = T.if_then_else(ax2 < 27 and ax3 < 27, placeholder[0, ax1, ax2, ax3], T.float32(-3.4028234663852886e+38), dtype="float32")
        for i0, i1, i2, i3, i4, i5 in T.grid(1, 256, 13, 13, 3, 3):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                T.reads(pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1])
                T.writes(tensor[ax0, ax1, ax2, ax3])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1])
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_max_pool2d_1(placeholder: T.Buffer[(1, 256, 27, 27), "float32"], tensor: T.Buffer[(1, 256, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 28, 28], dtype="float32")
        for i0_i1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2 in T.serial(13):
                for ax0, ax1, ax2 in T.grid(1, 1, 3):
                    for ax3_fused in T.vectorized(27):
                        with T.block("pad_temp"):
                            ax0_1 = T.axis.spatial(1, ax0)
                            ax1_1 = T.axis.spatial(256, i0_i1_fused % 256 + ax1)
                            ax2_1 = T.axis.spatial(28, i2 * 2 + ax2)
                            ax3 = T.axis.spatial(28, ax3_fused)
                            T.reads(placeholder[0, ax1_1, ax2_1, ax3])
                            T.writes(pad_temp[ax0_1, ax1_1, ax2_1, ax3])
                            pad_temp[ax0_1, ax1_1, ax2_1, ax3] = T.if_then_else(ax2_1 < 27 and ax3 < 27, placeholder[0, ax1_1, ax2_1, ax3], T.float32(-3.4028234663852886e+38), dtype="float32")
                for i3 in T.serial(13):
                    with T.block("tensor_init"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3 = T.axis.remap("SSS", [i0_i1_fused, i2, i3])
                        T.reads()
                        T.writes(tensor[ax0, ax1, ax2, ax3])
                        tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                    for i4, i5 in T.grid(3, 3):
                        with T.block("tensor_update"):
                            ax0 = T.axis.spatial(1, 0)
                            ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSRR", [i0_i1_fused, i2, i3, i4, i5])
                            T.reads(tensor[ax0, ax1, ax2, ax3], pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1])
                            T.writes(tensor[ax0, ax1, ax2, ax3])
                            tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1])
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v2 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v2)", "l3 = sch.sample_compute_location(block=b0, decision=2)", "sch.compute_at(block=b0, loop=l3, preserve_unit_loops=True)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, b6 = sch.get_child_blocks(b4)", "l7, l8, l9, l10, l11, l12, l13 = sch.get_loops(block=b5)", "l14 = sch.fuse(l7, l8)", "sch.parallel(loop=l14)", "l15 = sch.fuse(l13)", "sch.vectorize(loop=l15)", "sch.annotate(block_or_loop=l14, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l14, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l16, l17, l18, l19, l20 = sch.get_loops(block=b6)", "sch.annotate(block_or_loop=l16, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l16, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b21 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l22, l23, l24, l25, l26 = sch.get_loops(block=b21)", "b27 = sch.decompose_reduction(block=b21, loop=l25)"]
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 13, 13), "float32"], T_divide: T.Buffer[(1, 256, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_data = T.alloc_buffer([1, 260, 13, 13], dtype="float32")
        tensor = T.alloc_buffer([1, 256, 13, 13], dtype="float32")
        tensor_1 = T.alloc_buffer([1, 256, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 260, 13, 13):
            with T.block("pad_data"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, ax1 - 2, ax2, ax3])
                T.writes(pad_data[ax0, ax1, ax2, ax3])
                pad_data[ax0, ax1, ax2, ax3] = T.if_then_else(2 <= ax1 and ax1 < 258, placeholder[0, ax1 - 2, ax2, ax3], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 256, 13, 13, 5):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, rxs = T.axis.remap("SSSSR", [i0, i1, i2, i3, i4])
                T.reads(pad_data[0, ax1 + rxs, ax2, ax3])
                T.writes(tensor[ax0, ax1, ax2, ax3])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3] = T.float32(0)
                tensor[ax0, ax1, ax2, ax3] = tensor[ax0, ax1, ax2, ax3] + pad_data[0, ax1 + rxs, ax2, ax3] * pad_data[0, ax1 + rxs, ax2, ax3]
        for i0, i1, i2, i3 in T.grid(1, 256, 13, 13):
            with T.block("tensor_1"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(tensor[0, ax1, ax2, ax3])
                T.writes(tensor_1[ax0, ax1, ax2, ax3])
                tensor_1[ax0, ax1, ax2, ax3] = T.pow(T.float32(1) + T.float32(9.9999997473787516e-05) * tensor[0, ax1, ax2, ax3] * T.float32(0.20000000000000001), T.float32(0.75), dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 13, 13):
            with T.block("T_divide"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, ax1, ax2, ax3], tensor_1[0, ax1, ax2, ax3])
                T.writes(T_divide[ax0, ax1, ax2, ax3])
                T_divide[ax0, ax1, ax2, ax3] = placeholder[0, ax1, ax2, ax3] / tensor_1[0, ax1, ax2, ax3]
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_lrn_1(placeholder: T.Buffer[(1, 256, 13, 13), "float32"], T_divide: T.Buffer[(1, 256, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_data = T.alloc_buffer([1, 260, 13, 13], dtype="float32")
        tensor = T.alloc_buffer([1, 256, 13, 13], dtype="float32")
        for i0_i1_i2_fused in T.parallel(3328, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for ax0, ax1 in T.grid(1, 5):
                for ax2_ax3_fused in T.vectorized(13):
                    with T.block("pad_data"):
                        ax0_1 = T.axis.spatial(1, ax0)
                        ax1_1 = T.axis.spatial(260, i0_i1_i2_fused % 3328 // 13 + ax1)
                        ax2 = T.axis.spatial(13, i0_i1_i2_fused % 13 + 0)
                        ax3 = T.axis.spatial(13, ax2_ax3_fused % 13)
                        T.reads(placeholder[0, ax1_1 - 2, ax2, ax3])
                        T.writes(pad_data[ax0_1, ax1_1, ax2, ax3])
                        pad_data[ax0_1, ax1_1, ax2, ax3] = T.if_then_else(2 <= ax1_1 and ax1_1 < 258, placeholder[0, ax1_1 - 2, ax2, ax3], T.float32(0), dtype="float32")
            for i3 in T.serial(13):
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 1):
                    with T.block("tensor_init"):
                        ax0_2 = T.axis.spatial(1, 0)
                        ax1_2 = T.axis.spatial(256, i0_i1_i2_fused // 13)
                        ax2_1 = T.axis.spatial(13, i0_i1_i2_fused % 13)
                        ax3_1 = T.axis.spatial(13, i3)
                        T.reads()
                        T.writes(tensor[ax0_2, ax1_2, ax2_1, ax3_1])
                        tensor[ax0_2, ax1_2, ax2_1, ax3_1] = T.float32(0)
                    for ax4 in T.serial(5):
                        with T.block("tensor_update"):
                            ax0_3 = T.axis.spatial(1, 0)
                            ax1_3 = T.axis.spatial(256, i0_i1_i2_fused // 13)
                            ax2_2 = T.axis.spatial(13, i0_i1_i2_fused % 13)
                            ax3_2, rxs = T.axis.remap("SR", [i3, ax4])
                            T.reads(tensor[ax0_3, ax1_3, ax2_2, ax3_2], pad_data[0, ax1_3 + rxs, ax2_2, ax3_2])
                            T.writes(tensor[ax0_3, ax1_3, ax2_2, ax3_2])
                            tensor[ax0_3, ax1_3, ax2_2, ax3_2] = tensor[ax0_3, ax1_3, ax2_2, ax3_2] + pad_data[0, ax1_3 + rxs, ax2_2, ax3_2] * pad_data[0, ax1_3 + rxs, ax2_2, ax3_2]
                with T.block("T_divide"):
                    ax0_4 = T.axis.spatial(1, 0)
                    ax1_4 = T.axis.spatial(256, i0_i1_i2_fused // 13)
                    ax2_3 = T.axis.spatial(13, i0_i1_i2_fused % 13)
                    ax3_3 = T.axis.spatial(13, i3)
                    T.reads(placeholder[0, ax1_4, ax2_3, ax3_3], tensor[0, ax1_4, ax2_3, ax3_3])
                    T.writes(T_divide[ax0_4, ax1_4, ax2_3, ax3_3])
                    T_divide[ax0_4, ax1_4, ax2_3, ax3_3] = placeholder[0, ax1_4, ax2_3, ax3_3] / T.pow(T.float32(1) + T.float32(9.9999997473787516e-05) * tensor[0, ax1_4, ax2_3, ax3_3] * T.float32(0.20000000000000001), T.float32(0.75), dtype="float32")
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_data\", func_name=\"main\")", "b1 = sch.get_block(name=\"tensor\", func_name=\"main\")", "b2 = sch.get_block(name=\"tensor_1\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v4 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v4)", "l5 = sch.sample_compute_location(block=b1, decision=3)", "sch.compute_at(block=b1, loop=l5, preserve_unit_loops=True)", "l6 = sch.sample_compute_location(block=b0, decision=2)", "sch.compute_at(block=b0, loop=l6, preserve_unit_loops=True)", "sch.enter_postproc()", "b7 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b7, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b7, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b7, ann_key=\"meta_schedule.unroll_explicit\")", "b8, b9, b10 = sch.get_child_blocks(b7)", "l11, l12, l13, l14, l15, l16, l17 = sch.get_loops(block=b8)", "l18 = sch.fuse(l11, l12, l13)", "sch.parallel(loop=l18)", "l19 = sch.fuse(l16, l17)", "sch.vectorize(loop=l19)", "sch.annotate(block_or_loop=l18, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l18, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b9)", "sch.annotate(block_or_loop=l20, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l20, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l27, l28 = sch.get_loops(block=b10)", "sch.annotate(block_or_loop=l27, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l27, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b29 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l30, l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b29)", "b37 = sch.decompose_reduction(block=b29, loop=l36)"]
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 13, 13), "float32"], T_layout_trans: T.Buffer[(1, 16, 13, 13, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 13, 13, 16):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[0, ax1 * 16 + ax4, ax2, ax3])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                T_layout_trans[ax0, ax1, ax2, ax3, ax4] = placeholder[0, ax1 * 16 + ax4, ax2, ax3]
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_layout_transform_2(placeholder: T.Buffer[(1, 256, 13, 13), "float32"], T_layout_trans: T.Buffer[(1, 16, 13, 13, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2, i3, i4 in T.grid(13, 13, 16):
                with T.block("T_layout_trans"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1, ax2, ax3, ax4 = T.axis.remap("SSSS", [i0_i1_fused, i2, i3, i4])
                    T.reads(placeholder[0, ax1 * 16 + ax4, ax2, ax3])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                    T_layout_trans[ax0, ax1, ax2, ax3, ax4] = placeholder[0, ax1 * 16 + ax4, ax2, ax3]
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7, l8 = sch.get_loops(block=b3)", "l9 = sch.fuse(l4, l5)", "sch.parallel(loop=l9)", "sch.annotate(block_or_loop=l9, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l9, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 13, 13, 16), "float32"], placeholder_1: T.Buffer[(24, 16, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 24, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 24, 13, 13, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 16, 15, 15, 16], dtype="float32")
        conv2d_NCHWc = T.alloc_buffer([1, 24, 13, 13, 16], dtype="float32")
        T_add = T.alloc_buffer([1, 24, 13, 13, 16], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 15, 15, 16):
            with T.block("data_pad"):
                i0_1, i1_1, i2_1, i3_1, i4_1 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[0, i1_1, i2_1 - 1, i3_1 - 1, i4_1])
                T.writes(data_pad[i0_1, i1_1, i2_1, i3_1, i4_1])
                data_pad[i0_1, i1_1, i2_1, i3_1, i4_1] = T.if_then_else(1 <= i2_1 and i2_1 < 14 and 1 <= i3_1 and i3_1 < 14, placeholder[0, i1_1, i2_1 - 1, i3_1 - 1, i4_1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 24, 13, 13, 16, 256, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(data_pad[0, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 13, 13, 16], "float32"], ["TENSOR", [24, 16, 3, 3, 16, 16], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + data_pad[0, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 24, 13, 13, 16):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[0, ax1, ax2, ax3, ax4], placeholder_2[0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[0, ax1, ax2, ax3, ax4] + placeholder_2[0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 24, 13, 13, 16):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[0, ax1, ax2, ax3, ax4])
                T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(T_add[0, ax1, ax2, ax3, ax4], T.float32(0))
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1(placeholder: T.Buffer[(1, 16, 13, 13, 16), "float32"], placeholder_1: T.Buffer[(24, 16, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 24, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 24, 13, 13, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 16, 15, 15, 16], dtype="float32")
        conv2d_NCHWc = T.alloc_buffer([1, 24, 13, 13, 16], dtype="float32")
        for i0_0_i1_0_i2_0_fused in T.parallel(156, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for ax0, ax1, ax2, ax3 in T.grid(1, 16, 3, 15):
                for ax4_fused in T.vectorized(16):
                    with T.block("data_pad"):
                        i0, i1 = T.axis.remap("SS", [ax0, ax1])
                        i2 = T.axis.spatial(15, i0_0_i1_0_i2_0_fused % 13 + ax2)
                        i3, i4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(placeholder[0, i1, i2 - 1, i3 - 1, i4])
                        T.writes(data_pad[i0, i1, i2, i3, i4])
                        data_pad[i0, i1, i2, i3, i4] = T.if_then_else(1 <= i2 and i2 < 14 and 1 <= i3 and i3 < 14, placeholder[0, i1, i2 - 1, i3 - 1, i4], T.float32(0), dtype="float32")
            for i3_0, i4_0, i0_1, i1_1, i2_1, i3_1, i4_1 in T.grid(1, 1, 1, 2, 1, 1, 1):
                for i3_2_init in T.serial(13):
                    for i4_2_i5_1_i6_1_i7_1_i0_3_i1_3_i2_3_i3_3_i4_3_fused_init in T.vectorized(16):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(24, i0_0_i1_0_i2_0_fused // 13 * 2 + i1_1)
                            oh = T.axis.spatial(13, i0_0_i1_0_i2_0_fused % 13)
                            ow, oc_block = T.axis.remap("SS", [i3_2_init, i4_2_i5_1_i6_1_i7_1_i0_3_i1_3_i2_3_i3_3_i4_3_fused_init])
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 13, 13, 16], "float32"], ["TENSOR", [24, 16, 3, 3, 16, 16], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2 in T.grid(256, 3, 3, 1, 1, 1, 13):
                    for i4_2_i5_1_i6_1_i7_1_i0_3_i1_3_i2_3_i3_3_i4_3_fused in T.vectorized(16):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(24, i0_0_i1_0_i2_0_fused // 13 * 2 + i1_1)
                            oh = T.axis.spatial(13, i0_0_i1_0_i2_0_fused % 13)
                            ow, oc_block, ic, kh, kw = T.axis.remap("SSRRR", [i3_2, i4_2_i5_1_i6_1_i7_1_i0_3_i1_3_i2_3_i3_3_i4_3_fused, i5_0, i6_0, i7_0])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], data_pad[0, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 13, 13, 16], "float32"], ["TENSOR", [24, 16, 3, 3, 16, 16], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + data_pad[0, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
        for i0_i1_i2_fused in T.parallel(312, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(13):
                for i4_fused in T.vectorized(16):
                    with T.block("T_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(24, i0_i1_i2_fused // 13)
                        ax2 = T.axis.spatial(13, i0_i1_i2_fused % 13)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(conv2d_NCHWc[0, ax1, ax2, ax3, ax4], placeholder_2[0, ax1, 0, 0, ax4])
                        T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                        T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(conv2d_NCHWc[0, ax1, ax2, ax3, ax4] + placeholder_2[0, ax1, 0, 0, ax4], T.float32(0))
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"data_pad\", func_name=\"main\")", "b1 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "b2 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b3 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b2)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)", "v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15])", "v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[12, 2, 1, 1])", "l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23])", "v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])", "l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31])", "v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])", "l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39])", "v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])", "l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47])", "v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[256, 1])", "l54, l55 = sch.split(loop=l9, factors=[v52, v53])", "v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])", "l58, l59 = sch.split(loop=l10, factors=[v56, v57])", "v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])", "l62, l63 = sch.split(loop=l11, factors=[v60, v61])", "sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v64)", "l65 = sch.sample_compute_location(block=b0, decision=2)", "sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True)", "sch.enter_postproc()", "b66 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b66, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b66, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b66, ann_key=\"meta_schedule.unroll_explicit\")", "b67, b68, b69 = sch.get_child_blocks(b66)", "l70, l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b67)", "l78 = sch.fuse(l70, l71, l72)", "sch.parallel(loop=l78)", "l79 = sch.fuse(l77)", "sch.vectorize(loop=l79)", "sch.annotate(block_or_loop=l78, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l78, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)", "l104 = sch.fuse(l95, l96, l97, l98, l99, l100, l101, l102, l103)", "sch.vectorize(loop=l104)", "sch.annotate(block_or_loop=l80, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l80, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l105, l106, l107, l108, l109 = sch.get_loops(block=b69)", "l110 = sch.fuse(l105, l106, l107)", "sch.parallel(loop=l110)", "l111 = sch.fuse(l109)", "sch.vectorize(loop=l111)", "sch.annotate(block_or_loop=l110, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l110, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b112 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b112)", "b129 = sch.decompose_reduction(block=b112, loop=l121)"]
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 24, 13, 13, 16), "float32"], T_layout_trans: T.Buffer[(1, 384, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3 in T.grid(1, 384, 13, 13):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, ax1 // 16, ax2, ax3, ax1 % 16])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                T_layout_trans[ax0, ax1, ax2, ax3] = placeholder[0, ax1 // 16, ax2, ax3, ax1 % 16]
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_layout_transform_3(placeholder: T.Buffer[(1, 24, 13, 13, 16), "float32"], T_layout_trans: T.Buffer[(1, 384, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(384, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2, i3 in T.grid(13, 13):
                with T.block("T_layout_trans"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1, ax2, ax3 = T.axis.remap("SSS", [i0_i1_fused, i2, i3])
                    T.reads(placeholder[0, ax1 // 16, ax2, ax3, ax1 % 16])
                    T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                    T_layout_trans[ax0, ax1, ax2, ax3] = placeholder[0, ax1 // 16, ax2, ax3, ax1 % 16]
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7 = sch.get_loops(block=b3)", "l8 = sch.fuse(l4, l5)", "sch.parallel(loop=l8)", "sch.annotate(block_or_loop=l8, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l8, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 13, 13), "float32"], placeholder_1: T.Buffer[(384, 192, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 384, 1, 1), "float32"], T_relu: T.Buffer[(1, 384, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 384, 15, 15], dtype="float32")
        data_vec = T.alloc_buffer([2, 1, 12, 15, 16, 15], dtype="float32")
        kernel_vec = T.alloc_buffer([2, 12, 12, 3, 3, 16, 16], dtype="float32")
        conv = T.alloc_buffer([2, 1, 12, 13, 13, 16], dtype="float32")
        output_unpack = T.alloc_buffer([1, 384, 13, 13], dtype="float32")
        T_add = T.alloc_buffer([1, 384, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 384, 15, 15):
            with T.block("data_pad"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(data_pad[i0_1, i1_1, i2_1, i3_1])
                data_pad[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 14 and 1 <= i3_1 and i3_1 < 14, placeholder[0, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5 in T.grid(2, 1, 12, 15, 16, 15):
            with T.block("data_vec"):
                g, n, C, h, c, w = T.axis.remap("SSSSSS", [i0, i1, i2, i3, i4, i5])
                T.reads(data_pad[0, g * 192 + C * 16 + c, h, w])
                T.writes(data_vec[g, n, C, h, c, w])
                data_vec[g, n, C, h, c, w] = data_pad[0, g * 192 + C * 16 + c, h, w]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(2, 12, 12, 3, 3, 16, 16):
            with T.block("kernel_vec"):
                g, out_channel, in_channel, h, w, ci, co = T.axis.remap("SSSSSSS", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder_1[g * 192 + out_channel * 16 + co, in_channel * 16 + ci, h, w])
                T.writes(kernel_vec[g, out_channel, in_channel, h, w, ci, co])
                kernel_vec[g, out_channel, in_channel, h, w, ci, co] = placeholder_1[g * 192 + out_channel * 16 + co, in_channel * 16 + ci, h, w]
        for i0, i1, i2, i3, i4, i5, i6, i7, i8 in T.grid(2, 1, 12, 13, 13, 16, 192, 3, 3):
            with T.block("conv"):
                g, n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7, i8])
                T.reads(data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw], kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                T.writes(conv[g, n, oc_chunk, oh, ow, oc_block])
                with T.init():
                    conv[g, n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv[g, n, oc_chunk, oh, ow, oc_block] = conv[g, n, oc_chunk, oh, ow, oc_block] + data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw] * kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
        for i0, i1, i2, i3 in T.grid(1, 384, 13, 13):
            with T.block("output_unpack"):
                n, c, h, w = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv[c // 192, 0, c % 192 // 16, h, w, c % 16])
                T.writes(output_unpack[n, c, h, w])
                T.block_attr({"workload":["group_conv2d_nchw.x86", ["TENSOR", [1, 384, 13, 13], "float32"], ["TENSOR", [384, 192, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], 2, "float32"]})
                output_unpack[n, c, h, w] = conv[c // 192, 0, c % 192 // 16, h, w, c % 16]
        for i0, i1, i2, i3 in T.grid(1, 384, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(output_unpack[0, ax1, ax2, ax3], placeholder_2[0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = output_unpack[0, ax1, ax2, ax3] + placeholder_2[0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 384, 13, 13):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_1(placeholder: T.Buffer[(1, 384, 13, 13), "float32"], placeholder_1: T.Buffer[(384, 192, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 384, 1, 1), "float32"], T_relu: T.Buffer[(1, 384, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 384, 15, 15], dtype="float32")
        data_vec = T.alloc_buffer([2, 1, 12, 15, 16, 15], dtype="float32")
        kernel_vec = T.alloc_buffer([2, 12, 12, 3, 3, 16, 16], dtype="float32")
        conv = T.alloc_buffer([2, 1, 12, 13, 13, 16], dtype="float32")
        output_unpack = T.alloc_buffer([1, 384, 13, 13], dtype="float32")
        conv_global = T.alloc_buffer([2, 1, 12, 13, 13, 16], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused in T.parallel(16):
            for ax0, ax1, ax2, ax3, ax4, ax5, ax6 in T.grid(1, 3, 12, 3, 3, 16, 8):
                with T.block("kernel_vec"):
                    g = T.axis.spatial(2, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused % 2)
                    out_channel = T.axis.spatial(12, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused // 4 * 3 + ax1)
                    in_channel, h, w, ci = T.axis.remap("SSSS", [ax2, ax3, ax4, ax5])
                    co = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused % 4 // 2 * 8 + ax6)
                    T.reads(placeholder_1[g * 192 + out_channel * 16 + co, in_channel * 16 + ci, h, w])
                    T.writes(kernel_vec[g, out_channel, in_channel, h, w, ci, co])
                    kernel_vec[g, out_channel, in_channel, h, w, ci, co] = placeholder_1[g * 192 + out_channel * 16 + co, in_channel * 16 + ci, h, w]
            for ax0, ax1, ax2, ax3, ax4, ax5 in T.grid(1, 1, 12, 15, 16, 15):
                for ax0_1, ax1_1, ax2_1, ax3_1 in T.grid(1, 1, 1, 1):
                    with T.block("data_pad"):
                        i0 = T.axis.spatial(1, 0)
                        i1 = T.axis.spatial(384, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused % 2 * 192 + ax2 * 16 + ax4)
                        i2, i3 = T.axis.remap("SS", [ax3, ax5])
                        T.reads(placeholder[0, i1, i2 - 1, i3 - 1])
                        T.writes(data_pad[i0, i1, i2, i3])
                        data_pad[i0, i1, i2, i3] = T.if_then_else(1 <= i2 and i2 < 14 and 1 <= i3 and i3 < 14, placeholder[0, i1, i2 - 1, i3 - 1], T.float32(0), dtype="float32")
                with T.block("data_vec"):
                    g = T.axis.spatial(2, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused % 2)
                    n = T.axis.spatial(1, 0)
                    C, h, c, w = T.axis.remap("SSSS", [ax2, ax3, ax4, ax5])
                    T.reads(data_pad[0, g * 192 + C * 16 + c, h, w])
                    T.writes(data_vec[g, n, C, h, c, w])
                    data_vec[g, n, C, h, c, w] = data_pad[0, g * 192 + C * 16 + c, h, w]
            for i1_1, i2_1, i3_1, i4_1, i5_1 in T.grid(1, 3, 1, 1, 1):
                for i3_2_init, i4_3_init in T.grid(13, 13):
                    for i5_3_fused_init in T.vectorized(8):
                        with T.block("conv_init"):
                            g = T.axis.spatial(2, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused % 2)
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(12, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused // 4 * 3 + i2_1)
                            oh, ow = T.axis.remap("SS", [i3_2_init, i4_3_init])
                            oc_block = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused % 4 // 2 * 8 + i5_3_fused_init)
                            T.reads()
                            T.writes(conv_global[g, n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv_global[g, n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i6_0, i7_0, i8_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_2, i6_1, i7_1, i8_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(12, 3, 1, 1, 1, 1, 13, 1, 1, 16, 1, 3, 1, 1, 1, 1, 13):
                    for i5_3_fused in T.vectorized(8):
                        with T.block("conv_update"):
                            g = T.axis.spatial(2, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused % 2)
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(12, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused // 4 * 3 + i2_1)
                            oh, ow = T.axis.remap("SS", [i3_2, i4_3])
                            oc_block = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused % 4 // 2 * 8 + i5_3_fused)
                            ic = T.axis.reduce(192, i6_0 * 16 + i6_1)
                            kh, kw = T.axis.remap("RR", [i7_0, i8_1])
                            T.reads(conv_global[g, n, oc_chunk, oh, ow, oc_block], data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw], kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                            T.writes(conv_global[g, n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv_global[g, n, oc_chunk, oh, ow, oc_block] = conv_global[g, n, oc_chunk, oh, ow, oc_block] + data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw] * kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 1, 1, 13, 13):
                    for ax5_fused in T.vectorized(8):
                        with T.block("conv_global"):
                            v0 = T.axis.spatial(2, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused % 2)
                            v1 = T.axis.spatial(1, 0)
                            v2 = T.axis.spatial(12, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused // 4 * 3 + i2_1)
                            v3, v4 = T.axis.remap("SS", [ax3, ax4])
                            v5 = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_i0_1_fused_fused_fused_fused_fused % 4 // 2 * 8 + ax5_fused)
                            T.reads(conv_global[v0, v1, v2, v3, v4, v5])
                            T.writes(conv[v0, v1, v2, v3, v4, v5])
                            conv[v0, v1, v2, v3, v4, v5] = conv_global[v0, v1, v2, v3, v4, v5]
        for i0_i1_fused_fused in T.parallel(384):
            for ax0, ax1, ax2, ax3 in T.grid(1, 1, 13, 13):
                with T.block("output_unpack"):
                    n = T.axis.spatial(1, 0)
                    c, h, w = T.axis.remap("SSS", [i0_i1_fused_fused, ax2, ax3])
                    T.reads(conv[c // 192, 0, c % 192 // 16, h, w, c % 16])
                    T.writes(output_unpack[n, c, h, w])
                    T.block_attr({"workload":["group_conv2d_nchw.x86", ["TENSOR", [1, 384, 13, 13], "float32"], ["TENSOR", [384, 192, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], 2, "float32"]})
                    output_unpack[n, c, h, w] = conv[c // 192, 0, c % 192 // 16, h, w, c % 16]
            for i2 in T.serial(13):
                for i3_fused in T.vectorized(13):
                    with T.block("T_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3 = T.axis.remap("SSS", [i0_i1_fused_fused, i2, i3_fused])
                        T.reads(output_unpack[0, ax1, ax2, ax3], placeholder_2[0, ax1, 0, 0])
                        T.writes(T_relu[ax0, ax1, ax2, ax3])
                        T_relu[ax0, ax1, ax2, ax3] = T.max(output_unpack[0, ax1, ax2, ax3] + placeholder_2[0, ax1, 0, 0], T.float32(0))
    

[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:01] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"data_pad\", func_name=\"main\")", "b1 = sch.get_block(name=\"data_vec\", func_name=\"main\")", "b2 = sch.get_block(name=\"kernel_vec\", func_name=\"main\")", "b3 = sch.get_block(name=\"conv\", func_name=\"main\")", "b4 = sch.get_block(name=\"output_unpack\", func_name=\"main\")", "b5 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b6 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b5)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l7, l8, l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b3)", "v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])", "l20, l21, l22, l23 = sch.split(loop=l7, factors=[v16, v17, v18, v19])", "v24, v25, v26, v27 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l28, l29, l30, l31 = sch.split(loop=l8, factors=[v24, v25, v26, v27])", "v32, v33, v34, v35 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 3, 1, 1])", "l36, l37, l38, l39 = sch.split(loop=l9, factors=[v32, v33, v34, v35])", "v40, v41, v42, v43 = sch.sample_perfect_tile(loop=l10, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])", "l44, l45, l46, l47 = sch.split(loop=l10, factors=[v40, v41, v42, v43])", "v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l11, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])", "l52, l53, l54, l55 = sch.split(loop=l11, factors=[v48, v49, v50, v51])", "v56, v57, v58, v59 = sch.sample_perfect_tile(loop=l12, n=4, max_innermost_factor=64, decision=[2, 1, 1, 8])", "l60, l61, l62, l63 = sch.split(loop=l12, factors=[v56, v57, v58, v59])", "v64, v65 = sch.sample_perfect_tile(loop=l13, n=2, max_innermost_factor=64, decision=[12, 16])", "l66, l67 = sch.split(loop=l13, factors=[v64, v65])", "v68, v69 = sch.sample_perfect_tile(loop=l14, n=2, max_innermost_factor=64, decision=[3, 1])", "l70, l71 = sch.split(loop=l14, factors=[v68, v69])", "v72, v73 = sch.sample_perfect_tile(loop=l15, n=2, max_innermost_factor=64, decision=[1, 3])", "l74, l75 = sch.split(loop=l15, factors=[v72, v73])", "sch.reorder(l20, l28, l36, l44, l52, l60, l21, l29, l37, l45, l53, l61, l66, l70, l74, l22, l30, l38, l46, l54, l62, l67, l71, l75, l23, l31, l39, l47, l55, l63)", "b76 = sch.cache_write(block=b3, write_buffer_index=0, storage_scope=\"global\")", "sch.reverse_compute_at(block=b76, loop=l61, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b6, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b6, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v77 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)", "sch.annotate(block_or_loop=b6, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v77)", "l78 = sch.sample_compute_location(block=b4, decision=1)", "sch.compute_at(block=b4, loop=l78, preserve_unit_loops=True)", "l79 = sch.sample_compute_location(block=b2, decision=6)", "sch.compute_at(block=b2, loop=l79, preserve_unit_loops=True)", "l80 = sch.sample_compute_location(block=b1, decision=6)", "sch.compute_at(block=b1, loop=l80, preserve_unit_loops=True)", "l81 = sch.sample_compute_location(block=b0, decision=12)", "sch.compute_at(block=b0, loop=l81, preserve_unit_loops=True)", "sch.enter_postproc()", "b82 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b82, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b82, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b82, ann_key=\"meta_schedule.unroll_explicit\")", "b83, b84, b85, b86, b87, b88, b89 = sch.get_child_blocks(b82)", "l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b83)", "l104 = sch.fuse(l90, l91, l92, l93, l94, l95, l96)", "sch.parallel(loop=l104)", "l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b84)", "l116 = sch.fuse(l105)", "sch.parallel(loop=l116)", "l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b85)", "l124 = sch.fuse(l117)", "sch.parallel(loop=l124)", "l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148 = sch.get_loops(block=b86)", "l149 = sch.fuse(l125)", "sch.parallel(loop=l149)", "l150 = sch.fuse(l148)", "sch.vectorize(loop=l150)", "l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b87)", "l163 = sch.fuse(l151)", "sch.parallel(loop=l163)", "l164 = sch.fuse(l162)", "sch.vectorize(loop=l164)", "l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b88)", "l171 = sch.fuse(l165, l166)", "sch.parallel(loop=l171)", "l172, l173, l174 = sch.get_loops(block=b89)", "l175 = sch.fuse(l172)", "sch.parallel(loop=l175)", "l176 = sch.fuse(l174)", "sch.vectorize(loop=l176)", "b177 = sch.get_block(name=\"conv\", func_name=\"main\")", "l178, l179, l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b177)", "b202 = sch.decompose_reduction(block=b177, loop=l184)"]
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 384, 13, 13), "float32"], placeholder_1: T.Buffer[(256, 192, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_relu: T.Buffer[(1, 256, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 384, 15, 15], dtype="float32")
        data_vec = T.alloc_buffer([2, 1, 12, 15, 16, 15], dtype="float32")
        kernel_vec = T.alloc_buffer([2, 8, 12, 3, 3, 16, 16], dtype="float32")
        conv = T.alloc_buffer([2, 1, 8, 13, 13, 16], dtype="float32")
        output_unpack = T.alloc_buffer([1, 256, 13, 13], dtype="float32")
        T_add = T.alloc_buffer([1, 256, 13, 13], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 384, 15, 15):
            with T.block("data_pad"):
                i0_1, i1_1, i2_1, i3_1 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, i1_1, i2_1 - 1, i3_1 - 1])
                T.writes(data_pad[i0_1, i1_1, i2_1, i3_1])
                data_pad[i0_1, i1_1, i2_1, i3_1] = T.if_then_else(1 <= i2_1 and i2_1 < 14 and 1 <= i3_1 and i3_1 < 14, placeholder[0, i1_1, i2_1 - 1, i3_1 - 1], T.float32(0), dtype="float32")
        for i0, i1, i2, i3, i4, i5 in T.grid(2, 1, 12, 15, 16, 15):
            with T.block("data_vec"):
                g, n, C, h, c, w = T.axis.remap("SSSSSS", [i0, i1, i2, i3, i4, i5])
                T.reads(data_pad[0, g * 192 + C * 16 + c, h, w])
                T.writes(data_vec[g, n, C, h, c, w])
                data_vec[g, n, C, h, c, w] = data_pad[0, g * 192 + C * 16 + c, h, w]
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(2, 8, 12, 3, 3, 16, 16):
            with T.block("kernel_vec"):
                g, out_channel, in_channel, h, w, ci, co = T.axis.remap("SSSSSSS", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder_1[g * 128 + out_channel * 16 + co, in_channel * 16 + ci, h, w])
                T.writes(kernel_vec[g, out_channel, in_channel, h, w, ci, co])
                kernel_vec[g, out_channel, in_channel, h, w, ci, co] = placeholder_1[g * 128 + out_channel * 16 + co, in_channel * 16 + ci, h, w]
        for i0, i1, i2, i3, i4, i5, i6, i7, i8 in T.grid(2, 1, 8, 13, 13, 16, 192, 3, 3):
            with T.block("conv"):
                g, n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7, i8])
                T.reads(data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw], kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                T.writes(conv[g, n, oc_chunk, oh, ow, oc_block])
                with T.init():
                    conv[g, n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv[g, n, oc_chunk, oh, ow, oc_block] = conv[g, n, oc_chunk, oh, ow, oc_block] + data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw] * kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
        for i0, i1, i2, i3 in T.grid(1, 256, 13, 13):
            with T.block("output_unpack"):
                n, c, h, w = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(conv[c // 128, 0, c % 128 // 16, h, w, c % 16])
                T.writes(output_unpack[n, c, h, w])
                T.block_attr({"workload":["group_conv2d_nchw.x86", ["TENSOR", [1, 384, 13, 13], "float32"], ["TENSOR", [256, 192, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], 2, "float32"]})
                output_unpack[n, c, h, w] = conv[c // 128, 0, c % 128 // 16, h, w, c % 16]
        for i0, i1, i2, i3 in T.grid(1, 256, 13, 13):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(output_unpack[0, ax1, ax2, ax3], placeholder_2[0, ax1, 0, 0])
                T.writes(T_add[ax0, ax1, ax2, ax3])
                T_add[ax0, ax1, ax2, ax3] = output_unpack[0, ax1, ax2, ax3] + placeholder_2[0, ax1, 0, 0]
        for i0, i1, i2, i3 in T.grid(1, 256, 13, 13):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_add[0, ax1, ax2, ax3])
                T.writes(T_relu[ax0, ax1, ax2, ax3])
                T_relu[ax0, ax1, ax2, ax3] = T.max(T_add[0, ax1, ax2, ax3], T.float32(0))
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_conv2d_add_nn_relu_2(placeholder: T.Buffer[(1, 384, 13, 13), "float32"], placeholder_1: T.Buffer[(256, 192, 3, 3), "float32"], placeholder_2: T.Buffer[(1, 256, 1, 1), "float32"], T_relu: T.Buffer[(1, 256, 13, 13), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        data_pad = T.alloc_buffer([1, 384, 15, 15], dtype="float32")
        data_vec = T.alloc_buffer([2, 1, 12, 15, 16, 15], dtype="float32")
        kernel_vec = T.alloc_buffer([2, 8, 12, 3, 3, 16, 16], dtype="float32")
        conv = T.alloc_buffer([2, 1, 8, 13, 13, 16], dtype="float32")
        output_unpack = T.alloc_buffer([1, 256, 13, 13], dtype="float32")
        conv_global = T.alloc_buffer([2, 1, 8, 13, 13, 16], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_fused_fused_fused_fused_fused in T.parallel(16):
            for ax0, ax1, ax2, ax3, ax4, ax5, ax6 in T.grid(2, 1, 12, 3, 3, 16, 8):
                with T.block("kernel_vec"):
                    g = T.axis.spatial(2, ax0)
                    out_channel = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_fused_fused_fused_fused_fused // 2)
                    in_channel, h, w, ci = T.axis.remap("SSSS", [ax2, ax3, ax4, ax5])
                    co = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_fused_fused_fused_fused_fused % 2 * 8 + ax6)
                    T.reads(placeholder_1[g * 128 + out_channel * 16 + co, in_channel * 16 + ci, h, w])
                    T.writes(kernel_vec[g, out_channel, in_channel, h, w, ci, co])
                    kernel_vec[g, out_channel, in_channel, h, w, ci, co] = placeholder_1[g * 128 + out_channel * 16 + co, in_channel * 16 + ci, h, w]
            for ax0, ax1, ax2, ax3, ax4, ax5 in T.grid(2, 1, 12, 15, 16, 15):
                for ax0_1, ax1_1, ax2_1, ax3_1 in T.grid(1, 1, 1, 1):
                    with T.block("data_pad"):
                        i0 = T.axis.spatial(1, 0)
                        i1 = T.axis.spatial(384, ax0 * 192 + ax2 * 16 + ax4)
                        i2, i3 = T.axis.remap("SS", [ax3, ax5])
                        T.reads(placeholder[0, i1, i2 - 1, i3 - 1])
                        T.writes(data_pad[i0, i1, i2, i3])
                        data_pad[i0, i1, i2, i3] = T.if_then_else(1 <= i2 and i2 < 14 and 1 <= i3 and i3 < 14, placeholder[0, i1, i2 - 1, i3 - 1], T.float32(0), dtype="float32")
                with T.block("data_vec"):
                    g = T.axis.spatial(2, ax0)
                    n = T.axis.spatial(1, 0)
                    C, h, c, w = T.axis.remap("SSSS", [ax2, ax3, ax4, ax5])
                    T.reads(data_pad[0, g * 192 + C * 16 + c, h, w])
                    T.writes(data_vec[g, n, C, h, c, w])
                    data_vec[g, n, C, h, c, w] = data_pad[0, g * 192 + C * 16 + c, h, w]
            for i0_1, i1_1, i2_1, i3_1, i4_1, i5_1 in T.grid(2, 1, 1, 13, 1, 1):
                for i4_3_init in T.serial(13):
                    for i5_3_fused_init in T.vectorized(8):
                        with T.block("conv_init"):
                            g = T.axis.spatial(2, i0_1)
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_fused_fused_fused_fused_fused // 2)
                            oh, ow = T.axis.remap("SS", [i3_1, i4_3_init])
                            oc_block = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_fused_fused_fused_fused_fused % 2 * 8 + i5_3_fused_init)
                            T.reads()
                            T.writes(conv_global[g, n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv_global[g, n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i6_0, i7_0, i8_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_2, i6_1, i7_1, i8_1, i0_3, i1_3, i2_3, i3_3, i4_3 in T.grid(24, 3, 1, 1, 1, 1, 1, 1, 1, 8, 1, 3, 1, 1, 1, 1, 13):
                    for i5_3_fused in T.vectorized(8):
                        with T.block("conv_update"):
                            g = T.axis.spatial(2, i0_1)
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_fused_fused_fused_fused_fused // 2)
                            oh, ow = T.axis.remap("SS", [i3_1, i4_3])
                            oc_block = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_fused_fused_fused_fused_fused % 2 * 8 + i5_3_fused)
                            ic = T.axis.reduce(192, i6_0 * 8 + i6_1)
                            kh, kw = T.axis.remap("RR", [i7_0, i8_1])
                            T.reads(conv_global[g, n, oc_chunk, oh, ow, oc_block], data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw], kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                            T.writes(conv_global[g, n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                            conv_global[g, n, oc_chunk, oh, ow, oc_block] = conv_global[g, n, oc_chunk, oh, ow, oc_block] + data_vec[g, 0, ic // 16, oh + kh, ic % 16, ow + kw] * kernel_vec[g, oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(1, 1, 1, 1, 13):
                    for ax5_fused in T.vectorized(8):
                        with T.block("conv_global"):
                            v0 = T.axis.spatial(2, i0_1)
                            v1 = T.axis.spatial(1, 0)
                            v2 = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_fused_fused_fused_fused_fused // 2)
                            v3, v4 = T.axis.remap("SS", [i3_1, ax4])
                            v5 = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i5_0_fused_fused_fused_fused_fused % 2 * 8 + ax5_fused)
                            T.reads(conv_global[v0, v1, v2, v3, v4, v5])
                            T.writes(conv[v0, v1, v2, v3, v4, v5])
                            conv[v0, v1, v2, v3, v4, v5] = conv_global[v0, v1, v2, v3, v4, v5]
        for i0_i1_fused_fused in T.parallel(256):
            for i2, i3 in T.grid(13, 13):
                for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 1):
                    with T.block("output_unpack"):
                        n = T.axis.spatial(1, 0)
                        c, h, w = T.axis.remap("SSS", [i0_i1_fused_fused, i2, i3])
                        T.reads(conv[c // 128, 0, c % 128 // 16, h, w, c % 16])
                        T.writes(output_unpack[n, c, h, w])
                        T.block_attr({"workload":["group_conv2d_nchw.x86", ["TENSOR", [1, 384, 13, 13], "float32"], ["TENSOR", [256, 192, 3, 3], "float32"], [1, 1], [1, 1, 1, 1], [1, 1], 2, "float32"]})
                        output_unpack[n, c, h, w] = conv[c // 128, 0, c % 128 // 16, h, w, c % 16]
                with T.block("T_relu"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1, ax2, ax3 = T.axis.remap("SSS", [i0_i1_fused_fused, i2, i3])
                    T.reads(output_unpack[0, ax1, ax2, ax3], placeholder_2[0, ax1, 0, 0])
                    T.writes(T_relu[ax0, ax1, ax2, ax3])
                    T_relu[ax0, ax1, ax2, ax3] = T.max(output_unpack[0, ax1, ax2, ax3] + placeholder_2[0, ax1, 0, 0], T.float32(0))
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"data_pad\", func_name=\"main\")", "b1 = sch.get_block(name=\"data_vec\", func_name=\"main\")", "b2 = sch.get_block(name=\"kernel_vec\", func_name=\"main\")", "b3 = sch.get_block(name=\"conv\", func_name=\"main\")", "b4 = sch.get_block(name=\"output_unpack\", func_name=\"main\")", "b5 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b6 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b5)", "sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l7, l8, l9, l10, l11, l12, l13, l14, l15 = sch.get_loops(block=b3)", "v16, v17, v18, v19 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])", "l20, l21, l22, l23 = sch.split(loop=l7, factors=[v16, v17, v18, v19])", "v24, v25, v26, v27 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l28, l29, l30, l31 = sch.split(loop=l8, factors=[v24, v25, v26, v27])", "v32, v33, v34, v35 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 1, 1, 1])", "l36, l37, l38, l39 = sch.split(loop=l9, factors=[v32, v33, v34, v35])", "v40, v41, v42, v43 = sch.sample_perfect_tile(loop=l10, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])", "l44, l45, l46, l47 = sch.split(loop=l10, factors=[v40, v41, v42, v43])", "v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l11, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])", "l52, l53, l54, l55 = sch.split(loop=l11, factors=[v48, v49, v50, v51])", "v56, v57, v58, v59 = sch.sample_perfect_tile(loop=l12, n=4, max_innermost_factor=64, decision=[2, 1, 1, 8])", "l60, l61, l62, l63 = sch.split(loop=l12, factors=[v56, v57, v58, v59])", "v64, v65 = sch.sample_perfect_tile(loop=l13, n=2, max_innermost_factor=64, decision=[24, 8])", "l66, l67 = sch.split(loop=l13, factors=[v64, v65])", "v68, v69 = sch.sample_perfect_tile(loop=l14, n=2, max_innermost_factor=64, decision=[3, 1])", "l70, l71 = sch.split(loop=l14, factors=[v68, v69])", "v72, v73 = sch.sample_perfect_tile(loop=l15, n=2, max_innermost_factor=64, decision=[1, 3])", "l74, l75 = sch.split(loop=l15, factors=[v72, v73])", "sch.reorder(l20, l28, l36, l44, l52, l60, l21, l29, l37, l45, l53, l61, l66, l70, l74, l22, l30, l38, l46, l54, l62, l67, l71, l75, l23, l31, l39, l47, l55, l63)", "b76 = sch.cache_write(block=b3, write_buffer_index=0, storage_scope=\"global\")", "sch.reverse_compute_at(block=b76, loop=l61, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b6, ann_key=\"meta_schedule.parallel\", ann_val=32)", "sch.annotate(block_or_loop=b6, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v77 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)", "sch.annotate(block_or_loop=b6, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v77)", "l78 = sch.sample_compute_location(block=b4, decision=3)", "sch.compute_at(block=b4, loop=l78, preserve_unit_loops=True)", "l79 = sch.sample_compute_location(block=b2, decision=5)", "sch.compute_at(block=b2, loop=l79, preserve_unit_loops=True)", "l80 = sch.sample_compute_location(block=b1, decision=5)", "sch.compute_at(block=b1, loop=l80, preserve_unit_loops=True)", "l81 = sch.sample_compute_location(block=b0, decision=11)", "sch.compute_at(block=b0, loop=l81, preserve_unit_loops=True)", "sch.enter_postproc()", "b82 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b82, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b82, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b82, ann_key=\"meta_schedule.unroll_explicit\")", "b83, b84, b85, b86, b87, b88, b89 = sch.get_child_blocks(b82)", "l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b83)", "l103 = sch.fuse(l90, l91, l92, l93, l94, l95)", "sch.parallel(loop=l103)", "l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b84)", "l115 = sch.fuse(l104)", "sch.parallel(loop=l115)", "l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b85)", "l123 = sch.fuse(l116)", "sch.parallel(loop=l123)", "l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148 = sch.get_loops(block=b86)", "l149 = sch.fuse(l124)", "sch.parallel(loop=l149)", "l150 = sch.fuse(l148)", "sch.vectorize(loop=l150)", "l151, l152, l153, l154, l155, l156, l157, l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b87)", "l164 = sch.fuse(l151)", "sch.parallel(loop=l164)", "l165 = sch.fuse(l163)", "sch.vectorize(loop=l165)", "l166, l167, l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b88)", "l174 = sch.fuse(l166, l167)", "sch.parallel(loop=l174)", "l175, l176, l177 = sch.get_loops(block=b89)", "l178 = sch.fuse(l175)", "sch.parallel(loop=l178)", "b179 = sch.get_block(name=\"conv\", func_name=\"main\")", "l180, l181, l182, l183, l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203, l204 = sch.get_loops(block=b179)", "b205 = sch.decompose_reduction(block=b179, loop=l187)"]
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 13, 13), "float32"], tensor: T.Buffer[(1, 256, 6, 6), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 14, 14], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 14, 14):
            with T.block("pad_temp"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[0, ax1, ax2, ax3])
                T.writes(pad_temp[ax0, ax1, ax2, ax3])
                pad_temp[ax0, ax1, ax2, ax3] = T.if_then_else(ax2 < 13 and ax3 < 13, placeholder[0, ax1, ax2, ax3], T.float32(-3.4028234663852886e+38), dtype="float32")
        for i0, i1, i2, i3, i4, i5 in T.grid(1, 256, 6, 6, 3, 3):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSSRR", [i0, i1, i2, i3, i4, i5])
                T.reads(pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1])
                T.writes(tensor[ax0, ax1, ax2, ax3])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1])
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_max_pool2d_2(placeholder: T.Buffer[(1, 256, 13, 13), "float32"], tensor: T.Buffer[(1, 256, 6, 6), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([1, 256, 14, 14], dtype="float32")
        for i0_i1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i2 in T.serial(6):
                for ax0, ax1, ax2 in T.grid(1, 1, 3):
                    for ax3_fused in T.vectorized(13):
                        with T.block("pad_temp"):
                            ax0_1 = T.axis.spatial(1, ax0)
                            ax1_1 = T.axis.spatial(256, i0_i1_fused % 256 + ax1)
                            ax2_1 = T.axis.spatial(14, i2 * 2 + ax2)
                            ax3 = T.axis.spatial(14, ax3_fused)
                            T.reads(placeholder[0, ax1_1, ax2_1, ax3])
                            T.writes(pad_temp[ax0_1, ax1_1, ax2_1, ax3])
                            pad_temp[ax0_1, ax1_1, ax2_1, ax3] = T.if_then_else(ax2_1 < 13 and ax3 < 13, placeholder[0, ax1_1, ax2_1, ax3], T.float32(-3.4028234663852886e+38), dtype="float32")
                for i3 in T.serial(6):
                    with T.block("tensor_init"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3 = T.axis.remap("SSS", [i0_i1_fused, i2, i3])
                        T.reads()
                        T.writes(tensor[ax0, ax1, ax2, ax3])
                        tensor[ax0, ax1, ax2, ax3] = T.float32(-3.4028234663852886e+38)
                    for i4, i5 in T.grid(3, 3):
                        with T.block("tensor_update"):
                            ax0 = T.axis.spatial(1, 0)
                            ax1, ax2, ax3, rv0, rv1 = T.axis.remap("SSSRR", [i0_i1_fused, i2, i3, i4, i5])
                            T.reads(tensor[ax0, ax1, ax2, ax3], pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1])
                            T.writes(tensor[ax0, ax1, ax2, ax3])
                            tensor[ax0, ax1, ax2, ax3] = T.max(tensor[ax0, ax1, ax2, ax3], pad_temp[0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1])
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"pad_temp\", func_name=\"main\")", "b1 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v2 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v2)", "l3 = sch.sample_compute_location(block=b0, decision=2)", "sch.compute_at(block=b0, loop=l3, preserve_unit_loops=True)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, b6 = sch.get_child_blocks(b4)", "l7, l8, l9, l10, l11, l12, l13 = sch.get_loops(block=b5)", "l14 = sch.fuse(l7, l8)", "sch.parallel(loop=l14)", "l15 = sch.fuse(l13)", "sch.vectorize(loop=l15)", "sch.annotate(block_or_loop=l14, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l14, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l16, l17, l18, l19, l20 = sch.get_loops(block=b6)", "sch.annotate(block_or_loop=l16, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l16, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b21 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l22, l23, l24, l25, l26 = sch.get_loops(block=b21)", "b27 = sch.decompose_reduction(block=b21, loop=l25)"]
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 256, 6, 6), "float32"], T_reshape: T.Buffer[(1, 9216), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1 in T.grid(1, 9216):
            with T.block("T_reshape"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(placeholder[0, ax1 // 36, ax1 % 36 // 6, ax1 % 6])
                T.writes(T_reshape[ax0, ax1])
                T_reshape[ax0, ax1] = placeholder[0, ax1 // 36, ax1 % 36 // 6, ax1 % 6]
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_reshape(placeholder: T.Buffer[(1, 256, 6, 6), "float32"], T_reshape: T.Buffer[(1, 9216), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(9216, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            with T.block("T_reshape"):
                ax0 = T.axis.spatial(1, 0)
                ax1 = T.axis.spatial(9216, i0_i1_fused)
                T.reads(placeholder[0, ax1 // 36, ax1 % 36 // 6, ax1 % 6])
                T.writes(T_reshape[ax0, ax1])
                T_reshape[ax0, ax1] = placeholder[0, ax1 // 36, ax1 % 36 // 6, ax1 % 6]
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5 = sch.get_loops(block=b3)", "l6 = sch.fuse(l4, l5)", "sch.parallel(loop=l6)", "sch.annotate(block_or_loop=l6, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l6, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 9216), "float32"], placeholder_1: T.Buffer[(4096, 9216), "float32"], placeholder_2: T.Buffer[(1, 4096), "float32"], T_relu: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 4096], dtype="float32")
        T_add = T.alloc_buffer([1, 4096], dtype="float32")
        for i0, i1, i2 in T.grid(1, 4096, 9216):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[0, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
        for i0, i1 in T.grid(1, 4096):
            with T.block("T_add"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                T.writes(T_add[ax0, ax1])
                T_add[ax0, ax1] = T_matmul_NT[0, ax1] + placeholder_2[0, ax1]
        for i0, i1 in T.grid(1, 4096):
            with T.block("T_relu"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_add[0, ax1])
                T.writes(T_relu[ax0, ax1])
                T_relu[ax0, ax1] = T.max(T_add[0, ax1], T.float32(0))
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_dense_add_nn_relu(placeholder: T.Buffer[(1, 9216), "float32"], placeholder_1: T.Buffer[(4096, 9216), "float32"], placeholder_2: T.Buffer[(1, 4096), "float32"], T_relu: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 4096], dtype="float32")
        for i0_0_i1_0_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1 in T.grid(1, 4):
                for i1_3_init in T.serial(4):
                    with T.block("T_matmul_NT_init"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(4096, i0_0_i1_0_fused * 16 + i1_1 * 4 + i1_3_init)
                        T.reads()
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T.float32(0)
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(1152, 1, 1, 8, 1, 4):
                    with T.block("T_matmul_NT_update"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(4096, i0_0_i1_0_fused * 16 + i1_1 * 4 + i1_3)
                        k = T.axis.reduce(9216, i2_0 * 8 + i2_1)
                        T.reads(T_matmul_NT[i, j], placeholder[0, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
                for ax0_ax1_fused in T.vectorized(4):
                    with T.block("T_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(4096, i0_0_i1_0_fused * 16 + i1_1 * 4 + ax0_ax1_fused)
                        T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                        T.writes(T_relu[ax0, ax1])
                        T_relu[ax0, ax1] = T.max(T_matmul_NT[0, ax1] + placeholder_2[0, ax1], T.float32(0))
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5 = sch.get_loops(block=b0)", "v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l10, l11, l12, l13 = sch.split(loop=l3, factors=[v6, v7, v8, v9])", "v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[256, 4, 1, 4])", "l18, l19, l20, l21 = sch.split(loop=l4, factors=[v14, v15, v16, v17])", "v22, v23 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[1152, 8])", "l24, l25 = sch.split(loop=l5, factors=[v22, v23])", "sch.reorder(l10, l18, l11, l19, l24, l12, l20, l25, l13, l21)", "b26, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b26, loop=l19, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v27 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v27)", "sch.enter_postproc()", "b28 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.unroll_explicit\")", "b29, b30 = sch.get_child_blocks(b28)", "l31, l32, l33, l34, l35, l36, l37, l38, l39, l40 = sch.get_loops(block=b29)", "l41 = sch.fuse(l31, l32)", "sch.parallel(loop=l41)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l42, l43, l44, l45, l46 = sch.get_loops(block=b30)", "l47 = sch.fuse(l45, l46)", "sch.vectorize(loop=l47)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b48 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "l49, l50, l51, l52, l53, l54, l55, l56, l57 = sch.get_loops(block=b48)", "b58 = sch.decompose_reduction(block=b48, loop=l52)"]
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4096), "float32"], placeholder_1: T.Buffer[(4096, 4096), "float32"], placeholder_2: T.Buffer[(1, 4096), "float32"], T_relu: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 4096], dtype="float32")
        T_add = T.alloc_buffer([1, 4096], dtype="float32")
        for i0, i1, i2 in T.grid(1, 4096, 4096):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[0, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
        for i0, i1 in T.grid(1, 4096):
            with T.block("T_add"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                T.writes(T_add[ax0, ax1])
                T_add[ax0, ax1] = T_matmul_NT[0, ax1] + placeholder_2[0, ax1]
        for i0, i1 in T.grid(1, 4096):
            with T.block("T_relu"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_add[0, ax1])
                T.writes(T_relu[ax0, ax1])
                T_relu[ax0, ax1] = T.max(T_add[0, ax1], T.float32(0))
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_dense_add_nn_relu_1(placeholder: T.Buffer[(1, 4096), "float32"], placeholder_1: T.Buffer[(4096, 4096), "float32"], placeholder_2: T.Buffer[(1, 4096), "float32"], T_relu: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 4096], dtype="float32")
        for i0_0_i1_0_fused in T.parallel(512, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i0_1, i1_1 in T.grid(1, 2):
                for i1_3_init in T.serial(4):
                    with T.block("T_matmul_NT_init"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(4096, i0_0_i1_0_fused * 8 + i1_1 * 4 + i1_3_init)
                        T.reads()
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T.float32(0)
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(4096, 1, 1, 1, 1, 4):
                    with T.block("T_matmul_NT_update"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(4096, i0_0_i1_0_fused * 8 + i1_1 * 4 + i1_3)
                        k = T.axis.reduce(4096, i2_0)
                        T.reads(T_matmul_NT[i, j], placeholder[0, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
                for ax0_ax1_fused in T.vectorized(4):
                    with T.block("T_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(4096, i0_0_i1_0_fused * 8 + i1_1 * 4 + ax0_ax1_fused)
                        T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                        T.writes(T_relu[ax0, ax1])
                        T_relu[ax0, ax1] = T.max(T_matmul_NT[0, ax1] + placeholder_2[0, ax1], T.float32(0))
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5 = sch.get_loops(block=b0)", "v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l10, l11, l12, l13 = sch.split(loop=l3, factors=[v6, v7, v8, v9])", "v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[512, 2, 1, 4])", "l18, l19, l20, l21 = sch.split(loop=l4, factors=[v14, v15, v16, v17])", "v22, v23 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[4096, 1])", "l24, l25 = sch.split(loop=l5, factors=[v22, v23])", "sch.reorder(l10, l18, l11, l19, l24, l12, l20, l25, l13, l21)", "b26, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b26, loop=l19, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v27 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v27)", "sch.enter_postproc()", "b28 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.unroll_explicit\")", "b29, b30 = sch.get_child_blocks(b28)", "l31, l32, l33, l34, l35, l36, l37, l38, l39, l40 = sch.get_loops(block=b29)", "l41 = sch.fuse(l31, l32)", "sch.parallel(loop=l41)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l42, l43, l44, l45, l46 = sch.get_loops(block=b30)", "l47 = sch.fuse(l45, l46)", "sch.vectorize(loop=l47)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b48 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "l49, l50, l51, l52, l53, l54, l55, l56, l57 = sch.get_loops(block=b48)", "b58 = sch.decompose_reduction(block=b48, loop=l52)"]
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4096), "float32"], placeholder_1: T.Buffer[(200, 4096), "float32"], placeholder_2: T.Buffer[(1, 200), "float32"], T_add: T.Buffer[(1, 200), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 200], dtype="float32")
        for i0, i1, i2 in T.grid(1, 200, 4096):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[0, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[0, k] * placeholder_1[j, k]
        for i0, i1 in T.grid(1, 200):
            with T.block("T_add"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                T.writes(T_add[ax0, ax1])
                T_add[ax0, ax1] = T_matmul_NT[0, ax1] + placeholder_2[0, ax1]
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_dense_add(placeholder: T.Buffer[(1, 4096), "float32"], placeholder_1: T.Buffer[(200, 4096), "float32"], placeholder_2: T.Buffer[(1, 200), "float32"], T_add: T.Buffer[(1, 200), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 200], dtype="float32")
        T_matmul_NT_rf = T.alloc_buffer([1, 200, 32], dtype="float32")
        for i0_i1_fused in T.parallel(200, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i2_1_fused_init in T.vectorized(32):
                with T.block("T_matmul_NT_rf_init"):
                    vi2_1 = T.axis.spatial(32, i2_1_fused_init)
                    i = T.axis.spatial(1, 0)
                    j = T.axis.spatial(200, i0_i1_fused)
                    T.reads()
                    T.writes(T_matmul_NT_rf[i, j, vi2_1])
                    T_matmul_NT_rf[i, j, vi2_1] = T.float32(0)
            for i2_0 in T.serial(128):
                for i2_1_fused in T.vectorized(32):
                    with T.block("T_matmul_NT_rf_update"):
                        vi2_1 = T.axis.spatial(32, i2_1_fused)
                        i = T.axis.spatial(1, 0)
                        j, vi2_0 = T.axis.remap("SR", [i0_i1_fused, i2_0])
                        T.reads(T_matmul_NT_rf[i, j, vi2_1], placeholder[0, vi2_0 * 32 + vi2_1], placeholder_1[j, vi2_0 * 32 + vi2_1])
                        T.writes(T_matmul_NT_rf[i, j, vi2_1])
                        T_matmul_NT_rf[i, j, vi2_1] = T_matmul_NT_rf[i, j, vi2_1] + placeholder[0, vi2_0 * 32 + vi2_1] * placeholder_1[j, vi2_0 * 32 + vi2_1]
        for i0_i1_fused in T.parallel(200, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            with T.block("T_matmul_NT_init"):
                i = T.axis.spatial(1, 0)
                j = T.axis.spatial(200, i0_i1_fused)
                T.reads()
                T.writes(T_matmul_NT[i, j])
                T_matmul_NT[i, j] = T.float32(0)
            for ax0, ax1, ax2 in T.grid(32, 1, 1):
                with T.block("T_matmul_NT_update"):
                    vi2_1 = T.axis.reduce(32, ax0)
                    i = T.axis.spatial(1, 0)
                    j = T.axis.spatial(200, i0_i1_fused)
                    T.reads(T_matmul_NT[i, j], T_matmul_NT_rf[i, j, vi2_1])
                    T.writes(T_matmul_NT[i, j])
                    T_matmul_NT[i, j] = T_matmul_NT[i, j] + T_matmul_NT_rf[i, j, vi2_1]
            with T.block("T_add"):
                ax0 = T.axis.spatial(1, 0)
                ax1 = T.axis.spatial(200, i0_i1_fused)
                T.reads(T_matmul_NT[0, ax1], placeholder_2[0, ax1])
                T.writes(T_add[ax0, ax1])
                T_add[ax0, ax1] = T_matmul_NT[0, ax1] + placeholder_2[0, ax1]
    

[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[22:26:02] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "b1 = sch.get_block(name=\"root\", func_name=\"main\")", "l2, l3, l4 = sch.get_loops(block=b0)", "v5, v6 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[128, 32])", "l7, l8 = sch.split(loop=l4, factors=[v5, v6])", "b9 = sch.rfactor(loop=l8, factor_axis=2)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.random_compute_producer\", ann_val=1)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v10 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v10)", "b11, = sch.get_producers(block=b0)", "sch.unannotate(block_or_loop=b0, ann_key=\"meta_schedule.random_compute_producer\")", "l12 = sch.sample_compute_location(block=b0, decision=1)", "sch.compute_at(block=b0, loop=l12, preserve_unit_loops=True)", "l13 = sch.sample_compute_location(block=b11, decision=-1)", "sch.compute_at(block=b11, loop=l13, preserve_unit_loops=True)", "sch.enter_postproc()", "b14 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b14, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b14, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b14, ann_key=\"meta_schedule.unroll_explicit\")", "b15, b16, b17 = sch.get_child_blocks(b14)", "l18, l19, l20, l21 = sch.get_loops(block=b15)", "l22 = sch.fuse(l18, l19)", "sch.parallel(loop=l22)", "l23 = sch.fuse(l21)", "sch.vectorize(loop=l23)", "sch.annotate(block_or_loop=l22, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l22, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l24, l25, l26, l27, l28 = sch.get_loops(block=b16)", "l29 = sch.fuse(l24, l25)", "sch.parallel(loop=l29)", "sch.annotate(block_or_loop=l29, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l29, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l30, = sch.get_loops(block=b17)", "sch.annotate(block_or_loop=l30, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l30, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b31 = sch.get_block(name=\"T_matmul_NT_rf\", func_name=\"main\")", "l32, l33, l34 = sch.get_loops(block=b31)", "b35 = sch.decompose_reduction(block=b31, loop=l33)", "b36 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "l37, l38, l39, l40 = sch.get_loops(block=b36)", "b41 = sch.decompose_reduction(block=b36, loop=l38)"]
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ubuntu/anaconda3/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/tune_relay_meta_schedule.py", line 198, in <module>
    main()
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/tune_relay_meta_schedule.py", line 188, in main
    run_module_via_rpc(
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/custom_builder_runner.py", line 170, in run_module_via_rpc
    return continuation(rt_mod, dev, args)
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/tune_relay_meta_schedule.py", line 177, in f_per_layer
    mod = create(graph, rt_mod, dev)
  File "/home/ubuntu/tvm/python/tvm/contrib/debugger/debug_executor.py", line 73, in create
    gmod = GraphModuleDebug(func_obj, dev, graph_json_str, dump_root)
  File "/home/ubuntu/tvm/python/tvm/contrib/debugger/debug_executor.py", line 116, in __init__
    self._run_individual_node = module["run_individual_node"]
  File "/home/ubuntu/tvm/python/tvm/runtime/module.py", line 169, in __getitem__
    return self.get_function(name)
  File "/home/ubuntu/tvm/python/tvm/runtime/module.py", line 153, in get_function
    raise AttributeError("Module has no function '%s'" % name)
AttributeError: Module has no function 'run_individual_node'
Running time in time_evaluator:  [3.3167441655629144, 3.315532562913907, 3.318453450331126]
Avg running time: 3.3169100596026495
