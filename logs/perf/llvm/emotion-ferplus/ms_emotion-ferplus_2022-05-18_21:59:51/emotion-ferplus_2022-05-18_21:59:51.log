2022-05-18 21:59:58.310 INFO RPCRunner: max_workers = 1
https://storage.cloud.google.com/octoml-aquarium-models/onnx_model_zoo/vision_body_analysis_emotion-ferplus.onnx
file existed. Skipping downloading.
/home/ubuntu/cache-workloads/emotion-ferplus.onnx
Workload: emotion-ferplus
  input_name: Input3
  input_shape: [1, 1, 64, 64]
  input_dtype: float32
2022-05-18 22:00:00.995 INFO Logging directory: /home/ubuntu/tvm/logs/perf/llvm/emotion-ferplus//ms_emotion-ferplus_2022-05-18_21:59:51/logs
2022-05-18 22:00:00.996 INFO Working directory: /home/ubuntu/tvm/logs/perf/llvm/emotion-ferplus//ms_emotion-ferplus_2022-05-18_21:59:51/
2022-05-18 22:00:00.996 INFO Creating JSONDatabase. Workload at: /home/ubuntu/tvm/logs/perf/llvm/emotion-ferplus//ms_emotion-ferplus_2022-05-18_21:59:51/database_workload.json. Tuning records at: /home/ubuntu/tvm/logs/perf/llvm/emotion-ferplus//ms_emotion-ferplus_2022-05-18_21:59:51/database_tuning_record.json
2022-05-18 22:00:00.996 INFO LocalBuilder: max_workers = 48
2022-05-18 22:00:04.418 INFO 
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |            N/A |          N/A |                   N/A |      0 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 |                                  fused_nn_pad |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 0
Total latency (us): 0

2022-05-18 22:00:04.418 INFO Scheduler picks Task #0: "fused_subtract_divide_nn_pad_layout_transform"
2022-05-18 22:00:11.494 INFO Sending 28 sample(s) to builder
2022-05-18 22:00:12.498 INFO Sending 28 sample(s) to runner
WARNING:RPCServer:Cannot connect to tracker ('172.31.51.147', 4445), retry in 5 secs...
2022-05-18 22:00:12.509 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
WARNING:RPCServer:Cannot connect to tracker ('172.31.51.147', 4445), retry in 5 secs...
2022-05-18 22:00:18.574 INFO Sending 64 sample(s) to builder
WARNING:RPCServer:Cannot connect to tracker ('172.31.51.147', 4445), retry in 5 secs...
2022-05-18 22:00:34.190 INFO Sending 64 sample(s) to runner
2022-05-18 22:00:34.234 INFO Scheduler picks Task #2: "fused_nn_pad"
2022-05-18 22:00:36.189 INFO Sending 12 sample(s) to builder
2022-05-18 22:00:36.913 INFO Sending 12 sample(s) to runner
2022-05-18 22:00:36.918 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 22:00:44.127 INFO Sending 64 sample(s) to builder
2022-05-18 22:00:51.023 INFO Sending 64 sample(s) to runner
2022-05-18 22:00:51.067 INFO Scheduler picks Task #4: "fused_nn_max_pool2d"
2022-05-18 22:00:52.695 INFO Sending 12 sample(s) to builder
2022-05-18 22:00:53.315 INFO Sending 12 sample(s) to runner
2022-05-18 22:00:53.320 INFO Scheduler picks Task #5: "fused_nn_pad_1"
2022-05-18 22:00:55.282 INFO Sending 12 sample(s) to builder
2022-05-18 22:00:55.883 INFO Sending 12 sample(s) to runner
2022-05-18 22:00:55.888 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-18 22:01:03.146 INFO Sending 64 sample(s) to builder
2022-05-18 22:01:10.262 INFO Sending 64 sample(s) to runner
2022-05-18 22:01:10.307 INFO Scheduler picks Task #7: "fused_nn_pad_2"
2022-05-18 22:01:12.280 INFO Sending 12 sample(s) to builder
2022-05-18 22:01:12.926 INFO Sending 12 sample(s) to runner
2022-05-18 22:01:12.931 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 22:01:20.167 INFO Sending 64 sample(s) to builder
2022-05-18 22:01:26.745 INFO Sending 64 sample(s) to runner
2022-05-18 22:01:26.834 INFO Scheduler picks Task #9: "fused_nn_max_pool2d_1"
2022-05-18 22:01:29.270 INFO Sending 12 sample(s) to builder
2022-05-18 22:01:30.256 INFO Sending 12 sample(s) to runner
2022-05-18 22:01:30.261 INFO Scheduler picks Task #10: "fused_nn_pad_3"
2022-05-18 22:01:33.452 INFO Sending 12 sample(s) to builder
2022-05-18 22:01:34.467 INFO Sending 12 sample(s) to runner
2022-05-18 22:01:34.473 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-18 22:01:41.945 INFO Sending 64 sample(s) to builder
2022-05-18 22:01:50.815 INFO Sending 64 sample(s) to runner
2022-05-18 22:01:50.913 INFO Scheduler picks Task #12: "fused_nn_pad_4"
2022-05-18 22:01:53.472 INFO Sending 12 sample(s) to builder
2022-05-18 22:01:54.415 INFO Sending 12 sample(s) to runner
2022-05-18 22:01:54.420 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:02:01.794 INFO Sending 64 sample(s) to builder
2022-05-18 22:02:07.774 INFO Sending 64 sample(s) to runner
2022-05-18 22:02:07.818 INFO Scheduler picks Task #14: "fused_nn_max_pool2d_2"
2022-05-18 22:02:10.191 INFO Sending 12 sample(s) to builder
2022-05-18 22:02:11.207 INFO Sending 12 sample(s) to runner
2022-05-18 22:02:11.212 INFO Scheduler picks Task #15: "fused_nn_pad_5"
2022-05-18 22:02:13.342 INFO Sending 12 sample(s) to builder
2022-05-18 22:02:14.117 INFO Sending 12 sample(s) to runner
2022-05-18 22:02:14.123 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 22:02:23.433 INFO Sending 64 sample(s) to builder
2022-05-18 22:02:40.752 INFO Sending 64 sample(s) to runner
2022-05-18 22:02:40.802 INFO Scheduler picks Task #17: "fused_nn_max_pool2d_3"
2022-05-18 22:02:45.225 INFO Sending 16 sample(s) to builder
2022-05-18 22:02:48.864 INFO Sending 16 sample(s) to runner
2022-05-18 22:02:48.871 INFO Scheduler picks Task #18: "fused_layout_transform_reshape"
2022-05-18 22:02:52.884 INFO Sending 16 sample(s) to builder
2022-05-18 22:02:54.995 INFO Sending 16 sample(s) to runner
2022-05-18 22:02:55.005 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-18 22:03:00.658 INFO Sending 64 sample(s) to builder
2022-05-18 22:03:29.820 INFO Sending 64 sample(s) to runner
2022-05-18 22:03:29.900 INFO Scheduler picks Task #20: "fused_nn_dense_add_nn_relu_1"
2022-05-18 22:03:34.726 INFO Sending 64 sample(s) to builder
2022-05-18 22:03:45.150 INFO Sending 64 sample(s) to runner
2022-05-18 22:03:45.258 INFO Scheduler picks Task #21: "fused_nn_dense_add"
2022-05-18 22:03:53.415 INFO Sending 64 sample(s) to builder
2022-05-18 22:03:58.518 INFO Sending 64 sample(s) to runner
2022-05-18 22:04:05.690 INFO [Updated] Task #0: "fused_subtract_divide_nn_pad_layout_transform"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |            N/A |          N/A |                   N/A |      0 |            
  2 |                                  fused_nn_pad |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 28
Total latency (us): 2.61248

2022-05-18 22:04:12.916 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 92
Total latency (us): 13.2039

2022-05-18 22:04:18.076 INFO [Updated] Task #2: "fused_nn_pad"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |            N/A |          N/A |                   N/A |      0 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 104
Total latency (us): 16.6805

2022-05-18 22:04:27.416 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |            N/A |          N/A |                   N/A |      0 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 168
Total latency (us): 208.966

2022-05-18 22:04:38.303 INFO [Updated] Task #4: "fused_nn_max_pool2d"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 180
Total latency (us): 211.716

2022-05-18 22:04:45.372 INFO [Updated] Task #5: "fused_nn_pad_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |            N/A |          N/A |                   N/A |      0 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 192
Total latency (us): 214.756

2022-05-18 22:04:57.842 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 256
Total latency (us): 345.801

2022-05-18 22:05:09.376 INFO [Updated] Task #7: "fused_nn_pad_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |            N/A |          N/A |                   N/A |      0 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 268
Total latency (us): 348.674

2022-05-18 22:05:18.760 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |            N/A |          N/A |                   N/A |      0 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 332
Total latency (us): 498.488

2022-05-18 22:05:25.857 INFO [Updated] Task #9: "fused_nn_max_pool2d_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 344
Total latency (us): 501.203

2022-05-18 22:05:42.614 INFO [Updated] Task #10: "fused_nn_pad_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |            N/A |          N/A |                   N/A |      0 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 356
Total latency (us): 503.835

2022-05-18 22:05:52.742 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 420
Total latency (us): 619.763

2022-05-18 22:05:59.951 INFO [Updated] Task #12: "fused_nn_pad_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |            N/A |          N/A |                   N/A |      0 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 432
Total latency (us): 625.455

2022-05-18 22:06:18.179 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      1032.3911 |     292.6420 |              585.2839 |     64 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |            N/A |          N/A |                   N/A |      0 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 496
Total latency (us): 1210.74

2022-05-18 22:06:23.818 INFO [Updated] Task #14: "fused_nn_max_pool2d_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      1032.3911 |     292.6420 |              585.2839 |     64 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |            N/A |          N/A |                   N/A |      0 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 508
Total latency (us): 1213.4

2022-05-18 22:06:30.546 INFO [Updated] Task #15: "fused_nn_pad_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      1032.3911 |     292.6420 |              585.2839 |     64 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |            N/A |          N/A |                   N/A |      0 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 520
Total latency (us): 1221.02

2022-05-18 22:06:56.440 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      1032.3911 |     292.6420 |              585.2839 |     64 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      1502.4774 |      50.2705 |              150.8114 |     64 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |            N/A |          N/A |                   N/A |      0 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 584
Total latency (us): 1371.84

2022-05-18 22:07:04.713 INFO [Updated] Task #17: "fused_nn_max_pool2d_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      1032.3911 |     292.6420 |              585.2839 |     64 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      1502.4774 |      50.2705 |              150.8114 |     64 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |            N/A |          N/A |                   N/A |      0 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 600
Total latency (us): 1374.41

2022-05-18 22:07:12.893 INFO [Updated] Task #18: "fused_layout_transform_reshape"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      1032.3911 |     292.6420 |              585.2839 |     64 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      1502.4774 |      50.2705 |              150.8114 |     64 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |            N/A |          N/A |                   N/A |      0 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 616
Total latency (us): 1377.51

2022-05-18 22:07:35.802 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      1032.3911 |     292.6420 |              585.2839 |     64 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      1502.4774 |      50.2705 |              150.8114 |     64 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |            N/A |          N/A |                   N/A |      0 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 680
Total latency (us): 1458.44

2022-05-18 22:07:47.015 INFO [Updated] Task #20: "fused_nn_dense_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      1032.3911 |     292.6420 |              585.2839 |     64 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      1502.4774 |      50.2705 |              150.8114 |     64 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |            N/A |          N/A |                   N/A |      0 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 744
Total latency (us): 1478.48

2022-05-18 22:07:54.477 INFO [Updated] Task #21: "fused_nn_dense_add"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      1032.3911 |     292.6420 |              585.2839 |     64 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      1502.4774 |      50.2705 |              150.8114 |     64 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 808
Total latency (us): 1480.16

2022-05-18 22:07:54.477 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:08:17.732 INFO Sending 64 sample(s) to builder
2022-05-18 22:08:24.127 INFO Sending 64 sample(s) to runner
2022-05-18 22:09:04.169 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      1573.2550 |     192.2855 |              192.2855 |     64 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2672.9954 |     113.0271 |              226.0542 |    128 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      1502.4774 |      50.2705 |              150.8114 |     64 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 872
Total latency (us): 1120.93

2022-05-18 22:09:04.169 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:09:21.405 INFO Sending 64 sample(s) to builder
2022-05-18 22:09:28.398 INFO Sending 64 sample(s) to runner
2022-05-18 22:09:28.471 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 22:09:44.130 INFO Sending 64 sample(s) to builder
2022-05-18 22:09:48.851 INFO Sending 64 sample(s) to runner
2022-05-18 22:10:38.617 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2054.4015 |     147.2517 |              147.2517 |    128 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2672.9954 |     113.0271 |              226.0542 |    128 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      1502.4774 |      50.2705 |              150.8114 |     64 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 936
Total latency (us): 1075.9

2022-05-18 22:10:38.617 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 22:10:55.960 INFO Sending 64 sample(s) to builder
2022-05-18 22:11:05.109 INFO Sending 64 sample(s) to runner
2022-05-18 22:11:22.195 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2054.4015 |     147.2517 |              147.2517 |    128 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      1502.4774 |      50.2705 |              150.8114 |     64 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1000
Total latency (us): 1069.45

2022-05-18 22:11:22.195 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 22:11:48.613 INFO Sending 64 sample(s) to builder
2022-05-18 22:12:05.880 INFO Sending 64 sample(s) to runner
2022-05-18 22:12:17.742 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      1502.4774 |      50.2705 |              150.8114 |     64 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1064
Total latency (us): 1049.84

2022-05-18 22:12:42.589 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    128 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1128
Total latency (us): 987.946

2022-05-18 22:12:42.589 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 22:13:08.058 INFO Sending 64 sample(s) to builder
2022-05-18 22:13:26.385 INFO Sending 64 sample(s) to runner
2022-05-18 22:13:26.547 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 22:13:53.578 INFO Sending 64 sample(s) to builder
2022-05-18 22:14:07.493 INFO Sending 64 sample(s) to runner
2022-05-18 22:14:25.238 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2017.5171 |     149.8139 |              149.8139 |     64 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1192
Total latency (us): 987.946

2022-05-18 22:14:47.261 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2641.7728 |     114.4126 |              114.4126 |    128 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1256
Total latency (us): 952.545

2022-05-18 22:14:47.261 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 22:15:12.698 INFO Sending 64 sample(s) to builder
2022-05-18 22:15:26.434 INFO Sending 64 sample(s) to runner
2022-05-18 22:15:26.563 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-18 22:15:52.609 INFO Sending 64 sample(s) to builder
2022-05-18 22:16:17.357 INFO Sending 64 sample(s) to runner
2022-05-18 22:16:34.913 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      1154.2364 |     131.0452 |              131.0452 |     64 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1320
Total latency (us): 951.489

2022-05-18 22:16:51.358 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2167.3435 |      69.7892 |               69.7892 |    128 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1384
Total latency (us): 890.233

2022-05-18 22:16:51.358 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-18 22:17:18.493 INFO Sending 64 sample(s) to builder
2022-05-18 22:17:29.204 INFO Sending 64 sample(s) to runner
2022-05-18 22:17:29.336 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-18 22:17:56.706 INFO Sending 64 sample(s) to builder
2022-05-18 22:18:16.842 INFO Sending 64 sample(s) to runner
2022-05-18 22:18:34.999 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1303.6186 |     115.9281 |              115.9281 |     64 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1448
Total latency (us): 877.002

2022-05-18 22:18:53.143 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1500.5791 |     100.7118 |              100.7118 |    128 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       103.6690 |      80.9370 |               80.9370 |     64 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1512
Total latency (us): 861.786

2022-05-18 22:18:53.143 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-18 22:19:21.641 INFO Sending 64 sample(s) to builder
2022-05-18 22:19:33.532 INFO Sending 64 sample(s) to runner
2022-05-18 22:19:33.710 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-18 22:19:45.078 INFO Sending 64 sample(s) to builder
2022-05-18 22:19:51.028 INFO Sending 64 sample(s) to runner
2022-05-18 22:20:31.854 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      1500.5791 |     100.7118 |              100.7118 |    128 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       110.4488 |      75.9687 |               75.9687 |    128 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1576
Total latency (us): 856.818

2022-05-18 22:20:31.854 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-18 22:20:47.089 INFO Sending 64 sample(s) to builder
2022-05-18 22:20:51.720 INFO Sending 64 sample(s) to runner
2022-05-18 22:21:01.770 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       110.4488 |      75.9687 |               75.9687 |    128 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1640
Total latency (us): 826.995

2022-05-18 22:21:01.770 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:21:32.637 INFO Sending 64 sample(s) to builder
2022-05-18 22:21:40.646 INFO Sending 64 sample(s) to runner
2022-05-18 22:21:50.791 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2751.4985 |     109.8023 |              219.6047 |    192 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1704
Total latency (us): 826.381

2022-05-18 22:22:25.034 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    256 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1768
Total latency (us): 821.331

2022-05-18 22:22:25.035 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:22:51.484 INFO Sending 64 sample(s) to builder
2022-05-18 22:22:58.888 INFO Sending 64 sample(s) to runner
2022-05-18 22:23:36.815 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    320 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1832
Total latency (us): 821.331

2022-05-18 22:23:36.815 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:23:53.917 INFO Sending 64 sample(s) to builder
2022-05-18 22:23:59.317 INFO Sending 64 sample(s) to runner
2022-05-18 22:24:44.407 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    384 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1896
Total latency (us): 821.331

2022-05-18 22:24:44.407 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:25:08.872 INFO Sending 64 sample(s) to builder
2022-05-18 22:25:30.168 INFO Sending 64 sample(s) to runner
2022-05-18 22:25:30.547 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 22:25:56.967 INFO Sending 64 sample(s) to builder
2022-05-18 22:26:01.433 INFO Sending 64 sample(s) to runner
2022-05-18 22:26:13.009 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2369.9945 |     127.6434 |              127.6434 |    192 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    448 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1960
Total latency (us): 821.331

2022-05-18 22:26:26.926 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2789.7813 |     108.4365 |              108.4365 |    256 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    448 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2024
Total latency (us): 802.124

2022-05-18 22:26:26.926 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 22:26:49.867 INFO Sending 64 sample(s) to builder
2022-05-18 22:26:57.701 INFO Sending 64 sample(s) to runner
2022-05-18 22:26:57.912 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 22:27:20.488 INFO Sending 64 sample(s) to builder
2022-05-18 22:27:27.627 INFO Sending 64 sample(s) to runner
2022-05-18 22:27:50.833 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2666.3765 |     113.3568 |              113.3568 |    192 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    448 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2088
Total latency (us): 801.326

2022-05-18 22:28:02.647 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2681.5505 |     112.7154 |              112.7154 |    256 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    448 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2152
Total latency (us): 800.685

2022-05-18 22:28:02.647 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 22:28:31.403 INFO Sending 64 sample(s) to builder
2022-05-18 22:28:37.277 INFO Sending 64 sample(s) to runner
2022-05-18 22:29:17.019 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    320 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    448 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2216
Total latency (us): 799.077

2022-05-18 22:29:17.019 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 22:29:33.342 INFO Sending 64 sample(s) to builder
2022-05-18 22:29:36.847 INFO Sending 64 sample(s) to runner
2022-05-18 22:29:36.925 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:30:07.717 INFO Sending 64 sample(s) to builder
2022-05-18 22:30:15.442 INFO Sending 64 sample(s) to runner
2022-05-18 22:30:39.719 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    448 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2280
Total latency (us): 799.077

2022-05-18 22:30:57.815 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    512 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2548.3336 |      29.6391 |               88.9172 |    192 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2344
Total latency (us): 799.077

2022-05-18 22:30:57.815 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 22:31:20.148 INFO Sending 64 sample(s) to builder
2022-05-18 22:31:33.704 INFO Sending 64 sample(s) to runner
2022-05-18 22:32:06.221 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    512 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2571.3374 |      29.3739 |               88.1217 |    256 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2408
Total latency (us): 798.282

2022-05-18 22:32:06.221 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 22:32:27.568 INFO Sending 64 sample(s) to builder
2022-05-18 22:32:34.314 INFO Sending 64 sample(s) to runner
2022-05-18 22:33:32.672 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    512 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2575.3063 |      29.3286 |               87.9859 |    320 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2472
Total latency (us): 798.146

2022-05-18 22:33:32.673 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 22:33:54.912 INFO Sending 64 sample(s) to builder
2022-05-18 22:34:06.252 INFO Sending 64 sample(s) to runner
2022-05-18 22:34:06.301 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:34:35.720 INFO Sending 64 sample(s) to builder
2022-05-18 22:34:47.034 INFO Sending 64 sample(s) to runner
2022-05-18 22:35:08.498 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    512 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2536
Total latency (us): 797.59

2022-05-18 22:35:25.713 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    576 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    192 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2600
Total latency (us): 797.59

2022-05-18 22:35:25.713 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:35:43.886 INFO Sending 64 sample(s) to builder
2022-05-18 22:35:57.048 INFO Sending 64 sample(s) to runner
2022-05-18 22:35:57.182 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-18 22:36:10.955 INFO Sending 64 sample(s) to builder
2022-05-18 22:36:17.024 INFO Sending 64 sample(s) to runner
2022-05-18 22:37:08.911 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    576 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    256 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2664
Total latency (us): 797.59

2022-05-18 22:37:08.911 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-18 22:37:23.085 INFO Sending 64 sample(s) to builder
2022-05-18 22:37:31.624 INFO Sending 64 sample(s) to runner
2022-05-18 22:37:49.428 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    640 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       111.3493 |      75.3543 |               75.3543 |    256 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2728
Total latency (us): 797.59

2022-05-18 22:37:49.428 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 22:38:17.502 INFO Sending 64 sample(s) to builder
2022-05-18 22:38:24.236 INFO Sending 64 sample(s) to runner
2022-05-18 22:38:36.415 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2810.4569 |     107.6388 |              107.6388 |    320 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    640 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2792
Total latency (us): 794.218

2022-05-18 22:39:00.304 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.5035 |     105.7926 |              105.7926 |    384 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    640 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2856
Total latency (us): 792.372

2022-05-18 22:39:00.305 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 22:39:28.249 INFO Sending 64 sample(s) to builder
2022-05-18 22:39:46.748 INFO Sending 64 sample(s) to runner
2022-05-18 22:39:46.818 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-18 22:40:06.933 INFO Sending 64 sample(s) to builder
2022-05-18 22:40:12.228 INFO Sending 64 sample(s) to runner
2022-05-18 22:40:24.308 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2131.8663 |      70.8891 |               70.8891 |    192 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    640 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2920
Total latency (us): 792.363

2022-05-18 22:40:55.304 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2695.4566 |      56.0669 |               56.0669 |    256 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    640 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2984
Total latency (us): 777.541

2022-05-18 22:40:55.304 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-18 22:41:20.559 INFO Sending 64 sample(s) to builder
2022-05-18 22:41:26.526 INFO Sending 64 sample(s) to runner
2022-05-18 22:41:26.613 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:41:57.431 INFO Sending 64 sample(s) to builder
2022-05-18 22:42:06.308 INFO Sending 64 sample(s) to runner
2022-05-18 22:42:36.010 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    640 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3048
Total latency (us): 776.596

2022-05-18 22:42:58.418 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    704 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       104.7931 |      20.0319 |               20.0319 |     64 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3112
Total latency (us): 776.596

2022-05-18 22:42:58.419 INFO Scheduler picks Task #20: "fused_nn_dense_add_nn_relu_1"
2022-05-18 22:43:11.437 INFO Sending 64 sample(s) to builder
2022-05-18 22:43:28.396 INFO Sending 64 sample(s) to runner
2022-05-18 22:44:07.777 INFO [Updated] Task #20: "fused_nn_dense_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    704 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    128 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3176
Total latency (us): 774.655

2022-05-18 22:44:07.777 INFO Scheduler picks Task #20: "fused_nn_dense_add_nn_relu_1"
2022-05-18 22:44:16.072 INFO Sending 64 sample(s) to builder
2022-05-18 22:44:26.750 INFO Sending 64 sample(s) to runner
2022-05-18 22:44:26.868 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:44:59.401 INFO Sending 64 sample(s) to builder
2022-05-18 22:45:08.408 INFO Sending 64 sample(s) to runner
2022-05-18 22:45:34.164 INFO [Updated] Task #20: "fused_nn_dense_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    704 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3240
Total latency (us): 774.655

2022-05-18 22:46:12.922 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    768 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3304
Total latency (us): 774.655

2022-05-18 22:46:12.923 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:46:44.435 INFO Sending 64 sample(s) to builder
2022-05-18 22:46:51.935 INFO Sending 64 sample(s) to runner
2022-05-18 22:46:52.025 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-18 22:47:21.422 INFO Sending 64 sample(s) to builder
2022-05-18 22:47:31.205 INFO Sending 64 sample(s) to runner
2022-05-18 22:48:02.550 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2674.3647 |      56.5581 |               56.5581 |    192 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    832 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3368
Total latency (us): 774.655

2022-05-18 22:48:15.463 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2799.5909 |      54.0283 |               54.0283 |    256 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    832 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3432
Total latency (us): 772.125

2022-05-18 22:48:15.463 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-18 22:48:35.586 INFO Sending 64 sample(s) to builder
2022-05-18 22:48:44.317 INFO Sending 64 sample(s) to runner
2022-05-18 22:49:27.502 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    320 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    832 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3496
Total latency (us): 771.93

2022-05-18 22:49:27.502 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-18 22:49:53.046 INFO Sending 64 sample(s) to builder
2022-05-18 22:50:00.108 INFO Sending 64 sample(s) to runner
2022-05-18 22:50:00.199 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 22:50:29.418 INFO Sending 64 sample(s) to builder
2022-05-18 22:51:01.774 INFO Sending 64 sample(s) to runner
2022-05-18 22:51:17.232 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2720.3439 |     111.1080 |              111.1080 |    384 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    832 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3560
Total latency (us): 771.93

2022-05-18 22:51:52.150 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2892.0485 |     104.5114 |              104.5114 |    448 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    832 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3624
Total latency (us): 765.333

2022-05-18 22:51:52.151 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 22:52:17.399 INFO Sending 64 sample(s) to builder
2022-05-18 22:52:26.430 INFO Sending 64 sample(s) to runner
2022-05-18 22:52:26.601 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:52:54.802 INFO Sending 64 sample(s) to builder
2022-05-18 22:53:16.809 INFO Sending 64 sample(s) to runner
2022-05-18 22:53:48.503 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    832 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3688
Total latency (us): 764.521

2022-05-18 22:54:05.958 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2859.7432 |     105.7837 |              105.7837 |    448 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    896 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3752
Total latency (us): 764.521

2022-05-18 22:54:05.959 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 22:54:36.766 INFO Sending 64 sample(s) to builder
2022-05-18 22:54:45.617 INFO Sending 64 sample(s) to runner
2022-05-18 22:55:25.155 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.2255 |     105.3974 |              105.3974 |    512 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    896 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3816
Total latency (us): 764.134

2022-05-18 22:55:25.155 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 22:55:41.187 INFO Sending 64 sample(s) to builder
2022-05-18 22:55:47.608 INFO Sending 64 sample(s) to runner
2022-05-18 22:55:47.785 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 22:56:18.938 INFO Sending 64 sample(s) to builder
2022-05-18 22:56:29.302 INFO Sending 64 sample(s) to runner
2022-05-18 22:56:54.387 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    896 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3880
Total latency (us): 764.123

2022-05-18 22:57:20.720 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2741.6363 |      55.1226 |               55.1226 |    320 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    960 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3944
Total latency (us): 764.123

2022-05-18 22:57:20.720 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-18 22:57:51.763 INFO Sending 64 sample(s) to builder
2022-05-18 22:58:00.242 INFO Sending 64 sample(s) to runner
2022-05-18 22:58:42.303 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    384 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    960 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4008
Total latency (us): 762.979

2022-05-18 22:58:42.304 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-18 22:59:00.229 INFO Sending 64 sample(s) to builder
2022-05-18 22:59:08.637 INFO Sending 64 sample(s) to runner
2022-05-18 22:59:08.777 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-18 22:59:25.087 INFO Sending 64 sample(s) to builder
2022-05-18 22:59:36.889 INFO Sending 64 sample(s) to runner
2022-05-18 23:00:01.945 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    960 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    320 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4072
Total latency (us): 762.979

2022-05-18 23:00:30.712 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    960 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.6837 |      29.1433 |               87.4299 |    384 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    384 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4136
Total latency (us): 762.979

2022-05-18 23:00:30.713 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 23:00:57.625 INFO Sending 64 sample(s) to builder
2022-05-18 23:01:21.830 INFO Sending 64 sample(s) to runner
2022-05-18 23:02:16.541 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    960 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2591.9420 |      29.1404 |               87.4212 |    448 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    384 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4200
Total latency (us): 762.971

2022-05-18 23:02:16.541 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 23:02:36.487 INFO Sending 64 sample(s) to builder
2022-05-18 23:02:40.211 INFO Sending 64 sample(s) to runner
2022-05-18 23:02:40.299 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:02:59.544 INFO Sending 64 sample(s) to builder
2022-05-18 23:03:07.338 INFO Sending 64 sample(s) to runner
2022-05-18 23:03:34.233 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |    960 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    384 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4264
Total latency (us): 762.312

2022-05-18 23:04:00.720 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |   1024 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    384 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4328
Total latency (us): 762.312

2022-05-18 23:04:00.721 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:04:35.663 INFO Sending 64 sample(s) to builder
2022-05-18 23:04:42.597 INFO Sending 64 sample(s) to runner
2022-05-18 23:04:42.738 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 23:05:13.791 INFO Sending 64 sample(s) to builder
2022-05-18 23:05:23.687 INFO Sending 64 sample(s) to runner
2022-05-18 23:05:55.803 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2914.7024 |     103.6991 |              103.6991 |    512 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |   1088 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    384 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4392
Total latency (us): 762.312

2022-05-18 23:06:11.108 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    576 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |   1088 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    384 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4456
Total latency (us): 762.048

2022-05-18 23:06:11.109 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 23:06:38.697 INFO Sending 64 sample(s) to builder
2022-05-18 23:06:48.243 INFO Sending 64 sample(s) to runner
2022-05-18 23:06:48.368 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:07:17.960 INFO Sending 64 sample(s) to builder
2022-05-18 23:07:24.175 INFO Sending 64 sample(s) to runner
2022-05-18 23:07:58.882 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |   1088 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    384 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4520
Total latency (us): 762.048

2022-05-18 23:08:23.841 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |   1152 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    384 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4584
Total latency (us): 762.048

2022-05-18 23:08:23.841 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-18 23:08:37.920 INFO Sending 64 sample(s) to builder
2022-05-18 23:08:49.053 INFO Sending 64 sample(s) to runner
2022-05-18 23:09:42.581 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |   1152 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    448 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4648
Total latency (us): 762.048

2022-05-18 23:09:42.582 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-18 23:09:52.114 INFO Sending 64 sample(s) to builder
2022-05-18 23:09:58.322 INFO Sending 64 sample(s) to runner
2022-05-18 23:09:58.400 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:10:17.885 INFO Sending 64 sample(s) to builder
2022-05-18 23:10:24.466 INFO Sending 64 sample(s) to runner
2022-05-18 23:10:40.215 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2816.2606 |     107.2773 |              214.5547 |   1152 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4712
Total latency (us): 762.048

2022-05-18 23:11:22.278 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2825.2198 |     106.9372 |              213.8743 |   1216 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4776
Total latency (us): 761.368

2022-05-18 23:11:22.278 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:11:47.518 INFO Sending 64 sample(s) to builder
2022-05-18 23:11:55.942 INFO Sending 64 sample(s) to runner
2022-05-18 23:11:56.064 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 23:12:24.832 INFO Sending 64 sample(s) to builder
2022-05-18 23:12:59.899 INFO Sending 64 sample(s) to runner
2022-05-18 23:13:29.867 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2870.5327 |     105.3861 |              105.3861 |    576 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2825.2198 |     106.9372 |              213.8743 |   1280 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4840
Total latency (us): 761.368

2022-05-18 23:13:56.665 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    640 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2825.2198 |     106.9372 |              213.8743 |   1280 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4904
Total latency (us): 761.269

2022-05-18 23:13:56.665 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 23:14:28.539 INFO Sending 64 sample(s) to builder
2022-05-18 23:14:37.634 INFO Sending 64 sample(s) to runner
2022-05-18 23:14:37.719 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 23:14:58.547 INFO Sending 64 sample(s) to builder
2022-05-18 23:15:05.122 INFO Sending 64 sample(s) to runner
2022-05-18 23:15:35.394 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    704 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2825.2198 |     106.9372 |              213.8743 |   1280 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    512 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4968
Total latency (us): 761.269

2022-05-18 23:16:03.105 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    704 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2825.2198 |     106.9372 |              213.8743 |   1280 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    576 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5032
Total latency (us): 761.269

2022-05-18 23:16:03.105 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:16:35.787 INFO Sending 64 sample(s) to builder
2022-05-18 23:16:56.741 INFO Sending 64 sample(s) to runner
2022-05-18 23:17:40.132 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    704 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2825.2198 |     106.9372 |              213.8743 |   1344 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    576 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5096
Total latency (us): 761.269

2022-05-18 23:17:40.132 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:18:13.198 INFO Sending 64 sample(s) to builder
2022-05-18 23:18:22.026 INFO Sending 64 sample(s) to runner
2022-05-18 23:18:22.121 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-18 23:18:41.466 INFO Sending 64 sample(s) to builder
2022-05-18 23:18:56.225 INFO Sending 64 sample(s) to runner
2022-05-18 23:19:29.567 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       495.0096 |      10.5915 |               10.5915 |     64 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    704 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2825.2198 |     106.9372 |              213.8743 |   1408 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    576 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5160
Total latency (us): 761.269

2022-05-18 23:19:51.156 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       751.6991 |       6.9747 |                6.9747 |    128 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    704 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2825.2198 |     106.9372 |              213.8743 |   1408 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    576 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5224
Total latency (us): 757.653

2022-05-18 23:19:51.156 INFO Scheduler picks Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2022-05-18 23:20:18.379 INFO Sending 64 sample(s) to builder
2022-05-18 23:20:33.100 INFO Sending 64 sample(s) to runner
2022-05-18 23:20:33.282 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 23:21:03.632 INFO Sending 64 sample(s) to builder
2022-05-18 23:21:11.319 INFO Sending 64 sample(s) to runner
2022-05-18 23:21:37.859 INFO [Updated] Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    704 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2922.1276 |     103.4356 |              103.4356 |    640 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2825.2198 |     106.9372 |              213.8743 |   1408 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    576 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5288
Total latency (us): 756.66

2022-05-18 23:21:52.777 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    704 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    704 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2825.2198 |     106.9372 |              213.8743 |   1408 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    576 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5352
Total latency (us): 755.683

2022-05-18 23:21:52.777 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:22:24.245 INFO Sending 64 sample(s) to builder
2022-05-18 23:22:39.220 INFO Sending 64 sample(s) to runner
2022-05-18 23:23:23.732 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    704 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    704 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2825.2198 |     106.9372 |              213.8743 |   1472 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    576 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5416
Total latency (us): 755.683

2022-05-18 23:23:23.733 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:23:52.992 INFO Sending 64 sample(s) to builder
2022-05-18 23:24:21.159 INFO Sending 64 sample(s) to runner
2022-05-18 23:24:21.292 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 23:24:42.355 INFO Sending 64 sample(s) to builder
2022-05-18 23:24:53.105 INFO Sending 64 sample(s) to runner
2022-05-18 23:25:24.848 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    704 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    704 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1536 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    576 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5480
Total latency (us): 755.134

2022-05-18 23:25:54.568 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    704 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    704 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1536 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    640 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5544
Total latency (us): 755.134

2022-05-18 23:25:54.568 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 23:26:26.771 INFO Sending 64 sample(s) to builder
2022-05-18 23:26:35.604 INFO Sending 64 sample(s) to runner
2022-05-18 23:27:27.167 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    768 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    704 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1536 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    640 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5608
Total latency (us): 755.134

2022-05-18 23:27:27.167 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 23:27:45.348 INFO Sending 64 sample(s) to builder
2022-05-18 23:27:48.957 INFO Sending 64 sample(s) to runner
2022-05-18 23:27:49.003 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 23:28:20.632 INFO Sending 64 sample(s) to builder
2022-05-18 23:28:30.971 INFO Sending 64 sample(s) to runner
2022-05-18 23:29:11.290 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    704 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1536 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    640 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5672
Total latency (us): 755.134

2022-05-18 23:29:32.341 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    384 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    768 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1536 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    640 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5736
Total latency (us): 755.134

2022-05-18 23:29:32.341 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-18 23:29:53.139 INFO Sending 64 sample(s) to builder
2022-05-18 23:30:06.864 INFO Sending 64 sample(s) to runner
2022-05-18 23:30:54.064 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    448 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    768 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1536 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    640 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5800
Total latency (us): 755.134

2022-05-18 23:30:54.064 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-18 23:31:26.283 INFO Sending 64 sample(s) to builder
2022-05-18 23:31:35.543 INFO Sending 64 sample(s) to runner
2022-05-18 23:31:35.633 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-18 23:31:51.136 INFO Sending 64 sample(s) to builder
2022-05-18 23:32:05.418 INFO Sending 64 sample(s) to runner
2022-05-18 23:32:49.960 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    768 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1536 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    640 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    512 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5864
Total latency (us): 755.134

2022-05-18 23:33:11.419 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    768 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1536 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    640 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    576 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5928
Total latency (us): 755.134

2022-05-18 23:33:11.420 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:33:37.798 INFO Sending 64 sample(s) to builder
2022-05-18 23:33:55.287 INFO Sending 64 sample(s) to runner
2022-05-18 23:34:41.415 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    768 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1600 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    640 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    576 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5992
Total latency (us): 755.134

2022-05-18 23:34:41.415 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:34:58.052 INFO Sending 64 sample(s) to builder
2022-05-18 23:35:05.258 INFO Sending 64 sample(s) to runner
2022-05-18 23:35:05.386 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 23:35:37.704 INFO Sending 64 sample(s) to builder
2022-05-18 23:35:50.019 INFO Sending 64 sample(s) to runner
2022-05-18 23:36:23.504 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    768 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1664 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    640 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    576 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6056
Total latency (us): 755.134

2022-05-18 23:36:47.859 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    768 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1664 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    704 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    576 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6120
Total latency (us): 755.134

2022-05-18 23:36:47.859 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 23:37:18.980 INFO Sending 64 sample(s) to builder
2022-05-18 23:37:32.653 INFO Sending 64 sample(s) to runner
2022-05-18 23:38:13.764 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    832 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1664 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    704 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    576 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6184
Total latency (us): 755.134

2022-05-18 23:38:13.765 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 23:38:44.569 INFO Sending 64 sample(s) to builder
2022-05-18 23:38:59.197 INFO Sending 64 sample(s) to runner
2022-05-18 23:38:59.275 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:39:25.883 INFO Sending 64 sample(s) to builder
2022-05-18 23:39:31.909 INFO Sending 64 sample(s) to runner
2022-05-18 23:39:51.745 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1664 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    704 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    576 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6248
Total latency (us): 755.134

2022-05-18 23:40:20.087 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2832.4860 |     106.6628 |              213.3256 |   1728 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    704 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    576 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6312
Total latency (us): 755.134

2022-05-18 23:40:20.087 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:40:47.627 INFO Sending 64 sample(s) to builder
2022-05-18 23:40:52.378 INFO Sending 64 sample(s) to runner
2022-05-18 23:40:52.469 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 23:41:15.020 INFO Sending 64 sample(s) to builder
2022-05-18 23:41:20.189 INFO Sending 64 sample(s) to runner
2022-05-18 23:41:37.813 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    832 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1792 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    704 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    576 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6376
Total latency (us): 752.741

2022-05-18 23:42:10.251 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    896 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1792 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    704 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    576 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6440
Total latency (us): 752.741

2022-05-18 23:42:10.251 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 23:42:40.382 INFO Sending 64 sample(s) to builder
2022-05-18 23:42:48.554 INFO Sending 64 sample(s) to runner
2022-05-18 23:42:48.640 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-18 23:43:00.718 INFO Sending 64 sample(s) to builder
2022-05-18 23:43:06.219 INFO Sending 64 sample(s) to runner
2022-05-18 23:44:06.081 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    896 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1792 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    704 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    640 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6504
Total latency (us): 752.741

2022-05-18 23:44:06.081 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-18 23:44:22.381 INFO Sending 64 sample(s) to builder
2022-05-18 23:44:34.074 INFO Sending 64 sample(s) to runner
2022-05-18 23:45:19.226 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1792 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    704 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    640 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6568
Total latency (us): 752.741

2022-05-18 23:45:44.160 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1792 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    704 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6632
Total latency (us): 752.741

2022-05-18 23:45:44.160 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 23:46:12.499 INFO Sending 64 sample(s) to builder
2022-05-18 23:46:22.644 INFO Sending 64 sample(s) to runner
2022-05-18 23:46:54.700 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1792 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    768 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6696
Total latency (us): 752.741

2022-05-18 23:46:54.701 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-18 23:47:18.554 INFO Sending 64 sample(s) to builder
2022-05-18 23:47:27.802 INFO Sending 64 sample(s) to runner
2022-05-18 23:47:28.014 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-18 23:47:57.937 INFO Sending 64 sample(s) to builder
2022-05-18 23:48:10.998 INFO Sending 64 sample(s) to runner
2022-05-18 23:48:55.445 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    448 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1792 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6760
Total latency (us): 752.741

2022-05-18 23:49:17.061 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    512 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1792 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6824
Total latency (us): 752.741

2022-05-18 23:49:17.062 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-18 23:49:49.263 INFO Sending 64 sample(s) to builder
2022-05-18 23:49:56.819 INFO Sending 64 sample(s) to runner
2022-05-18 23:49:56.902 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:50:26.368 INFO Sending 64 sample(s) to builder
2022-05-18 23:50:38.037 INFO Sending 64 sample(s) to runner
2022-05-18 23:51:04.788 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1792 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6888
Total latency (us): 752.741

2022-05-18 23:51:34.164 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1856 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6952
Total latency (us): 752.741

2022-05-18 23:51:34.164 INFO Scheduler picks Task #15: "fused_nn_pad_5"
2022-05-18 23:51:45.670 INFO Sending 0 sample(s) to builder
2022-05-18 23:51:45.672 INFO Sending 0 sample(s) to runner
2022-05-18 23:51:45.673 INFO [Updated] Task #15: "fused_nn_pad_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1856 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6952
Total latency (us): 752.741

2022-05-18 23:51:45.673 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:52:07.758 INFO Sending 64 sample(s) to builder
2022-05-18 23:52:14.721 INFO Sending 64 sample(s) to runner
2022-05-18 23:53:14.697 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1920 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7016
Total latency (us): 752.741

2022-05-18 23:53:14.697 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:53:43.916 INFO Sending 64 sample(s) to builder
2022-05-18 23:53:52.923 INFO Sending 64 sample(s) to runner
2022-05-18 23:53:53.092 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 23:54:22.538 INFO Sending 64 sample(s) to builder
2022-05-18 23:54:28.655 INFO Sending 64 sample(s) to runner
2022-05-18 23:54:47.072 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    896 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1984 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7080
Total latency (us): 752.741

2022-05-18 23:55:16.738 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |    960 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1984 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7144
Total latency (us): 752.741

2022-05-18 23:55:16.738 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-18 23:55:50.460 INFO Sending 64 sample(s) to builder
2022-05-18 23:55:56.449 INFO Sending 64 sample(s) to runner
2022-05-18 23:55:56.573 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 23:56:19.291 INFO Sending 64 sample(s) to builder
2022-05-18 23:56:25.215 INFO Sending 64 sample(s) to runner
2022-05-18 23:56:44.937 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |    960 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1024 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1984 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7208
Total latency (us): 752.741

2022-05-18 23:57:10.821 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1024 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1024 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1984 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7272
Total latency (us): 752.741

2022-05-18 23:57:10.822 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-18 23:57:42.836 INFO Sending 64 sample(s) to builder
2022-05-18 23:57:52.433 INFO Sending 64 sample(s) to runner
2022-05-18 23:57:52.479 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-18 23:58:16.508 INFO Sending 64 sample(s) to builder
2022-05-18 23:58:24.957 INFO Sending 64 sample(s) to runner
2022-05-18 23:58:51.900 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1024 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   1984 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7336
Total latency (us): 752.741

2022-05-18 23:59:32.969 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    512 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1024 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   2048 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7400
Total latency (us): 752.741

2022-05-18 23:59:32.969 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-18 23:59:56.813 INFO Sending 64 sample(s) to builder
2022-05-19 00:00:04.594 INFO Sending 64 sample(s) to runner
2022-05-19 00:00:31.911 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    576 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1024 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   2048 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7464
Total latency (us): 752.741

2022-05-19 00:00:31.911 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 00:00:54.689 INFO Sending 64 sample(s) to builder
2022-05-19 00:01:04.515 INFO Sending 64 sample(s) to runner
2022-05-19 00:01:04.683 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 00:01:34.993 INFO Sending 64 sample(s) to builder
2022-05-19 00:01:42.392 INFO Sending 64 sample(s) to runner
2022-05-19 00:02:10.588 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1024 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   2048 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    832 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7528
Total latency (us): 752.741

2022-05-19 00:02:49.393 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1024 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   2048 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    896 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7592
Total latency (us): 752.741

2022-05-19 00:02:49.393 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:03:20.844 INFO Sending 64 sample(s) to builder
2022-05-19 00:03:27.904 INFO Sending 64 sample(s) to runner
2022-05-19 00:04:25.635 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1024 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   2112 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    896 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    704 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7656
Total latency (us): 752.741

2022-05-19 00:04:25.635 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:04:56.512 INFO Sending 64 sample(s) to builder
2022-05-19 00:05:04.182 INFO Sending 64 sample(s) to runner
2022-05-19 00:05:04.267 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 00:05:19.293 INFO Sending 64 sample(s) to builder
2022-05-19 00:05:24.920 INFO Sending 64 sample(s) to runner
2022-05-19 00:06:06.766 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1024 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2864.6195 |     105.4663 |              210.9327 |   2112 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    896 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    768 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7720
Total latency (us): 752.741

2022-05-19 00:06:06.777 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 00:06:21.922 INFO Sending 64 sample(s) to builder
2022-05-19 00:06:37.515 INFO Sending 64 sample(s) to runner
2022-05-19 00:07:14.930 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1024 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2879.7314 |     104.9129 |              209.8258 |   2176 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    896 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    768 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7784
Total latency (us): 751.634

2022-05-19 00:07:46.816 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1024 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2879.7314 |     104.9129 |              209.8258 |   2176 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    896 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7848
Total latency (us): 751.634

2022-05-19 00:07:46.816 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 00:08:15.880 INFO Sending 64 sample(s) to builder
2022-05-19 00:08:38.220 INFO Sending 64 sample(s) to runner
2022-05-19 00:09:26.739 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1088 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2879.7314 |     104.9129 |              209.8258 |   2176 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    896 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7912
Total latency (us): 751.634

2022-05-19 00:09:26.740 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 00:09:54.161 INFO Sending 64 sample(s) to builder
2022-05-19 00:10:06.381 INFO Sending 64 sample(s) to runner
2022-05-19 00:10:06.555 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:10:34.485 INFO Sending 64 sample(s) to builder
2022-05-19 00:10:50.483 INFO Sending 64 sample(s) to runner
2022-05-19 00:11:14.108 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2879.7314 |     104.9129 |              209.8258 |   2176 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    896 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7976
Total latency (us): 751.634

2022-05-19 00:11:42.268 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2879.7314 |     104.9129 |              209.8258 |   2240 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    896 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8040
Total latency (us): 751.634

2022-05-19 00:11:42.268 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:12:14.743 INFO Sending 64 sample(s) to builder
2022-05-19 00:12:24.777 INFO Sending 64 sample(s) to runner
2022-05-19 00:12:24.881 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 00:12:53.231 INFO Sending 64 sample(s) to builder
2022-05-19 00:13:00.771 INFO Sending 64 sample(s) to runner
2022-05-19 00:13:27.366 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2304 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    896 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8104
Total latency (us): 751.299

2022-05-19 00:14:06.354 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2873.2243 |     105.2874 |              105.2874 |   1088 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2304 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    960 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8168
Total latency (us): 751.299

2022-05-19 00:14:06.354 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 00:14:33.159 INFO Sending 64 sample(s) to builder
2022-05-19 00:14:43.259 INFO Sending 64 sample(s) to runner
2022-05-19 00:15:40.258 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1152 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2304 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    960 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8232
Total latency (us): 750.797

2022-05-19 00:15:40.259 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 00:16:09.816 INFO Sending 64 sample(s) to builder
2022-05-19 00:16:18.231 INFO Sending 64 sample(s) to runner
2022-05-19 00:16:18.395 INFO Scheduler picks Task #20: "fused_nn_dense_add_nn_relu_1"
2022-05-19 00:16:32.673 INFO Sending 64 sample(s) to builder
2022-05-19 00:16:43.735 INFO Sending 64 sample(s) to runner
2022-05-19 00:17:20.356 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1216 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2304 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    960 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.0413 |      18.0901 |               18.0901 |    192 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8296
Total latency (us): 750.797

2022-05-19 00:17:53.615 INFO [Updated] Task #20: "fused_nn_dense_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1216 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    576 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2304 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    960 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8360
Total latency (us): 750.698

2022-05-19 00:17:53.616 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 00:18:25.661 INFO Sending 64 sample(s) to builder
2022-05-19 00:18:47.976 INFO Sending 64 sample(s) to runner
2022-05-19 00:19:48.101 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1216 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    640 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2304 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    960 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8424
Total latency (us): 750.698

2022-05-19 00:19:48.102 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 00:20:19.424 INFO Sending 64 sample(s) to builder
2022-05-19 00:20:32.017 INFO Sending 64 sample(s) to runner
2022-05-19 00:20:32.219 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:21:04.931 INFO Sending 64 sample(s) to builder
2022-05-19 00:21:30.295 INFO Sending 64 sample(s) to runner
2022-05-19 00:22:07.276 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1216 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2304 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    960 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8488
Total latency (us): 750.698

2022-05-19 00:22:36.550 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1216 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2368 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |    960 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8552
Total latency (us): 750.698

2022-05-19 00:22:36.550 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 00:23:09.639 INFO Sending 64 sample(s) to builder
2022-05-19 00:23:18.736 INFO Sending 64 sample(s) to runner
2022-05-19 00:24:14.273 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1216 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2368 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1024 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8616
Total latency (us): 750.698

2022-05-19 00:24:14.273 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 00:24:37.701 INFO Sending 64 sample(s) to builder
2022-05-19 00:24:52.014 INFO Sending 64 sample(s) to runner
2022-05-19 00:24:52.255 INFO Scheduler picks Task #12: "fused_nn_pad_4"
2022-05-19 00:25:05.040 INFO Sending 0 sample(s) to builder
2022-05-19 00:25:05.051 INFO Sending 0 sample(s) to runner
2022-05-19 00:25:05.051 INFO [Updated] Task #12: "fused_nn_pad_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1216 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2368 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1024 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8616
Total latency (us): 750.698

2022-05-19 00:25:05.052 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 00:25:36.017 INFO Sending 64 sample(s) to builder
2022-05-19 00:25:59.000 INFO Sending 64 sample(s) to runner
2022-05-19 00:26:41.315 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1216 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1152 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2368 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8680
Total latency (us): 750.698

2022-05-19 00:27:12.728 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1216 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1216 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2368 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8744
Total latency (us): 750.698

2022-05-19 00:27:12.737 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 00:27:44.972 INFO Sending 64 sample(s) to builder
2022-05-19 00:27:54.532 INFO Sending 64 sample(s) to runner
2022-05-19 00:27:54.663 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:28:25.924 INFO Sending 64 sample(s) to builder
2022-05-19 00:28:35.346 INFO Sending 64 sample(s) to runner
2022-05-19 00:29:16.949 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1216 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2368 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8808
Total latency (us): 750.698

2022-05-19 00:29:51.926 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1216 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2432 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8872
Total latency (us): 750.698

2022-05-19 00:29:51.927 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 00:30:21.638 INFO Sending 64 sample(s) to builder
2022-05-19 00:30:29.328 INFO Sending 64 sample(s) to runner
2022-05-19 00:31:21.887 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2886.9802 |     104.7857 |              104.7857 |   1280 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2432 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8936
Total latency (us): 750.698

2022-05-19 00:31:21.888 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 00:31:44.813 INFO Sending 64 sample(s) to builder
2022-05-19 00:32:11.458 INFO Sending 64 sample(s) to runner
2022-05-19 00:32:11.651 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:32:35.883 INFO Sending 64 sample(s) to builder
2022-05-19 00:32:43.677 INFO Sending 64 sample(s) to runner
2022-05-19 00:33:17.787 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2432 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9000
Total latency (us): 750.244

2022-05-19 00:33:56.633 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2496 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    832 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9064
Total latency (us): 750.244

2022-05-19 00:33:56.634 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 00:34:10.422 INFO Sending 64 sample(s) to builder
2022-05-19 00:34:17.418 INFO Sending 64 sample(s) to runner
2022-05-19 00:35:19.288 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    640 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2496 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    896 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9128
Total latency (us): 750.244

2022-05-19 00:35:19.288 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 00:35:36.195 INFO Sending 64 sample(s) to builder
2022-05-19 00:36:05.005 INFO Sending 64 sample(s) to runner
2022-05-19 00:36:05.055 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 00:36:20.594 INFO Sending 64 sample(s) to builder
2022-05-19 00:36:24.564 INFO Sending 64 sample(s) to runner
2022-05-19 00:37:32.484 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    704 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2496 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    896 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9192
Total latency (us): 750.244

2022-05-19 00:37:32.484 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 00:37:56.611 INFO Sending 64 sample(s) to builder
2022-05-19 00:38:05.106 INFO Sending 64 sample(s) to runner
2022-05-19 00:38:39.473 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    704 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2496 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9256
Total latency (us): 750.244

2022-05-19 00:38:39.473 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:39:09.343 INFO Sending 64 sample(s) to builder
2022-05-19 00:39:21.509 INFO Sending 64 sample(s) to runner
2022-05-19 00:40:02.895 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2496 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9320
Total latency (us): 750.244

2022-05-19 00:40:38.823 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2560 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9384
Total latency (us): 750.244

2022-05-19 00:40:38.823 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:41:04.315 INFO Sending 64 sample(s) to builder
2022-05-19 00:41:14.977 INFO Sending 64 sample(s) to runner
2022-05-19 00:42:10.452 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2624 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9448
Total latency (us): 750.244

2022-05-19 00:42:10.452 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:42:43.865 INFO Sending 64 sample(s) to builder
2022-05-19 00:42:50.283 INFO Sending 64 sample(s) to runner
2022-05-19 00:42:50.417 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 00:43:13.496 INFO Sending 64 sample(s) to builder
2022-05-19 00:43:19.497 INFO Sending 64 sample(s) to runner
2022-05-19 00:44:00.398 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1280 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2688 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9512
Total latency (us): 750.244

2022-05-19 00:44:42.262 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1344 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2688 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9576
Total latency (us): 750.244

2022-05-19 00:44:42.263 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 00:45:04.814 INFO Sending 64 sample(s) to builder
2022-05-19 00:45:12.777 INFO Sending 64 sample(s) to runner
2022-05-19 00:45:12.854 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 00:45:38.550 INFO Sending 64 sample(s) to builder
2022-05-19 00:45:48.767 INFO Sending 64 sample(s) to runner
2022-05-19 00:46:32.034 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2688 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2611.6167 |      28.9209 |               86.7626 |   1088 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9640
Total latency (us): 750.244

2022-05-19 00:47:00.867 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2899.5284 |     104.3322 |              104.3322 |   1344 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2688 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1152 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9704
Total latency (us): 750.045

2022-05-19 00:47:00.867 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 00:47:30.489 INFO Sending 64 sample(s) to builder
2022-05-19 00:47:38.143 INFO Sending 64 sample(s) to runner
2022-05-19 00:48:22.812 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1408 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2688 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1152 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9768
Total latency (us): 749.86

2022-05-19 00:48:22.812 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 00:48:52.389 INFO Sending 64 sample(s) to builder
2022-05-19 00:49:28.075 INFO Sending 64 sample(s) to runner
2022-05-19 00:49:29.354 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:49:54.058 INFO Sending 64 sample(s) to builder
2022-05-19 00:50:05.940 INFO Sending 64 sample(s) to runner
2022-05-19 00:50:31.709 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2688 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1152 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9832
Total latency (us): 749.86

2022-05-19 00:51:10.616 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    704 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2752 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1152 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9896
Total latency (us): 749.86

2022-05-19 00:51:10.616 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 00:51:37.330 INFO Sending 64 sample(s) to builder
2022-05-19 00:51:42.214 INFO Sending 64 sample(s) to runner
2022-05-19 00:52:30.698 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    768 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2752 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1152 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9960
Total latency (us): 749.86

2022-05-19 00:52:30.698 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 00:53:01.655 INFO Sending 64 sample(s) to builder
2022-05-19 00:53:10.061 INFO Sending 64 sample(s) to runner
2022-05-19 00:53:10.136 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:53:26.924 INFO Sending 64 sample(s) to builder
2022-05-19 00:53:32.143 INFO Sending 64 sample(s) to runner
2022-05-19 00:54:47.893 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    768 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2816 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1152 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10024
Total latency (us): 749.86

2022-05-19 00:54:47.893 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 00:55:05.474 INFO Sending 64 sample(s) to builder
2022-05-19 00:55:12.469 INFO Sending 64 sample(s) to runner
2022-05-19 00:55:46.570 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2816 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1152 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10088
Total latency (us): 749.86

2022-05-19 00:56:23.272 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2880 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1152 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10152
Total latency (us): 749.86

2022-05-19 00:56:23.272 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 00:56:55.491 INFO Sending 64 sample(s) to builder
2022-05-19 00:57:05.992 INFO Sending 64 sample(s) to runner
2022-05-19 00:58:04.297 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2880 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1216 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |    960 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10216
Total latency (us): 749.86

2022-05-19 00:58:04.297 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 00:58:35.616 INFO Sending 64 sample(s) to builder
2022-05-19 00:58:56.176 INFO Sending 64 sample(s) to runner
2022-05-19 00:58:56.363 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 00:59:12.219 INFO Sending 64 sample(s) to builder
2022-05-19 00:59:18.180 INFO Sending 64 sample(s) to runner
2022-05-19 01:00:18.475 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2880 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1216 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1024 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10280
Total latency (us): 749.86

2022-05-19 01:00:18.475 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 01:00:37.253 INFO Sending 63 sample(s) to builder
2022-05-19 01:00:43.186 INFO Sending 63 sample(s) to runner
2022-05-19 01:01:34.683 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2880 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1024 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10344
Total latency (us): 749.86

2022-05-19 01:02:04.185 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2880 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    256 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10407
Total latency (us): 749.86

2022-05-19 01:02:04.185 INFO Scheduler picks Task #20: "fused_nn_dense_add_nn_relu_1"
2022-05-19 01:02:17.178 INFO Sending 64 sample(s) to builder
2022-05-19 01:02:49.675 INFO Sending 64 sample(s) to runner
2022-05-19 01:03:48.602 INFO [Updated] Task #20: "fused_nn_dense_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2880 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    320 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10471
Total latency (us): 749.86

2022-05-19 01:03:48.602 INFO Scheduler picks Task #20: "fused_nn_dense_add_nn_relu_1"
2022-05-19 01:04:00.727 INFO Sending 64 sample(s) to builder
2022-05-19 01:04:13.091 INFO Sending 64 sample(s) to runner
2022-05-19 01:04:13.124 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 01:04:44.026 INFO Sending 64 sample(s) to builder
2022-05-19 01:04:54.279 INFO Sending 64 sample(s) to runner
2022-05-19 01:05:30.997 INFO [Updated] Task #20: "fused_nn_dense_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1408 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2880 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10535
Total latency (us): 749.86

2022-05-19 01:06:06.219 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1472 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2880 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10599
Total latency (us): 749.86

2022-05-19 01:06:06.219 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 01:06:41.265 INFO Sending 64 sample(s) to builder
2022-05-19 01:06:58.787 INFO Sending 64 sample(s) to runner
2022-05-19 01:06:58.875 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:07:29.986 INFO Sending 64 sample(s) to builder
2022-05-19 01:07:40.308 INFO Sending 64 sample(s) to runner
2022-05-19 01:08:30.317 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1536 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2880 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10663
Total latency (us): 749.86

2022-05-19 01:08:46.519 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2904.6660 |     104.1477 |              104.1477 |   1472 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1536 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2944 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10727
Total latency (us): 749.86

2022-05-19 01:08:46.519 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 01:09:16.597 INFO Sending 64 sample(s) to builder
2022-05-19 01:09:29.272 INFO Sending 64 sample(s) to runner
2022-05-19 01:10:27.512 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1536 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1536 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2944 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10791
Total latency (us): 749.418

2022-05-19 01:10:27.512 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 01:10:56.485 INFO Sending 64 sample(s) to builder
2022-05-19 01:11:04.023 INFO Sending 64 sample(s) to runner
2022-05-19 01:11:04.136 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:11:38.164 INFO Sending 64 sample(s) to builder
2022-05-19 01:11:58.182 INFO Sending 64 sample(s) to runner
2022-05-19 01:12:42.658 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1536 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   2944 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10855
Total latency (us): 749.418

2022-05-19 01:13:16.800 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    768 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1536 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3008 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10919
Total latency (us): 749.418

2022-05-19 01:13:16.800 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 01:13:47.303 INFO Sending 64 sample(s) to builder
2022-05-19 01:14:05.155 INFO Sending 64 sample(s) to runner
2022-05-19 01:14:56.592 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    832 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1536 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3008 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 10983
Total latency (us): 749.418

2022-05-19 01:14:56.599 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 01:15:31.069 INFO Sending 64 sample(s) to builder
2022-05-19 01:16:07.620 INFO Sending 64 sample(s) to runner
2022-05-19 01:16:08.355 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:16:25.923 INFO Sending 64 sample(s) to builder
2022-05-19 01:16:32.032 INFO Sending 64 sample(s) to runner
2022-05-19 01:17:10.358 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1536 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3008 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11047
Total latency (us): 749.418

2022-05-19 01:17:54.587 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1536 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3072 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11111
Total latency (us): 749.418

2022-05-19 01:17:54.587 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:18:25.926 INFO Sending 64 sample(s) to builder
2022-05-19 01:18:35.663 INFO Sending 64 sample(s) to runner
2022-05-19 01:19:44.259 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1536 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3136 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11175
Total latency (us): 749.418

2022-05-19 01:19:44.259 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:20:09.413 INFO Sending 64 sample(s) to builder
2022-05-19 01:20:19.722 INFO Sending 64 sample(s) to runner
2022-05-19 01:20:19.801 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 01:20:52.930 INFO Sending 64 sample(s) to builder
2022-05-19 01:21:07.988 INFO Sending 64 sample(s) to runner
2022-05-19 01:21:55.285 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1536 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3200 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1280 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11239
Total latency (us): 749.418

2022-05-19 01:22:38.582 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1536 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3200 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1344 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11303
Total latency (us): 749.418

2022-05-19 01:22:38.582 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 01:23:10.979 INFO Sending 64 sample(s) to builder
2022-05-19 01:23:19.931 INFO Sending 64 sample(s) to runner
2022-05-19 01:24:15.048 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1600 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3200 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1344 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11367
Total latency (us): 749.418

2022-05-19 01:24:15.048 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 01:24:43.576 INFO Sending 64 sample(s) to builder
2022-05-19 01:25:02.110 INFO Sending 64 sample(s) to runner
2022-05-19 01:25:02.291 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 01:25:19.957 INFO Sending 64 sample(s) to builder
2022-05-19 01:25:30.199 INFO Sending 64 sample(s) to runner
2022-05-19 01:26:07.430 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3200 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1344 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1087 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11431
Total latency (us): 749.418

2022-05-19 01:26:35.498 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3200 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1344 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1151 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11495
Total latency (us): 749.418

2022-05-19 01:26:35.498 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:27:07.030 INFO Sending 64 sample(s) to builder
2022-05-19 01:27:17.281 INFO Sending 64 sample(s) to runner
2022-05-19 01:28:23.269 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3264 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1344 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1151 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11559
Total latency (us): 749.418

2022-05-19 01:28:23.278 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:28:50.003 INFO Sending 64 sample(s) to builder
2022-05-19 01:28:57.817 INFO Sending 64 sample(s) to runner
2022-05-19 01:28:57.992 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 01:29:32.240 INFO Sending 64 sample(s) to builder
2022-05-19 01:29:41.885 INFO Sending 64 sample(s) to runner
2022-05-19 01:30:21.773 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1600 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3328 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1344 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1151 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11623
Total latency (us): 749.418

2022-05-19 01:31:03.472 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2917.0682 |     103.7049 |              103.7049 |   1664 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3328 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1344 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1151 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11687
Total latency (us): 749.418

2022-05-19 01:31:03.472 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 01:31:31.413 INFO Sending 64 sample(s) to builder
2022-05-19 01:31:37.526 INFO Sending 64 sample(s) to runner
2022-05-19 01:31:37.641 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 01:32:01.201 INFO Sending 64 sample(s) to builder
2022-05-19 01:32:09.965 INFO Sending 64 sample(s) to runner
2022-05-19 01:32:36.791 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    832 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3328 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1344 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1151 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11751
Total latency (us): 749.284

2022-05-19 01:33:14.005 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    896 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3328 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1344 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1151 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11815
Total latency (us): 749.284

2022-05-19 01:33:14.005 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 01:33:46.516 INFO Sending 64 sample(s) to builder
2022-05-19 01:33:55.199 INFO Sending 64 sample(s) to runner
2022-05-19 01:34:53.538 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    896 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3328 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1408 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1151 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11879
Total latency (us): 749.284

2022-05-19 01:34:53.538 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 01:35:28.979 INFO Sending 64 sample(s) to builder
2022-05-19 01:35:38.689 INFO Sending 64 sample(s) to runner
2022-05-19 01:35:38.769 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:36:01.863 INFO Sending 64 sample(s) to builder
2022-05-19 01:36:09.550 INFO Sending 64 sample(s) to runner
2022-05-19 01:36:41.340 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    896 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3328 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1151 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 11943
Total latency (us): 749.284

2022-05-19 01:37:39.596 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    896 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3392 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1151 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12007
Total latency (us): 749.284

2022-05-19 01:37:39.597 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:38:02.309 INFO Sending 64 sample(s) to builder
2022-05-19 01:38:09.072 INFO Sending 64 sample(s) to runner
2022-05-19 01:38:09.160 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 01:38:26.275 INFO Sending 64 sample(s) to builder
2022-05-19 01:38:37.346 INFO Sending 64 sample(s) to runner
2022-05-19 01:39:19.182 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    896 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3456 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       116.5651 |      71.9826 |               71.9826 |   1151 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12071
Total latency (us): 749.284

2022-05-19 01:39:58.032 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1664 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    896 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3456 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1215 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12135
Total latency (us): 747.47

2022-05-19 01:39:58.032 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 01:40:23.283 INFO Sending 64 sample(s) to builder
2022-05-19 01:40:28.854 INFO Sending 64 sample(s) to runner
2022-05-19 01:41:31.246 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1728 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    896 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3456 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1215 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12199
Total latency (us): 747.47

2022-05-19 01:41:31.247 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 01:41:59.811 INFO Sending 64 sample(s) to builder
2022-05-19 01:42:17.460 INFO Sending 64 sample(s) to runner
2022-05-19 01:42:17.605 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:42:51.632 INFO Sending 64 sample(s) to builder
2022-05-19 01:43:14.371 INFO Sending 64 sample(s) to runner
2022-05-19 01:43:51.712 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    896 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3456 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1215 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12263
Total latency (us): 747.47

2022-05-19 01:44:30.861 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    896 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3520 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1215 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12327
Total latency (us): 747.47

2022-05-19 01:44:30.861 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 01:44:53.533 INFO Sending 64 sample(s) to builder
2022-05-19 01:45:03.469 INFO Sending 64 sample(s) to runner
2022-05-19 01:46:20.678 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |    960 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3520 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1215 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12391
Total latency (us): 747.47

2022-05-19 01:46:20.678 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 01:46:53.025 INFO Sending 64 sample(s) to builder
2022-05-19 01:47:11.491 INFO Sending 64 sample(s) to runner
2022-05-19 01:47:11.695 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 01:47:44.256 INFO Sending 64 sample(s) to builder
2022-05-19 01:48:01.928 INFO Sending 64 sample(s) to runner
2022-05-19 01:48:38.471 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1728 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3520 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1215 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12455
Total latency (us): 747.47

2022-05-19 01:49:19.299 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1792 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3520 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1215 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12519
Total latency (us): 747.47

2022-05-19 01:49:19.300 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 01:49:32.603 INFO Sending 64 sample(s) to builder
2022-05-19 01:49:43.720 INFO Sending 64 sample(s) to runner
2022-05-19 01:49:43.865 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 01:50:18.954 INFO Sending 64 sample(s) to builder
2022-05-19 01:50:28.986 INFO Sending 64 sample(s) to runner
2022-05-19 01:51:18.359 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    896 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3520 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1215 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12583
Total latency (us): 747.47

2022-05-19 01:52:03.713 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3520 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1215 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12647
Total latency (us): 747.47

2022-05-19 01:52:03.713 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 01:52:15.209 INFO Sending 64 sample(s) to builder
2022-05-19 01:52:23.375 INFO Sending 64 sample(s) to runner
2022-05-19 01:53:34.566 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3520 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1279 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12711
Total latency (us): 747.47

2022-05-19 01:53:34.567 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 01:53:49.020 INFO Sending 64 sample(s) to builder
2022-05-19 01:53:56.607 INFO Sending 64 sample(s) to runner
2022-05-19 01:53:56.733 INFO Scheduler picks Task #15: "fused_nn_pad_5"
2022-05-19 01:54:10.768 INFO Sending 0 sample(s) to builder
2022-05-19 01:54:10.788 INFO Sending 0 sample(s) to runner
2022-05-19 01:54:10.789 INFO [Updated] Task #15: "fused_nn_pad_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3520 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1279 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12711
Total latency (us): 747.47

2022-05-19 01:54:10.789 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:54:40.612 INFO Sending 64 sample(s) to builder
2022-05-19 01:54:52.852 INFO Sending 64 sample(s) to runner
2022-05-19 01:55:46.159 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3520 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12775
Total latency (us): 747.47

2022-05-19 01:56:36.463 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3584 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12839
Total latency (us): 747.47

2022-05-19 01:56:36.463 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 01:57:07.053 INFO Sending 64 sample(s) to builder
2022-05-19 01:57:15.221 INFO Sending 64 sample(s) to runner
2022-05-19 01:57:15.358 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 01:57:49.483 INFO Sending 64 sample(s) to builder
2022-05-19 01:57:57.829 INFO Sending 64 sample(s) to runner
2022-05-19 01:58:55.463 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3648 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1472 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12903
Total latency (us): 747.47

2022-05-19 01:59:32.117 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3648 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1536 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 12967
Total latency (us): 747.47

2022-05-19 01:59:32.132 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:00:06.540 INFO Sending 64 sample(s) to builder
2022-05-19 02:00:15.141 INFO Sending 64 sample(s) to runner
2022-05-19 02:01:15.934 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3712 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1536 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13031
Total latency (us): 747.47

2022-05-19 02:01:15.934 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:01:50.356 INFO Sending 64 sample(s) to builder
2022-05-19 02:01:59.982 INFO Sending 64 sample(s) to runner
2022-05-19 02:02:00.200 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 02:02:24.226 INFO Sending 64 sample(s) to builder
2022-05-19 02:02:32.260 INFO Sending 64 sample(s) to runner
2022-05-19 02:03:03.511 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1792 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3776 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1536 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13095
Total latency (us): 747.47

2022-05-19 02:03:56.651 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1856 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3776 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1536 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13159
Total latency (us): 747.47

2022-05-19 02:03:56.651 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 02:04:25.440 INFO Sending 64 sample(s) to builder
2022-05-19 02:04:37.980 INFO Sending 64 sample(s) to runner
2022-05-19 02:04:38.147 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 02:05:11.508 INFO Sending 64 sample(s) to builder
2022-05-19 02:05:19.226 INFO Sending 64 sample(s) to runner
2022-05-19 02:05:55.657 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3776 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1536 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13223
Total latency (us): 747.47

2022-05-19 02:06:50.586 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |    960 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3776 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1600 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13287
Total latency (us): 747.47

2022-05-19 02:06:50.586 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 02:07:08.567 INFO Sending 64 sample(s) to builder
2022-05-19 02:07:15.656 INFO Sending 64 sample(s) to runner
2022-05-19 02:08:22.694 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1024 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3776 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1600 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13351
Total latency (us): 747.47

2022-05-19 02:08:22.694 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 02:08:48.161 INFO Sending 64 sample(s) to builder
2022-05-19 02:08:59.073 INFO Sending 64 sample(s) to runner
2022-05-19 02:08:59.130 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 02:09:16.819 INFO Sending 64 sample(s) to builder
2022-05-19 02:09:23.524 INFO Sending 64 sample(s) to runner
2022-05-19 02:10:06.122 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1856 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3776 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1600 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13415
Total latency (us): 747.47

2022-05-19 02:10:56.288 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1920 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3776 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1600 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13479
Total latency (us): 747.47

2022-05-19 02:10:56.289 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 02:11:30.568 INFO Sending 64 sample(s) to builder
2022-05-19 02:11:41.522 INFO Sending 64 sample(s) to runner
2022-05-19 02:11:41.703 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:12:12.698 INFO Sending 64 sample(s) to builder
2022-05-19 02:12:21.654 INFO Sending 64 sample(s) to runner
2022-05-19 02:13:12.159 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3776 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1600 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13543
Total latency (us): 747.47

2022-05-19 02:13:48.780 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3840 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1600 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1343 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13607
Total latency (us): 747.47

2022-05-19 02:13:48.781 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 02:14:07.640 INFO Sending 64 sample(s) to builder
2022-05-19 02:14:17.826 INFO Sending 64 sample(s) to runner
2022-05-19 02:15:15.268 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3840 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1600 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1407 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13671
Total latency (us): 747.47

2022-05-19 02:15:15.268 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 02:15:31.402 INFO Sending 62 sample(s) to builder
2022-05-19 02:15:38.314 INFO Sending 62 sample(s) to runner
2022-05-19 02:15:38.420 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:16:07.190 INFO Sending 64 sample(s) to builder
2022-05-19 02:16:19.630 INFO Sending 64 sample(s) to runner
2022-05-19 02:16:53.828 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3840 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1600 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13733
Total latency (us): 747.47

2022-05-19 02:17:47.108 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3904 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1600 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13797
Total latency (us): 747.47

2022-05-19 02:17:47.108 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:18:14.281 INFO Sending 64 sample(s) to builder
2022-05-19 02:18:21.766 INFO Sending 64 sample(s) to runner
2022-05-19 02:18:21.846 INFO Scheduler picks Task #2: "fused_nn_pad"
2022-05-19 02:18:32.812 INFO Sending 0 sample(s) to builder
2022-05-19 02:18:32.814 INFO Sending 0 sample(s) to runner
2022-05-19 02:18:32.815 INFO [Updated] Task #2: "fused_nn_pad"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3904 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1600 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13797
Total latency (us): 747.47

2022-05-19 02:18:32.815 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 02:18:51.500 INFO Sending 64 sample(s) to builder
2022-05-19 02:18:58.325 INFO Sending 64 sample(s) to runner
2022-05-19 02:19:41.913 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3968 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1600 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13861
Total latency (us): 747.47

2022-05-19 02:20:28.296 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1920 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3968 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1664 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13925
Total latency (us): 747.47

2022-05-19 02:20:28.296 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 02:20:55.922 INFO Sending 64 sample(s) to builder
2022-05-19 02:21:03.479 INFO Sending 64 sample(s) to runner
2022-05-19 02:22:09.114 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   1984 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3968 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1664 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 13989
Total latency (us): 747.47

2022-05-19 02:22:09.114 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 02:22:44.252 INFO Sending 64 sample(s) to builder
2022-05-19 02:22:55.963 INFO Sending 64 sample(s) to runner
2022-05-19 02:22:56.082 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:23:20.091 INFO Sending 64 sample(s) to builder
2022-05-19 02:23:28.618 INFO Sending 64 sample(s) to runner
2022-05-19 02:24:06.923 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   3968 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1664 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14053
Total latency (us): 747.47

2022-05-19 02:25:02.968 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1024 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4032 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1664 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14117
Total latency (us): 747.47

2022-05-19 02:25:02.968 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 02:25:28.161 INFO Sending 64 sample(s) to builder
2022-05-19 02:25:33.171 INFO Sending 64 sample(s) to runner
2022-05-19 02:26:44.080 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1088 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4032 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1664 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14181
Total latency (us): 747.47

2022-05-19 02:26:44.080 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 02:27:19.263 INFO Sending 64 sample(s) to builder
2022-05-19 02:27:27.972 INFO Sending 64 sample(s) to runner
2022-05-19 02:27:28.053 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 02:27:53.644 INFO Sending 64 sample(s) to builder
2022-05-19 02:28:01.697 INFO Sending 64 sample(s) to runner
2022-05-19 02:28:35.412 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   1984 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4032 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1664 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14245
Total latency (us): 747.47

2022-05-19 02:29:27.712 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2048 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4032 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1664 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14309
Total latency (us): 747.47

2022-05-19 02:29:27.712 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 02:29:51.967 INFO Sending 64 sample(s) to builder
2022-05-19 02:30:01.954 INFO Sending 64 sample(s) to runner
2022-05-19 02:30:02.128 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 02:30:38.139 INFO Sending 64 sample(s) to builder
2022-05-19 02:30:53.881 INFO Sending 64 sample(s) to runner
2022-05-19 02:32:00.197 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2112 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4032 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1664 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14373
Total latency (us): 747.47

2022-05-19 02:32:52.234 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2112 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4032 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1728 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14437
Total latency (us): 747.47

2022-05-19 02:32:52.234 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:33:25.324 INFO Sending 64 sample(s) to builder
2022-05-19 02:33:39.773 INFO Sending 64 sample(s) to runner
2022-05-19 02:34:52.741 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2112 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4096 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1728 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14501
Total latency (us): 747.47

2022-05-19 02:34:52.766 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:35:26.318 INFO Sending 64 sample(s) to builder
2022-05-19 02:35:35.401 INFO Sending 64 sample(s) to runner
2022-05-19 02:36:53.327 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2112 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4160 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1728 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14565
Total latency (us): 747.47

2022-05-19 02:36:53.328 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:37:17.362 INFO Sending 64 sample(s) to builder
2022-05-19 02:37:28.468 INFO Sending 64 sample(s) to runner
2022-05-19 02:38:38.496 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2112 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4224 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1728 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14629
Total latency (us): 747.47

2022-05-19 02:38:38.496 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:39:06.119 INFO Sending 64 sample(s) to builder
2022-05-19 02:39:31.254 INFO Sending 64 sample(s) to runner
2022-05-19 02:39:31.342 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 02:40:03.423 INFO Sending 64 sample(s) to builder
2022-05-19 02:40:13.507 INFO Sending 64 sample(s) to runner
2022-05-19 02:41:02.289 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2112 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4288 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1728 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14693
Total latency (us): 747.47

2022-05-19 02:42:02.605 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2112 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2048 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4288 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1792 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14757
Total latency (us): 747.47

2022-05-19 02:42:02.605 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 02:42:29.462 INFO Sending 64 sample(s) to builder
2022-05-19 02:42:42.948 INFO Sending 64 sample(s) to runner
2022-05-19 02:43:51.456 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2112 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2112 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4288 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1792 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14821
Total latency (us): 747.47

2022-05-19 02:43:51.456 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 02:44:21.540 INFO Sending 64 sample(s) to builder
2022-05-19 02:44:44.229 INFO Sending 64 sample(s) to runner
2022-05-19 02:44:44.339 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 02:45:13.381 INFO Sending 64 sample(s) to builder
2022-05-19 02:45:23.991 INFO Sending 64 sample(s) to runner
2022-05-19 02:46:11.734 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2112 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1088 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4288 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1792 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14885
Total latency (us): 747.47

2022-05-19 02:47:05.875 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2112 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1152 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4288 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1792 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 14949
Total latency (us): 747.47

2022-05-19 02:47:05.875 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 02:47:31.606 INFO Sending 64 sample(s) to builder
2022-05-19 02:47:46.191 INFO Sending 64 sample(s) to runner
2022-05-19 02:47:46.301 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 02:48:10.851 INFO Sending 64 sample(s) to builder
2022-05-19 02:48:19.301 INFO Sending 64 sample(s) to runner
2022-05-19 02:49:11.103 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2112 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4288 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1792 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15013
Total latency (us): 747.47

2022-05-19 02:49:58.188 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2176 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4288 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1792 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15077
Total latency (us): 747.47

2022-05-19 02:49:58.188 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 02:50:33.409 INFO Sending 64 sample(s) to builder
2022-05-19 02:50:55.203 INFO Sending 64 sample(s) to runner
2022-05-19 02:50:55.288 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:51:22.188 INFO Sending 64 sample(s) to builder
2022-05-19 02:51:31.618 INFO Sending 64 sample(s) to runner
2022-05-19 02:52:21.295 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4288 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1792 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15141
Total latency (us): 747.47

2022-05-19 02:53:07.340 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4352 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1792 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15205
Total latency (us): 747.47

2022-05-19 02:53:07.341 INFO Scheduler picks Task #18: "fused_layout_transform_reshape"
2022-05-19 02:53:19.899 INFO Sending 0 sample(s) to builder
2022-05-19 02:53:19.900 INFO Sending 0 sample(s) to runner
2022-05-19 02:53:19.901 INFO [Updated] Task #18: "fused_layout_transform_reshape"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4352 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1792 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15205
Total latency (us): 747.47

2022-05-19 02:53:19.901 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 02:53:50.653 INFO Sending 64 sample(s) to builder
2022-05-19 02:54:00.218 INFO Sending 64 sample(s) to runner
2022-05-19 02:55:14.615 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4352 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1856 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15269
Total latency (us): 747.47

2022-05-19 02:55:14.615 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 02:55:50.473 INFO Sending 64 sample(s) to builder
2022-05-19 02:56:05.749 INFO Sending 64 sample(s) to runner
2022-05-19 02:56:05.904 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:56:39.586 INFO Sending 64 sample(s) to builder
2022-05-19 02:56:49.694 INFO Sending 64 sample(s) to runner
2022-05-19 02:57:48.216 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4352 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15333
Total latency (us): 747.47

2022-05-19 02:58:32.988 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4416 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1469 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15397
Total latency (us): 747.47

2022-05-19 02:58:32.988 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 02:59:05.340 INFO Sending 64 sample(s) to builder
2022-05-19 02:59:15.345 INFO Sending 64 sample(s) to runner
2022-05-19 02:59:15.427 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 02:59:28.895 INFO Sending 64 sample(s) to builder
2022-05-19 02:59:32.627 INFO Sending 64 sample(s) to runner
2022-05-19 03:01:04.642 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4416 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1533 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15461
Total latency (us): 747.47

2022-05-19 03:01:04.642 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 03:01:18.710 INFO Sending 63 sample(s) to builder
2022-05-19 03:01:25.386 INFO Sending 63 sample(s) to runner
2022-05-19 03:02:15.965 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4480 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1533 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15525
Total latency (us): 747.47

2022-05-19 03:03:06.652 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4480 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15588
Total latency (us): 747.47

2022-05-19 03:03:06.652 INFO Scheduler picks Task #5: "fused_nn_pad_1"
2022-05-19 03:03:18.456 INFO Sending 0 sample(s) to builder
2022-05-19 03:03:18.458 INFO Sending 0 sample(s) to runner
2022-05-19 03:03:18.459 INFO [Updated] Task #5: "fused_nn_pad_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2949.9880 |     102.4587 |              102.4587 |   2176 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4480 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15588
Total latency (us): 747.47

2022-05-19 03:03:18.459 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 03:03:50.061 INFO Sending 64 sample(s) to builder
2022-05-19 03:04:00.183 INFO Sending 64 sample(s) to runner
2022-05-19 03:05:20.025 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2240 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4480 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15652
Total latency (us): 747.445

2022-05-19 03:05:20.046 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 03:05:49.323 INFO Sending 64 sample(s) to builder
2022-05-19 03:05:55.807 INFO Sending 64 sample(s) to runner
2022-05-19 03:05:55.898 INFO Scheduler picks Task #20: "fused_nn_dense_add_nn_relu_1"
2022-05-19 03:06:06.907 INFO Sending 64 sample(s) to builder
2022-05-19 03:06:17.556 INFO Sending 64 sample(s) to runner
2022-05-19 03:07:15.799 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4480 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    384 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15716
Total latency (us): 747.445

2022-05-19 03:08:09.542 INFO [Updated] Task #20: "fused_nn_dense_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1152 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4480 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15780
Total latency (us): 747.445

2022-05-19 03:08:09.542 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 03:08:30.836 INFO Sending 64 sample(s) to builder
2022-05-19 03:08:42.144 INFO Sending 64 sample(s) to runner
2022-05-19 03:09:59.397 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1216 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4480 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15844
Total latency (us): 747.445

2022-05-19 03:09:59.397 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 03:10:25.434 INFO Sending 64 sample(s) to builder
2022-05-19 03:10:39.728 INFO Sending 64 sample(s) to runner
2022-05-19 03:10:39.848 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:11:10.657 INFO Sending 64 sample(s) to builder
2022-05-19 03:11:22.786 INFO Sending 64 sample(s) to runner
2022-05-19 03:12:20.471 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4480 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15908
Total latency (us): 747.445

2022-05-19 03:13:02.220 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2240 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4544 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 15972
Total latency (us): 747.445

2022-05-19 03:13:02.220 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 03:13:31.752 INFO Sending 64 sample(s) to builder
2022-05-19 03:13:39.937 INFO Sending 64 sample(s) to runner
2022-05-19 03:14:48.095 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2304 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4544 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16036
Total latency (us): 747.445

2022-05-19 03:14:48.095 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 03:15:22.976 INFO Sending 64 sample(s) to builder
2022-05-19 03:15:32.030 INFO Sending 64 sample(s) to runner
2022-05-19 03:15:32.112 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:15:56.982 INFO Sending 64 sample(s) to builder
2022-05-19 03:16:05.684 INFO Sending 64 sample(s) to runner
2022-05-19 03:16:58.800 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4544 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16100
Total latency (us): 747.445

2022-05-19 03:17:50.367 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4608 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16164
Total latency (us): 747.445

2022-05-19 03:17:50.368 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:18:14.638 INFO Sending 64 sample(s) to builder
2022-05-19 03:18:23.620 INFO Sending 64 sample(s) to runner
2022-05-19 03:19:46.336 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4672 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16228
Total latency (us): 747.445

2022-05-19 03:19:46.336 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:20:13.425 INFO Sending 64 sample(s) to builder
2022-05-19 03:20:25.383 INFO Sending 64 sample(s) to runner
2022-05-19 03:20:25.566 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 03:20:57.897 INFO Sending 64 sample(s) to builder
2022-05-19 03:21:09.030 INFO Sending 64 sample(s) to runner
2022-05-19 03:22:03.121 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4736 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1920 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16292
Total latency (us): 747.445

2022-05-19 03:23:04.037 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4736 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16356
Total latency (us): 747.445

2022-05-19 03:23:04.037 INFO Scheduler picks Task #7: "fused_nn_pad_2"
2022-05-19 03:23:12.924 INFO Sending 0 sample(s) to builder
2022-05-19 03:23:12.935 INFO Sending 0 sample(s) to runner
2022-05-19 03:23:12.935 INFO [Updated] Task #7: "fused_nn_pad_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2304 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4736 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16356
Total latency (us): 747.445

2022-05-19 03:23:12.936 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 03:23:40.188 INFO Sending 64 sample(s) to builder
2022-05-19 03:23:50.325 INFO Sending 64 sample(s) to runner
2022-05-19 03:25:02.605 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2368 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4736 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16420
Total latency (us): 747.445

2022-05-19 03:25:02.606 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 03:25:35.501 INFO Sending 64 sample(s) to builder
2022-05-19 03:25:51.203 INFO Sending 64 sample(s) to runner
2022-05-19 03:25:51.356 INFO Scheduler picks Task #12: "fused_nn_pad_4"
2022-05-19 03:26:06.011 INFO Sending 0 sample(s) to builder
2022-05-19 03:26:06.013 INFO Sending 0 sample(s) to runner
2022-05-19 03:26:06.047 INFO [Updated] Task #12: "fused_nn_pad_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2368 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4736 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16420
Total latency (us): 747.445

2022-05-19 03:26:06.047 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 03:26:31.114 INFO Sending 64 sample(s) to builder
2022-05-19 03:26:36.696 INFO Sending 64 sample(s) to runner
2022-05-19 03:27:19.296 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1216 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4736 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16484
Total latency (us): 747.445

2022-05-19 03:28:18.141 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1280 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4736 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16548
Total latency (us): 747.445

2022-05-19 03:28:18.141 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 03:28:40.976 INFO Sending 64 sample(s) to builder
2022-05-19 03:28:50.079 INFO Sending 64 sample(s) to runner
2022-05-19 03:28:50.169 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:29:24.488 INFO Sending 64 sample(s) to builder
2022-05-19 03:29:35.418 INFO Sending 64 sample(s) to runner
2022-05-19 03:30:29.767 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4736 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16612
Total latency (us): 747.445

2022-05-19 03:31:18.223 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4800 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1596 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16676
Total latency (us): 747.445

2022-05-19 03:31:18.223 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 03:31:35.659 INFO Sending 64 sample(s) to builder
2022-05-19 03:31:47.383 INFO Sending 64 sample(s) to runner
2022-05-19 03:32:42.845 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4800 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1660 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16740
Total latency (us): 747.445

2022-05-19 03:32:42.846 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 03:32:58.204 INFO Sending 64 sample(s) to builder
2022-05-19 03:33:04.065 INFO Sending 64 sample(s) to runner
2022-05-19 03:33:04.148 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 03:33:29.540 INFO Sending 64 sample(s) to builder
2022-05-19 03:33:37.266 INFO Sending 64 sample(s) to runner
2022-05-19 03:34:23.225 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2368 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4800 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16804
Total latency (us): 747.445

2022-05-19 03:35:11.669 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2432 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4800 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16868
Total latency (us): 747.445

2022-05-19 03:35:11.669 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 03:35:40.820 INFO Sending 64 sample(s) to builder
2022-05-19 03:35:52.113 INFO Sending 64 sample(s) to runner
2022-05-19 03:35:52.159 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:36:11.058 INFO Sending 64 sample(s) to builder
2022-05-19 03:36:16.348 INFO Sending 64 sample(s) to runner
2022-05-19 03:36:56.904 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4800 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16932
Total latency (us): 747.445

2022-05-19 03:38:00.852 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4864 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   1984 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 16996
Total latency (us): 747.445

2022-05-19 03:38:00.852 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 03:38:19.781 INFO Sending 64 sample(s) to builder
2022-05-19 03:38:24.499 INFO Sending 64 sample(s) to runner
2022-05-19 03:39:33.246 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4864 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2048 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17060
Total latency (us): 747.445

2022-05-19 03:39:33.246 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 03:39:55.328 INFO Sending 64 sample(s) to builder
2022-05-19 03:40:05.487 INFO Sending 64 sample(s) to runner
2022-05-19 03:40:05.569 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:40:33.855 INFO Sending 64 sample(s) to builder
2022-05-19 03:40:42.530 INFO Sending 64 sample(s) to runner
2022-05-19 03:41:34.332 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4864 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17124
Total latency (us): 747.445

2022-05-19 03:42:18.365 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4928 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17188
Total latency (us): 747.445

2022-05-19 03:42:18.366 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:42:41.829 INFO Sending 64 sample(s) to builder
2022-05-19 03:42:51.749 INFO Sending 64 sample(s) to runner
2022-05-19 03:42:51.866 INFO Scheduler picks Task #4: "fused_nn_max_pool2d"
2022-05-19 03:43:02.947 INFO Sending 0 sample(s) to builder
2022-05-19 03:43:02.964 INFO Sending 0 sample(s) to runner
2022-05-19 03:43:02.965 INFO [Updated] Task #4: "fused_nn_max_pool2d"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4928 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17188
Total latency (us): 747.445

2022-05-19 03:44:12.300 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4992 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17252
Total latency (us): 747.445

2022-05-19 03:44:12.300 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:44:32.170 INFO Sending 64 sample(s) to builder
2022-05-19 03:44:48.558 INFO Sending 64 sample(s) to runner
2022-05-19 03:44:48.647 INFO Scheduler picks Task #9: "fused_nn_max_pool2d_1"
2022-05-19 03:44:56.654 INFO Sending 0 sample(s) to builder
2022-05-19 03:44:56.657 INFO Sending 0 sample(s) to runner
2022-05-19 03:44:56.658 INFO [Updated] Task #9: "fused_nn_max_pool2d_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   4992 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17252
Total latency (us): 747.445

2022-05-19 03:44:56.658 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 03:45:23.624 INFO Sending 64 sample(s) to builder
2022-05-19 03:45:33.907 INFO Sending 64 sample(s) to runner
2022-05-19 03:46:21.954 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1280 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5056 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17316
Total latency (us): 747.445

2022-05-19 03:47:03.376 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1344 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5056 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17380
Total latency (us): 747.445

2022-05-19 03:47:03.376 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 03:47:28.692 INFO Sending 64 sample(s) to builder
2022-05-19 03:47:46.020 INFO Sending 64 sample(s) to runner
2022-05-19 03:47:46.149 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 03:48:12.290 INFO Sending 64 sample(s) to builder
2022-05-19 03:48:17.254 INFO Sending 64 sample(s) to runner
2022-05-19 03:48:57.720 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2432 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5056 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17444
Total latency (us): 747.445

2022-05-19 03:49:54.475 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2496 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5056 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17508
Total latency (us): 747.445

2022-05-19 03:49:54.475 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 03:50:09.496 INFO Sending 64 sample(s) to builder
2022-05-19 03:50:14.088 INFO Sending 64 sample(s) to runner
2022-05-19 03:50:14.185 INFO Scheduler picks Task #14: "fused_nn_max_pool2d_2"
2022-05-19 03:50:23.643 INFO Sending 0 sample(s) to builder
2022-05-19 03:50:23.645 INFO Sending 0 sample(s) to runner
2022-05-19 03:50:23.646 INFO [Updated] Task #14: "fused_nn_max_pool2d_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2496 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5056 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17508
Total latency (us): 747.445

2022-05-19 03:50:23.646 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 03:50:51.095 INFO Sending 64 sample(s) to builder
2022-05-19 03:51:01.176 INFO Sending 64 sample(s) to runner
2022-05-19 03:51:55.641 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2496 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5056 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17572
Total latency (us): 747.445

2022-05-19 03:52:25.987 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2560 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5056 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17636
Total latency (us): 747.445

2022-05-19 03:52:25.987 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 03:52:52.450 INFO Sending 64 sample(s) to builder
2022-05-19 03:53:01.694 INFO Sending 64 sample(s) to runner
2022-05-19 03:53:01.985 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:53:30.541 INFO Sending 64 sample(s) to builder
2022-05-19 03:53:39.795 INFO Sending 64 sample(s) to runner
2022-05-19 03:54:34.868 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5056 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17700
Total latency (us): 747.445

2022-05-19 03:55:21.373 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5120 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17764
Total latency (us): 747.445

2022-05-19 03:55:21.373 INFO Scheduler picks Task #10: "fused_nn_pad_3"
2022-05-19 03:55:31.651 INFO Sending 0 sample(s) to builder
2022-05-19 03:55:31.653 INFO Sending 0 sample(s) to runner
2022-05-19 03:55:31.666 INFO [Updated] Task #10: "fused_nn_pad_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5120 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2112 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17764
Total latency (us): 747.445

2022-05-19 03:55:31.666 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 03:56:00.101 INFO Sending 64 sample(s) to builder
2022-05-19 03:56:09.065 INFO Sending 64 sample(s) to runner
2022-05-19 03:56:59.936 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5120 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2176 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17828
Total latency (us): 747.445

2022-05-19 03:56:59.936 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 03:57:28.412 INFO Sending 64 sample(s) to builder
2022-05-19 03:57:38.326 INFO Sending 64 sample(s) to runner
2022-05-19 03:57:38.454 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:58:05.512 INFO Sending 64 sample(s) to builder
2022-05-19 03:58:12.454 INFO Sending 64 sample(s) to runner
2022-05-19 03:58:53.094 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5120 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17892
Total latency (us): 747.445

2022-05-19 03:59:28.127 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5184 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17956
Total latency (us): 747.445

2022-05-19 03:59:28.127 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 03:59:56.328 INFO Sending 64 sample(s) to builder
2022-05-19 04:00:05.602 INFO Sending 64 sample(s) to runner
2022-05-19 04:00:05.716 INFO Scheduler picks Task #0: "fused_subtract_divide_nn_pad_layout_transform"
2022-05-19 04:00:24.539 INFO Sending 0 sample(s) to builder
2022-05-19 04:00:24.541 INFO Sending 0 sample(s) to runner
2022-05-19 04:00:24.542 INFO [Updated] Task #0: "fused_subtract_divide_nn_pad_layout_transform"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5184 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 17956
Total latency (us): 747.445

2022-05-19 04:00:24.543 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 04:00:33.873 INFO Sending 64 sample(s) to builder
2022-05-19 04:00:38.489 INFO Sending 64 sample(s) to runner
2022-05-19 04:01:14.212 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5248 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1724 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18020
Total latency (us): 747.445

2022-05-19 04:01:56.978 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5248 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18084
Total latency (us): 747.445

2022-05-19 04:01:56.978 INFO Scheduler picks Task #17: "fused_nn_max_pool2d_3"
2022-05-19 04:02:03.279 INFO Sending 0 sample(s) to builder
2022-05-19 04:02:03.281 INFO Sending 0 sample(s) to runner
2022-05-19 04:02:03.282 INFO [Updated] Task #17: "fused_nn_max_pool2d_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5248 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    448 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18084
Total latency (us): 747.445

2022-05-19 04:02:03.282 INFO Scheduler picks Task #20: "fused_nn_dense_add_nn_relu_1"
2022-05-19 04:02:10.758 INFO Sending 64 sample(s) to builder
2022-05-19 04:02:19.522 INFO Sending 64 sample(s) to runner
2022-05-19 04:03:28.903 INFO [Updated] Task #20: "fused_nn_dense_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5248 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    512 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18148
Total latency (us): 747.445

2022-05-19 04:03:28.903 INFO Scheduler picks Task #20: "fused_nn_dense_add_nn_relu_1"
2022-05-19 04:03:35.986 INFO Sending 64 sample(s) to builder
2022-05-19 04:03:41.913 INFO Sending 64 sample(s) to runner
2022-05-19 04:03:41.963 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 04:04:09.711 INFO Sending 64 sample(s) to builder
2022-05-19 04:04:18.597 INFO Sending 64 sample(s) to runner
2022-05-19 04:05:04.891 INFO [Updated] Task #20: "fused_nn_dense_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1344 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5248 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18212
Total latency (us): 747.445

2022-05-19 04:05:43.929 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1408 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5248 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18276
Total latency (us): 747.445

2022-05-19 04:05:43.929 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 04:06:12.703 INFO Sending 64 sample(s) to builder
2022-05-19 04:06:23.653 INFO Sending 64 sample(s) to runner
2022-05-19 04:06:23.791 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 04:06:44.147 INFO Sending 64 sample(s) to builder
2022-05-19 04:06:51.030 INFO Sending 64 sample(s) to runner
2022-05-19 04:07:26.867 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2950.7076 |     102.4337 |              102.4337 |   2560 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5248 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18340
Total latency (us): 747.445

2022-05-19 04:08:14.369 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2967.0253 |     101.8704 |              101.8704 |   2624 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5248 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18404
Total latency (us): 746.881

2022-05-19 04:08:14.369 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 04:08:32.538 INFO Sending 64 sample(s) to builder
2022-05-19 04:08:41.229 INFO Sending 64 sample(s) to runner
2022-05-19 04:10:02.596 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2967.0253 |     101.8704 |              101.8704 |   2624 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5312 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18468
Total latency (us): 746.881

2022-05-19 04:10:02.596 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 04:10:28.843 INFO Sending 64 sample(s) to builder
2022-05-19 04:10:36.485 INFO Sending 64 sample(s) to runner
2022-05-19 04:10:36.573 INFO Scheduler picks Task #15: "fused_nn_pad_5"
2022-05-19 04:10:45.777 INFO Sending 0 sample(s) to builder
2022-05-19 04:10:45.779 INFO Sending 0 sample(s) to runner
2022-05-19 04:10:45.780 INFO [Updated] Task #15: "fused_nn_pad_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2967.0253 |     101.8704 |              101.8704 |   2624 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5312 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18468
Total latency (us): 746.881

2022-05-19 04:10:45.780 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 04:11:15.025 INFO Sending 64 sample(s) to builder
2022-05-19 04:11:23.879 INFO Sending 64 sample(s) to runner
2022-05-19 04:12:07.140 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2967.0253 |     101.8704 |              101.8704 |   2624 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5376 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18532
Total latency (us): 746.881

2022-05-19 04:12:52.113 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2688 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5376 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18596
Total latency (us): 746.661

2022-05-19 04:12:52.113 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 04:13:11.151 INFO Sending 64 sample(s) to builder
2022-05-19 04:13:16.941 INFO Sending 64 sample(s) to runner
2022-05-19 04:13:17.044 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 04:13:35.148 INFO Sending 64 sample(s) to builder
2022-05-19 04:13:39.414 INFO Sending 64 sample(s) to runner
2022-05-19 04:14:24.480 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2624 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2752 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5376 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18660
Total latency (us): 746.661

2022-05-19 04:15:31.871 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2920.8386 |     103.5710 |              103.5710 |   2688 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2752 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5376 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18724
Total latency (us): 746.661

2022-05-19 04:15:31.871 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 04:15:57.050 INFO Sending 64 sample(s) to builder
2022-05-19 04:16:04.953 INFO Sending 64 sample(s) to runner
2022-05-19 04:16:05.089 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 04:16:20.027 INFO Sending 64 sample(s) to builder
2022-05-19 04:16:31.366 INFO Sending 64 sample(s) to runner
2022-05-19 04:17:21.851 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2752 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5376 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1788 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18788
Total latency (us): 746.598

2022-05-19 04:17:58.833 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2752 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5376 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1852 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18852
Total latency (us): 746.598

2022-05-19 04:17:58.844 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 04:18:26.456 INFO Sending 64 sample(s) to builder
2022-05-19 04:18:39.443 INFO Sending 64 sample(s) to runner
2022-05-19 04:19:42.462 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2752 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5440 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1852 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18916
Total latency (us): 746.598

2022-05-19 04:19:42.462 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 04:20:11.555 INFO Sending 64 sample(s) to builder
2022-05-19 04:20:19.919 INFO Sending 64 sample(s) to runner
2022-05-19 04:20:20.006 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 04:20:42.324 INFO Sending 64 sample(s) to builder
2022-05-19 04:20:52.721 INFO Sending 64 sample(s) to runner
2022-05-19 04:21:46.614 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2752 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5504 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2240 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1852 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 18980
Total latency (us): 746.598

2022-05-19 04:22:35.454 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2752 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1408 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5504 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2304 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1852 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19044
Total latency (us): 746.598

2022-05-19 04:22:35.454 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 04:22:52.882 INFO Sending 64 sample(s) to builder
2022-05-19 04:22:57.279 INFO Sending 64 sample(s) to runner
2022-05-19 04:24:00.774 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2752 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1472 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5504 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2304 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1852 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19108
Total latency (us): 746.598

2022-05-19 04:24:00.774 INFO Scheduler picks Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
2022-05-19 04:24:18.788 INFO Sending 64 sample(s) to builder
2022-05-19 04:24:23.383 INFO Sending 64 sample(s) to runner
2022-05-19 04:24:23.438 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 04:24:38.466 INFO Sending 64 sample(s) to builder
2022-05-19 04:24:42.112 INFO Sending 64 sample(s) to runner
2022-05-19 04:25:43.596 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2752 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1472 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5568 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2304 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1852 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19172
Total latency (us): 746.598

2022-05-19 04:25:43.596 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 04:26:00.443 INFO Sending 64 sample(s) to builder
2022-05-19 04:26:07.451 INFO Sending 64 sample(s) to runner
2022-05-19 04:26:49.212 INFO [Updated] Task #11: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2752 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5568 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2304 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1852 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19236
Total latency (us): 746.598

2022-05-19 04:27:31.792 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2752 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5632 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2304 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1852 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19300
Total latency (us): 746.598

2022-05-19 04:27:31.792 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 04:27:53.227 INFO Sending 64 sample(s) to builder
2022-05-19 04:28:02.499 INFO Sending 64 sample(s) to runner
2022-05-19 04:29:13.815 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2816 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5632 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2304 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1852 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19364
Total latency (us): 746.598

2022-05-19 04:29:13.815 INFO Scheduler picks Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
2022-05-19 04:29:31.907 INFO Sending 64 sample(s) to builder
2022-05-19 04:29:41.854 INFO Sending 64 sample(s) to runner
2022-05-19 04:29:41.930 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 04:29:53.346 INFO Sending 64 sample(s) to builder
2022-05-19 04:29:58.647 INFO Sending 64 sample(s) to runner
2022-05-19 04:31:12.254 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2816 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5632 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2304 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1916 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19428
Total latency (us): 746.598

2022-05-19 04:31:12.254 INFO Scheduler picks Task #19: "fused_nn_dense_add_nn_relu"
2022-05-19 04:31:23.961 INFO Sending 64 sample(s) to builder
2022-05-19 04:31:43.691 INFO Sending 64 sample(s) to runner
2022-05-19 04:32:23.336 INFO [Updated] Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2880 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5632 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2304 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1916 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19492
Total latency (us): 746.598

2022-05-19 04:33:04.129 INFO [Updated] Task #19: "fused_nn_dense_add_nn_relu"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2752 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2880 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5632 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2304 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1980 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19556
Total latency (us): 746.598

2022-05-19 04:33:04.129 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 04:33:25.585 INFO Sending 64 sample(s) to builder
2022-05-19 04:33:32.240 INFO Sending 64 sample(s) to runner
2022-05-19 04:34:31.948 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2816 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2880 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5632 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2304 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1980 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19620
Total latency (us): 746.598

2022-05-19 04:34:31.948 INFO Scheduler picks Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2022-05-19 04:34:52.244 INFO Sending 64 sample(s) to builder
2022-05-19 04:34:59.152 INFO Sending 64 sample(s) to runner
2022-05-19 04:34:59.216 INFO Scheduler picks Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
2022-05-19 04:35:21.040 INFO Sending 64 sample(s) to builder
2022-05-19 04:35:28.217 INFO Sending 64 sample(s) to runner
2022-05-19 04:36:10.317 INFO [Updated] Task #3: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2880 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2880 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5632 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2304 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1980 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19684
Total latency (us): 746.598

2022-05-19 04:36:54.105 INFO [Updated] Task #16: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2880 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2880 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5632 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2368 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1980 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19748
Total latency (us): 746.598

2022-05-19 04:36:54.105 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 04:37:12.770 INFO Sending 64 sample(s) to builder
2022-05-19 04:37:20.689 INFO Sending 64 sample(s) to runner
2022-05-19 04:38:22.321 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2880 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2880 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5696 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2368 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1980 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19812
Total latency (us): 746.598

2022-05-19 04:38:22.321 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 04:38:35.153 INFO Sending 64 sample(s) to builder
2022-05-19 04:38:39.580 INFO Sending 64 sample(s) to runner
2022-05-19 04:39:40.849 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |            
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |            
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |            
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2880 |            
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |            
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |            
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1472 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2880 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5760 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2368 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1980 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19876
Total latency (us): 746.598

2022-05-19 04:39:40.849 INFO Scheduler picks Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
2022-05-19 04:40:02.560 INFO Sending 64 sample(s) to builder
2022-05-19 04:40:10.614 INFO Sending 64 sample(s) to runner
2022-05-19 04:40:10.694 INFO Scheduler picks Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2022-05-19 04:40:32.203 INFO Sending 64 sample(s) to builder
2022-05-19 04:40:39.121 INFO Sending 64 sample(s) to runner
2022-05-19 04:40:39.201 INFO Task #0 has finished. Remaining task(s): 21
2022-05-19 04:40:39.212 INFO Task #1 has finished. Remaining task(s): 20
2022-05-19 04:40:39.213 INFO Task #2 has finished. Remaining task(s): 19
2022-05-19 04:40:39.213 INFO Task #3 has finished. Remaining task(s): 18
2022-05-19 04:40:39.213 INFO Task #4 has finished. Remaining task(s): 17
2022-05-19 04:40:39.213 INFO Task #5 has finished. Remaining task(s): 16
2022-05-19 04:41:41.721 INFO [Updated] Task #6: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |          Y 
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |          Y 
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |          Y 
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2880 |          Y 
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |          Y 
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |          Y 
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1536 |            
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |            
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2880 |            
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |            
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |            
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |            
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |            
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5760 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2368 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1980 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 19940
Total latency (us): 746.598

2022-05-19 04:41:41.721 INFO Task #6 has finished. Remaining task(s): 15
2022-05-19 04:41:41.721 INFO Task #7 has finished. Remaining task(s): 14
2022-05-19 04:41:41.721 INFO Task #8 has finished. Remaining task(s): 13
2022-05-19 04:41:41.721 INFO Task #9 has finished. Remaining task(s): 12
2022-05-19 04:41:41.721 INFO Task #10 has finished. Remaining task(s): 11
2022-05-19 04:41:41.721 INFO Task #11 has finished. Remaining task(s): 10
2022-05-19 04:41:41.722 INFO Task #12 has finished. Remaining task(s): 9
2022-05-19 04:42:19.976 INFO [Updated] Task #13: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5"
 ID |                                          Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Terminated 
-------------------------------------------------------------------------------------------------------------------------------------------------------
  0 | fused_subtract_divide_nn_pad_layout_transform |      8192 |      1 |         3.1357 |       2.6125 |                2.6125 |     28 |          Y 
  1 |     fused_nn_contrib_conv2d_NCHWc_add_nn_relu |   5242880 |      1 |       876.4723 |       5.9818 |                5.9818 |    192 |          Y 
  2 |                                  fused_nn_pad |         1 |      1 |         0.0003 |       3.4766 |                3.4766 |     12 |          Y 
  3 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 | 302514176 |      1 |      2922.6047 |     103.5084 |              103.5084 |   2880 |          Y 
  4 |                           fused_nn_max_pool2d |    262144 |      1 |        95.3218 |       2.7501 |                2.7501 |     12 |          Y 
  5 |                                fused_nn_pad_1 |         1 |      1 |         0.0003 |       3.0401 |                3.0401 |     12 |          Y 
  6 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 | 151257088 |      1 |      2809.7508 |      53.8329 |               53.8329 |   1536 |          Y 
  7 |                                fused_nn_pad_2 |         1 |      1 |         0.0003 |       2.8731 |                2.8731 |     12 |          Y 
  8 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 | 302252032 |      1 |      2973.4564 |     101.6501 |              101.6501 |   2880 |          Y 
  9 |                         fused_nn_max_pool2d_1 |    131072 |      1 |        48.2883 |       2.7144 |                2.7144 |     12 |          Y 
 10 |                                fused_nn_pad_3 |         1 |      1 |         0.0004 |       2.6319 |                2.6319 |     12 |          Y 
 11 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 | 151126016 |      1 |      2799.7288 |      53.9788 |               53.9788 |   1536 |          Y 
 12 |                                fused_nn_pad_4 |         1 |      2 |         0.0004 |       2.8464 |                5.6927 |     12 |          Y 
 13 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 | 302120960 |      2 |      2884.3424 |     104.7452 |              209.4904 |   5824 |            
 14 |                         fused_nn_max_pool2d_2 |     65536 |      1 |        24.6578 |       2.6578 |                2.6578 |     12 |            
 15 |                                fused_nn_pad_5 |         1 |      3 |         0.0004 |       2.5424 |                7.6271 |     12 |            
 16 |   fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 |  75530240 |      3 |      2617.6231 |      28.8545 |               86.5635 |   2368 |            
 17 |                         fused_nn_max_pool2d_3 |     16384 |      1 |         6.3600 |       2.5761 |                2.5761 |     16 |            
 18 |                fused_layout_transform_reshape |         1 |      1 |         0.0003 |       3.0947 |                3.0947 |     16 |            
 19 |                    fused_nn_dense_add_nn_relu |   8390656 |      1 |       119.5788 |      70.1684 |               70.1684 |   1980 |            
 20 |                  fused_nn_dense_add_nn_relu_1 |   2099200 |      1 |       116.6839 |      17.9905 |               17.9905 |    576 |            
 21 |                            fused_nn_dense_add |     16392 |      1 |         9.7196 |       1.6865 |                1.6865 |     64 |            
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 20004
Total latency (us): 746.598

2022-05-19 04:42:19.976 INFO Task #13 has finished. Remaining task(s): 8
2022-05-19 04:42:19.976 INFO Task #14 has finished. Remaining task(s): 7
2022-05-19 04:42:19.976 INFO Task #15 has finished. Remaining task(s): 6
2022-05-19 04:42:19.976 INFO Task #16 has finished. Remaining task(s): 5
2022-05-19 04:42:19.977 INFO Task #17 has finished. Remaining task(s): 4
2022-05-19 04:42:19.977 INFO Task #18 has finished. Remaining task(s): 3
2022-05-19 04:42:19.977 INFO Task #19 has finished. Remaining task(s): 2
2022-05-19 04:42:19.977 INFO Task #20 has finished. Remaining task(s): 1
2022-05-19 04:42:19.977 INFO Task #21 has finished. Remaining task(s): 0
2022-05-19 04:42:20.685 INFO Saved XGBModel to /home/ubuntu/tvm/logs/perf/llvm/emotion-ferplus//ms_emotion-ferplus_2022-05-18_21:59:51/cost_model.xgb
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 64, 64), "float32"], T_layout_trans: T.Buffer[(1, 1, 66, 66, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_subtract = T.alloc_buffer([1, 1, 64, 64], dtype="float32")
        compile_engine_const_1 = T.alloc_buffer([], dtype="float32")
        T_divide = T.alloc_buffer([1, 1, 64, 64], dtype="float32")
        compile_engine_const_2 = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        T_pad = T.alloc_buffer([1, 1, 66, 66], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(127.5)
        for i0, i1, i2, i3 in T.grid(1, 1, 64, 64):
            with T.block("T_subtract"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax1, ax2, ax3], compile_engine_const[()])
                T.writes(T_subtract[ax0, ax1, ax2, ax3])
                T_subtract[ax0, ax1, ax2, ax3] = placeholder[ax0, ax1, ax2, ax3] - compile_engine_const[()]
        with T.block("compile_engine_const_1"):
            T.reads()
            T.writes(compile_engine_const_1[()])
            compile_engine_const_1[()] = T.float32(255)
        for i0, i1, i2, i3 in T.grid(1, 1, 64, 64):
            with T.block("T_divide"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_subtract[ax0, ax1, ax2, ax3], compile_engine_const_1[()])
                T.writes(T_divide[ax0, ax1, ax2, ax3])
                T_divide[ax0, ax1, ax2, ax3] = T_subtract[ax0, ax1, ax2, ax3] / compile_engine_const_1[()]
        with T.block("compile_engine_const_2"):
            T.reads()
            T.writes(compile_engine_const_2[()])
            compile_engine_const_2[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const_2[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const_2[()]
        for i0, i1, i2, i3 in T.grid(1, 1, 66, 66):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_divide[ax0, ax1, ax2 - 1, ax3 - 1], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3])
                T_pad[ax0, ax1, ax2, ax3] = T.if_then_else(1 <= ax2 and ax2 < 65 and 1 <= ax3 and ax3 < 65, T_divide[ax0, ax1, ax2 - 1, ax3 - 1], T_cast[()], dtype="float32")
        for i0, i1, i2, i3, i4 in T.grid(1, 1, 66, 66, 1):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_pad[ax0, ax1 + ax4, ax2, ax3])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                T_layout_trans[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax0 < 1 and ax1 + ax4 < 1 and ax2 < 66 and ax3 < 66, T_pad[ax0, ax1 + ax4, ax2, ax3], T.float32(0), dtype="float32")
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_subtract_divide_nn_pad_layout_transform(placeholder: T.Buffer[(1, 1, 64, 64), "float32"], T_layout_trans: T.Buffer[(1, 1, 66, 66, 1), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_pad = T.alloc_buffer([1, 1, 66, 66], dtype="float32")
        for i0_i1_i2_fused in T.parallel(66, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for ax0, ax1, ax2, ax3 in T.grid(1, 1, 1, 66):
                with T.block("T_pad"):
                    ax0_1 = T.axis.spatial(1, 0)
                    ax1_1 = T.axis.spatial(1, 0)
                    ax2_1, ax3_1 = T.axis.remap("SS", [i0_i1_i2_fused, ax3])
                    T.reads(placeholder[ax0_1, ax1_1, ax2_1 - 1, ax3_1 - 1])
                    T.writes(T_pad[ax0_1, ax1_1, ax2_1, ax3_1])
                    T_pad[ax0_1, ax1_1, ax2_1, ax3_1] = T.if_then_else(1 <= ax2_1 and ax2_1 < 65 and 1 <= ax3_1 and ax3_1 < 65, (placeholder[ax0_1, ax1_1, ax2_1 - 1, ax3_1 - 1] - T.float32(127.5)) / T.float32(255), T.float32(0), dtype="float32")
            for i3 in T.serial(66):
                for i4_fused in T.vectorized(1):
                    with T.block("T_layout_trans"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(1, 0)
                        ax2, ax3 = T.axis.remap("SS", [i0_i1_i2_fused, i3])
                        ax4 = T.axis.spatial(1, 0)
                        T.reads(T_pad[ax0, ax1 + ax4, ax2, ax3])
                        T.writes(T_layout_trans[ax0, ax1, ax2, ax3, ax4])
                        T_layout_trans[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(ax0 < 1 and ax1 + ax4 < 1 and ax2 < 66 and ax3 < 66, T_pad[ax0, ax1 + ax4, ax2, ax3], T.float32(0), dtype="float32")
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"compile_engine_const\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_subtract\", func_name=\"main\")", "b2 = sch.get_block(name=\"compile_engine_const_1\", func_name=\"main\")", "b3 = sch.get_block(name=\"T_divide\", func_name=\"main\")", "b4 = sch.get_block(name=\"compile_engine_const_2\", func_name=\"main\")", "b5 = sch.get_block(name=\"T_cast\", func_name=\"main\")", "b6 = sch.get_block(name=\"T_pad\", func_name=\"main\")", "b7 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b5)", "sch.compute_inline(block=b4)", "sch.compute_inline(block=b3)", "sch.compute_inline(block=b2)", "sch.compute_inline(block=b1)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b7, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b7, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v8 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b7, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v8)", "l9 = sch.sample_compute_location(block=b6, decision=2)", "sch.compute_at(block=b6, loop=l9, preserve_unit_loops=True)", "sch.enter_postproc()", "b10 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b10, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b10, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b10, ann_key=\"meta_schedule.unroll_explicit\")", "b11, b12 = sch.get_child_blocks(b10)", "l13, l14, l15, l16, l17, l18, l19 = sch.get_loops(block=b11)", "l20 = sch.fuse(l13, l14, l15)", "sch.parallel(loop=l20)", "sch.annotate(block_or_loop=l20, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l20, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l21, l22, l23 = sch.get_loops(block=b12)", "l24 = sch.fuse(l23)", "sch.vectorize(loop=l24)", "sch.annotate(block_or_loop=l21, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l21, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1, 66, 66, 1), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 1, 16), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 4, 64, 64, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 4, 64, 64, 16], dtype="float32")
        T_add = T.alloc_buffer([1, 4, 64, 64, 16], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 4, 64, 64, 16, 1, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic, oh + kh, ow + kw, 0], placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 66, 66, 1], "float32"], ["TENSOR", [4, 1, 3, 3, 1, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW16c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic, oh + kh, ow + kw, 0] * placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 4, 64, 64, 16):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 4, 64, 64, 16):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(T_add[ax0, ax1, ax2, ax3, ax4], T.float32(0))
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu(placeholder: T.Buffer[(1, 1, 66, 66, 1), "float32"], placeholder_1: T.Buffer[(4, 1, 3, 3, 1, 16), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 4, 64, 64, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 4, 64, 64, 16], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1, i2_1, i3_1, i4_1, i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1 in T.grid(1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1):
                for i3_3_init in T.serial(8):
                    for i4_3_fused_init in T.vectorized(16):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 64)
                            oh = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 64 // 4 * 4 + i2_1)
                            ow = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 4 * 16 + i3_2 * 8 + i3_3_init)
                            oc_block = T.axis.spatial(16, i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 66, 66, 1], "float32"], ["TENSOR", [4, 1, 3, 3, 1, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(3, 3, 1, 1, 1, 8):
                    for i4_3_fused in T.vectorized(16):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 64)
                            oh = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 64 // 4 * 4 + i2_1)
                            ow = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 4 * 16 + i3_2 * 8 + i3_3)
                            oc_block = T.axis.spatial(16, i4_3_fused)
                            ic = T.axis.reduce(1, 0)
                            kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic, oh + kh, ow + kw, 0], placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 1, 66, 66, 1], "float32"], ["TENSOR", [4, 1, 3, 3, 1, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW1c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic, oh + kh, ow + kw, 0] * placeholder_1[oc_chunk, ic, kh, kw, 0, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 1, 4, 16):
                for ax4_fused in T.vectorized(16):
                    with T.block("T_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_fused // 64)
                        ax2_1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 64 // 4 * 4 + ax2)
                        ax3_1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_fused % 4 * 16 + ax3)
                        ax4 = T.axis.spatial(16, ax4_fused)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.max(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], T.float32(0))
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])", "l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 4, 1, 1])", "l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 2, 8])", "l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])", "v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])", "l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])", "v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 1])", "l53, l54 = sch.split(loop=l8, factors=[v51, v52])", "v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])", "l57, l58 = sch.split(loop=l9, factors=[v55, v56])", "v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])", "l61, l62 = sch.split(loop=l10, factors=[v59, v60])", "sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)", "b63, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b63, loop=l47, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v64)", "sch.enter_postproc()", "b65 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.unroll_explicit\")", "b66, b67 = sch.get_child_blocks(b65)", "l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)", "l94 = sch.fuse(l68, l69, l70, l71, l72)", "sch.parallel(loop=l94)", "l95 = sch.fuse(l93)", "sch.vectorize(loop=l95)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)", "l102 = sch.fuse(l101)", "sch.vectorize(loop=l102)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b103 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b103)", "b126 = sch.decompose_reduction(block=b103, loop=l119)"]
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 64, 64, 16), "float32"], T_pad: T.Buffer[(1, 4, 66, 66, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 4, 66, 66, 16):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 65 and 1 <= ax3 and ax3 < 65, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_pad(placeholder: T.Buffer[(1, 4, 64, 64, 16), "float32"], T_pad: T.Buffer[(1, 4, 66, 66, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(264, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i3 in T.serial(66):
                for i4_fused in T.vectorized(16):
                    with T.block("T_pad"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(4, i0_i1_i2_fused // 66)
                        ax2 = T.axis.spatial(66, i0_i1_i2_fused % 66)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                        T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                        T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 65 and 1 <= ax3 and ax3 < 65, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"compile_engine_const\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_cast\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=4)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v3)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, = sch.get_child_blocks(b4)", "l6, l7, l8, l9, l10 = sch.get_loops(block=b5)", "l11 = sch.fuse(l6, l7, l8)", "sch.parallel(loop=l11)", "l12 = sch.fuse(l10)", "sch.vectorize(loop=l12)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 66, 66, 16), "float32"], placeholder_1: T.Buffer[(4, 4, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 4, 64, 64, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 4, 64, 64, 16], dtype="float32")
        T_add = T.alloc_buffer([1, 4, 64, 64, 16], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 4, 64, 64, 16, 64, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 66, 66, 16], "float32"], ["TENSOR", [4, 4, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 4, 64, 64, 16):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 4, 64, 64, 16):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(T_add[ax0, ax1, ax2, ax3, ax4], T.float32(0))
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1(placeholder: T.Buffer[(1, 4, 66, 66, 16), "float32"], placeholder_1: T.Buffer[(4, 4, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 4, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 4, 64, 64, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 4, 64, 64, 16], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(1024, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_1 in T.serial(1):
                for i1_3_init, i3_3_init in T.grid(2, 8):
                    for i4_3_fused_init in T.vectorized(16):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 256 // 128 * 2 + i1_3_init)
                            oh = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 256 * 16 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 8)
                            ow = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 8 * 8 + i3_3_init)
                            oc_block = T.axis.spatial(16, i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 66, 66, 16], "float32"], ["TENSOR", [4, 4, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(8, 1, 1, 1, 1, 1, 1, 1, 8, 3, 3, 1, 2, 1, 8):
                    for i4_3_fused in T.vectorized(16):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 256 // 128 * 2 + i1_3)
                            oh = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 256 * 16 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 8)
                            ow = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 8 * 8 + i3_3)
                            oc_block = T.axis.spatial(16, i4_3_fused)
                            ic = T.axis.reduce(64, i5_0 * 8 + i5_1)
                            kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 66, 66, 16], "float32"], ["TENSOR", [4, 4, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(1, 2, 1, 8):
                    for ax4_fused in T.vectorized(16):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(4, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 256 // 128 * 2 + ax1)
                            ax2_1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 256 * 16 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 8)
                            ax3_1 = T.axis.spatial(64, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 8 * 8 + ax3)
                            ax4 = T.axis.spatial(16, ax4_fused)
                            T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.max(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], T.float32(0))
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])", "l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 16, 1, 1])", "l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 8])", "l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])", "v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])", "l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])", "v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 8])", "l53, l54 = sch.split(loop=l8, factors=[v51, v52])", "v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])", "l57, l58 = sch.split(loop=l9, factors=[v55, v56])", "v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])", "l61, l62 = sch.split(loop=l10, factors=[v59, v60])", "sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)", "b63, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v64)", "sch.enter_postproc()", "b65 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.unroll_explicit\")", "b66, b67 = sch.get_child_blocks(b65)", "l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)", "l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76)", "sch.parallel(loop=l94)", "l95 = sch.fuse(l93)", "sch.vectorize(loop=l95)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b67)", "l103 = sch.fuse(l102)", "sch.vectorize(loop=l103)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b104 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b104)", "b123 = sch.decompose_reduction(block=b104, loop=l107)"]
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 64, 64, 16), "float32"], tensor: T.Buffer[(1, 4, 32, 32, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 4, 32, 32, 16, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_max_pool2d(placeholder: T.Buffer[(1, 4, 64, 64, 16), "float32"], tensor: T.Buffer[(1, 4, 32, 32, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(128):
            for i3, i4 in T.grid(32, 16):
                with T.block("tensor_init"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(4, i0_i1_i2_fused // 32)
                    ax2 = T.axis.spatial(32, i0_i1_i2_fused % 32)
                    ax3, ax4 = T.axis.remap("SS", [i3, i4])
                    T.reads()
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                for i5, i6 in T.grid(2, 2):
                    with T.block("tensor_update"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(4, i0_i1_i2_fused // 32)
                        ax2 = T.axis.spatial(32, i0_i1_i2_fused % 32)
                        ax3, ax4, rv0, rv1 = T.axis.remap("SSRR", [i3, i4, i5, i6])
                        T.reads(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                        T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=4)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b3)", "l11 = sch.fuse(l4, l5, l6)", "sch.parallel(loop=l11)", "b12 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l13, l14, l15, l16, l17 = sch.get_loops(block=b12)", "b18 = sch.decompose_reduction(block=b12, loop=l16)"]
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 32, 32, 16), "float32"], T_pad: T.Buffer[(1, 4, 34, 34, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 4, 34, 34, 16):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 33 and 1 <= ax3 and ax3 < 33, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_pad_1(placeholder: T.Buffer[(1, 4, 32, 32, 16), "float32"], T_pad: T.Buffer[(1, 4, 34, 34, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(136, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(34):
                for i4_fused in T.vectorized(16):
                    with T.block("T_pad"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(4, i0_i1_i2_fused // 34)
                        ax2 = T.axis.spatial(34, i0_i1_i2_fused % 34)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                        T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                        T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 33 and 1 <= ax3 and ax3 < 33, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"compile_engine_const\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_cast\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=4)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v3)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, = sch.get_child_blocks(b4)", "l6, l7, l8, l9, l10 = sch.get_loops(block=b5)", "l11 = sch.fuse(l6, l7, l8)", "sch.parallel(loop=l11)", "l12 = sch.fuse(l10)", "sch.vectorize(loop=l12)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4, 34, 34, 16), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 8, 32, 32, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 8, 32, 32, 16], dtype="float32")
        T_add = T.alloc_buffer([1, 8, 32, 32, 16], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 8, 32, 32, 16, 64, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 34, 34, 16], "float32"], ["TENSOR", [8, 4, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 8, 32, 32, 16):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 8, 32, 32, 16):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(T_add[ax0, ax1, ax2, ax3, ax4], T.float32(0))
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2(placeholder: T.Buffer[(1, 4, 34, 34, 16), "float32"], placeholder_1: T.Buffer[(8, 4, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 8, 32, 32, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 8, 32, 32, 16], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(512, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_1 in T.serial(1):
                for i1_3_init, i2_3_init, i3_3_init in T.grid(2, 4, 2):
                    for i4_3_fused_init in T.vectorized(16):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 128 * 2 + i1_3_init)
                            oh = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 16 * 4 + i2_3_init)
                            ow = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 16 * 2 + i3_3_init)
                            oc_block = T.axis.spatial(16, i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 34, 34, 16], "float32"], ["TENSOR", [8, 4, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(4, 1, 1, 1, 1, 1, 1, 1, 16, 3, 3, 1, 2, 4, 2):
                    for i4_3_fused in T.vectorized(16):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 128 * 2 + i1_3)
                            oh = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 16 * 4 + i2_3)
                            ow = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 16 * 2 + i3_3)
                            oc_block = T.axis.spatial(16, i4_3_fused)
                            ic = T.axis.reduce(64, i5_0 * 16 + i5_1)
                            kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 4, 34, 34, 16], "float32"], ["TENSOR", [8, 4, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
                for ax0, ax1, ax2 in T.grid(1, 2, 4):
                    for ax3_ax4_fused in T.vectorized(32):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 128 * 2 + ax1)
                            ax2_1 = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 16 * 4 + ax2)
                            ax3 = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 16 * 2 + ax3_ax4_fused // 16)
                            ax4 = T.axis.spatial(16, ax3_ax4_fused % 16)
                            T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3, ax4])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3, ax4] = T.max(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], T.float32(0))
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 4, 1, 2])", "l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 8, 1, 4])", "l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 2])", "l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])", "v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])", "l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])", "v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[4, 16])", "l53, l54 = sch.split(loop=l8, factors=[v51, v52])", "v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])", "l57, l58 = sch.split(loop=l9, factors=[v55, v56])", "v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])", "l61, l62 = sch.split(loop=l10, factors=[v59, v60])", "sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)", "b63, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v64)", "sch.enter_postproc()", "b65 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.unroll_explicit\")", "b66, b67 = sch.get_child_blocks(b65)", "l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)", "l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76)", "sch.parallel(loop=l94)", "l95 = sch.fuse(l93)", "sch.vectorize(loop=l95)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b67)", "l103 = sch.fuse(l101, l102)", "sch.vectorize(loop=l103)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b104 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b104)", "b123 = sch.decompose_reduction(block=b104, loop=l107)"]
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 32, 32, 16), "float32"], T_pad: T.Buffer[(1, 8, 34, 34, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 8, 34, 34, 16):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 33 and 1 <= ax3 and ax3 < 33, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_pad_2(placeholder: T.Buffer[(1, 8, 32, 32, 16), "float32"], T_pad: T.Buffer[(1, 8, 34, 34, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(272, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i3 in T.serial(34):
                for i4_fused in T.vectorized(16):
                    with T.block("T_pad"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(8, i0_i1_i2_fused // 34)
                        ax2 = T.axis.spatial(34, i0_i1_i2_fused % 34)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                        T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                        T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 33 and 1 <= ax3 and ax3 < 33, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"compile_engine_const\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_cast\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=8)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v3)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, = sch.get_child_blocks(b4)", "l6, l7, l8, l9, l10 = sch.get_loops(block=b5)", "l11 = sch.fuse(l6, l7, l8)", "sch.parallel(loop=l11)", "l12 = sch.fuse(l10)", "sch.vectorize(loop=l12)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 34, 34, 16), "float32"], placeholder_1: T.Buffer[(8, 8, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 8, 32, 32, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 8, 32, 32, 16], dtype="float32")
        T_add = T.alloc_buffer([1, 8, 32, 32, 16], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 8, 32, 32, 16, 128, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 34, 34, 16], "float32"], ["TENSOR", [8, 8, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 8, 32, 32, 16):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 8, 32, 32, 16):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(T_add[ax0, ax1, ax2, ax3, ax4], T.float32(0))
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3(placeholder: T.Buffer[(1, 8, 34, 34, 16), "float32"], placeholder_1: T.Buffer[(8, 8, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 8, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 8, 32, 32, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 8, 32, 32, 16], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(512, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_1 in T.serial(1):
                for i1_3_init, i3_3_init in T.grid(2, 8):
                    for i4_3_fused_init in T.vectorized(16):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 128 * 2 + i1_3_init)
                            oh = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 8 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 4 // 2)
                            ow = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 8 // 4 * 16 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 8 + i3_3_init)
                            oc_block = T.axis.spatial(16, i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 34, 34, 16], "float32"], ["TENSOR", [8, 8, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(8, 1, 1, 1, 1, 1, 1, 1, 16, 3, 3, 1, 2, 1, 8):
                    for i4_3_fused in T.vectorized(16):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 128 * 2 + i1_3)
                            oh = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 8 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 4 // 2)
                            ow = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 8 // 4 * 16 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 8 + i3_3)
                            oc_block = T.axis.spatial(16, i4_3_fused)
                            ic = T.axis.reduce(128, i5_0 * 16 + i5_1)
                            kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 34, 34, 16], "float32"], ["TENSOR", [8, 8, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(1, 2, 1, 8):
                    for ax4_fused in T.vectorized(16):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 128 * 2 + ax1)
                            ax2_1 = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 8 * 2 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 4 // 2)
                            ax3_1 = T.axis.spatial(32, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 8 // 4 * 16 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 8 + ax3)
                            ax4 = T.axis.spatial(16, ax4_fused)
                            T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.max(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], T.float32(0))
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 1, 1, 2])", "l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 2, 1, 1])", "l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 8])", "l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])", "v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])", "l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])", "v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[8, 16])", "l53, l54 = sch.split(loop=l8, factors=[v51, v52])", "v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])", "l57, l58 = sch.split(loop=l9, factors=[v55, v56])", "v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])", "l61, l62 = sch.split(loop=l10, factors=[v59, v60])", "sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)", "b63, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=256)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v64)", "sch.enter_postproc()", "b65 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.unroll_explicit\")", "b66, b67 = sch.get_child_blocks(b65)", "l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)", "l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76)", "sch.parallel(loop=l94)", "l95 = sch.fuse(l93)", "sch.vectorize(loop=l95)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b67)", "l103 = sch.fuse(l102)", "sch.vectorize(loop=l103)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b104 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b104)", "b123 = sch.decompose_reduction(block=b104, loop=l107)"]
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 32, 32, 16), "float32"], tensor: T.Buffer[(1, 8, 16, 16, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 8, 16, 16, 16, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_max_pool2d_1(placeholder: T.Buffer[(1, 8, 32, 32, 16), "float32"], tensor: T.Buffer[(1, 8, 16, 16, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(8, annotations={"pragma_auto_unroll_max_step":64, "pragma_unroll_explicit":1}):
            for i2, i3, i4 in T.grid(16, 16, 16):
                with T.block("tensor_init"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1, ax2, ax3, ax4 = T.axis.remap("SSSS", [i0_i1_fused, i2, i3, i4])
                    T.reads()
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                for i5, i6 in T.grid(2, 2):
                    with T.block("tensor_update"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSRR", [i0_i1_fused, i2, i3, i4, i5, i6])
                        T.reads(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                        T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b3)", "l11 = sch.fuse(l4, l5)", "sch.parallel(loop=l11)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_auto_unroll_max_step\", ann_val=64)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b12 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l13, l14, l15, l16, l17, l18 = sch.get_loops(block=b12)", "b19 = sch.decompose_reduction(block=b12, loop=l17)"]
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 16, 16, 16), "float32"], T_pad: T.Buffer[(1, 8, 18, 18, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 8, 18, 18, 16):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 17 and 1 <= ax3 and ax3 < 17, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_pad_3(placeholder: T.Buffer[(1, 8, 16, 16, 16), "float32"], T_pad: T.Buffer[(1, 8, 18, 18, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_i2_fused in T.parallel(144, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3 in T.serial(18):
                for i4_fused in T.vectorized(16):
                    with T.block("T_pad"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(8, i0_i1_i2_fused // 18)
                        ax2 = T.axis.spatial(18, i0_i1_i2_fused % 18)
                        ax3, ax4 = T.axis.remap("SS", [i3, i4_fused])
                        T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                        T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                        T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 17 and 1 <= ax3 and ax3 < 17, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:26] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"compile_engine_const\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_cast\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=8)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v3)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, = sch.get_child_blocks(b4)", "l6, l7, l8, l9, l10 = sch.get_loops(block=b5)", "l11 = sch.fuse(l6, l7, l8)", "sch.parallel(loop=l11)", "l12 = sch.fuse(l10)", "sch.vectorize(loop=l12)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 8, 18, 18, 16), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 16, 16, 16, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 16, 16, 16], dtype="float32")
        T_add = T.alloc_buffer([1, 16, 16, 16, 16], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 16, 16, 16, 16, 128, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 18, 18, 16], "float32"], ["TENSOR", [16, 8, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 16, 16, 16):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 16, 16, 16):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(T_add[ax0, ax1, ax2, ax3, ax4], T.float32(0))
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4(placeholder: T.Buffer[(1, 8, 18, 18, 16), "float32"], placeholder_1: T.Buffer[(16, 8, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 16, 16, 16, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 16, 16, 16], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i3_2_init, i1_3_init, i3_3_init in T.grid(2, 2, 4):
                for i4_3_fused_init in T.vectorized(16):
                    with T.block("conv2d_NCHWc_init"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 64 * 4 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 // 8 * 2 + i1_3_init)
                        oh = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 64 // 16 * 4 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 8 // 2)
                        ow = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 8 + i3_2_init * 4 + i3_3_init)
                        oc_block = T.axis.spatial(16, i4_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 18, 18, 16], "float32"], ["TENSOR", [16, 8, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
            for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(128, 3, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 4):
                for i4_3_fused in T.vectorized(16):
                    with T.block("conv2d_NCHWc_update"):
                        n = T.axis.spatial(1, 0)
                        oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 64 * 4 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 // 8 * 2 + i1_3)
                        oh = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 64 // 16 * 4 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 8 // 2)
                        ow = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 8 + i3_2 * 4 + i3_3)
                        oc_block, ic, kh, kw = T.axis.remap("SRRR", [i4_3_fused, i5_0, i6_0, i7_0])
                        T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                        T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 8, 18, 18, 16], "float32"], ["TENSOR", [16, 8, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                        conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(1, 2, 1, 8):
                for ax4_fused in T.vectorized(16):
                    with T.block("T_relu"):
                        ax0_1 = T.axis.spatial(1, 0)
                        ax1_1 = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused // 64 * 4 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 16 // 8 * 2 + ax1)
                        ax2_1 = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 64 // 16 * 4 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 8 // 2)
                        ax3_1 = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_i4_1_fused % 2 * 8 + ax3)
                        ax4 = T.axis.spatial(16, ax4_fused)
                        T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                        T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                        T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.max(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], T.float32(0))
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])", "l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])", "l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])", "l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])", "v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])", "l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])", "v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[128, 1])", "l53, l54 = sch.split(loop=l8, factors=[v51, v52])", "v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])", "l57, l58 = sch.split(loop=l9, factors=[v55, v56])", "v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])", "l61, l62 = sch.split(loop=l10, factors=[v59, v60])", "sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)", "b63, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v64)", "sch.enter_postproc()", "b65 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.unroll_explicit\")", "b66, b67 = sch.get_child_blocks(b65)", "l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)", "l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76, l77)", "sch.parallel(loop=l94)", "l95 = sch.fuse(l93)", "sch.vectorize(loop=l95)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l96, l97, l98, l99, l100, l101 = sch.get_loops(block=b67)", "l102 = sch.fuse(l101)", "sch.vectorize(loop=l102)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b103 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)", "b121 = sch.decompose_reduction(block=b103, loop=l105)"]
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 16, 16, 16), "float32"], T_pad: T.Buffer[(1, 16, 18, 18, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 18, 18, 16):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 17 and 1 <= ax3 and ax3 < 17, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_pad_4(placeholder: T.Buffer[(1, 16, 16, 16, 16), "float32"], T_pad: T.Buffer[(1, 16, 18, 18, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(16):
            for i2, i3 in T.grid(18, 18):
                for i4_fused in T.vectorized(16):
                    with T.block("T_pad"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3, ax4 = T.axis.remap("SSSS", [i0_i1_fused, i2, i3, i4_fused])
                        T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                        T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                        T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 17 and 1 <= ax3 and ax3 < 17, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"compile_engine_const\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_cast\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v3)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, = sch.get_child_blocks(b4)", "l6, l7, l8, l9, l10 = sch.get_loops(block=b5)", "l11 = sch.fuse(l6, l7)", "sch.parallel(loop=l11)", "l12 = sch.fuse(l10)", "sch.vectorize(loop=l12)"]
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 18, 18, 16), "float32"], placeholder_1: T.Buffer[(16, 16, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 16, 16, 16, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 16, 16, 16], dtype="float32")
        T_add = T.alloc_buffer([1, 16, 16, 16, 16], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 16, 16, 16, 16, 256, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 18, 18, 16], "float32"], ["TENSOR", [16, 16, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 16, 16, 16):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 16, 16, 16):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(T_add[ax0, ax1, ax2, ax3, ax4], T.float32(0))
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5(placeholder: T.Buffer[(1, 16, 18, 18, 16), "float32"], placeholder_1: T.Buffer[(16, 16, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 16, 16, 16, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 16, 16, 16], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused in T.parallel(256, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i4_1 in T.serial(1):
                for i1_3_init, i3_3_init in T.grid(2, 8):
                    for i4_3_fused_init in T.vectorized(16):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 128 * 8 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 32 * 2 + i1_3_init)
                            oh = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 32 // 2)
                            ow = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 8 + i3_3_init)
                            oc_block = T.axis.spatial(16, i4_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 18, 18, 16], "float32"], ["TENSOR", [16, 16, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(16, 1, 1, 1, 1, 1, 1, 1, 16, 3, 3, 1, 2, 1, 8):
                    for i4_3_fused in T.vectorized(16):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 128 * 8 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 32 * 2 + i1_3)
                            oh = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 32 // 2)
                            ow = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 8 + i3_3)
                            oc_block = T.axis.spatial(16, i4_3_fused)
                            ic = T.axis.reduce(256, i5_0 * 16 + i5_1)
                            kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 18, 18, 16], "float32"], ["TENSOR", [16, 16, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(1, 2, 1, 8):
                    for ax4_fused in T.vectorized(16):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused // 128 * 8 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 128 // 32 * 2 + ax1)
                            ax2_1 = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 32 // 2)
                            ax3_1 = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_i2_1_i3_1_fused % 2 * 8 + ax3)
                            ax4 = T.axis.spatial(16, ax4_fused)
                            T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.max(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], T.float32(0))
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])", "l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])", "l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 1, 8])", "l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])", "v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])", "l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])", "v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[16, 16])", "l53, l54 = sch.split(loop=l8, factors=[v51, v52])", "v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])", "l57, l58 = sch.split(loop=l9, factors=[v55, v56])", "v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])", "l61, l62 = sch.split(loop=l10, factors=[v59, v60])", "sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)", "b63, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=128)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v64)", "sch.enter_postproc()", "b65 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.unroll_explicit\")", "b66, b67 = sch.get_child_blocks(b65)", "l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)", "l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74, l75, l76)", "sch.parallel(loop=l94)", "l95 = sch.fuse(l93)", "sch.vectorize(loop=l95)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b67)", "l103 = sch.fuse(l102)", "sch.vectorize(loop=l103)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b104 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b104)", "b123 = sch.decompose_reduction(block=b104, loop=l107)"]
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 16, 16, 16), "float32"], tensor: T.Buffer[(1, 16, 8, 8, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 16, 8, 8, 16, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_max_pool2d_2(placeholder: T.Buffer[(1, 16, 16, 16, 16), "float32"], tensor: T.Buffer[(1, 16, 8, 8, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_i2_i3_fused in T.parallel(1024, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i4 in T.serial(16):
                with T.block("tensor_init"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(16, i0_i1_i2_i3_fused // 64)
                    ax2 = T.axis.spatial(8, i0_i1_i2_i3_fused % 64 // 8)
                    ax3 = T.axis.spatial(8, i0_i1_i2_i3_fused % 8)
                    ax4 = T.axis.spatial(16, i4)
                    T.reads()
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                for i5, i6 in T.grid(2, 2):
                    with T.block("tensor_update"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(16, i0_i1_i2_i3_fused // 64)
                        ax2 = T.axis.spatial(8, i0_i1_i2_i3_fused % 64 // 8)
                        ax3 = T.axis.spatial(8, i0_i1_i2_i3_fused % 8)
                        ax4, rv0, rv1 = T.axis.remap("SRR", [i4, i5, i6])
                        T.reads(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                        T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b3)", "l11 = sch.fuse(l4, l5, l6, l7)", "sch.parallel(loop=l11)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b12 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l13, l14, l15, l16 = sch.get_loops(block=b12)", "b17 = sch.decompose_reduction(block=b12, loop=l15)"]
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 8, 8, 16), "float32"], T_pad: T.Buffer[(1, 16, 10, 10, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_cast = T.alloc_buffer([], dtype="float32")
        with T.block("compile_engine_const"):
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0)
        with T.block("T_cast"):
            T.reads(compile_engine_const[()])
            T.writes(T_cast[()])
            T_cast[()] = compile_engine_const[()]
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 10, 10, 16):
            with T.block("T_pad"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()])
                T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 9 and 1 <= ax3 and ax3 < 9, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T_cast[()], dtype="float32")
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_pad_5(placeholder: T.Buffer[(1, 16, 8, 8, 16), "float32"], T_pad: T.Buffer[(1, 16, 10, 10, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":16, "pragma_unroll_explicit":1}):
            for i2, i3 in T.grid(10, 10):
                for i4_fused in T.vectorized(16):
                    with T.block("T_pad"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3, ax4 = T.axis.remap("SSSS", [i0_i1_fused, i2, i3, i4_fused])
                        T.reads(placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4])
                        T.writes(T_pad[ax0, ax1, ax2, ax3, ax4])
                        T_pad[ax0, ax1, ax2, ax3, ax4] = T.if_then_else(1 <= ax2 and ax2 < 9 and 1 <= ax3 and ax3 < 9, placeholder[ax0, ax1, ax2 - 1, ax3 - 1, ax4], T.float32(0), dtype="float32")
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"compile_engine_const\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_cast\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.compute_inline(block=b0)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v3 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v3)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, = sch.get_child_blocks(b4)", "l6, l7, l8, l9, l10 = sch.get_loops(block=b5)", "l11 = sch.fuse(l6, l7)", "sch.parallel(loop=l11)", "l12 = sch.fuse(l10)", "sch.vectorize(loop=l12)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_auto_unroll_max_step\", ann_val=16)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_unroll_explicit\", ann_val=1)"]
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 10, 10, 16), "float32"], placeholder_1: T.Buffer[(16, 16, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 16, 8, 8, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 8, 8, 16], dtype="float32")
        T_add = T.alloc_buffer([1, 16, 8, 8, 16], dtype="float32")
        for i0, i1, i2, i3, i4, i5, i6, i7 in T.grid(1, 16, 8, 8, 16, 256, 3, 3):
            with T.block("conv2d_NCHWc"):
                n, oc_chunk, oh, ow, oc_block, ic, kh, kw = T.axis.remap("SSSSSRRR", [i0, i1, i2, i3, i4, i5, i6, i7])
                T.reads(placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                T.block_attr({"workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 10, 10, 16], "float32"], ["TENSOR", [16, 16, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                with T.init():
                    conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 8, 8, 16):
            with T.block("T_add"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4], placeholder_2[ax0, ax1, 0, 0, ax4])
                T.writes(T_add[ax0, ax1, ax2, ax3, ax4])
                T_add[ax0, ax1, ax2, ax3, ax4] = conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder_2[ax0, ax1, 0, 0, ax4]
        for i0, i1, i2, i3, i4 in T.grid(1, 16, 8, 8, 16):
            with T.block("T_relu"):
                ax0, ax1, ax2, ax3, ax4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(T_add[ax0, ax1, ax2, ax3, ax4])
                T.writes(T_relu[ax0, ax1, ax2, ax3, ax4])
                T_relu[ax0, ax1, ax2, ax3, ax4] = T.max(T_add[ax0, ax1, ax2, ax3, ax4], T.float32(0))
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6(placeholder: T.Buffer[(1, 16, 10, 10, 16), "float32"], placeholder_1: T.Buffer[(16, 16, 3, 3, 16, 16), "float32"], placeholder_2: T.Buffer[(1, 16, 1, 1, 16), "float32"], T_relu: T.Buffer[(1, 16, 8, 8, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        conv2d_NCHWc = T.alloc_buffer([1, 16, 8, 8, 16], dtype="float32")
        for i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2_1, i3_1, i4_1 in T.grid(4, 1, 1):
                for i1_3_init, i3_3_init in T.grid(2, 8):
                    for i4_3_fused_init in T.vectorized(16):
                        with T.block("conv2d_NCHWc_init"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused // 4 * 4 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 2 * 2 + i1_3_init)
                            oh = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 4 // 2 * 4 + i2_1)
                            ow, oc_block = T.axis.remap("SS", [i3_3_init, i4_3_fused_init])
                            T.reads()
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 10, 10, 16], "float32"], ["TENSOR", [16, 16, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = T.float32(0)
                for i5_0, i6_0, i7_0, i0_2, i1_2, i2_2, i3_2, i4_2, i5_1, i6_1, i7_1, i0_3, i1_3, i2_3, i3_3 in T.grid(16, 1, 1, 1, 1, 1, 1, 1, 16, 3, 3, 1, 2, 1, 8):
                    for i4_3_fused in T.vectorized(16):
                        with T.block("conv2d_NCHWc_update"):
                            n = T.axis.spatial(1, 0)
                            oc_chunk = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused // 4 * 4 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 2 * 2 + i1_3)
                            oh = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 4 // 2 * 4 + i2_1)
                            ow, oc_block = T.axis.remap("SS", [i3_3, i4_3_fused])
                            ic = T.axis.reduce(256, i5_0 * 16 + i5_1)
                            kh, kw = T.axis.remap("RR", [i6_1, i7_1])
                            T.reads(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block], placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16], placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block])
                            T.writes(conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block])
                            T.block_attr({"meta_schedule.tiling_structure":"SSRSRS", "workload":["conv2d_NCHWc.x86", ["TENSOR", [1, 16, 10, 10, 16], "float32"], ["TENSOR", [16, 16, 3, 3, 16, 16], "float32"], [1, 1], [0, 0, 0, 0], [1, 1], "NCHW16c", "NCHW16c", "float32"]})
                            conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] = conv2d_NCHWc[n, oc_chunk, oh, ow, oc_block] + placeholder[n, ic // 16, oh + kh, ow + kw, ic % 16] * placeholder_1[oc_chunk, ic // 16, kh, kw, ic % 16, oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(1, 2, 1, 8):
                    for ax4_fused in T.vectorized(16):
                        with T.block("T_relu"):
                            ax0_1 = T.axis.spatial(1, 0)
                            ax1_1 = T.axis.spatial(16, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused // 4 * 4 + i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 2 * 2 + ax1)
                            ax2_1 = T.axis.spatial(8, i0_0_i1_0_i2_0_i3_0_i4_0_i0_1_i1_1_fused % 4 // 2 * 4 + i2_1)
                            ax3_1, ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4], placeholder_2[ax0_1, ax1_1, 0, 0, ax4])
                            T.writes(T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4])
                            T_relu[ax0_1, ax1_1, ax2_1, ax3_1, ax4] = T.max(conv2d_NCHWc[ax0_1, ax1_1, ax2_1, ax3_1, ax4] + placeholder_2[ax0_1, ax1_1, 0, 0, ax4], T.float32(0))
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b0)", "v11, v12, v13, v14 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l15, l16, l17, l18 = sch.split(loop=l3, factors=[v11, v12, v13, v14])", "v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])", "l23, l24, l25, l26 = sch.split(loop=l4, factors=[v19, v20, v21, v22])", "v27, v28, v29, v30 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 1, 1])", "l31, l32, l33, l34 = sch.split(loop=l5, factors=[v27, v28, v29, v30])", "v35, v36, v37, v38 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 8])", "l39, l40, l41, l42 = sch.split(loop=l6, factors=[v35, v36, v37, v38])", "v43, v44, v45, v46 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])", "l47, l48, l49, l50 = sch.split(loop=l7, factors=[v43, v44, v45, v46])", "v51, v52 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[16, 16])", "l53, l54 = sch.split(loop=l8, factors=[v51, v52])", "v55, v56 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])", "l57, l58 = sch.split(loop=l9, factors=[v55, v56])", "v59, v60 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])", "l61, l62 = sch.split(loop=l10, factors=[v59, v60])", "sch.reorder(l15, l23, l31, l39, l47, l16, l24, l32, l40, l48, l53, l57, l61, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50)", "b63, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b63, loop=l48, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=8)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v64)", "sch.enter_postproc()", "b65 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b65, ann_key=\"meta_schedule.unroll_explicit\")", "b66, b67 = sch.get_child_blocks(b65)", "l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93 = sch.get_loops(block=b66)", "l94 = sch.fuse(l68, l69, l70, l71, l72, l73, l74)", "sch.parallel(loop=l94)", "l95 = sch.fuse(l93)", "sch.vectorize(loop=l95)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l94, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b67)", "l105 = sch.fuse(l104)", "sch.vectorize(loop=l105)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l96, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b106 = sch.get_block(name=\"conv2d_NCHWc\", func_name=\"main\")", "l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b106)", "b127 = sch.decompose_reduction(block=b106, loop=l111)"]
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 8, 8, 16), "float32"], tensor: T.Buffer[(1, 16, 4, 4, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0, i1, i2, i3, i4, i5, i6 in T.grid(1, 16, 4, 4, 16, 2, 2):
            with T.block("tensor"):
                ax0, ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSSRR", [i0, i1, i2, i3, i4, i5, i6])
                T.reads(placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                with T.init():
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_max_pool2d_3(placeholder: T.Buffer[(1, 16, 8, 8, 16), "float32"], tensor: T.Buffer[(1, 16, 4, 4, 16), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(16, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i2, i3, i4 in T.grid(4, 4, 16):
                with T.block("tensor_init"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1, ax2, ax3, ax4 = T.axis.remap("SSSS", [i0_i1_fused, i2, i3, i4])
                    T.reads()
                    T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                    tensor[ax0, ax1, ax2, ax3, ax4] = T.float32(-3.4028234663852886e+38)
                for i5, i6 in T.grid(2, 2):
                    with T.block("tensor_update"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1, ax2, ax3, ax4, rv0, rv1 = T.axis.remap("SSSSRR", [i0_i1_fused, i2, i3, i4, i5, i6])
                        T.reads(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
                        T.writes(tensor[ax0, ax1, ax2, ax3, ax4])
                        tensor[ax0, ax1, ax2, ax3, ax4] = T.max(tensor[ax0, ax1, ax2, ax3, ax4], placeholder[ax0, ax1, ax2 * 2 + rv0, ax3 * 2 + rv1, ax4])
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v1 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v1)", "sch.enter_postproc()", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\")", "b3, = sch.get_child_blocks(b2)", "l4, l5, l6, l7, l8, l9, l10 = sch.get_loops(block=b3)", "l11 = sch.fuse(l4, l5)", "sch.parallel(loop=l11)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l11, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b12 = sch.get_block(name=\"tensor\", func_name=\"main\")", "l13, l14, l15, l16, l17, l18 = sch.get_loops(block=b12)", "b19 = sch.decompose_reduction(block=b12, loop=l17)"]
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 16, 4, 4, 16), "float32"], T_reshape: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        T_layout_trans = T.alloc_buffer([1, 256, 4, 4], dtype="float32")
        for i0, i1, i2, i3 in T.grid(1, 256, 4, 4):
            with T.block("T_layout_trans"):
                ax0, ax1, ax2, ax3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(placeholder[ax0, ax1 // 16, ax2, ax3, ax1 % 16])
                T.writes(T_layout_trans[ax0, ax1, ax2, ax3])
                T_layout_trans[ax0, ax1, ax2, ax3] = T.if_then_else(ax0 < 1 and ax1 < 256 and ax2 < 4 and ax3 < 4, placeholder[ax0, ax1 // 16, ax2, ax3, ax1 % 16], T.float32(0), dtype="float32")
        for i0, i1 in T.grid(1, 4096):
            with T.block("T_reshape"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_layout_trans[0, ax1 % 4096 // 16, ax1 % 16 // 4, ax1 % 4])
                T.writes(T_reshape[ax0, ax1])
                T_reshape[ax0, ax1] = T_layout_trans[0, ax1 % 4096 // 16, ax1 % 16 // 4, ax1 % 4]
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_layout_transform_reshape(placeholder: T.Buffer[(1, 16, 4, 4, 16), "float32"], T_reshape: T.Buffer[(1, 4096), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for i0_i1_fused in T.parallel(4096):
            with T.block("T_reshape"):
                ax0 = T.axis.spatial(1, 0)
                ax1 = T.axis.spatial(4096, i0_i1_fused)
                T.reads(placeholder[0, ax1 % 4096 // 256, ax1 % 16 // 4, ax1 % 4, ax1 % 256 // 16])
                T.writes(T_reshape[ax0, ax1])
                T_reshape[ax0, ax1] = T.if_then_else(0 < 1 and ax1 % 4096 // 16 < 256 and ax1 % 16 // 4 < 4 and ax1 % 4 < 4, placeholder[0, ax1 % 4096 // 16 // 16, ax1 % 16 // 4, ax1 % 4, ax1 % 4096 // 16 % 16], T.float32(0), dtype="float32")
    

[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:27] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_layout_trans\", func_name=\"main\")", "b1 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v2 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v2)", "l3 = sch.sample_compute_location(block=b0, decision=-2)", "sch.compute_at(block=b0, loop=l3, preserve_unit_loops=True)", "sch.enter_postproc()", "b4 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b4, ann_key=\"meta_schedule.unroll_explicit\")", "b5, = sch.get_child_blocks(b4)", "l6, l7 = sch.get_loops(block=b5)", "l8 = sch.fuse(l6, l7)", "sch.parallel(loop=l8)"]
[04:42:28] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 4096), "float32"], placeholder_1: T.Buffer[(1024, 4096), "float32"], placeholder_2: T.Buffer[(1, 1024), "float32"], T_relu: T.Buffer[(1, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 1024], dtype="float32")
        T_add = T.alloc_buffer([1, 1024], dtype="float32")
        for i0, i1, i2 in T.grid(1, 1024, 4096):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[i, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
        for i0, i1 in T.grid(1, 1024):
            with T.block("T_add"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_matmul_NT[ax0, ax1], placeholder_2[ax0, ax1])
                T.writes(T_add[ax0, ax1])
                T_add[ax0, ax1] = T_matmul_NT[ax0, ax1] + placeholder_2[ax0, ax1]
        for i0, i1 in T.grid(1, 1024):
            with T.block("T_relu"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_add[ax0, ax1])
                T.writes(T_relu[ax0, ax1])
                T_relu[ax0, ax1] = T.max(T_add[ax0, ax1], T.float32(0))
    

[04:42:28] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:28] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_dense_add_nn_relu(placeholder: T.Buffer[(1, 4096), "float32"], placeholder_1: T.Buffer[(1024, 4096), "float32"], placeholder_2: T.Buffer[(1, 1024), "float32"], T_relu: T.Buffer[(1, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 1024], dtype="float32")
        for i0_0_i1_0_fused in T.parallel(32, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1 in T.grid(1, 4):
                for i1_3_init in T.serial(8):
                    with T.block("T_matmul_NT_init"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(1024, i0_0_i1_0_fused * 32 + i1_1 * 8 + i1_3_init)
                        T.reads()
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T.float32(0)
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(64, 1, 1, 64, 1, 8):
                    with T.block("T_matmul_NT_update"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(1024, i0_0_i1_0_fused * 32 + i1_1 * 8 + i1_3)
                        k = T.axis.reduce(4096, i2_0 * 64 + i2_1)
                        T.reads(T_matmul_NT[i, j], placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
                for ax0_ax1_fused in T.vectorized(8):
                    with T.block("T_relu"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(1024, i0_0_i1_0_fused * 32 + i1_1 * 8 + ax0_ax1_fused)
                        T.reads(T_matmul_NT[ax0, ax1], placeholder_2[ax0, ax1])
                        T.writes(T_relu[ax0, ax1])
                        T_relu[ax0, ax1] = T.max(T_matmul_NT[ax0, ax1] + placeholder_2[ax0, ax1], T.float32(0))
    

[04:42:28] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:28] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5 = sch.get_loops(block=b0)", "v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l10, l11, l12, l13 = sch.split(loop=l3, factors=[v6, v7, v8, v9])", "v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[32, 4, 1, 8])", "l18, l19, l20, l21 = sch.split(loop=l4, factors=[v14, v15, v16, v17])", "v22, v23 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[64, 64])", "l24, l25 = sch.split(loop=l5, factors=[v22, v23])", "sch.reorder(l10, l18, l11, l19, l24, l12, l20, l25, l13, l21)", "b26, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b26, loop=l19, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=1)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v27 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v27)", "sch.enter_postproc()", "b28 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.unroll_explicit\")", "b29, b30 = sch.get_child_blocks(b28)", "l31, l32, l33, l34, l35, l36, l37, l38, l39, l40 = sch.get_loops(block=b29)", "l41 = sch.fuse(l31, l32)", "sch.parallel(loop=l41)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l42, l43, l44, l45, l46 = sch.get_loops(block=b30)", "l47 = sch.fuse(l45, l46)", "sch.vectorize(loop=l47)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b48 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "l49, l50, l51, l52, l53, l54, l55, l56, l57 = sch.get_loops(block=b48)", "b58 = sch.decompose_reduction(block=b48, loop=l52)"]
[04:42:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024), "float32"], placeholder_1: T.Buffer[(1024, 1024), "float32"], placeholder_2: T.Buffer[(1, 1024), "float32"], T_relu: T.Buffer[(1, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 1024], dtype="float32")
        T_add = T.alloc_buffer([1, 1024], dtype="float32")
        for i0, i1, i2 in T.grid(1, 1024, 1024):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[i, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
        for i0, i1 in T.grid(1, 1024):
            with T.block("T_add"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_matmul_NT[ax0, ax1], placeholder_2[ax0, ax1])
                T.writes(T_add[ax0, ax1])
                T_add[ax0, ax1] = T_matmul_NT[ax0, ax1] + placeholder_2[ax0, ax1]
        for i0, i1 in T.grid(1, 1024):
            with T.block("T_relu"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_add[ax0, ax1])
                T.writes(T_relu[ax0, ax1])
                T_relu[ax0, ax1] = T.max(T_add[ax0, ax1], T.float32(0))
    

[04:42:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_dense_add_nn_relu_1(placeholder: T.Buffer[(1, 1024), "float32"], placeholder_1: T.Buffer[(1024, 1024), "float32"], placeholder_2: T.Buffer[(1, 1024), "float32"], T_relu: T.Buffer[(1, 1024), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 1024], dtype="float32")
        for i0_0_i1_0_fused in T.parallel(128, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i0_1, i1_1 in T.grid(1, 1):
                for i1_3_init in T.serial(8):
                    with T.block("T_matmul_NT_init"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(1024, i0_0_i1_0_fused * 8 + i1_3_init)
                        T.reads()
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T.float32(0)
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(16, 1, 1, 64, 1, 8):
                    with T.block("T_matmul_NT_update"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(1024, i0_0_i1_0_fused * 8 + i1_3)
                        k = T.axis.reduce(1024, i2_0 * 64 + i2_1)
                        T.reads(T_matmul_NT[i, j], placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
            for ax0_ax1_fused in T.vectorized(8):
                with T.block("T_relu"):
                    ax0 = T.axis.spatial(1, 0)
                    ax1 = T.axis.spatial(1024, i0_0_i1_0_fused * 8 + ax0_ax1_fused)
                    T.reads(T_matmul_NT[ax0, ax1], placeholder_2[ax0, ax1])
                    T.writes(T_relu[ax0, ax1])
                    T_relu[ax0, ax1] = T.max(T_matmul_NT[ax0, ax1] + placeholder_2[ax0, ax1], T.float32(0))
    

[04:42:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:29] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "b1 = sch.get_block(name=\"T_add\", func_name=\"main\")", "b2 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.compute_inline(block=b1)", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l3, l4, l5 = sch.get_loops(block=b0)", "v6, v7, v8, v9 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l10, l11, l12, l13 = sch.split(loop=l3, factors=[v6, v7, v8, v9])", "v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[128, 1, 1, 8])", "l18, l19, l20, l21 = sch.split(loop=l4, factors=[v14, v15, v16, v17])", "v22, v23 = sch.sample_perfect_tile(loop=l5, n=2, max_innermost_factor=64, decision=[16, 64])", "l24, l25 = sch.split(loop=l5, factors=[v22, v23])", "sch.reorder(l10, l18, l11, l19, l24, l12, l20, l25, l13, l21)", "b26, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b26, loop=l18, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v27 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b2, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v27)", "sch.enter_postproc()", "b28 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b28, ann_key=\"meta_schedule.unroll_explicit\")", "b29, b30 = sch.get_child_blocks(b28)", "l31, l32, l33, l34, l35, l36, l37, l38, l39, l40 = sch.get_loops(block=b29)", "l41 = sch.fuse(l31, l32)", "sch.parallel(loop=l41)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l41, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l42, l43, l44 = sch.get_loops(block=b30)", "l45 = sch.fuse(l43, l44)", "sch.vectorize(loop=l45)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l42, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b46 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "l47, l48, l49, l50, l51, l52, l53, l54, l55 = sch.get_loops(block=b46)", "b56 = sch.decompose_reduction(block=b46, loop=l50)"]
[04:42:30] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:123: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(placeholder: T.Buffer[(1, 1024), "float32"], placeholder_1: T.Buffer[(8, 1024), "float32"], placeholder_2: T.Buffer[(1, 8), "float32"], T_add: T.Buffer[(1, 8), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 8], dtype="float32")
        for i0, i1, i2 in T.grid(1, 8, 1024):
            with T.block("T_matmul_NT"):
                i, j, k = T.axis.remap("SSR", [i0, i1, i2])
                T.reads(placeholder[i, k], placeholder_1[j, k])
                T.writes(T_matmul_NT[i, j])
                with T.init():
                    T_matmul_NT[i, j] = T.float32(0)
                T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
        for i0, i1 in T.grid(1, 8):
            with T.block("T_add"):
                ax0, ax1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_matmul_NT[ax0, ax1], placeholder_2[ax0, ax1])
                T.writes(T_add[ax0, ax1])
                T_add[ax0, ax1] = T_matmul_NT[ax0, ax1] + placeholder_2[ax0, ax1]
    

[04:42:30] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:124: best replacement TIR found for the above:

[04:42:30] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:125: # from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def tvmgen_default_fused_nn_dense_add(placeholder: T.Buffer[(1, 1024), "float32"], placeholder_1: T.Buffer[(8, 1024), "float32"], placeholder_2: T.Buffer[(1, 8), "float32"], T_add: T.Buffer[(1, 8), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True, "layout_free_placeholders": [1]})
        # body
        # with T.block("root")
        T_matmul_NT = T.alloc_buffer([1, 8], dtype="float32")
        for i0_0 in T.serial(1, annotations={"pragma_auto_unroll_max_step":512, "pragma_unroll_explicit":1}):
            for i1_0, i0_1, i1_1 in T.grid(1, 1, 1):
                for i1_3_init in T.serial(8):
                    with T.block("T_matmul_NT_init"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(8, i1_3_init)
                        T.reads()
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T.float32(0)
                for i2_0, i0_2, i1_2, i2_1, i0_3, i1_3 in T.grid(64, 1, 1, 16, 1, 8):
                    with T.block("T_matmul_NT_update"):
                        i = T.axis.spatial(1, 0)
                        j = T.axis.spatial(8, i1_3)
                        k = T.axis.reduce(1024, i2_0 * 16 + i2_1)
                        T.reads(T_matmul_NT[i, j], placeholder[i, k], placeholder_1[j, k])
                        T.writes(T_matmul_NT[i, j])
                        T.block_attr({"meta_schedule.tiling_structure":"SSRSRS"})
                        T_matmul_NT[i, j] = T_matmul_NT[i, j] + placeholder[i, k] * placeholder_1[j, k]
                for ax0_ax1_fused in T.vectorized(8):
                    with T.block("T_add"):
                        ax0 = T.axis.spatial(1, 0)
                        ax1 = T.axis.spatial(8, ax0_ax1_fused)
                        T.reads(T_matmul_NT[ax0, ax1], placeholder_2[ax0, ax1])
                        T.writes(T_add[ax0, ax1])
                        T_add[ax0, ax1] = T_matmul_NT[ax0, ax1] + placeholder_2[ax0, ax1]
    

[04:42:30] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:126: Printing out trace for AHB:
[04:42:30] /home/ubuntu/tvm/src/meta_schedule/apply_history_best.cc:127: ["b0 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "b1 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")", "l2, l3, l4 = sch.get_loops(block=b0)", "v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])", "l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8])", "v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 8])", "l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16])", "v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[64, 16])", "l23, l24 = sch.split(loop=l4, factors=[v21, v22])", "sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)", "b25, = sch.get_consumers(block=b0)", "sch.reverse_compute_at(block=b25, loop=l18, preserve_unit_loops=True)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=288)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)", "v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)", "sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v26)", "sch.enter_postproc()", "b27 = sch.get_block(name=\"root\", func_name=\"main\")", "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.parallel\")", "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.vectorize\")", "sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.unroll_explicit\")", "b28, b29 = sch.get_child_blocks(b27)", "l30, l31, l32, l33, l34, l35, l36, l37, l38, l39 = sch.get_loops(block=b28)", "sch.annotate(block_or_loop=l30, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l30, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "l40, l41, l42, l43, l44, l45 = sch.get_loops(block=b29)", "l46 = sch.fuse(l44, l45)", "sch.vectorize(loop=l46)", "sch.annotate(block_or_loop=l40, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)", "sch.annotate(block_or_loop=l40, ann_key=\"pragma_unroll_explicit\", ann_val=1)", "b47 = sch.get_block(name=\"T_matmul_NT\", func_name=\"main\")", "l48, l49, l50, l51, l52, l53, l54, l55, l56, l57 = sch.get_loops(block=b47)", "b58 = sch.decompose_reduction(block=b47, loop=l52)"]
Running time in time_evaluator:  [1.115405213186813, 1.1463588395604396, 1.1557165362637363]
Avg running time: 1.1391601963369962
|graph_nodes| =  55
|graph_time| =  55
Input3 : 0.000
tvmgen_default_fused_subtract_divide_nn_pad_layout_transform : 0.000
p0 : 0.000
p1 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu : 0.000
tvmgen_default_fused_nn_pad : 0.000
p2 : 0.000
p3 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 : 0.000
tvmgen_default_fused_nn_max_pool2d : 0.000
tvmgen_default_fused_nn_pad_1 : 0.000
p4 : 0.000
p5 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 : 0.000
tvmgen_default_fused_nn_pad_2 : 0.000
p6 : 0.000
p7 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 : 0.000
tvmgen_default_fused_nn_max_pool2d_1 : 0.000
tvmgen_default_fused_nn_pad_3 : 0.000
p8 : 0.000
p9 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4 : 0.000
tvmgen_default_fused_nn_pad_4 : 0.000
p10 : 0.000
p11 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_5 : 0.000
tvmgen_default_fused_nn_pad_41 : 0.000
p12 : 0.000
p13 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_51 : 0.000
tvmgen_default_fused_nn_max_pool2d_2 : 0.000
tvmgen_default_fused_nn_pad_5 : 0.000
p14 : 0.000
p15 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_6 : 0.000
tvmgen_default_fused_nn_pad_51 : 0.000
p16 : 0.000
p17 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_61 : 0.000
tvmgen_default_fused_nn_pad_52 : 0.000
p18 : 0.000
p19 : 0.000
tvmgen_default_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_62 : 0.000
tvmgen_default_fused_nn_max_pool2d_3 : 0.000
tvmgen_default_fused_layout_transform_reshape : 0.000
p20 : 0.000
p21 : 0.000
tvmgen_default_fused_nn_dense_add_nn_relu : 0.000
p22 : 0.000
p23 : 0.000
tvmgen_default_fused_nn_dense_add_nn_relu_1 : 0.000
p24 : 0.000
p25 : 0.000
tvmgen_default_fused_nn_dense_add : 0.000
/home/ubuntu/miniconda/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
  from pandas import MultiIndex, Int64Index
/home/ubuntu/miniconda/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)
