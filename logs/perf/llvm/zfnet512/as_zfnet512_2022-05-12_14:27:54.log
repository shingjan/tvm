----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
Get devices for measurement successfully!
https://storage.cloud.google.com/octoml-aquarium-models/onnx_model_zoo/vision_classification_zfnet512.onnx
file existed. Skipping downloading.
/home/ubuntu/cache-workloads/zfnet512.onnx
Workload: zfnet512
  input_name: gpu_0/data_0
  input_shape: [1, 3, 224, 224]
  input_dtype: float32
==== Task 0: vm_mod_fused_nn_lrn_1 (weight 1 key: ["0f353233a06b32a162590935e5014785", [1, 256, 25, 25], [1, 256, 25, 25]]) =====
placeholder = PLACEHOLDER [1, 256, 25, 25]
pad_data(ax0, ax1, ax2, ax3) = tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)
tensor(ax0, ax1, ax2, ax3) += (pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])
tensor(ax0, ax1, ax2, ax3) = tir.pow((2f + ((0.0005f*tensor[ax0, ax1, ax2, ax3])/5f)), 0.75f)
T_divide(ax0, ax1, ax2, ax3) = (placeholder[ax0, ax1, ax2, ax3]/tensor[ax0, ax1, ax2, ax3])

==== Task 1: vm_mod_fused_nn_max_pool2d (weight 1 key: ["9abffad12b503cdcfdda685c0a0b65f2", [1, 96, 109, 109], [1, 96, 54, 54]]) =====
placeholder = PLACEHOLDER [1, 96, 109, 109]
tensor(ax0, ax1, ax2, ax3) max= placeholder[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1)]

==== Task 2: vm_mod_fused_nn_dense_add_nn_relu_1 (weight 1 key: ["7c7999b7bbdaec23cf87b49ec0ce3a97", [1, 4096], [1024, 4096], [1, 1024], [1, 1024]]) =====
placeholder = PLACEHOLDER [1, 4096]
placeholder = PLACEHOLDER [1024, 4096]
T_matmul_NT(i, j) += (placeholder[i, k]*placeholder[j, k])
placeholder = PLACEHOLDER [1, 1024]
T_add(ax0, ax1) = (T_matmul_NT[ax0, ax1] + placeholder[ax0, ax1])
T_relu(ax0, ax1) = max(T_add[ax0, ax1], 0f)

==== Task 3: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu (weight 1 key: ["01a6b9ff57444c5d506f411c1a32175c", [1, 1, 224, 224, 3], [6, 1, 7, 7, 3, 16], [1, 6, 1, 1, 16], [1, 6, 109, 109, 16]]) =====
placeholder = PLACEHOLDER [1, 1, 224, 224, 3]
placeholder = PLACEHOLDER [6, 1, 7, 7, 3, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 3), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 3)]*placeholder[oc_chunk, floordiv(ic, 3), kh, kw, floormod(ic, 3), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 4: vm_mod_fused_nn_max_pool2d_1 (weight 1 key: ["9abffad12b503cdcfdda685c0a0b65f2", [1, 256, 25, 25], [1, 256, 12, 12]]) =====
placeholder = PLACEHOLDER [1, 256, 25, 25]
tensor(ax0, ax1, ax2, ax3) max= placeholder[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1)]

==== Task 5: vm_mod_fused_nn_softmax (weight 1 key: ["d7b65649a4dd54becea0a52aabbc5af5", [1, 1000], [1, 1000]]) =====
placeholder = PLACEHOLDER [1, 1000]
T_softmax_maxelem(i0) max= placeholder[i0, k]
T_softmax_exp(i0, i1) = tir.exp((placeholder[i0, i1] - T_softmax_maxelem[i0]))
T_softmax_expsum(i0) += T_softmax_exp[i0, k]
T_softmax_norm(i0, i1) = (T_softmax_exp[i0, i1]/T_softmax_expsum[i0])

==== Task 6: vm_mod_fused_nn_max_pool2d_2 (weight 1 key: ["a02f874db93bbd6a17c0cfc6f9372f5a", [1, 32, 12, 12, 16], [1, 32, 6, 6, 16]]) =====
placeholder = PLACEHOLDER [1, 32, 12, 12, 16]
tensor(ax0, ax1, ax2, ax3, ax4) max= placeholder[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1), ax4]

==== Task 7: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 (weight 1 key: ["218f348ca19713d944f219d28361e292", [1, 6, 54, 54, 16], [16, 6, 5, 5, 16, 16], [1, 16, 1, 1, 16], [1, 16, 25, 25, 16]]) =====
placeholder = PLACEHOLDER [1, 6, 54, 54, 16]
placeholder = PLACEHOLDER [16, 6, 5, 5, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 16, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 8: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 16, 12, 12, 16], [32, 16, 3, 3, 16, 16], [1, 32, 1, 1, 16], [1, 32, 12, 12, 16]]) =====
placeholder = PLACEHOLDER [1, 16, 12, 12, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 13)) && (i3 >= 1)) && (i3 < 13)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [32, 16, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 32, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 9: vm_mod_fused_nn_lrn (weight 1 key: ["0f353233a06b32a162590935e5014785", [1, 96, 109, 109], [1, 96, 109, 109]]) =====
placeholder = PLACEHOLDER [1, 96, 109, 109]
pad_data(ax0, ax1, ax2, ax3) = tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)
tensor(ax0, ax1, ax2, ax3) += (pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])
tensor(ax0, ax1, ax2, ax3) = tir.pow((2f + ((0.0005f*tensor[ax0, ax1, ax2, ax3])/5f)), 0.75f)
T_divide(ax0, ax1, ax2, ax3) = (placeholder[ax0, ax1, ax2, ax3]/tensor[ax0, ax1, ax2, ax3])

==== Task 10: vm_mod_fused_nn_dense_add (weight 1 key: ["7d44c6e3c81cd80f61ff2265b2bae89a", [1, 1024], [1000, 1024], [1, 1000], [1, 1000]]) =====
placeholder = PLACEHOLDER [1, 1024]
placeholder = PLACEHOLDER [1000, 1024]
T_matmul_NT(i, j) += (placeholder[i, k]*placeholder[j, k])
placeholder = PLACEHOLDER [1, 1000]
T_add(ax0, ax1) = (T_matmul_NT[ax0, ax1] + placeholder[ax0, ax1])

==== Task 11: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 (weight 2 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 32, 12, 12, 16], [32, 32, 3, 3, 16, 16], [1, 32, 1, 1, 16], [1, 32, 12, 12, 16]]) =====
placeholder = PLACEHOLDER [1, 32, 12, 12, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 13)) && (i3 >= 1)) && (i3 < 13)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [32, 32, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 32, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)

==== Task 12: vm_mod_fused_nn_dense_add_nn_relu (weight 1 key: ["7c7999b7bbdaec23cf87b49ec0ce3a97", [1, 18432], [4096, 18432], [1, 4096], [1, 4096]]) =====
placeholder = PLACEHOLDER [1, 18432]
placeholder = PLACEHOLDER [4096, 18432]
T_matmul_NT(i, j) += (placeholder[i, k]*placeholder[j, k])
placeholder = PLACEHOLDER [1, 4096]
T_add(ax0, ax1) = (T_matmul_NT[ax0, ax1] + placeholder[ax0, ax1])
T_relu(ax0, ax1) = max(T_add[ax0, ax1], 0f)

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |            - |              - |      0 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |            - |              - |      0 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |            - |              - |      0 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |            - |              - |      0 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |            - |              - |      0 |
|    5 |                                       vm_mod_fused_nn_softmax |            - |              - |      0 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 80	fail_ct: 1665	Time elapsed: 0.45
GA Iter: 0	Max score: 0.9770	Min score: 0.0024	#Pop: 80	#M+: 0	#M-: 0
[14:28:02] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ (None)
  for ax1 (None)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            for rxs (None)
              tensor = ...
    for ax2 (None)
      for ax0 (None)
        for ax1 (None)
          for ax2 (None)
            for ax3 (None)
              pad_data = ...
      for ax3 (None)
        T_divide = ...

with: [14:28:02] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9994	Min score: 0.8633	#Pop: 128	#M+: 397	#M-: 6746
EvolutionarySearch		#s: 128	Time elapsed: 1.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 7.28 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
/home/ubuntu/anaconda3/lib/python3.9/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)
Time elapsed for training: 1.68 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Iter: 5	#Pop: 4	#Target: 50	fail_ct: 10236	Time elapsed: 1.05
#Target has been reduced to 25 due to too many failures or duplications
Sample Iter: 10	#Pop: 4	#Target: 25	fail_ct: 20476	Time elapsed: 2.04
#Target has been reduced to 12 due to too many failures or duplications
Sample Iter: 15	#Pop: 4	#Target: 12	fail_ct: 30716	Time elapsed: 3.18
#Target has been reduced to 6 due to too many failures or duplications
Sample Iter: 20	#Pop: 4	#Target: 6	fail_ct: 40956	Time elapsed: 4.24
#Target has been reduced to 3 due to too many failures or duplications
Sample Initial Population	#s: 4	fail_ct: 43004	Time elapsed: 4.42
GA Iter: 0	Max score: 0.9051	Min score: 0.3267	#Pop: 4	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9992	Min score: 0.0887	#Pop: 16	#M+: 351	#M-: 6881
EvolutionarySearch		#s: 16	Time elapsed: 0.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 16 programs to measure:
................****************Time elapsed for measurement: 2.79 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.21 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1560	fail_ct: 313	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9995	Min score: 0.9160	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9864	#Pop: 128	#M+: 1369	#M-: 83
EvolutionarySearch		#s: 128	Time elapsed: 1.34
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.90 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1962	fail_ct: 6	Time elapsed: 0.68
GA Iter: 0	Max score: 0.9991	Min score: 0.9300	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9849	#Pop: 128	#M+: 1349	#M-: 210
EvolutionarySearch		#s: 128	Time elapsed: 2.90
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.17 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.77 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |            - |              - |      0 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |            - |              - |      0 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |            - |              - |      0 |
|    9 |                                           vm_mod_fused_nn_lrn |            - |              - |      0 |
|   10 |                                     vm_mod_fused_nn_dense_add |            - |              - |      0 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 0	Used time : 0 s	Next ID: 0	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |            - |              - |      0 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |            - |              - |      0 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |            - |              - |      0 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |            - |              - |      0 |
|    5 |                                       vm_mod_fused_nn_softmax |            - |              - |      0 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |            - |              - |      0 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |            - |              - |      0 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |            - |              - |      0 |
|    9 |                                           vm_mod_fused_nn_lrn |            - |              - |      0 |
|   10 |                                     vm_mod_fused_nn_dense_add |            - |              - |      0 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 64	Used time : 12 s	Next ID: 1	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |            - |              - |      0 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |            - |              - |      0 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |            - |              - |      0 |
|    5 |                                       vm_mod_fused_nn_softmax |            - |              - |      0 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |            - |              - |      0 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |            - |              - |      0 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |            - |              - |      0 |
|    9 |                                           vm_mod_fused_nn_lrn |            - |              - |      0 |
|   10 |                                     vm_mod_fused_nn_dense_add |            - |              - |      0 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 80	Used time : 21 s	Next ID: 2	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |            - |              - |      0 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |            - |              - |      0 |
|    5 |                                       vm_mod_fused_nn_softmax |            - |              - |      0 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |            - |              - |      0 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |            - |              - |      0 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |            - |              - |      0 |
|    9 |                                           vm_mod_fused_nn_lrn |            - |              - |      0 |
|   10 |                                     vm_mod_fused_nn_dense_add |            - |              - |      0 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 144	Used time : 43 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |            - |              - |      0 |
|    5 |                                       vm_mod_fused_nn_softmax |            - |              - |      0 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |            - |              - |      0 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |            - |              - |      0 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |            - |              - |      0 |
|    9 |                                           vm_mod_fused_nn_lrn |            - |              - |      0 |
|   10 |                                     vm_mod_fused_nn_dense_add |            - |              - |      0 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Iter: 5	#Pop: 4	#Target: 50	fail_ct: 10236	Time elapsed: 1.46
#Target has been reduced to 25 due to too many failures or duplications
Sample Iter: 10	#Pop: 4	#Target: 25	fail_ct: 20476	Time elapsed: 2.57
#Target has been reduced to 12 due to too many failures or duplications
Sample Iter: 15	#Pop: 4	#Target: 12	fail_ct: 30716	Time elapsed: 3.85
#Target has been reduced to 6 due to too many failures or duplications
Sample Iter: 20	#Pop: 4	#Target: 6	fail_ct: 40956	Time elapsed: 4.75
#Target has been reduced to 3 due to too many failures or duplications
Sample Initial Population	#s: 4	fail_ct: 43004	Time elapsed: 4.95
GA Iter: 0	Max score: 0.4625	Min score: 0.0907	#Pop: 4	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9957	Min score: 0.0212	#Pop: 16	#M+: 348	#M-: 6894
EvolutionarySearch		#s: 16	Time elapsed: 0.80
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 16 programs to measure:
................****************Time elapsed for measurement: 3.30 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.33 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 9
Sample Initial Population	#s: 1094	fail_ct: 140	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9991	Min score: 0.8910	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9836	#Pop: 128	#M+: 1371	#M-: 105
EvolutionarySearch		#s: 128	Time elapsed: 1.71
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 8.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.31 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Iter: 5	#Pop: 4	#Target: 50	fail_ct: 10236	Time elapsed: 1.36
#Target has been reduced to 25 due to too many failures or duplications
Sample Iter: 10	#Pop: 4	#Target: 25	fail_ct: 20476	Time elapsed: 2.83
#Target has been reduced to 12 due to too many failures or duplications
Sample Iter: 15	#Pop: 4	#Target: 12	fail_ct: 30716	Time elapsed: 3.89
#Target has been reduced to 6 due to too many failures or duplications
Sample Iter: 20	#Pop: 4	#Target: 6	fail_ct: 40956	Time elapsed: 4.96
#Target has been reduced to 3 due to too many failures or duplications
Sample Initial Population	#s: 4	fail_ct: 43004	Time elapsed: 5.18
GA Iter: 0	Max score: 0.8822	Min score: 0.0656	#Pop: 4	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9871	Min score: 0.0451	#Pop: 20	#M+: 356	#M-: 6926
EvolutionarySearch		#s: 20	Time elapsed: 0.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 20 programs to measure:
....................***************Time elapsed for measurement: 4.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.84 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 2002	fail_ct: 0	Time elapsed: 0.73
GA Iter: 0	Max score: 0.9995	Min score: 0.9410	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9859	#Pop: 128	#M+: 1387	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 3.06
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.04 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.09 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1838	fail_ct: 0	Time elapsed: 0.95
GA Iter: 0	Max score: 0.9997	Min score: 0.9193	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9863	#Pop: 128	#M+: 1387	#M-: 28
EvolutionarySearch		#s: 128	Time elapsed: 4.28
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.18 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 208	Used time : 69 s	Next ID: 4	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |            - |              - |      0 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |            - |              - |      0 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |            - |              - |      0 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |            - |              - |      0 |
|    9 |                                           vm_mod_fused_nn_lrn |            - |              - |      0 |
|   10 |                                     vm_mod_fused_nn_dense_add |            - |              - |      0 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 224	Used time : 79 s	Next ID: 5	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |            - |              - |      0 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |            - |              - |      0 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |            - |              - |      0 |
|    9 |                                           vm_mod_fused_nn_lrn |            - |              - |      0 |
|   10 |                                     vm_mod_fused_nn_dense_add |            - |              - |      0 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 288	Used time : 92 s	Next ID: 6	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |            - |              - |      0 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |            - |              - |      0 |
|    9 |                                           vm_mod_fused_nn_lrn |            - |              - |      0 |
|   10 |                                     vm_mod_fused_nn_dense_add |            - |              - |      0 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 308	Used time : 105 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.670 |        1147.13 |     64 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |            - |              - |      0 |
|    9 |                                           vm_mod_fused_nn_lrn |            - |              - |      0 |
|   10 |                                     vm_mod_fused_nn_dense_add |            - |              - |      0 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 372	Used time : 134 s	Next ID: 8	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 80	fail_ct: 1690	Time elapsed: 0.53
GA Iter: 0	Max score: 0.9995	Min score: 0.0443	#Pop: 80	#M+: 0	#M-: 0
[14:30:36] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
for ax1 (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [14:30:36] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[14:30:36] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (None)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (None)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (None)
      T_divide = ...

with: [14:30:36] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9995	Min score: 0.8278	#Pop: 128	#M+: 394	#M-: 6671
EvolutionarySearch		#s: 128	Time elapsed: 1.95
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 8.78 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.86 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1594	fail_ct: 273	Time elapsed: 0.53
GA Iter: 0	Max score: 1.0000	Min score: 0.9241	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9854	#Pop: 128	#M+: 1376	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 2.03
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.670 |        1147.13 |     64 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |            - |              - |      0 |
|   10 |                                     vm_mod_fused_nn_dense_add |            - |              - |      0 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 436	Used time : 156 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.670 |        1147.13 |     64 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.64 |     64 |
|   10 |                                     vm_mod_fused_nn_dense_add |            - |              - |      0 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 500	Used time : 171 s	Next ID: 10	
.T***************************************************************Time elapsed for measurement: 24.20 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.17 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1827	fail_ct: 0	Time elapsed: 1.60
GA Iter: 0	Max score: 0.9996	Min score: 0.9238	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9880	#Pop: 128	#M+: 1393	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 8.43
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.56 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 3
Sample Initial Population	#s: 1801	fail_ct: 133	Time elapsed: 0.57
GA Iter: 0	Max score: 0.9999	Min score: 0.9331	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9873	#Pop: 128	#M+: 1383	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 2.35
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 38.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.24 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1774	fail_ct: 138	Time elapsed: 0.39
GA Iter: 0	Max score: 0.9990	Min score: 0.9259	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9865	#Pop: 128	#M+: 1370	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 1.58
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 37.32 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.61 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1803	fail_ct: 0	Time elapsed: 0.92
GA Iter: 0	Max score: 0.9996	Min score: 0.9355	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9868	#Pop: 128	#M+: 1378	#M-: 30
EvolutionarySearch		#s: 128	Time elapsed: 4.17
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.09 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.55 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.670 |        1147.13 |     64 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.64 |     64 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |            - |              - |      0 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 564	Used time : 204 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.670 |        1147.13 |     64 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.64 |     64 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.812 |         837.30 |     64 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |            - |              - |      0 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: - ms	Trials: 628	Used time : 245 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.670 |        1147.13 |     64 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.64 |     64 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.812 |         837.30 |     64 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.539 |          59.47 |     64 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 6.321 ms	Trials: 692	Used time : 287 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.670 |        1147.13 |     64 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.64 |     64 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.812 |         837.30 |     64 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.539 |          59.48 |    128 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 6.321 ms	Trials: 756	Used time : 333 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1802	fail_ct: 114	Time elapsed: 0.50
GA Iter: 0	Max score: 0.9994	Min score: 0.9294	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9881	#Pop: 128	#M+: 1383	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 1.53
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 36.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.17 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1785	fail_ct: 145	Time elapsed: 0.42
GA Iter: 0	Max score: 1.0076	Min score: 0.9897	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0183	Min score: 0.9994	#Pop: 128	#M+: 1380	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 1.86
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 38.06 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.30 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1793	fail_ct: 0	Time elapsed: 0.95
GA Iter: 0	Max score: 0.8791	Min score: 0.4512	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9684	Min score: 0.7828	#Pop: 128	#M+: 1383	#M-: 31
EvolutionarySearch		#s: 128	Time elapsed: 4.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.16 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.37 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2002	fail_ct: 0	Time elapsed: 0.72
GA Iter: 0	Max score: 0.7640	Min score: 0.4272	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9981	Min score: 0.7053	#Pop: 128	#M+: 1373	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 3.31
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 9.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.40 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.670 |        1147.13 |     64 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.64 |     64 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.715 |         950.91 |    128 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.539 |          59.48 |    128 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 6.127 ms	Trials: 820	Used time : 358 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.670 |        1147.13 |     64 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.64 |     64 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.715 |         950.91 |    128 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.539 |          59.48 |    192 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 6.127 ms	Trials: 884	Used time : 398 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.670 |        1147.13 |     64 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.64 |     64 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.715 |         950.91 |    128 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.530 |          59.69 |    256 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 6.118 ms	Trials: 948	Used time : 439 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.670 |        1147.13 |     64 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.64 |     64 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.530 |          59.69 |    256 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 5.547 ms	Trials: 1012	Used time : 460 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.576 |        1334.22 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1793	fail_ct: 130	Time elapsed: 0.42
GA Iter: 0	Max score: 0.9981	Min score: 0.9842	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9981	Min score: 0.9905	#Pop: 128	#M+: 1376	#M-: 81
EvolutionarySearch		#s: 128	Time elapsed: 1.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 38.35 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.97 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1651	Time elapsed: 0.85
GA Iter: 0	Max score: 0.9723	Min score: 0.7780	#Pop: 40	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9723	Min score: 0.3657	#Pop: 128	#M+: 390	#M-: 6651
EvolutionarySearch		#s: 128	Time elapsed: 3.33
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................************************************************Time elapsed for measurement: 14.62 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.22 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1782	fail_ct: 136	Time elapsed: 0.46
GA Iter: 0	Max score: 0.9947	Min score: 0.9797	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9995	Min score: 0.9870	#Pop: 128	#M+: 1379	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 3.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 48.53 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 17.00 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1797	fail_ct: 0	Time elapsed: 1.00
GA Iter: 0	Max score: 0.7170	Min score: 0.3543	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0050	Min score: 0.6780	#Pop: 128	#M+: 1389	#M-: 30
EvolutionarySearch		#s: 128	Time elapsed: 7.13
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.96 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 17.12 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.64 |     64 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.530 |          59.69 |    256 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 5.453 ms	Trials: 1076	Used time : 475 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.576 |        1334.22 |    128 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.64 |     64 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.522 |          59.87 |    320 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 5.446 ms	Trials: 1140	Used time : 528 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.576 |        1334.22 |    128 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.67 |    128 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.522 |          59.87 |    320 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 5.445 ms	Trials: 1204	Used time : 558 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.576 |        1334.22 |    128 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.448 |         758.15 |     64 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.67 |    128 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.522 |          59.87 |    384 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 5.445 ms	Trials: 1268	Used time : 627 s	Next ID: 8	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.576 |        1334.22 |    128 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.67 |    128 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.522 |          59.87 |    384 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1781	fail_ct: 122	Time elapsed: 0.72
GA Iter: 0	Max score: 0.9880	Min score: 0.9778	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9954	Min score: 0.9837	#Pop: 128	#M+: 1373	#M-: 82
EvolutionarySearch		#s: 128	Time elapsed: 4.13
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 43.16 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.70 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1785	fail_ct: 148	Time elapsed: 0.43
GA Iter: 0	Max score: 0.9865	Min score: 0.9774	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9889	Min score: 0.9816	#Pop: 128	#M+: 1381	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.18
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 43.03 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.96 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1790	fail_ct: 112	Time elapsed: 0.83
GA Iter: 0	Max score: 0.9938	Min score: 0.9773	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9945	Min score: 0.9824	#Pop: 128	#M+: 1376	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 4.38
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 44.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.57 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1692	Time elapsed: 1.64
GA Iter: 0	Max score: 0.8766	Min score: 0.7665	#Pop: 12	#M+: 0	#M-: 0
[14:41:55] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [14:41:55] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9705	Min score: 0.0659	#Pop: 128	#M+: 370	#M-: 6572
EvolutionarySearch		#s: 128	Time elapsed: 6.34
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 5.140 ms	Trials: 1332	Used time : 667 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.576 |        1334.22 |    128 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.67 |    128 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.522 |          59.87 |    448 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 5.140 ms	Trials: 1396	Used time : 717 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.576 |        1334.22 |    128 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.67 |    128 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.522 |          59.87 |    512 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 5.140 ms	Trials: 1460	Used time : 774 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.576 |        1334.22 |    128 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.599 |          26.67 |    128 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    576 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 5.135 ms	Trials: 1524	Used time : 832 s	Next ID: 9	
.T***************************************************************Time elapsed for measurement: 28.98 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 16.54 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1998	fail_ct: 1	Time elapsed: 0.72
GA Iter: 0	Max score: 0.7816	Min score: 0.3734	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9977	Min score: 0.7497	#Pop: 128	#M+: 1376	#M-: 84
EvolutionarySearch		#s: 128	Time elapsed: 5.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.20 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.61 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1971	fail_ct: 10	Time elapsed: 0.66
GA Iter: 0	Max score: 0.9370	Min score: 0.3921	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9839	Min score: 0.8767	#Pop: 128	#M+: 1357	#M-: 221
EvolutionarySearch		#s: 128	Time elapsed: 2.86
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.36 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.74 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1822	fail_ct: 0	Time elapsed: 1.66
GA Iter: 0	Max score: 0.5441	Min score: 0.2792	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9831	Min score: 0.7085	#Pop: 128	#M+: 1393	#M-: 22
EvolutionarySearch		#s: 128	Time elapsed: 7.87
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.22 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.57 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1813	fail_ct: 107	Time elapsed: 0.50
GA Iter: 0	Max score: 0.9808	Min score: 0.9749	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9822	Min score: 0.9784	#Pop: 128	#M+: 1378	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 2.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.97 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.13 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.576 |        1334.22 |    128 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    192 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    576 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 5.135 ms	Trials: 1588	Used time : 886 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.287 |        1176.44 |     64 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    192 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    576 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.970 ms	Trials: 1652	Used time : 910 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    192 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.429 |        1582.84 |    192 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    576 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.862 ms	Trials: 1716	Used time : 944 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    192 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.410 |        1657.38 |    256 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    576 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.824 ms	Trials: 1780	Used time : 990 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1832	fail_ct: 0	Time elapsed: 0.96
GA Iter: 0	Max score: 0.5966	Min score: 0.2715	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0347	Min score: 0.7981	#Pop: 128	#M+: 1394	#M-: 19
EvolutionarySearch		#s: 128	Time elapsed: 5.50
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.21 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.22 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1801	fail_ct: 107	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9839	Min score: 0.9749	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9885	Min score: 0.9797	#Pop: 128	#M+: 1385	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 1.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 38.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 44.42 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1785	fail_ct: 121	Time elapsed: 1.62
GA Iter: 0	Max score: 0.9828	Min score: 0.9731	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9868	Min score: 0.9801	#Pop: 128	#M+: 1370	#M-: 66
EvolutionarySearch		#s: 128	Time elapsed: 4.70
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 36.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.51 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1788	fail_ct: 124	Time elapsed: 1.00
GA Iter: 0	Max score: 0.9818	Min score: 0.9734	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9851	Min score: 0.9784	#Pop: 128	#M+: 1394	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 3.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 40.93 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 18.34 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    192 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.410 |        1657.38 |    256 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    640 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.824 ms	Trials: 1844	Used time : 1043 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    192 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.383 |        1774.62 |    320 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    640 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.770 ms	Trials: 1908	Used time : 1067 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    192 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.383 |        1774.62 |    320 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    704 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.770 ms	Trials: 1972	Used time : 1153 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    192 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.383 |        1774.62 |    320 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    768 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.770 ms	Trials: 2036	Used time : 1209 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1818	fail_ct: 0	Time elapsed: 1.97
GA Iter: 0	Max score: 0.6014	Min score: 0.2620	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9883	Min score: 0.8388	#Pop: 128	#M+: 1390	#M-: 20
EvolutionarySearch		#s: 128	Time elapsed: 13.47
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    192 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.383 |        1774.62 |    320 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    832 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.770 ms	Trials: 2100	Used time : 1273 s	Next ID: 11	
.T***************************************************************Time elapsed for measurement: 26.26 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 18.48 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1685	Time elapsed: 1.19
GA Iter: 0	Max score: 0.8164	Min score: 0.7571	#Pop: 5	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9533	Min score: 0.0415	#Pop: 128	#M+: 392	#M-: 6636
EvolutionarySearch		#s: 128	Time elapsed: 5.66
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
..............................................................
|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    192 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    384 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    832 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.738 ms	Trials: 2164	Used time : 1334 s	Next ID: 9	
.T.T**************************************************************Time elapsed for measurement: 23.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 26.46 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1784	fail_ct: 139	Time elapsed: 1.47
GA Iter: 0	Max score: 0.9844	Min score: 0.9742	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9869	Min score: 0.9798	#Pop: 128	#M+: 1376	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 4.28
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 53.96 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.62 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1790	fail_ct: 143	Time elapsed: 0.42
GA Iter: 0	Max score: 0.9851	Min score: 0.9737	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9854	Min score: 0.9791	#Pop: 128	#M+: 1374	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 2.03
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 51.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.03 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1805	fail_ct: 108	Time elapsed: 0.53
GA Iter: 0	Max score: 0.9823	Min score: 0.9738	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9859	Min score: 0.9792	#Pop: 128	#M+: 1381	#M-: 81
EvolutionarySearch		#s: 128	Time elapsed: 2.40
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 53.94 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 47.18 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1781	fail_ct: 139	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9828	Min score: 0.9737	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9902	Min score: 0.9791	#Pop: 128	#M+: 1381	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 2.52
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 53.26 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.01 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    256 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    384 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          59.99 |    832 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.738 ms	Trials: 2228	Used time : 1391 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    256 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    384 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          60.00 |    896 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.738 ms	Trials: 2292	Used time : 1452 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    256 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    384 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          60.00 |    960 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.738 ms	Trials: 2356	Used time : 1508 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    256 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    384 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.517 |          60.00 |   1024 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.738 ms	Trials: 2420	Used time : 1612 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1643	Time elapsed: 0.50
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[14:55:51] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [14:55:51] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9573	Min score: 0.0189	#Pop: 128	#M+: 377	#M-: 6603
EvolutionarySearch		#s: 128	Time elapsed: 2.23
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    256 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    384 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.514 |          60.08 |   1088 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.735 ms	Trials: 2484	Used time : 1671 s	Next ID: 9	
.T***************************************************************Time elapsed for measurement: 36.43 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.03 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1797	fail_ct: 129	Time elapsed: 1.44
GA Iter: 0	Max score: 0.9824	Min score: 0.9703	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9861	Min score: 0.9773	#Pop: 128	#M+: 1389	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.45
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 40.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.72 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1778	fail_ct: 118	Time elapsed: 0.54
GA Iter: 0	Max score: 0.9817	Min score: 0.9729	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9896	Min score: 0.9781	#Pop: 128	#M+: 1380	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 3.39
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 51.22 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.76 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2002	fail_ct: 0	Time elapsed: 0.70
GA Iter: 0	Max score: 0.8498	Min score: 0.2960	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0007	Min score: 0.7091	#Pop: 128	#M+: 1388	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 3.57
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.14 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.55 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1831	fail_ct: 0	Time elapsed: 0.99
GA Iter: 0	Max score: 0.6721	Min score: 0.2690	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9852	Min score: 0.8552	#Pop: 128	#M+: 1410	#M-: 15
EvolutionarySearch		#s: 128	Time elapsed: 5.30
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.81 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.39 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    320 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    384 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.514 |          60.08 |   1088 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.735 ms	Trials: 2548	Used time : 1720 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    320 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    384 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.514 |          60.08 |   1152 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.735 ms	Trials: 2612	Used time : 1777 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.412 |        1867.10 |    192 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    320 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    384 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.514 |          60.08 |   1216 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.735 ms	Trials: 2676	Used time : 1837 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.310 |        2475.79 |    256 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    320 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    384 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.514 |          60.08 |   1216 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.633 ms	Trials: 2740	Used time : 1859 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1785	fail_ct: 140	Time elapsed: 0.44
GA Iter: 0	Max score: 0.9842	Min score: 0.9714	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9886	Min score: 0.9782	#Pop: 128	#M+: 1378	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 1.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 43.58 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.13 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1761	fail_ct: 136	Time elapsed: 0.43
GA Iter: 0	Max score: 0.9830	Min score: 0.9719	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9855	Min score: 0.9776	#Pop: 128	#M+: 1376	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 1.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 55.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.21 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1789	fail_ct: 124	Time elapsed: 0.40
GA Iter: 0	Max score: 0.9802	Min score: 0.9713	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9879	Min score: 0.9785	#Pop: 128	#M+: 1388	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.22
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 39.85 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 16.79 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1683	Time elapsed: 0.89
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[15:02:26] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:02:26] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9352	Min score: -0.0317	#Pop: 128	#M+: 388	#M-: 6796
EvolutionarySearch		#s: 128	Time elapsed: 5.27
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.84 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.30 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.310 |        2475.79 |    256 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    320 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    448 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.514 |          60.08 |   1216 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.633 ms	Trials: 2804	Used time : 1896 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.310 |        2475.79 |    256 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    320 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    448 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.514 |          60.08 |   1280 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.633 ms	Trials: 2868	Used time : 1944 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.310 |        2475.79 |    256 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    320 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    448 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1344 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.633 ms	Trials: 2932	Used time : 2003 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.310 |        2475.79 |    256 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    320 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    448 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1408 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.633 ms	Trials: 2996	Used time : 2063 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.310 |        2475.79 |    256 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1787	fail_ct: 120	Time elapsed: 0.54
GA Iter: 0	Max score: 0.9906	Min score: 0.9712	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9906	Min score: 0.9786	#Pop: 128	#M+: 1383	#M-: 84
EvolutionarySearch		#s: 128	Time elapsed: 3.16
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.98 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1821	fail_ct: 0	Time elapsed: 0.95
GA Iter: 0	Max score: 0.6037	Min score: 0.2947	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9958	Min score: 0.8669	#Pop: 128	#M+: 1387	#M-: 20
EvolutionarySearch		#s: 128	Time elapsed: 5.38
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 29.76 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1786	fail_ct: 119	Time elapsed: 1.36
GA Iter: 0	Max score: 0.9792	Min score: 0.9704	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9852	Min score: 0.9779	#Pop: 128	#M+: 1370	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 4.73
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 52.26 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.23 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1984	fail_ct: 0	Time elapsed: 0.71
GA Iter: 0	Max score: 0.6136	Min score: 0.2535	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9343	Min score: 0.6712	#Pop: 128	#M+: 1375	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 3.71
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.03 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    384 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    448 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1408 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.633 ms	Trials: 3060	Used time : 2091 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.310 |        2475.79 |    256 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    384 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    448 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1472 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.633 ms	Trials: 3124	Used time : 2152 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.310 |        2475.79 |    256 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    384 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    512 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1472 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.633 ms	Trials: 3188	Used time : 2202 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.310 |        2475.79 |    256 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    384 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    512 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1536 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.633 ms	Trials: 3252	Used time : 2263 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    384 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    512 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1536 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1813	fail_ct: 128	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9855	Min score: 0.9701	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9871	Min score: 0.9786	#Pop: 128	#M+: 1372	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 1.88
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.43 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.04 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1765	fail_ct: 121	Time elapsed: 0.40
GA Iter: 0	Max score: 0.9838	Min score: 0.9722	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9905	Min score: 0.9796	#Pop: 128	#M+: 1389	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 1.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.85 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1653	Time elapsed: 1.23
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[15:08:08] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:08:08] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:08:11] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:08:11] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9301	Min score: -0.2213	#Pop: 98	#M+: 384	#M-: 6632
EvolutionarySearch		#s: 98	Time elapsed: 4.81
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.24 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.43 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1784	fail_ct: 120	Time elapsed: 0.53
GA Iter: 0	Max score: 0.9810	Min score: 0.9717	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9884	Min score: 0.9783	#Pop: 128	#M+: 1383	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 3.42
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 57.07 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1816	fail_ct: 0	Time elapsed: 0.99
GA Iter: 0	Max score: 0.7348	Min score: 0.2598	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9775	Min score: 0.8816	#Pop: 128	#M+: 1389	#M-: 22
EvolutionarySearch		#s: 128	Time elapsed: 5.62
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.13 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.39 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.621 ms	Trials: 3316	Used time : 2294 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    384 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    512 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1600 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.621 ms	Trials: 3380	Used time : 2346 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    384 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    512 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1664 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.621 ms	Trials: 3444	Used time : 2406 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    448 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    512 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1664 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.621 ms	Trials: 3508	Used time : 2431 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    448 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    512 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1728 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.621 ms	Trials: 3572	Used time : 2495 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1775	fail_ct: 118	Time elapsed: 0.43
GA Iter: 0	Max score: 0.9822	Min score: 0.9722	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9857	Min score: 0.9780	#Pop: 128	#M+: 1375	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 1.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 36.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.01 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1771	fail_ct: 128	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9811	Min score: 0.9715	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9858	Min score: 0.9777	#Pop: 128	#M+: 1384	#M-: 85
EvolutionarySearch		#s: 128	Time elapsed: 1.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 46.85 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.70 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1957	fail_ct: 6	Time elapsed: 0.67
GA Iter: 0	Max score: 0.8827	Min score: 0.3697	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0322	Min score: 0.6415	#Pop: 128	#M+: 1366	#M-: 216
EvolutionarySearch		#s: 128	Time elapsed: 3.29
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.24 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1794	fail_ct: 125	Time elapsed: 0.50
GA Iter: 0	Max score: 0.9807	Min score: 0.9704	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9863	Min score: 0.9773	#Pop: 128	#M+: 1372	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 2.33
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 56.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 16.80 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    448 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    576 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.513 |          60.08 |   1728 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.621 ms	Trials: 3636	Used time : 2528 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    448 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    576 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   1792 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.619 ms	Trials: 3700	Used time : 2581 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.179 |        1883.78 |    128 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    448 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    576 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   1856 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.619 ms	Trials: 3764	Used time : 2635 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    448 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    576 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   1856 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.592 ms	Trials: 3828	Used time : 2664 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.087 |          25.86 |     64 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1638	Time elapsed: 1.08
GA Iter: 0	Max score: 0.9890	Min score: 0.6830	#Pop: 42	#M+: 0	#M-: 0
[15:13:42] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [15:13:42] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:13:42] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (None)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (None)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (None)
      T_divide = ...

with: [15:13:42] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:13:43] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (None)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (None)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (None)
      T_divide = ...

with: [15:13:43] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:13:43] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [15:13:43] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:13:43] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [15:13:43] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 1.0010	Min score: 0.5628	#Pop: 128	#M+: 396	#M-: 6754
EvolutionarySearch		#s: 128	Time elapsed: 3.53
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 9.71 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 16.58 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1654	Time elapsed: 0.61
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[15:14:11] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:14:11] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:14:11] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:14:11] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:14:11] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:14:11] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:14:13] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:14:13] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:14:13] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:14:13] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:14:14] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:14:14] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9183	Min score: -0.4916	#Pop: 93	#M+: 396	#M-: 6743
EvolutionarySearch		#s: 93	Time elapsed: 3.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 10.99 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1789	fail_ct: 118	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9793	Min score: 0.9710	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9865	Min score: 0.9774	#Pop: 128	#M+: 1380	#M-: 83
EvolutionarySearch		#s: 128	Time elapsed: 1.95
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 37.10 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 15.09 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2003	fail_ct: 1	Time elapsed: 0.94
GA Iter: 0	Max score: 0.5583	Min score: 0.2615	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9845	Min score: 0.7857	#Pop: 128	#M+: 1391	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 5.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.47 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.56 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    448 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    576 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   1920 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.592 ms	Trials: 3892	Used time : 2740 s	Next ID: 0	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    448 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    576 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   1920 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.588 ms	Trials: 3956	Used time : 2771 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    512 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    576 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   1920 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.588 ms	Trials: 4020	Used time : 2789 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.298 |        2579.09 |    320 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    512 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    576 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   1984 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.588 ms	Trials: 4084	Used time : 2843 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    512 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1794	fail_ct: 0	Time elapsed: 0.94
GA Iter: 0	Max score: 0.6614	Min score: 0.2969	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9798	Min score: 0.8854	#Pop: 128	#M+: 1395	#M-: 23
EvolutionarySearch		#s: 128	Time elapsed: 5.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.10 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.55 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1800	fail_ct: 114	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9825	Min score: 0.9709	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9856	Min score: 0.9782	#Pop: 128	#M+: 1385	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 1.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 45.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 22.52 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1756	fail_ct: 143	Time elapsed: 0.84
GA Iter: 0	Max score: 0.9803	Min score: 0.9714	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9883	Min score: 0.9777	#Pop: 128	#M+: 1383	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.70
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 52.24 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.26 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1784	fail_ct: 137	Time elapsed: 0.42
GA Iter: 0	Max score: 0.9800	Min score: 0.9708	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9863	Min score: 0.9776	#Pop: 128	#M+: 1380	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 2.50
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 57.82 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.32 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1661	Time elapsed: 0.54
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[15:19:33] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:19:33] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:19:34] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:19:34] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:19:34] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:19:34] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:19:34] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:19:34] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9124	Min score: -0.2526	#Pop: 67	#M+: 388	#M-: 6718
EvolutionarySearch		#s: 67	Time elapsed: 2.26
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.97 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.26 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    576 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   1984 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.580 ms	Trials: 4148	Used time : 2875 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    512 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    640 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   1984 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.580 ms	Trials: 4212	Used time : 2896 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    512 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    640 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2048 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.580 ms	Trials: 4276	Used time : 2966 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    512 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    640 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2112 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.580 ms	Trials: 4340	Used time : 3024 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    512 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    640 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2176 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.580 ms	Trials: 4404	Used time : 3094 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1807	fail_ct: 113	Time elapsed: 1.05
GA Iter: 0	Max score: 0.9801	Min score: 0.9705	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9833	Min score: 0.9771	#Pop: 128	#M+: 1374	#M-: 82
EvolutionarySearch		#s: 128	Time elapsed: 4.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 61.91 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.47 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1810	fail_ct: 0	Time elapsed: 1.25
GA Iter: 0	Max score: 0.7650	Min score: 0.2395	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9829	Min score: 0.8996	#Pop: 128	#M+: 1387	#M-: 24
EvolutionarySearch		#s: 128	Time elapsed: 5.83
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.24 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.44 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1777	fail_ct: 134	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9780	Min score: 0.9706	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9861	Min score: 0.9770	#Pop: 128	#M+: 1387	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 1.91
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.90 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.37 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1815	fail_ct: 0	Time elapsed: 0.95
GA Iter: 0	Max score: 0.6541	Min score: 0.2432	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9931	Min score: 0.6729	#Pop: 128	#M+: 1392	#M-: 20
EvolutionarySearch		#s: 128	Time elapsed: 4.88
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.62 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 29.41 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    576 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    640 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2176 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.580 ms	Trials: 4468	Used time : 3133 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    576 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    640 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2240 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.580 ms	Trials: 4532	Used time : 3214 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    576 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    704 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2240 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.580 ms	Trials: 4596	Used time : 3242 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.143 |        2375.89 |    128 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    576 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    704 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2304 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.580 ms	Trials: 4660	Used time : 3302 s	Next ID: 8	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1786	fail_ct: 138	Time elapsed: 1.12
GA Iter: 0	Max score: 0.9811	Min score: 0.9709	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9857	Min score: 0.9769	#Pop: 128	#M+: 1391	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 5.33
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 38.26 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.00 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1800	fail_ct: 120	Time elapsed: 0.39
GA Iter: 0	Max score: 0.9829	Min score: 0.9726	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9858	Min score: 0.9776	#Pop: 128	#M+: 1373	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 1.95
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 48.36 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.67 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1809	fail_ct: 0	Time elapsed: 1.00
GA Iter: 0	Max score: 0.6181	Min score: 0.2479	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9697	Min score: 0.8987	#Pop: 128	#M+: 1380	#M-: 23
EvolutionarySearch		#s: 128	Time elapsed: 5.86
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.52 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1658	Time elapsed: 0.48
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[15:26:06] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:26:06] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:26:06] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:26:06] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:26:06] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:26:06] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9051	Min score: -0.2335	#Pop: 37	#M+: 386	#M-: 6803
EvolutionarySearch		#s: 37	Time elapsed: 2.25
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 37 programs to measure:
.....................................*************************************Time elapsed for measurement: 14.64 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.50 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    576 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    704 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2304 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 4724	Used time : 3352 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    576 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    704 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2368 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 4788	Used time : 3403 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    576 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    704 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2432 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 4852	Used time : 3456 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    576 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    768 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2432 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 4916	Used time : 3485 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1805	fail_ct: 106	Time elapsed: 0.59
GA Iter: 0	Max score: 0.9801	Min score: 0.9717	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9843	Min score: 0.9775	#Pop: 128	#M+: 1377	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 2.51
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 56.76 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.75 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1793	fail_ct: 119	Time elapsed: 0.39
GA Iter: 0	Max score: 0.9795	Min score: 0.9702	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9834	Min score: 0.9771	#Pop: 128	#M+: 1379	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 1.89
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 50.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.51 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1781	fail_ct: 119	Time elapsed: 0.76
GA Iter: 0	Max score: 0.9847	Min score: 0.9698	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9857	Min score: 0.9774	#Pop: 128	#M+: 1373	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 3.24
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 44.92 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.60 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1789	fail_ct: 125	Time elapsed: 0.58
GA Iter: 0	Max score: 0.9845	Min score: 0.9706	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9857	Min score: 0.9768	#Pop: 128	#M+: 1382	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.61
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 46.09 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.47 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    640 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    768 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2432 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 4953	Used time : 3517 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    640 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    768 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2496 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 5017	Used time : 3581 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    640 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    768 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2560 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 5081	Used time : 3645 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    640 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    768 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2624 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 5145	Used time : 3697 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    640 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    768 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2688 |
-----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1809	fail_ct: 0	Time elapsed: 1.25
GA Iter: 0	Max score: 0.5900	Min score: 0.2817	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9758	Min score: 0.9011	#Pop: 128	#M+: 1388	#M-: 27
EvolutionarySearch		#s: 128	Time elapsed: 5.87
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.94 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 19.58 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1647	Time elapsed: 1.63
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[15:31:11] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:31:11] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:31:11] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:31:11] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:31:11] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:31:11] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:31:12] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:31:12] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:31:14] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:31:14] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:31:14] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:31:14] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:31:14] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:31:14] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9013	Min score: -0.2333	#Pop: 31	#M+: 390	#M-: 6774
EvolutionarySearch		#s: 31	Time elapsed: 5.51
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 31 programs to measure:
...............................*******************************Time elapsed for measurement: 7.36 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 35.37 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1784	fail_ct: 133	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9807	Min score: 0.9701	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9864	Min score: 0.9775	#Pop: 128	#M+: 1382	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 2.08
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 59.41 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.43 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2007	fail_ct: 0	Time elapsed: 0.71
GA Iter: 0	Max score: 0.5941	Min score: 0.2714	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9413	Min score: 0.8264	#Pop: 128	#M+: 1390	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 4.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.32 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 25.91 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1793	fail_ct: 130	Time elapsed: 0.74
GA Iter: 0	Max score: 0.9795	Min score: 0.9703	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9856	Min score: 0.9768	#Pop: 128	#M+: 1366	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 3.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 34.04 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 35.14 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 5209	Used time : 3750 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    640 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    832 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2688 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 5273	Used time : 3789 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    704 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    832 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2688 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 5304	Used time : 3839 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.290 |        2650.00 |    384 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    704 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    832 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2752 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.567 ms	Trials: 5368	Used time : 3904 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    704 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    832 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2752 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 5432	Used time : 3947 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1788	fail_ct: 136	Time elapsed: 0.78
GA Iter: 0	Max score: 0.9786	Min score: 0.9698	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9864	Min score: 0.9769	#Pop: 128	#M+: 1380	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 3.43
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 51.70 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.13 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1771	fail_ct: 0	Time elapsed: 1.18
GA Iter: 0	Max score: 0.7405	Min score: 0.2572	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9798	Min score: 0.9011	#Pop: 128	#M+: 1388	#M-: 23
EvolutionarySearch		#s: 128	Time elapsed: 6.06
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.12 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 26.77 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1782	fail_ct: 147	Time elapsed: 1.10
GA Iter: 0	Max score: 0.9811	Min score: 0.9713	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9873	Min score: 0.9772	#Pop: 128	#M+: 1391	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 4.26
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 42.32 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.84 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1739	fail_ct: 161	Time elapsed: 0.40
GA Iter: 0	Max score: 0.9796	Min score: 0.9701	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9852	Min score: 0.9768	#Pop: 128	#M+: 1382	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 1.91
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 53.61 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.82 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    704 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    832 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2816 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 5496	Used time : 4020 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    704 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    832 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2880 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 5560	Used time : 4088 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    704 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    896 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2880 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 5624	Used time : 4138 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    704 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    896 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   2944 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 5688	Used time : 4188 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1678	Time elapsed: 0.49
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[15:38:47] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:38:47] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:38:50] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:38:50] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:38:50] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:38:50] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.7867	Min score: -0.2138	#Pop: 20	#M+: 393	#M-: 6682
EvolutionarySearch		#s: 20	Time elapsed: 4.49
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 20 programs to measure:
....................********************Time elapsed for measurement: 7.88 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 22.70 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1810	fail_ct: 121	Time elapsed: 0.55
GA Iter: 0	Max score: 0.9818	Min score: 0.9708	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9898	Min score: 0.9769	#Pop: 128	#M+: 1392	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 43.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.66 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1825	fail_ct: 0	Time elapsed: 0.95
GA Iter: 0	Max score: 0.7145	Min score: 0.2589	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9775	Min score: 0.8946	#Pop: 128	#M+: 1389	#M-: 26
EvolutionarySearch		#s: 128	Time elapsed: 5.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.18 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1767	fail_ct: 143	Time elapsed: 0.72
GA Iter: 0	Max score: 0.9791	Min score: 0.9713	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9868	Min score: 0.9770	#Pop: 128	#M+: 1378	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 3.38
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 40.91 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.93 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    704 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    896 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3008 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 5752	Used time : 4247 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    768 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    896 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3008 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 5772	Used time : 4283 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    768 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    896 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3072 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 5836	Used time : 4332 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    768 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    960 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3072 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 5900	Used time : 4388 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    768 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    960 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1801	fail_ct: 125	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9821	Min score: 0.9723	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9880	Min score: 0.9766	#Pop: 128	#M+: 1387	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 45.53 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.83 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1958	fail_ct: 7	Time elapsed: 0.61
GA Iter: 0	Max score: 0.6249	Min score: 0.3003	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9462	Min score: 0.5812	#Pop: 128	#M+: 1353	#M-: 217
EvolutionarySearch		#s: 128	Time elapsed: 2.87
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.28 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1806	fail_ct: 127	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9781	Min score: 0.9703	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9850	Min score: 0.9765	#Pop: 128	#M+: 1378	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 1.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.01 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.91 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1672	Time elapsed: 0.50
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[15:44:12] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:44:12] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:44:14] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:44:14] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:44:14] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:44:14] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:44:14] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:44:14] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:44:15] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:44:15] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:44:15] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:44:15] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.7569	Min score: -0.2044	#Pop: 21	#M+: 386	#M-: 6620
EvolutionarySearch		#s: 21	Time elapsed: 4.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 21 programs to measure:
.....................*********************Time elapsed for measurement: 6.52 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.12 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1956	fail_ct: 13	Time elapsed: 1.49
GA Iter: 0	Max score: 0.6544	Min score: 0.3067	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9554	Min score: 0.5993	#Pop: 128	#M+: 1364	#M-: 214
EvolutionarySearch		#s: 128	Time elapsed: 5.90
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.88 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 30.77 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3136 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 5964	Used time : 4444 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    192 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    768 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    960 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3200 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 6028	Used time : 4495 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    256 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    768 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    960 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3200 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 6092	Used time : 4512 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    256 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    768 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    960 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3264 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 6156	Used time : 4572 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.153 |        2212.89 |    256 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    832 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    960 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3264 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.565 ms	Trials: 6177	Used time : 4604 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1818	fail_ct: 121	Time elapsed: 0.44
GA Iter: 0	Max score: 0.9800	Min score: 0.9704	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9859	Min score: 0.9761	#Pop: 128	#M+: 1383	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 2.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 52.64 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.18 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1798	fail_ct: 0	Time elapsed: 1.18
GA Iter: 0	Max score: 0.6682	Min score: 0.2844	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9735	Min score: 0.8963	#Pop: 128	#M+: 1383	#M-: 25
EvolutionarySearch		#s: 128	Time elapsed: 5.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.57 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.55 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1808	fail_ct: 116	Time elapsed: 0.58
GA Iter: 0	Max score: 0.9779	Min score: 0.9699	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9862	Min score: 0.9767	#Pop: 128	#M+: 1378	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 3.25
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    832 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    960 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3264 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6241	Used time : 4664 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    832 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |    960 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3328 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6305	Used time : 4725 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    832 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |   1024 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3328 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6369	Used time : 4772 s	Next ID: 12	
.T***********************************************Time elapsed for measurement: 69.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.17 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1767	fail_ct: 146	Time elapsed: 0.51
GA Iter: 0	Max score: 0.9798	Min score: 0.9712	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9868	Min score: 0.9766	#Pop: 128	#M+: 1377	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 3.31
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.16 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.02 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1787	fail_ct: 137	Time elapsed: 0.42
GA Iter: 0	Max score: 0.9795	Min score: 0.9705	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9875	Min score: 0.9767	#Pop: 128	#M+: 1382	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.38
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 51.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.70 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1670	Time elapsed: 1.10
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[15:51:12] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:51:12] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:51:14] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:51:14] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.6131	Min score: -0.0111	#Pop: 9	#M+: 377	#M-: 6789
EvolutionarySearch		#s: 9	Time elapsed: 3.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 9 programs to measure:
.........*********Time elapsed for measurement: 2.99 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 7.00 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1807	fail_ct: 0	Time elapsed: 0.91
GA Iter: 0	Max score: 0.6028	Min score: 0.2929	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9852	Min score: 0.8941	#Pop: 128	#M+: 1378	#M-: 25
EvolutionarySearch		#s: 128	Time elapsed: 5.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.70 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    832 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |   1024 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3392 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6433	Used time : 4857 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    832 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |   1024 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3456 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6497	Used time : 4912 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    832 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |   1024 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3520 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6561	Used time : 4992 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    896 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1850.20 |   1024 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3520 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6570	Used time : 5007 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1801	fail_ct: 124	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9805	Min score: 0.9709	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9862	Min score: 0.9769	#Pop: 128	#M+: 1389	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 2.07
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 49.71 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.79 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1785	fail_ct: 125	Time elapsed: 0.40
GA Iter: 0	Max score: 0.9786	Min score: 0.9718	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9867	Min score: 0.9766	#Pop: 128	#M+: 1393	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 1.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.40 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.13 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1797	fail_ct: 114	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9790	Min score: 0.9715	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9877	Min score: 0.9768	#Pop: 128	#M+: 1384	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 2.03
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 39.22 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.33 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1783	fail_ct: 126	Time elapsed: 0.35
GA Iter: 0	Max score: 0.9810	Min score: 0.9704	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9883	Min score: 0.9773	#Pop: 128	#M+: 1380	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.21 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.05 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    896 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1088 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3520 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6634	Used time : 5042 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    896 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1088 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3584 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6698	Used time : 5097 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    896 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1088 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3648 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6762	Used time : 5157 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    896 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1088 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3712 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6826	Used time : 5219 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1799	fail_ct: 0	Time elapsed: 0.91
GA Iter: 0	Max score: 0.7474	Min score: 0.2750	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9731	Min score: 0.8881	#Pop: 128	#M+: 1387	#M-: 31
EvolutionarySearch		#s: 128	Time elapsed: 5.07
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.30 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.14 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1814	fail_ct: 0	Time elapsed: 0.91
GA Iter: 0	Max score: 0.5150	Min score: 0.2275	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9643	Min score: 0.7939	#Pop: 128	#M+: 1382	#M-: 19
EvolutionarySearch		#s: 128	Time elapsed: 6.01
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.75 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1808	fail_ct: 0	Time elapsed: 1.67
GA Iter: 0	Max score: 0.7128	Min score: 0.2445	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9393	Min score: 0.8619	#Pop: 128	#M+: 1389	#M-: 8
EvolutionarySearch		#s: 128	Time elapsed: 12.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 17.76 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 48.59 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1997	fail_ct: 1	Time elapsed: 1.10
GA Iter: 0	Max score: 0.7497	Min score: 0.2676	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9685	Min score: 0.8450	#Pop: 128	#M+: 1386	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 5.36
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 25.11 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 35.98 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    896 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1088 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3776 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6890	Used time : 5279 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.129 |        2627.29 |    192 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    896 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1152 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3776 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.563 ms	Trials: 6954	Used time : 5306 s	Next ID: 8	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    256 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    896 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1152 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3776 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.560 ms	Trials: 7018	Used time : 5353 s	Next ID: 8	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2666.65 |    448 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    896 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1152 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3776 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.560 ms	Trials: 7082	Used time : 5435 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    896 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1152 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3776 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1695	Time elapsed: 0.85
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[15:59:43] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:59:43] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:59:45] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:59:45] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[15:59:47] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [15:59:47] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.6103	Min score: -0.0395	#Pop: 12	#M+: 379	#M-: 6747
EvolutionarySearch		#s: 12	Time elapsed: 5.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 12 programs to measure:
............************Time elapsed for measurement: 5.95 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 23.50 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1796	fail_ct: 129	Time elapsed: 0.68
GA Iter: 0	Max score: 0.9803	Min score: 0.9718	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9870	Min score: 0.9773	#Pop: 128	#M+: 1387	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 2.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 43.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1801	fail_ct: 109	Time elapsed: 1.12
GA Iter: 0	Max score: 0.9916	Min score: 0.9714	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9916	Min score: 0.9770	#Pop: 128	#M+: 1372	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 5.39
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 46.69 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 22.80 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1648	Time elapsed: 0.80
GA Iter: 0	Max score: 0.8386	Min score: 0.6425	#Pop: 18	#M+: 0	#M-: 0
[16:02:35] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [16:02:35] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:02:35] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [16:02:35] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:02:35] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [16:02:35] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9427	Min score: 0.3756	#Pop: 128	#M+: 385	#M-: 6777
EvolutionarySearch		#s: 128	Time elapsed: 2.65
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.49 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 9.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1778	fail_ct: 133	Time elapsed: 0.43
GA Iter: 0	Max score: 0.9786	Min score: 0.9698	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9875	Min score: 0.9774	#Pop: 128	#M+: 1386	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 2.13
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.560 ms	Trials: 7146	Used time : 5502 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    960 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1152 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3776 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.560 ms	Trials: 7158	Used time : 5538 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    960 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1152 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3840 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.560 ms	Trials: 7222	Used time : 5598 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.01 |    128 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    960 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1152 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3904 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.560 ms	Trials: 7286	Used time : 5674 s	Next ID: 0	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    960 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1152 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3904 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7350	Used time : 5704 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1790	fail_ct: 0	Time elapsed: 0.93
GA Iter: 0	Max score: 0.7332	Min score: 0.2739	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9863	Min score: 0.8936	#Pop: 128	#M+: 1389	#M-: 26
EvolutionarySearch		#s: 128	Time elapsed: 5.08
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.15 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 26.38 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1786	fail_ct: 121	Time elapsed: 1.32
GA Iter: 0	Max score: 0.9798	Min score: 0.9699	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9865	Min score: 0.9772	#Pop: 128	#M+: 1383	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 4.55
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 36.38 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.08 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1687	Time elapsed: 0.94
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[16:06:05] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:06:05] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:06:05] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:06:05] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.6919	Min score: -0.2003	#Pop: 10	#M+: 381	#M-: 6696
EvolutionarySearch		#s: 10	Time elapsed: 3.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 10 programs to measure:
..........**********Time elapsed for measurement: 5.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 23.47 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1783	fail_ct: 128	Time elapsed: 0.66
GA Iter: 0	Max score: 0.9795	Min score: 0.9716	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9880	Min score: 0.9772	#Pop: 128	#M+: 1387	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 3.51
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.33 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    960 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1152 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3968 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7414	Used time : 5764 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    960 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1216 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   3968 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7478	Used time : 5818 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |    960 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1216 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   4032 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7542	Used time : 5884 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1024 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1216 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   4032 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7552	Used time : 5918 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1777	fail_ct: 134	Time elapsed: 0.81
GA Iter: 0	Max score: 0.9788	Min score: 0.9710	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9863	Min score: 0.9768	#Pop: 128	#M+: 1383	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 4.10
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 49.84 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.16 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1813	fail_ct: 0	Time elapsed: 0.96
GA Iter: 0	Max score: 0.5683	Min score: 0.2759	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0110	Min score: 0.8915	#Pop: 128	#M+: 1376	#M-: 33
EvolutionarySearch		#s: 128	Time elapsed: 5.16
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 9.50 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1792	fail_ct: 130	Time elapsed: 0.40
GA Iter: 0	Max score: 0.9799	Min score: 0.9698	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9850	Min score: 0.9775	#Pop: 128	#M+: 1390	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 2.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 38.03 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.99 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1814	fail_ct: 115	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9813	Min score: 0.9705	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9874	Min score: 0.9777	#Pop: 128	#M+: 1369	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 2.29
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 53.06 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 7.79 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1024 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1216 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   4096 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7616	Used time : 5981 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1024 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1216 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   4160 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7680	Used time : 6039 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1024 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1280 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   4160 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7744	Used time : 6074 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1024 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1280 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.13 |   4224 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7808	Used time : 6128 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1024 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1787	fail_ct: 135	Time elapsed: 0.62
GA Iter: 0	Max score: 0.9793	Min score: 0.9706	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9865	Min score: 0.9766	#Pop: 128	#M+: 1395	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 2.27
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 55.82 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.54 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1705	Time elapsed: 0.49
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[16:12:15] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:12:15] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:12:15] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:12:15] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:12:15] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:12:15] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:12:16] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:12:16] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.6363	Min score: -0.2220	#Pop: 7	#M+: 370	#M-: 6758
EvolutionarySearch		#s: 7	Time elapsed: 2.24
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 7 programs to measure:
.......*******Time elapsed for measurement: 4.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.32 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1757	fail_ct: 133	Time elapsed: 0.86
GA Iter: 0	Max score: 0.9789	Min score: 0.9715	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9903	Min score: 0.9770	#Pop: 128	#M+: 1381	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 3.52
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 58.55 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.14 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2000	fail_ct: 0	Time elapsed: 0.69
GA Iter: 0	Max score: 0.5586	Min score: 0.2593	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9669	Min score: 0.8428	#Pop: 128	#M+: 1382	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 4.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.08 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.18 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1811	fail_ct: 0	Time elapsed: 0.92
GA Iter: 0	Max score: 0.6611	Min score: 0.2526	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9752	Min score: 0.8980	#Pop: 128	#M+: 1389	#M-: 35
EvolutionarySearch		#s: 128	Time elapsed: 6.71
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.96 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.51 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1280 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4288 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7872	Used time : 6192 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1024 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1280 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4352 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7936	Used time : 6255 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1088 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1280 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4352 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 7943	Used time : 6287 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    512 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1088 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1280 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4416 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8007	Used time : 6353 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1088 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1280 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4416 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8071	Used time : 6383 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1784	fail_ct: 131	Time elapsed: 0.39
GA Iter: 0	Max score: 0.9795	Min score: 0.9705	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9856	Min score: 0.9769	#Pop: 128	#M+: 1384	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.13 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1777	fail_ct: 134	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9795	Min score: 0.9707	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9861	Min score: 0.9771	#Pop: 128	#M+: 1374	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 1.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 40.44 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.39 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1800	fail_ct: 120	Time elapsed: 1.22
GA Iter: 0	Max score: 0.9813	Min score: 0.9715	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9866	Min score: 0.9771	#Pop: 128	#M+: 1376	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 4.88
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 44.58 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.10 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 79	fail_ct: 1683	Time elapsed: 0.49
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[16:18:08] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:18:08] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:18:08] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:18:08] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:18:08] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:18:08] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:18:09] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:18:09] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:18:09] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:18:09] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:18:09] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:18:09] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:18:09] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:18:09] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.6923	Min score: -0.0381	#Pop: 5	#M+: 365	#M-: 6770
EvolutionarySearch		#s: 5	Time elapsed: 2.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 5 programs to measure:
.....*****Time elapsed for measurement: 3.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.42 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1088 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1344 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4416 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8135	Used time : 6424 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1088 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1344 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4480 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8199	Used time : 6476 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1088 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1344 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4544 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8263	Used time : 6554 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1088 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1344 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4608 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8327	Used time : 6608 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1813	fail_ct: 0	Time elapsed: 0.94
GA Iter: 0	Max score: 0.7347	Min score: 0.2468	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9765	Min score: 0.8895	#Pop: 128	#M+: 1379	#M-: 27
EvolutionarySearch		#s: 128	Time elapsed: 5.88
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.77 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1798	fail_ct: 121	Time elapsed: 0.75
GA Iter: 0	Max score: 0.9795	Min score: 0.9712	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9865	Min score: 0.9768	#Pop: 128	#M+: 1381	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 3.86
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 50.30 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.38 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1797	fail_ct: 121	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9858	Min score: 0.9716	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9873	Min score: 0.9773	#Pop: 128	#M+: 1377	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 1.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 45.74 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.78 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1766	fail_ct: 134	Time elapsed: 0.36
GA Iter: 0	Max score: 0.9840	Min score: 0.9713	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9863	Min score: 0.9778	#Pop: 128	#M+: 1382	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 2.13
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 57.24 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.15 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1152 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1344 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4608 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8332	Used time : 6617 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1152 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1408 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4608 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8396	Used time : 6661 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1152 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1408 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4672 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8460	Used time : 6720 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1152 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1408 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4736 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8524	Used time : 6772 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1798	fail_ct: 114	Time elapsed: 0.44
GA Iter: 0	Max score: 0.9832	Min score: 0.9717	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9883	Min score: 0.9774	#Pop: 128	#M+: 1382	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.49
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 56.63 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.91 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1799	fail_ct: 0	Time elapsed: 1.17
GA Iter: 0	Max score: 0.6757	Min score: 0.2691	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9758	Min score: 0.8922	#Pop: 128	#M+: 1384	#M-: 29
EvolutionarySearch		#s: 128	Time elapsed: 5.35
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.82 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.61 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1683	Time elapsed: 1.75
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[16:24:12] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:24:12] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:24:12] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:24:12] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:24:13] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:24:13] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:24:13] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:24:13] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.6803	Min score: -0.1855	#Pop: 2	#M+: 383	#M-: 6657
EvolutionarySearch		#s: 2	Time elapsed: 4.90
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 2 programs to measure:
..**Time elapsed for measurement: 1.95 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 16.82 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1798	fail_ct: 125	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9792	Min score: 0.9711	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9866	Min score: 0.9769	#Pop: 128	#M+: 1377	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.38
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 44.75 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 9.82 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1152 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1408 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4800 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8588	Used time : 6840 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1152 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1408 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4864 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8652	Used time : 6908 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1152 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1472 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4864 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8716	Used time : 6970 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1216 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1472 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4864 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8718	Used time : 6996 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1216 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1472 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4928 |
-----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1807	fail_ct: 112	Time elapsed: 1.17
GA Iter: 0	Max score: 0.9836	Min score: 0.9717	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9876	Min score: 0.9766	#Pop: 128	#M+: 1369	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 4.40
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 33.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.10 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1976	fail_ct: 9	Time elapsed: 0.62
GA Iter: 0	Max score: 0.6911	Min score: 0.2926	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9259	Min score: 0.6572	#Pop: 128	#M+: 1365	#M-: 208
EvolutionarySearch		#s: 128	Time elapsed: 3.01
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.02 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.90 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1811	fail_ct: 123	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9849	Min score: 0.9709	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9875	Min score: 0.9771	#Pop: 128	#M+: 1370	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 1.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.17 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.58 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2003	fail_ct: 0	Time elapsed: 0.69
GA Iter: 0	Max score: 0.6962	Min score: 0.2717	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9631	Min score: 0.8457	#Pop: 128	#M+: 1389	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 3.75
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.21 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.81 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1811	fail_ct: 0	Time elapsed: 0.90
GA Iter: 0	Max score: 0.7433	Min score: 0.2491	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9764	Min score: 0.8831	#Pop: 128	#M+: 1386	#M-: 28
EvolutionarySearch		#s: 128	Time elapsed: 5.62
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.57 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 50.11 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8782	Used time : 7053 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.41 |    320 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1216 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1472 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4992 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8846	Used time : 7120 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1216 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1472 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   4992 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8910	Used time : 7141 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.288 |        2667.16 |    576 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1216 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1472 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5056 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.559 ms	Trials: 8974	Used time : 7201 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1216 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1472 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5056 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.543 ms	Trials: 9038	Used time : 7224 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1785	fail_ct: 122	Time elapsed: 1.15
GA Iter: 0	Max score: 0.9821	Min score: 0.9711	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9861	Min score: 0.9764	#Pop: 128	#M+: 1385	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 4.75
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 52.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.56 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1677	Time elapsed: 0.47
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[16:30:39] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:30:39] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:30:39] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:30:39] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:30:40] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:30:40] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:30:40] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:30:40] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:30:41] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:30:41] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:30:41] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:30:41] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:30:41] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:30:41] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.7600	Min score: 0.0990	#Pop: 4	#M+: 377	#M-: 6753
EvolutionarySearch		#s: 4	Time elapsed: 3.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 4 programs to measure:
....****Time elapsed for measurement: 3.31 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 18.83 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1793	fail_ct: 107	Time elapsed: 0.92
GA Iter: 0	Max score: 0.9805	Min score: 0.9706	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9849	Min score: 0.9771	#Pop: 128	#M+: 1383	#M-: 65
EvolutionarySearch		#s: 128	Time elapsed: 2.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.88 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1777	fail_ct: 126	Time elapsed: 0.39
GA Iter: 0	Max score: 0.9787	Min score: 0.9707	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9852	Min score: 0.9767	#Pop: 128	#M+: 1377	#M-: 84
EvolutionarySearch		#s: 128	Time elapsed: 1.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.14 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 16.88 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1216 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1536 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5056 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.543 ms	Trials: 9102	Used time : 7297 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1216 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1536 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5120 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.543 ms	Trials: 9166	Used time : 7359 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1280 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1536 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5120 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.543 ms	Trials: 9170	Used time : 7385 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1280 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1536 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5184 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.543 ms	Trials: 9234	Used time : 7450 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1786	fail_ct: 129	Time elapsed: 0.54
GA Iter: 0	Max score: 0.9833	Min score: 0.9716	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9870	Min score: 0.9768	#Pop: 128	#M+: 1381	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 3.24
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 35.63 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 29.04 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1808	fail_ct: 0	Time elapsed: 1.19
GA Iter: 0	Max score: 0.7288	Min score: 0.2638	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9760	Min score: 0.8893	#Pop: 128	#M+: 1395	#M-: 30
EvolutionarySearch		#s: 128	Time elapsed: 8.84
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.62 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.06 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1807	fail_ct: 119	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9790	Min score: 0.9701	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9848	Min score: 0.9763	#Pop: 128	#M+: 1371	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 3.07
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 41.28 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.66 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1631	Time elapsed: 0.49
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[16:36:01] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:36:01] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.8087	Min score: 0.0119	#Pop: 2	#M+: 379	#M-: 6800
EvolutionarySearch		#s: 2	Time elapsed: 2.29
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 2 programs to measure:
..**Time elapsed for measurement: 1.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.62 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1280 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1536 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5248 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.543 ms	Trials: 9298	Used time : 7517 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1280 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.367 |        1851.46 |   1536 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5312 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.543 ms	Trials: 9362	Used time : 7585 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1280 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1600 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5312 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.539 ms	Trials: 9426	Used time : 7630 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1280 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1600 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5376 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.539 ms	Trials: 9490	Used time : 7680 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1344 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1600 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1796	fail_ct: 125	Time elapsed: 1.02
GA Iter: 0	Max score: 0.9796	Min score: 0.9702	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9859	Min score: 0.9765	#Pop: 128	#M+: 1385	#M-: 67
EvolutionarySearch		#s: 128	Time elapsed: 4.54
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 48.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1816	fail_ct: 0	Time elapsed: 0.89
GA Iter: 0	Max score: 0.5959	Min score: 0.2599	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9659	Min score: 0.8692	#Pop: 128	#M+: 1383	#M-: 32
EvolutionarySearch		#s: 128	Time elapsed: 4.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.99 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.59 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1816	fail_ct: 101	Time elapsed: 0.84
GA Iter: 0	Max score: 0.9835	Min score: 0.9699	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9850	Min score: 0.9761	#Pop: 128	#M+: 1374	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 2.76
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.83 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.61 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1783	fail_ct: 136	Time elapsed: 0.39
GA Iter: 0	Max score: 0.9796	Min score: 0.9707	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9836	Min score: 0.9761	#Pop: 128	#M+: 1386	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 2.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 51.07 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.83 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1789	fail_ct: 123	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9796	Min score: 0.9713	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9876	Min score: 0.9766	#Pop: 128	#M+: 1386	#M-: 83
EvolutionarySearch		#s: 128	Time elapsed: 2.13
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 56.58 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 7.41 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5376 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.539 ms	Trials: 9492	Used time : 7692 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1344 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1600 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5440 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.539 ms	Trials: 9556	Used time : 7751 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1344 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1664 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5440 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.539 ms	Trials: 9620	Used time : 7782 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1344 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1664 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5504 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.539 ms	Trials: 9684	Used time : 7837 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1344 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1664 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5568 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.539 ms	Trials: 9748	Used time : 7894 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1996	fail_ct: 1	Time elapsed: 0.82
GA Iter: 0	Max score: 0.6044	Min score: 0.2559	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9544	Min score: 0.8109	#Pop: 128	#M+: 1371	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 4.24
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.84 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1769	fail_ct: 140	Time elapsed: 0.63
GA Iter: 0	Max score: 0.9801	Min score: 0.9716	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9885	Min score: 0.9759	#Pop: 128	#M+: 1381	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 2.85
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 38.85 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 30.64 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1685	Time elapsed: 0.99
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[16:42:28] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:42:28] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:42:32] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:42:32] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:42:32] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:42:32] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:42:32] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:42:32] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:42:32] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:42:32] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.8155	Min score: 0.1125	#Pop: 4	#M+: 387	#M-: 6704
EvolutionarySearch		#s: 4	Time elapsed: 5.86
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 4 programs to measure:
....****Time elapsed for measurement: 2.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 22.03 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1818	fail_ct: 0	Time elapsed: 1.08
GA Iter: 0	Max score: 0.5057	Min score: 0.2562	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9643	Min score: 0.8803	#Pop: 128	#M+: 1376	#M-: 31
EvolutionarySearch		#s: 128	Time elapsed: 5.12
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.67 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 28.51 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.273 |        2819.08 |    640 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1344 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1664 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5632 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.539 ms	Trials: 9812	Used time : 7961 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1344 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1664 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5632 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.537 ms	Trials: 9876	Used time : 7994 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1344 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1664 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5696 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.537 ms	Trials: 9940	Used time : 8067 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1408 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1664 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5696 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.537 ms	Trials: 9944	Used time : 8099 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.028 |         295.62 |     64 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1567	fail_ct: 334	Time elapsed: 0.43
GA Iter: 0	Max score: 0.9793	Min score: 0.7950	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9841	Min score: 0.9282	#Pop: 128	#M+: 1393	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 1.88
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.23 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 16.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1790	fail_ct: 134	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9827	Min score: 0.9701	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9855	Min score: 0.9763	#Pop: 128	#M+: 1385	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 2.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 36.44 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 39.52 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1797	fail_ct: 103	Time elapsed: 0.45
GA Iter: 0	Max score: 0.9812	Min score: 0.9699	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9845	Min score: 0.9763	#Pop: 128	#M+: 1366	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 2.79
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 46.06 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.54 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1784	fail_ct: 140	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9807	Min score: 0.9701	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9863	Min score: 0.9764	#Pop: 128	#M+: 1389	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 2.16
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 42.78 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 44.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1408 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1728 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5696 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.537 ms	Trials: 10008	Used time : 8149 s	Next ID: 2	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1408 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1728 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5696 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10072	Used time : 8185 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1408 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1728 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5760 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10136	Used time : 8263 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1408 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1728 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5824 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10200	Used time : 8317 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    192 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1408 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1679	Time elapsed: 0.83
GA Iter: 0	Max score: 0.8358	Min score: 0.6346	#Pop: 11	#M+: 0	#M-: 0
[16:48:08] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [16:48:08] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:48:09] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [16:48:09] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:48:09] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [16:48:09] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9156	Min score: 0.0509	#Pop: 128	#M+: 396	#M-: 6704
EvolutionarySearch		#s: 128	Time elapsed: 3.28
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.76 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1782	fail_ct: 0	Time elapsed: 0.92
GA Iter: 0	Max score: 0.5815	Min score: 0.2496	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9696	Min score: 0.8793	#Pop: 128	#M+: 1398	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 5.06
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.12 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.01 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1800	fail_ct: 127	Time elapsed: 0.56
GA Iter: 0	Max score: 0.9799	Min score: 0.9707	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9850	Min score: 0.9759	#Pop: 128	#M+: 1371	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 3.24
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 50.06 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.30 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1686	Time elapsed: 0.95
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[16:50:29] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:50:29] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.3183	Min score: -0.0301	#Pop: 3	#M+: 377	#M-: 6650
EvolutionarySearch		#s: 3	Time elapsed: 4.10
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 3 programs to measure:
...***Time elapsed for measurement: 2.51 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 21.79 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1783	fail_ct: 123	Time elapsed: 0.44
GA Iter: 0	Max score: 0.9793	Min score: 0.9717	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9835	Min score: 0.9767	#Pop: 128	#M+: 1378	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 3.45
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 50.41 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.02 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1728 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5888 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10264	Used time : 8408 s	Next ID: 0	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1408 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1728 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5888 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10328	Used time : 8441 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1408 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1792 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5888 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10392	Used time : 8484 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1408 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1792 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5952 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10456	Used time : 8546 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1472 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1792 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   5952 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10459	Used time : 8576 s	Next ID: 12	

----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1807	fail_ct: 114	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9810	Min score: 0.9704	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9882	Min score: 0.9762	#Pop: 128	#M+: 1375	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 2.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 53.60 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.80 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1806	fail_ct: 0	Time elapsed: 0.92
GA Iter: 0	Max score: 0.6467	Min score: 0.2335	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9551	Min score: 0.8561	#Pop: 128	#M+: 1391	#M-: 7
EvolutionarySearch		#s: 128	Time elapsed: 5.61
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.61 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.09 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1790	fail_ct: 116	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9841	Min score: 0.9712	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9841	Min score: 0.9762	#Pop: 128	#M+: 1381	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 2.83
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 42.96 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 20.69 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1805	fail_ct: 119	Time elapsed: 0.74
GA Iter: 0	Max score: 0.9798	Min score: 0.9709	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9842	Min score: 0.9766	#Pop: 128	#M+: 1386	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.87
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.43 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.52 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1472 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1792 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6016 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10523	Used time : 8641 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    320 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1472 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1792 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6080 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10587	Used time : 8702 s	Next ID: 8	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1472 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1792 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6080 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10651	Used time : 8724 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1472 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1792 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6144 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10715	Used time : 8791 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1807	fail_ct: 0	Time elapsed: 0.92
GA Iter: 0	Max score: 0.5755	Min score: 0.2509	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9801	Min score: 0.8800	#Pop: 128	#M+: 1389	#M-: 31
EvolutionarySearch		#s: 128	Time elapsed: 7.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1472 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1862.16 |   1792 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6208 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10779	Used time : 8847 s	Next ID: 11	
.T***************************************************************Time elapsed for measurement: 25.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.33 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2007	fail_ct: 0	Time elapsed: 0.70
GA Iter: 0	Max score: 0.7362	Min score: 0.2448	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9488	Min score: 0.7991	#Pop: 128	#M+: 1383	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 3.53
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................***********************************************Time elapsed for measurement: 16.85 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.84 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1657	Time elapsed: 0.47
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[16:56:42] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:56:42] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[16:56:42] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [16:56:42] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.5007	Min score: -0.4122	#Pop: 4	#M+: 394	#M-: 6726
EvolutionarySearch		#s: 4	Time elapsed: 2.19
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 4 programs to measure:
....****Time elapsed for measurement: 2.40 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.41 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1801	fail_ct: 104	Time elapsed: 0.40
GA Iter: 0	Max score: 0.9821	Min score: 0.9707	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9850	Min score: 0.9764	#Pop: 128	#M+: 1388	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 1.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 52.56 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.04 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1802	fail_ct: 119	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9815	Min score: 0.9700	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9883	Min score: 0.9764	#Pop: 128	#M+: 1367	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 1.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 33.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 30.59 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    704 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1472 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1856 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6208 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10843	Used time : 8889 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1472 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1856 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6208 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10907	Used time : 8921 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1536 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1856 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6208 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10911	Used time : 8931 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1536 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1856 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6272 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 10975	Used time : 8991 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1771	fail_ct: 130	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9815	Min score: 0.9710	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9841	Min score: 0.9759	#Pop: 128	#M+: 1380	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 2.19
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.20 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.35 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1965	fail_ct: 8	Time elapsed: 0.59
GA Iter: 0	Max score: 0.5825	Min score: 0.3073	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9233	Min score: 0.6384	#Pop: 128	#M+: 1364	#M-: 227
EvolutionarySearch		#s: 128	Time elapsed: 3.35
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.41 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 22.99 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1809	fail_ct: 0	Time elapsed: 0.90
GA Iter: 0	Max score: 0.5614	Min score: 0.2572	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9667	Min score: 0.8765	#Pop: 128	#M+: 1378	#M-: 29
EvolutionarySearch		#s: 128	Time elapsed: 5.53
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.44 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 36.20 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1783	fail_ct: 142	Time elapsed: 0.55
GA Iter: 0	Max score: 0.9822	Min score: 0.9707	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9845	Min score: 0.9762	#Pop: 128	#M+: 1381	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.18
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 46.47 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.51 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1536 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1856 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6336 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11039	Used time : 9057 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    384 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1536 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1856 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6400 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11103	Used time : 9118 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1536 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1856 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6400 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11167	Used time : 9159 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1536 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1920 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6400 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11231	Used time : 9216 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1666	Time elapsed: 0.48
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[17:02:30] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (None)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (None)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (None)
      T_divide = ...

with: [17:02:30] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.0598	Min score: 0.0598	#Pop: 1	#M+: 382	#M-: 6891
EvolutionarySearch		#s: 1	Time elapsed: 2.20
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 1 programs to measure:
.*Time elapsed for measurement: 1.38 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.40 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1776	fail_ct: 125	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9822	Min score: 0.9701	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9845	Min score: 0.9758	#Pop: 128	#M+: 1374	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 1.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 48.84 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.27 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1803	fail_ct: 122	Time elapsed: 0.74
GA Iter: 0	Max score: 0.9794	Min score: 0.9707	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9832	Min score: 0.9756	#Pop: 128	#M+: 1378	#M-: 83
EvolutionarySearch		#s: 128	Time elapsed: 2.51
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 55.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1771	fail_ct: 127	Time elapsed: 0.40
GA Iter: 0	Max score: 0.9811	Min score: 0.9697	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9835	Min score: 0.9761	#Pop: 128	#M+: 1383	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 2.26
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.51 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.29 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1536 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1920 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6464 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11295	Used time : 9270 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1600 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1920 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6464 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11296	Used time : 9278 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1600 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1920 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6528 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11360	Used time : 9340 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1600 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1920 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6592 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11424	Used time : 9412 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1600 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1920 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6656 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1806	fail_ct: 0	Time elapsed: 0.95
GA Iter: 0	Max score: 0.5931	Min score: 0.2513	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9701	Min score: 0.8695	#Pop: 128	#M+: 1387	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 5.04
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.02 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.08 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1784	fail_ct: 129	Time elapsed: 0.54
GA Iter: 0	Max score: 0.9792	Min score: 0.9700	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9872	Min score: 0.9757	#Pop: 128	#M+: 1367	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 2.63
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 34.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 60.90 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2006	fail_ct: 0	Time elapsed: 1.26
GA Iter: 0	Max score: 0.6860	Min score: 0.2492	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9612	Min score: 0.8038	#Pop: 128	#M+: 1376	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 7.06
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11488	Used time : 9504 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1600 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1984 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6656 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11552	Used time : 9545 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    768 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1600 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1984 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6720 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11616	Used time : 9644 s	Next ID: 7	
.T***************************************************************Time elapsed for measurement: 28.33 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 40.37 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1642	Time elapsed: 0.86
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[17:10:02] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:10:02] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:10:02] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:10:02] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:10:03] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:10:03] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.4644	Min score: 0.0947	#Pop: 2	#M+: 390	#M-: 6788
EvolutionarySearch		#s: 2	Time elapsed: 3.91
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 2 programs to measure:
..**Time elapsed for measurement: 2.42 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.11 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1795	fail_ct: 124	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9792	Min score: 0.9705	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9832	Min score: 0.9758	#Pop: 128	#M+: 1382	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 2.59
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 43.91 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.45 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1796	fail_ct: 120	Time elapsed: 0.74
GA Iter: 0	Max score: 0.9820	Min score: 0.9686	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9831	Min score: 0.9755	#Pop: 128	#M+: 1379	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 3.43
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................************************************************Time elapsed for measurement: 56.96 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 9.86 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1803	fail_ct: 0	Time elapsed: 0.90
GA Iter: 0	Max score: 0.6440	Min score: 0.2397	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9661	Min score: 0.8562	#Pop: 128	#M+: 1387	#M-: 31
EvolutionarySearch		#s: 128	Time elapsed: 5.12
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.15 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.87 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1600 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1984 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6720 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11680	Used time : 9721 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1664 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1984 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6720 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11682	Used time : 9740 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1664 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1984 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6784 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11746	Used time : 9815 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1664 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   1984 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6848 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11810	Used time : 9886 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1800	fail_ct: 114	Time elapsed: 0.40
GA Iter: 0	Max score: 0.9805	Min score: 0.9694	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9854	Min score: 0.9756	#Pop: 128	#M+: 1382	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 2.38
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 51.81 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.83 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1796	fail_ct: 133	Time elapsed: 0.61
GA Iter: 0	Max score: 0.9791	Min score: 0.9698	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9931	Min score: 0.9759	#Pop: 128	#M+: 1371	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 3.58
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.56 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 21.50 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1791	fail_ct: 148	Time elapsed: 0.78
GA Iter: 0	Max score: 0.9815	Min score: 0.9695	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9842	Min score: 0.9755	#Pop: 128	#M+: 1376	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 3.44
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 45.28 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 58.01 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1652	Time elapsed: 1.34
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[17:17:35] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:17:35] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:17:35] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:17:35] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:17:38] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:17:38] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.5099	Min score: -0.1685	#Pop: 4	#M+: 373	#M-: 6873
EvolutionarySearch		#s: 4	Time elapsed: 5.54
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 4 programs to measure:
....****Time elapsed for measurement: 3.53 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 25.76 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1664 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2048 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6848 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11874	Used time : 9926 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1664 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2048 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6912 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 11938	Used time : 9992 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1664 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2048 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   6976 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12002	Used time : 10065 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1664 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2048 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7040 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12066	Used time : 10173 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1798	fail_ct: 115	Time elapsed: 1.05
GA Iter: 0	Max score: 0.9779	Min score: 0.9697	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9823	Min score: 0.9753	#Pop: 128	#M+: 1375	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 4.31
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 44.81 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 46.99 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1817	fail_ct: 0	Time elapsed: 2.09
GA Iter: 0	Max score: 0.7012	Min score: 0.2635	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9668	Min score: 0.8599	#Pop: 128	#M+: 1390	#M-: 31
EvolutionarySearch		#s: 128	Time elapsed: 11.84
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 30.92 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.54 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1812	fail_ct: 112	Time elapsed: 0.58
GA Iter: 0	Max score: 0.9788	Min score: 0.9691	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9829	Min score: 0.9749	#Pop: 128	#M+: 1382	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.52
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 46.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.07 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1768	fail_ct: 130	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9780	Min score: 0.9685	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9833	Min score: 0.9757	#Pop: 128	#M+: 1387	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 2.03
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 44.99 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1728 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2048 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7040 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12070	Used time : 10209 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1728 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2048 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7104 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12134	Used time : 10306 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1728 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2112 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7104 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12198	Used time : 10366 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1728 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2112 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7168 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12262	Used time : 10424 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1728 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2112 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1782	fail_ct: 127	Time elapsed: 0.39
GA Iter: 0	Max score: 0.9791	Min score: 0.9700	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9845	Min score: 0.9753	#Pop: 128	#M+: 1380	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 2.25
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 41.94 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.79 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1675	Time elapsed: 0.53
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[17:23:34] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:23:34] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:23:34] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:23:34] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:23:34] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:23:34] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:23:34] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:23:34] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:23:35] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:23:35] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:23:35] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:23:35] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:23:35] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:23:35] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: -0.0000	Min score: -0.1959	#Pop: 2	#M+: 394	#M-: 6679
EvolutionarySearch		#s: 2	Time elapsed: 2.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 2 programs to measure:
..**Time elapsed for measurement: 1.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.96 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1800	fail_ct: 0	Time elapsed: 0.95
GA Iter: 0	Max score: 0.7056	Min score: 0.2431	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9688	Min score: 0.8611	#Pop: 128	#M+: 1392	#M-: 37
EvolutionarySearch		#s: 128	Time elapsed: 5.27
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.21 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.30 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1775	fail_ct: 127	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9804	Min score: 0.9701	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9837	Min score: 0.9747	#Pop: 128	#M+: 1389	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 2.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 42.21 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 17.85 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1814	fail_ct: 119	Time elapsed: 1.02
GA Iter: 0	Max score: 0.9800	Min score: 0.9705	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9835	Min score: 0.9745	#Pop: 128	#M+: 1387	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 4.35
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 44.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7232 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12326	Used time : 10484 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1728 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2112 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7296 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12390	Used time : 10534 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1792 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2112 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7296 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12392	Used time : 10542 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1792 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2176 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7296 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12456	Used time : 10568 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1792 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2176 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7360 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12520	Used time : 10631 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1969	fail_ct: 10	Time elapsed: 0.84
GA Iter: 0	Max score: 0.5942	Min score: 0.2987	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9397	Min score: 0.6722	#Pop: 128	#M+: 1351	#M-: 221
EvolutionarySearch		#s: 128	Time elapsed: 3.76
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 9.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.37 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1791	fail_ct: 118	Time elapsed: 0.35
GA Iter: 0	Max score: 0.9823	Min score: 0.9693	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9836	Min score: 0.9748	#Pop: 128	#M+: 1382	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 1.90
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 49.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.62 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1797	fail_ct: 132	Time elapsed: 0.39
GA Iter: 0	Max score: 0.9779	Min score: 0.9693	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9862	Min score: 0.9749	#Pop: 128	#M+: 1397	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 1.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 38.78 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 40.10 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1807	fail_ct: 0	Time elapsed: 1.89
GA Iter: 0	Max score: 0.6019	Min score: 0.2560	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9695	Min score: 0.8545	#Pop: 128	#M+: 1389	#M-: 26
EvolutionarySearch		#s: 128	Time elapsed: 8.44
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 28.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.92 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2238.74 |    448 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1792 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2176 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7424 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.536 ms	Trials: 12584	Used time : 10706 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1792 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2176 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7424 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.535 ms	Trials: 12648	Used time : 10733 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1792 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2176 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7488 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.535 ms	Trials: 12712	Used time : 10790 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1792 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2176 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7552 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.535 ms	Trials: 12776	Used time : 10871 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1675	Time elapsed: 0.53
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.2010	Min score: 0.1958	#Pop: 2	#M+: 387	#M-: 6809
EvolutionarySearch		#s: 2	Time elapsed: 2.24
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 2 programs to measure:
..**Time elapsed for measurement: 1.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.22 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1811	fail_ct: 0	Time elapsed: 1.40
GA Iter: 0	Max score: 0.4816	Min score: 0.2035	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9684	Min score: 0.8639	#Pop: 128	#M+: 1397	#M-: 8
EvolutionarySearch		#s: 128	Time elapsed: 6.05
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.75 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.10 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1774	fail_ct: 128	Time elapsed: 0.49
GA Iter: 0	Max score: 0.9786	Min score: 0.9687	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9839	Min score: 0.9747	#Pop: 128	#M+: 1375	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.52
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................************************************************Time elapsed for measurement: 49.18 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 21.45 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1794	fail_ct: 129	Time elapsed: 0.96
GA Iter: 0	Max score: 0.9779	Min score: 0.9681	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9831	Min score: 0.9743	#Pop: 128	#M+: 1373	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 3.74
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 55.54 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.16 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1792 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2240 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7552 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.535 ms	Trials: 12840	Used time : 10915 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.126 |        2690.71 |    384 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1856 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2240 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7552 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.535 ms	Trials: 12842	Used time : 10932 s	Next ID: 8	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1856 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2240 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7552 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 12906	Used time : 10970 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1856 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2240 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7616 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 12970	Used time : 11043 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    256 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1856 |----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1675	Time elapsed: 0.49
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[17:33:09] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [17:33:09] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:33:10] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [17:33:10] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:33:10] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (None)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (None)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (None)
      T_divide = ...

with: [17:33:10] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9238	Min score: 0.0337	#Pop: 128	#M+: 405	#M-: 6630
EvolutionarySearch		#s: 128	Time elapsed: 2.26
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 24.57 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.56 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2000	fail_ct: 1	Time elapsed: 0.70
GA Iter: 0	Max score: 0.7349	Min score: 0.2467	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9474	Min score: 0.8213	#Pop: 128	#M+: 1387	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 3.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.83 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.55 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1809	fail_ct: 110	Time elapsed: 0.76
GA Iter: 0	Max score: 0.9786	Min score: 0.9683	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9847	Min score: 0.9749	#Pop: 128	#M+: 1383	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 3.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 36.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 23.48 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1808	fail_ct: 0	Time elapsed: 1.42
GA Iter: 0	Max score: 0.8264	Min score: 0.2436	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9689	Min score: 0.8550	#Pop: 128	#M+: 1388	#M-: 32
EvolutionarySearch		#s: 128	Time elapsed: 7.88
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 29.58 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1793	fail_ct: 142	Time elapsed: 1.16
GA Iter: 0	Max score: 0.9782	Min score: 0.9698	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9842	Min score: 0.9745	#Pop: 128	#M+: 1379	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 5.19
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 38.41 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.02 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2240 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7680 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13034	Used time : 11109 s	Next ID: 0	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    832 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1856 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2240 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7680 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13098	Used time : 11141 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1856 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2240 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7680 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13162	Used time : 11172 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1856 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2240 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7744 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13226	Used time : 11236 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1856 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2304 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7744 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13290	Used time : 11291 s	Next ID: 12	

----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1650	Time elapsed: 0.50
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[17:37:23] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:37:23] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.0600	Min score: 0.0600	#Pop: 1	#M+: 400	#M-: 6805
EvolutionarySearch		#s: 1	Time elapsed: 2.25
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 1 programs to measure:
.*Time elapsed for measurement: 1.03 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.70 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1791	fail_ct: 127	Time elapsed: 0.53
GA Iter: 0	Max score: 0.9785	Min score: 0.9681	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9825	Min score: 0.9743	#Pop: 128	#M+: 1380	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 57.17 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.77 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1803	fail_ct: 116	Time elapsed: 0.52
GA Iter: 0	Max score: 0.9782	Min score: 0.9684	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9834	Min score: 0.9744	#Pop: 128	#M+: 1391	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 2.53
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.93 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1827	fail_ct: 0	Time elapsed: 1.33
GA Iter: 0	Max score: 0.6077	Min score: 0.2540	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9737	Min score: 0.8578	#Pop: 128	#M+: 1385	#M-: 30
EvolutionarySearch		#s: 128	Time elapsed: 9.62
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.97 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 33.58 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1856 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2304 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7808 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13354	Used time : 11362 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1920 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2304 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7808 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13355	Used time : 11379 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1920 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2304 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7872 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13419	Used time : 11474 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1920 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2304 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7936 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13483	Used time : 11546 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1816	fail_ct: 101	Time elapsed: 0.58
GA Iter: 0	Max score: 0.9778	Min score: 0.9684	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9846	Min score: 0.9734	#Pop: 128	#M+: 1387	#M-: 64
EvolutionarySearch		#s: 128	Time elapsed: 3.66
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 49.81 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.28 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1810	fail_ct: 122	Time elapsed: 0.64
GA Iter: 0	Max score: 0.9767	Min score: 0.9691	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9845	Min score: 0.9741	#Pop: 128	#M+: 1378	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 2.46
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 35.28 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 41.33 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1650	Time elapsed: 1.78
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[17:43:55] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:43:55] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.3159	Min score: -0.1589	#Pop: 3	#M+: 403	#M-: 6601
EvolutionarySearch		#s: 3	Time elapsed: 7.03
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 3 programs to measure:
...***Time elapsed for measurement: 3.76 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 47.04 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1802	fail_ct: 114	Time elapsed: 1.28
GA Iter: 0	Max score: 0.9773	Min score: 0.9681	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9825	Min score: 0.9747	#Pop: 128	#M+: 1382	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 5.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 49.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.28 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1920 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2368 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   7936 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13547	Used time : 11613 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1920 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2368 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8000 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13611	Used time : 11673 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1920 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2368 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8064 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13675	Used time : 11753 s	Next ID: 9	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1984 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2368 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8064 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13678	Used time : 11813 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1803	fail_ct: 114	Time elapsed: 0.39
GA Iter: 0	Max score: 0.9765	Min score: 0.9692	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9827	Min score: 0.9741	#Pop: 128	#M+: 1373	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 1.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................************************************************Time elapsed for measurement: 51.47 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.05 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1801	fail_ct: 0	Time elapsed: 0.88
GA Iter: 0	Max score: 0.5532	Min score: 0.2513	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9605	Min score: 0.8463	#Pop: 128	#M+: 1395	#M-: 32
EvolutionarySearch		#s: 128	Time elapsed: 5.09
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 31.91 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1778	fail_ct: 136	Time elapsed: 1.04
GA Iter: 0	Max score: 0.9772	Min score: 0.9687	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9818	Min score: 0.9736	#Pop: 128	#M+: 1383	#M-: 85
EvolutionarySearch		#s: 128	Time elapsed: 4.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 59.22 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 29.15 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1808	fail_ct: 124	Time elapsed: 0.91
GA Iter: 0	Max score: 0.9789	Min score: 0.9685	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9819	Min score: 0.9741	#Pop: 128	#M+: 1389	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 4.29
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 54.20 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.74 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1984 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2368 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8128 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13742	Used time : 11882 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1984 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2368 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8192 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13806	Used time : 11944 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1984 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2432 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8192 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13870	Used time : 12002 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1984 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2432 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8256 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13934	Used time : 12096 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    896 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1984 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2008	fail_ct: 1	Time elapsed: 0.71
GA Iter: 0	Max score: 0.6631	Min score: 0.2519	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9432	Min score: 0.8295	#Pop: 128	#M+: 1392	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 4.08
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.62 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.75 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1765	fail_ct: 154	Time elapsed: 0.39
GA Iter: 0	Max score: 0.9782	Min score: 0.9696	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9861	Min score: 0.9745	#Pop: 128	#M+: 1381	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 1.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 51.40 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 28.96 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1650	Time elapsed: 0.81
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[17:52:36] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:52:36] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:52:36] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:52:36] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:52:36] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:52:36] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[17:52:39] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,96)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,109)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,109)
      T_divide = ...

with: [17:52:39] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=100)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=96)), iter_var(ax2, range(min=0, ext=109)), iter_var(ax3, range(min=0, ext=109))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 383	#M-: 6803
EvolutionarySearch		#s: 0	Time elapsed: 3.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 0 programs to measure:
Time elapsed for measurement: 0.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.00 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1823	fail_ct: 0	Time elapsed: 1.14
GA Iter: 0	Max score: 0.5940	Min score: 0.2452	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9582	Min score: 0.8492	#Pop: 128	#M+: 1386	#M-: 30
EvolutionarySearch		#s: 128	Time elapsed: 5.65
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 28.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 15.23 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1785	fail_ct: 131	Time elapsed: 0.79
GA Iter: 0	Max score: 0.9784	Min score: 0.9695	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9831	Min score: 0.9740	#Pop: 128	#M+: 1386	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 2.34
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 50.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 48.36 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2432 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8320 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 13998	Used time : 12161 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1984 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2432 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8320 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14062	Used time : 12193 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   1984 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2432 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8384 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14126	Used time : 12276 s	Next ID: 9	
|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2432 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8384 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14126	Used time : 12280 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2496 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8384 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14190	Used time : 12331 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1778	fail_ct: 132	Time elapsed: 1.16
GA Iter: 0	Max score: 0.9781	Min score: 0.9671	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9841	Min score: 0.9739	#Pop: 128	#M+: 1395	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 3.95
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 56.71 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 18.14 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1772	fail_ct: 126	Time elapsed: 0.80
GA Iter: 0	Max score: 0.9765	Min score: 0.9685	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9816	Min score: 0.9748	#Pop: 128	#M+: 1390	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 4.10
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 52.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 18.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1957	fail_ct: 10	Time elapsed: 0.86
GA Iter: 0	Max score: 0.6371	Min score: 0.3046	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9371	Min score: 0.6677	#Pop: 128	#M+: 1355	#M-: 217
EvolutionarySearch		#s: 128	Time elapsed: 3.76
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.31 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.92 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1782	fail_ct: 130	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9766	Min score: 0.9688	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9845	Min score: 0.9739	#Pop: 128	#M+: 1378	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 2.42
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 34.78 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 57.43 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2496 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8448 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14254	Used time : 12433 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2496 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8512 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14318	Used time : 12513 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    512 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2496 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8576 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14382	Used time : 12589 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2496 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8576 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14446	Used time : 12616 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1824	fail_ct: 0	Time elapsed: 2.73
GA Iter: 0	Max score: 0.6361	Min score: 0.2453	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9775	Min score: 0.8431	#Pop: 128	#M+: 1385	#M-: 32
EvolutionarySearch		#s: 128	Time elapsed: 11.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.35 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 48.43 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1794	fail_ct: 138	Time elapsed: 0.74
GA Iter: 0	Max score: 0.9789	Min score: 0.9681	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9850	Min score: 0.9742	#Pop: 128	#M+: 1384	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 4.05
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.75 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.42 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1808	fail_ct: 125	Time elapsed: 0.41
GA Iter: 0	Max score: 0.9768	Min score: 0.9690	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9854	Min score: 0.9740	#Pop: 128	#M+: 1379	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.05
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 48.51 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.28 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1802	fail_ct: 119	Time elapsed: 0.66
GA Iter: 0	Max score: 0.9802	Min score: 0.9674	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9843	Min score: 0.9743	#Pop: 128	#M+: 1387	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 2.69
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 58.06 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 15.79 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2496 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8640 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14510	Used time : 12711 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2560 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8640 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14574	Used time : 12798 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2560 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8704 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14638	Used time : 12856 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2560 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8768 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14702	Used time : 12934 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1832	fail_ct: 0	Time elapsed: 1.46
GA Iter: 0	Max score: 0.6595	Min score: 0.2399	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9611	Min score: 0.8415	#Pop: 128	#M+: 1378	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 5.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.51 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 37.25 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1799	fail_ct: 111	Time elapsed: 1.08
GA Iter: 0	Max score: 0.9762	Min score: 0.9684	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9851	Min score: 0.9743	#Pop: 128	#M+: 1382	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 4.34
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 46.83 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.78 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1997	fail_ct: 0	Time elapsed: 0.68
GA Iter: 0	Max score: 0.7905	Min score: 0.2652	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9570	Min score: 0.8451	#Pop: 128	#M+: 1376	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 3.57
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 9.16 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1792	fail_ct: 127	Time elapsed: 0.40
GA Iter: 0	Max score: 0.9787	Min score: 0.9681	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9832	Min score: 0.9744	#Pop: 128	#M+: 1368	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 1.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 51.04 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 43.05 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2560 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8832 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14766	Used time : 13012 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2624 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8832 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14830	Used time : 13078 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |    960 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2624 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8896 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14894	Used time : 13136 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2624 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8896 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 14958	Used time : 13162 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    448 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2624 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8960 |----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1807	fail_ct: 0	Time elapsed: 2.45
GA Iter: 0	Max score: 0.8016	Min score: 0.2265	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9495	Min score: 0.8701	#Pop: 128	#M+: 1389	#M-: 9
EvolutionarySearch		#s: 128	Time elapsed: 11.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.98 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 22.90 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1810	fail_ct: 118	Time elapsed: 0.70
GA Iter: 0	Max score: 0.9760	Min score: 0.9683	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9837	Min score: 0.9741	#Pop: 128	#M+: 1388	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 2.70
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 52.24 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.44 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1760	fail_ct: 143	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9776	Min score: 0.9682	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9841	Min score: 0.9738	#Pop: 128	#M+: 1389	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 1.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 56.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.65 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1810	fail_ct: 0	Time elapsed: 1.29
GA Iter: 0	Max score: 0.6366	Min score: 0.2521	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9674	Min score: 0.8975	#Pop: 128	#M+: 1388	#M-: 33
EvolutionarySearch		#s: 128	Time elapsed: 6.85
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.36 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 51.81 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1808	fail_ct: 0	Time elapsed: 0.91
GA Iter: 0	Max score: 0.7170	Min score: 0.2107	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9764	Min score: 0.8989	#Pop: 128	#M+: 1393	#M-: 30
EvolutionarySearch		#s: 128	Time elapsed: 5.85
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 15.90 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 30.07 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 15022	Used time : 13258 s	Next ID: 8	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2624 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   8960 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 15086	Used time : 13309 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2624 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9024 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 15150	Used time : 13370 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.365 |        1863.24 |   2624 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9088 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.534 ms	Trials: 15214	Used time : 13438 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.255 |        2667.93 |   2688 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9088 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.314 ms	Trials: 15278	Used time : 13519 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1812	fail_ct: 0	Time elapsed: 1.62
GA Iter: 0	Max score: 0.5306	Min score: 0.2082	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9705	Min score: 0.8992	#Pop: 128	#M+: 1380	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 8.13
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 21.98 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 25.45 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1826	fail_ct: 0	Time elapsed: 1.32
GA Iter: 0	Max score: 0.7572	Min score: 0.2135	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9795	Min score: 0.9073	#Pop: 128	#M+: 1396	#M-: 34
EvolutionarySearch		#s: 128	Time elapsed: 7.03
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 20.43 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.58 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1790	fail_ct: 132	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9764	Min score: 0.9686	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9857	Min score: 0.9740	#Pop: 128	#M+: 1382	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 1.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 42.15 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.54 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1779	fail_ct: 130	Time elapsed: 0.52
GA Iter: 0	Max score: 0.9757	Min score: 0.9686	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9828	Min score: 0.9742	#Pop: 128	#M+: 1388	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 2.56
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 52.18 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 56.69 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2752 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9088 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 15342	Used time : 13572 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2816 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9088 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 15406	Used time : 13630 s	Next ID: 11	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9088 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 15470	Used time : 13683 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9152 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 15534	Used time : 13734 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1794	fail_ct: 136	Time elapsed: 0.97
GA Iter: 0	Max score: 0.9800	Min score: 0.9675	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9849	Min score: 0.9738	#Pop: 128	#M+: 1384	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 3.35
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 55.33 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.89 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1805	fail_ct: 138	Time elapsed: 0.62
GA Iter: 0	Max score: 0.9779	Min score: 0.9689	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9832	Min score: 0.9746	#Pop: 128	#M+: 1379	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 2.59
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 46.88 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.93 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1779	fail_ct: 140	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9781	Min score: 0.9685	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9842	Min score: 0.9745	#Pop: 128	#M+: 1397	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.31
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 44.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 37.19 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1808	fail_ct: 129	Time elapsed: 1.30
GA Iter: 0	Max score: 0.9793	Min score: 0.9682	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9838	Min score: 0.9742	#Pop: 128	#M+: 1380	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 6.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............................................................|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9216 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 15598	Used time : 13846 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9280 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 15662	Used time : 13914 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9344 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 15726	Used time : 13970 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9408 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 15790	Used time : 14055 s	Next ID: 12	
.T***************************************************************Time elapsed for measurement: 71.48 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 17.66 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1778	fail_ct: 128	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9777	Min score: 0.9682	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9862	Min score: 0.9743	#Pop: 128	#M+: 1374	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 1.95
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 48.52 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.68 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1995	fail_ct: 0	Time elapsed: 0.87
GA Iter: 0	Max score: 0.7223	Min score: 0.2696	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9657	Min score: 0.8508	#Pop: 128	#M+: 1381	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 4.26
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 23.89 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 44.63 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1815	fail_ct: 109	Time elapsed: 0.94
GA Iter: 0	Max score: 0.9764	Min score: 0.9680	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9836	Min score: 0.9736	#Pop: 128	#M+: 1384	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 4.70
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 40.45 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 53.61 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1960	fail_ct: 11	Time elapsed: 0.86
GA Iter: 0	Max score: 0.6697	Min score: 0.2991	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9428	Min score: 0.6681	#Pop: 128	#M+: 1361	#M-: 234
EvolutionarySearch		#s: 128	Time elapsed: 3.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.23 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 27.74 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9472 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 15854	Used time : 14152 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1024 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9536 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 15918	Used time : 14214 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9536 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 15982	Used time : 14288 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    576 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9600 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16046	Used time : 14387 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1767	fail_ct: 132	Time elapsed: 0.36
GA Iter: 0	Max score: 0.9785	Min score: 0.9689	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9853	Min score: 0.9740	#Pop: 128	#M+: 1378	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 1.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 51.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.99 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1771	fail_ct: 126	Time elapsed: 0.36
GA Iter: 0	Max score: 0.9767	Min score: 0.9678	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9840	Min score: 0.9740	#Pop: 128	#M+: 1393	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 1.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 52.44 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 18.19 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1650	Time elapsed: 1.12
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[18:30:52] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 64
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [18:30:52] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[18:30:54] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [18:30:54] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.9151	Min score: -0.0154	#Pop: 128	#M+: 400	#M-: 6620
EvolutionarySearch		#s: 128	Time elapsed: 5.30
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 14.38 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 17.42 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1778	fail_ct: 120	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9777	Min score: 0.9675	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9851	Min score: 0.9743	#Pop: 128	#M+: 1386	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 2.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 53.08 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.55 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9600 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16110	Used time : 14436 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9664 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16174	Used time : 14496 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    320 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9728 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16238	Used time : 14569 s	Next ID: 0	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9728 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16302	Used time : 14607 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1806	fail_ct: 125	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9795	Min score: 0.9679	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9824	Min score: 0.9740	#Pop: 128	#M+: 1375	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 1.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 49.96 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.29 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1804	fail_ct: 118	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9770	Min score: 0.9683	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9828	Min score: 0.9742	#Pop: 128	#M+: 1372	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 1.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 38.70 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 30.59 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1767	fail_ct: 139	Time elapsed: 0.60
GA Iter: 0	Max score: 0.9779	Min score: 0.9682	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9825	Min score: 0.9744	#Pop: 128	#M+: 1387	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.78
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.08 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 7.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1767	fail_ct: 136	Time elapsed: 1.11
GA Iter: 0	Max score: 0.9757	Min score: 0.9676	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9860	Min score: 0.9742	#Pop: 128	#M+: 1387	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 4.46
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 36.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 38.33 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9792 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16366	Used time : 14669 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9856 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16430	Used time : 14726 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9920 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16494	Used time : 14798 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |   9984 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16558	Used time : 14856 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1777	fail_ct: 139	Time elapsed: 0.40
GA Iter: 0	Max score: 0.9809	Min score: 0.9676	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9832	Min score: 0.9736	#Pop: 128	#M+: 1391	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 2.91
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 39.45 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 13.66 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2000	fail_ct: 0	Time elapsed: 0.69
GA Iter: 0	Max score: 0.6114	Min score: 0.2452	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9634	Min score: 0.8469	#Pop: 128	#M+: 1388	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 3.61
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................************************************************Time elapsed for measurement: 14.60 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 17.19 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1775	fail_ct: 133	Time elapsed: 0.85
GA Iter: 0	Max score: 0.9758	Min score: 0.9676	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9840	Min score: 0.9740	#Pop: 128	#M+: 1380	#M-: 82
EvolutionarySearch		#s: 128	Time elapsed: 3.57
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 49.98 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 21.75 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1765	fail_ct: 129	Time elapsed: 0.96
GA Iter: 0	Max score: 0.9765	Min score: 0.9678	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9814	Min score: 0.9741	#Pop: 128	#M+: 1377	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 4.55
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 52.21 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.79 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1813	fail_ct: 0	Time elapsed: 0.97
GA Iter: 0	Max score: 0.6645	Min score: 0.2062	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9788	Min score: 0.9019	#Pop: 128	#M+: 1397	#M-: 14
EvolutionarySearch		#s: 128	Time elapsed: 5.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 11.13 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 25.96 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10048 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16622	Used time : 14937 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1088 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10112 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16686	Used time : 14994 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10112 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16750	Used time : 15030 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10176 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16814	Used time : 15106 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    512 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10240 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16878	Used time : 15170 s	Next ID: 8	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1791	fail_ct: 125	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9760	Min score: 0.9670	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9828	Min score: 0.9734	#Pop: 128	#M+: 1385	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 1.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 50.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 21.22 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1773	fail_ct: 130	Time elapsed: 1.00
GA Iter: 0	Max score: 0.9760	Min score: 0.9673	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9821	Min score: 0.9732	#Pop: 128	#M+: 1391	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 4.59
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 45.21 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.75 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1811	fail_ct: 115	Time elapsed: 0.36
GA Iter: 0	Max score: 0.9786	Min score: 0.9675	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9828	Min score: 0.9732	#Pop: 128	#M+: 1378	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 2.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 36.74 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 51.10 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1760	fail_ct: 135	Time elapsed: 0.79
GA Iter: 0	Max score: 0.9760	Min score: 0.9677	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9815	Min score: 0.9737	#Pop: 128	#M+: 1387	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 3.04
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 49.23 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.18 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10240 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 16942	Used time : 15214 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10304 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17006	Used time : 15289 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10368 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17070	Used time : 15350 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10432 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17134	Used time : 15441 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1795	fail_ct: 116	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9761	Min score: 0.9679	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9826	Min score: 0.9731	#Pop: 128	#M+: 1385	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 1.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.94 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.81 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1816	fail_ct: 110	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9768	Min score: 0.9668	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9818	Min score: 0.9736	#Pop: 128	#M+: 1392	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.35
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 41.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 50.77 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1777	fail_ct: 125	Time elapsed: 0.65
GA Iter: 0	Max score: 0.9763	Min score: 0.9676	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9819	Min score: 0.9737	#Pop: 128	#M+: 1392	#M-: 81
EvolutionarySearch		#s: 128	Time elapsed: 3.06
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 53.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.38 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1967	fail_ct: 6	Time elapsed: 0.60
GA Iter: 0	Max score: 0.5474	Min score: 0.2873	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9420	Min score: 0.6803	#Pop: 128	#M+: 1364	#M-: 234
EvolutionarySearch		#s: 128	Time elapsed: 3.04
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 9.60 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 17.53 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10496 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17198	Used time : 15504 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10560 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17262	Used time : 15560 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10624 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17326	Used time : 15655 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    640 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10688 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17390	Used time : 15719 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1152 |----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2001	fail_ct: 0	Time elapsed: 1.16
GA Iter: 0	Max score: 0.7685	Min score: 0.2483	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9601	Min score: 0.8468	#Pop: 128	#M+: 1388	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 5.45
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 19.87 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 32.83 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1774	fail_ct: 137	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9767	Min score: 0.9673	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9837	Min score: 0.9738	#Pop: 128	#M+: 1380	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.16
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 49.93 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.49 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1763	fail_ct: 155	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9777	Min score: 0.9677	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9821	Min score: 0.9732	#Pop: 128	#M+: 1377	#M-: 81
EvolutionarySearch		#s: 128	Time elapsed: 1.95
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 46.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1780	fail_ct: 133	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9785	Min score: 0.9673	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9889	Min score: 0.9742	#Pop: 128	#M+: 1380	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 2.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 53.46 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.16 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10688 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17454	Used time : 15750 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1216 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10688 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17518	Used time : 15809 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1216 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10752 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17582	Used time : 15868 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1216 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10816 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17646	Used time : 15923 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1216 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1800	fail_ct: 119	Time elapsed: 0.38
GA Iter: 0	Max score: 0.9778	Min score: 0.9684	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9832	Min score: 0.9736	#Pop: 128	#M+: 1384	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 2.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 44.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 40.53 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1778	fail_ct: 131	Time elapsed: 0.91
GA Iter: 0	Max score: 0.9768	Min score: 0.9672	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9878	Min score: 0.9732	#Pop: 128	#M+: 1387	#M-: 67
EvolutionarySearch		#s: 128	Time elapsed: 3.74
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 50.04 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.47 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1807	fail_ct: 131	Time elapsed: 0.40
GA Iter: 0	Max score: 0.9755	Min score: 0.9678	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9883	Min score: 0.9737	#Pop: 128	#M+: 1375	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 2.43
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 39.25 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 33.30 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1799	fail_ct: 119	Time elapsed: 0.95
GA Iter: 0	Max score: 0.9772	Min score: 0.9682	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9822	Min score: 0.9733	#Pop: 128	#M+: 1384	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 2.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 46.84 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 17.85 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1798	fail_ct: 127	Time elapsed: 0.93
GA Iter: 0	Max score: 0.9754	Min score: 0.9678	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9827	Min score: 0.9736	#Pop: 128	#M+: 1387	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 4.26
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 42.94 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 18.34 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10880 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17710	Used time : 15985 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1216 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  10944 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17774	Used time : 16073 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1216 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11008 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17838	Used time : 16134 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1216 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11072 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17902	Used time : 16209 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1216 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11136 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 17966	Used time : 16278 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1780	fail_ct: 130	Time elapsed: 0.61
GA Iter: 0	Max score: 0.9769	Min score: 0.9675	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9852	Min score: 0.9733	#Pop: 128	#M+: 1385	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 3.22
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 51.15 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 42.66 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1797	fail_ct: 117	Time elapsed: 1.05
GA Iter: 0	Max score: 0.9783	Min score: 0.9680	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9828	Min score: 0.9732	#Pop: 128	#M+: 1389	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 5.80
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 40.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 14.48 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1992	fail_ct: 1	Time elapsed: 0.69
GA Iter: 0	Max score: 0.6616	Min score: 0.2423	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9605	Min score: 0.8485	#Pop: 128	#M+: 1377	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 3.64
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 18.06 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 39.74 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1787	fail_ct: 122	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9762	Min score: 0.9663	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9851	Min score: 0.9730	#Pop: 128	#M+: 1383	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 2.59
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 48.75 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 25.98 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1216 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11200 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18030	Used time : 16345 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1216 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11264 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18094	Used time : 16443 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1216 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11328 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18158	Used time : 16505 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11328 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18222	Used time : 16567 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1792	fail_ct: 131	Time elapsed: 0.57
GA Iter: 0	Max score: 0.9786	Min score: 0.9676	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9817	Min score: 0.9735	#Pop: 128	#M+: 1371	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 2.44
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 55.62 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.12 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1793	fail_ct: 131	Time elapsed: 0.49
GA Iter: 0	Max score: 0.9772	Min score: 0.9669	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9834	Min score: 0.9735	#Pop: 128	#M+: 1376	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 2.32
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 39.24 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 39.29 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1802	fail_ct: 0	Time elapsed: 2.04
GA Iter: 0	Max score: 0.6339	Min score: 0.2133	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9810	Min score: 0.9037	#Pop: 128	#M+: 1375	#M-: 16
EvolutionarySearch		#s: 128	Time elapsed: 12.91
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 31.78 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.82 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1776	fail_ct: 132	Time elapsed: 0.36
GA Iter: 0	Max score: 0.9765	Min score: 0.9670	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9847	Min score: 0.9735	#Pop: 128	#M+: 1392	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 1.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 47.98 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.93 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11392 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18286	Used time : 16645 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11456 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18350	Used time : 16715 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    576 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11520 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18414	Used time : 16796 s	Next ID: 8	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11520 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18478	Used time : 16855 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1776	fail_ct: 121	Time elapsed: 0.53
GA Iter: 0	Max score: 0.9754	Min score: 0.9674	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9819	Min score: 0.9734	#Pop: 128	#M+: 1379	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 2.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 43.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 12.34 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1784	fail_ct: 133	Time elapsed: 0.56
GA Iter: 0	Max score: 0.9765	Min score: 0.9682	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9822	Min score: 0.9736	#Pop: 128	#M+: 1378	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 2.29
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 40.14 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 32.95 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 80	fail_ct: 1662	Time elapsed: 1.24
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
[19:12:28] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 16
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [19:12:28] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



[19:12:30] /home/ubuntu/tvm/src/auto_scheduler/compute_dag.cc:1375: Warning: InferBound fails on the state:
Placeholder: placeholder
parallel ax0@ax1@ (0,256)
  tensor auto_unroll: 512
  for ax0 (None)
    for ax1 (None)
      for ax2 (None)
        for ax3 (None)
          for rxs (None)
            tensor = ...
  for ax2 (0,25)
    for ax0 (None)
      for ax1 (None)
        for ax2 (None)
          for ax3 (None)
            pad_data = ...
    for ax3 (0,25)
      T_divide = ...

with: [19:12:30] /home/ubuntu/tvm/src/te/schedule/bound.cc:175: 
---------------------------------------------------------------
An error occurred during the execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (found_attach || stage_attach.size() == 0) is false: Invalid Schedule, cannot find the producer compute(pad_data, body=[tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=260)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[], tag=elemwise, attrs={}) along the loop nest specified by compute_at of consumer compute(tensor, body=[reduce(combiner=comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f]), source=[(pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])], init=[], axis=[iter_var(rxs, range(min=0, ext=5))], where=(bool)1, value_index=0)], axis=[iter_var(ax0, range(min=0, ext=1)), iter_var(ax1, range(min=0, ext=256)), iter_var(ax2, range(min=0, ext=25)), iter_var(ax3, range(min=0, ext=25))], reduce_axis=[iter_var(rxs, range(min=0, ext=5))], tag=sqr_sum, attrs={})
Stack trace:
  0: tvm::te::InferRootBound(tvm::te::Stage const&, tvm::te::GraphContext const&, std::unordered_map<tvm::tir::IterVar, tvm::Range, std::hash<tvm::tir::IterVar>, std::equal_to<tvm::tir::IterVar>, std::allocator<std::pair<tvm::tir::IterVar const, tvm::Range> > >*)
  1: tvm::te::InferBound(tvm::te::Schedule const&)
  2: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::auto_scheduler::State const&) const
  3: tvm::auto_scheduler::ComputeDAG::InferBound(tvm::runtime::Array<tvm::auto_scheduler::State, void> const&) const::{lambda(int)#1}::operator()(int) const
  4: _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIvEES3_EZNS1_11_Task_stateIZN3tvm7support12parallel_for
  5: std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*)
  6: __pthread_once_slow
  7: std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::packaged_task<void (std::vector<int, std::allocator<int> > const&, std::function<void (int)> const&)>, std::vector<int, std::allocator<int> >, std::function<void (int)> > > >::_M_run()
  8: 0x00007fa1ff81a6b3
  9: start_thread
  10: __clone
  11: 0xffffffffffffffff



GA Iter: 4	Max score: 0.8716	Min score: -0.1277	#Pop: 128	#M+: 397	#M-: 6721
EvolutionarySearch		#s: 128	Time elapsed: 4.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 13.49 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 32.95 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1777	fail_ct: 134	Time elapsed: 0.53
GA Iter: 0	Max score: 0.9761	Min score: 0.9675	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9846	Min score: 0.9726	#Pop: 128	#M+: 1383	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 2.37
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................************************************************Time elapsed for measurement: 52.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 52.54 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11584 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18542	Used time : 16931 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11648 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18606	Used time : 16989 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    384 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11712 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18670	Used time : 17066 s	Next ID: 0	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11712 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18734	Used time : 17118 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2241.71 |    704 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11776 |
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1968	fail_ct: 7	Time elapsed: 1.86
GA Iter: 0	Max score: 0.6459	Min score: 0.2922	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9569	Min score: 0.6767	#Pop: 128	#M+: 1355	#M-: 215
EvolutionarySearch		#s: 128	Time elapsed: 5.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.51 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1809	fail_ct: 102	Time elapsed: 0.94
GA Iter: 0	Max score: 0.9757	Min score: 0.9679	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9828	Min score: 0.9731	#Pop: 128	#M+: 1378	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 4.08
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................************************************************Time elapsed for measurement: 50.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 56.12 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1820	fail_ct: 112	Time elapsed: 1.04
GA Iter: 0	Max score: 0.9765	Min score: 0.9669	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9823	Min score: 0.9732	#Pop: 128	#M+: 1375	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 5.13
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 51.60 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 44.63 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 2007	fail_ct: 0	Time elapsed: 0.96
GA Iter: 0	Max score: 0.6055	Min score: 0.2771	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9436	Min score: 0.8449	#Pop: 128	#M+: 1383	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 4.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 16.94 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 32.16 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1542	fail_ct: 333	Time elapsed: 0.82
GA Iter: 0	Max score: 0.9237	Min score: 0.7175	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9613	Min score: 0.8709	#Pop: 128	#M+: 1388	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 3.32
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 12.82 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 32.82 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------

Estimated total latency: 4.311 ms	Trials: 18798	Used time : 17226 s	Next ID: 3	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11776 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18862	Used time : 17281 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11840 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18926	Used time : 17393 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1280 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11904 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 18990	Used time : 17496 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    128 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11904 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19054	Used time : 17551 s	Next ID: 2	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1783	fail_ct: 123	Time elapsed: 0.83
GA Iter: 0	Max score: 0.9756	Min score: 0.9674	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9823	Min score: 0.9735	#Pop: 128	#M+: 1388	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 3.42
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................***********************************************Time elapsed for measurement: 45.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 25.64 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1810	fail_ct: 112	Time elapsed: 0.46
GA Iter: 0	Max score: 0.9754	Min score: 0.9669	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9817	Min score: 0.9728	#Pop: 128	#M+: 1382	#M-: 83
EvolutionarySearch		#s: 128	Time elapsed: 1.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 42.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 7.47 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1810	fail_ct: 114	Time elapsed: 0.36
GA Iter: 0	Max score: 0.9764	Min score: 0.9671	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9868	Min score: 0.9729	#Pop: 128	#M+: 1398	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 2.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 50.57 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.49 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1796	fail_ct: 125	Time elapsed: 0.39
GA Iter: 0	Max score: 0.9791	Min score: 0.9672	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9837	Min score: 0.9727	#Pop: 128	#M+: 1373	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 2.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 37.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 36.31 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11904 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19118	Used time : 17601 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  11968 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19182	Used time : 17676 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12032 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19246	Used time : 17729 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12096 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19310	Used time : 17788 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |     64 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 4	fail_ct: 2044	Time elapsed: 0.37
GA Iter: 0	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 0	#M-: 0
GA Iter: 4	Max score: N/A	Min score: N/A	#Pop: 0	#M+: 344	#M-: 6930
EvolutionarySearch		#s: 0	Time elapsed: 1.41
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 0 programs to measure:
Time elapsed for measurement: 0.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.00 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1764	fail_ct: 132	Time elapsed: 0.90
GA Iter: 0	Max score: 0.9780	Min score: 0.9675	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9881	Min score: 0.9733	#Pop: 128	#M+: 1377	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 4.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 44.10 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 34.46 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1807	fail_ct: 98	Time elapsed: 0.36
GA Iter: 0	Max score: 0.9774	Min score: 0.9664	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9814	Min score: 0.9727	#Pop: 128	#M+: 1385	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 1.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 37.82 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 42.79 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1789	fail_ct: 131	Time elapsed: 0.36
GA Iter: 0	Max score: 0.9750	Min score: 0.9676	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9890	Min score: 0.9725	#Pop: 128	#M+: 1377	#M-: 81
EvolutionarySearch		#s: 128	Time elapsed: 2.03
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 46.68 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.97 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12160 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19374	Used time : 17864 s	Next ID: 1	
|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |    128 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12160 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19374	Used time : 17866 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |    128 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12224 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19438	Used time : 17951 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |    128 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12288 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19502	Used time : 18034 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |    128 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1777	fail_ct: 136	Time elapsed: 0.92
GA Iter: 0	Max score: 0.9765	Min score: 0.9672	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9844	Min score: 0.9728	#Pop: 128	#M+: 1373	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 5.40
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 39.99 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 81.60 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1794	fail_ct: 128	Time elapsed: 1.11
GA Iter: 0	Max score: 0.9757	Min score: 0.9667	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9817	Min score: 0.9728	#Pop: 128	#M+: 1380	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 5.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................************************************************Time elapsed for measurement: 45.09 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 45.55 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1994	fail_ct: 0	Time elapsed: 1.50
GA Iter: 0	Max score: 0.7817	Min score: 0.2647	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9658	Min score: 0.8317	#Pop: 128	#M+: 1392	#M-: 81
EvolutionarySearch		#s: 128	Time elapsed: 7.19
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 22.97 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 15.47 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1787	fail_ct: 125	Time elapsed: 0.85
GA Iter: 0	Max score: 0.9752	Min score: 0.9658	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9827	Min score: 0.9732	#Pop: 128	#M+: 1369	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 4.40
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 50.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.50 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1778	fail_ct: 127	Time elapsed: 0.37
GA Iter: 0	Max score: 0.9782	Min score: 0.9676	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9820	Min score: 0.9733	#Pop: 128	#M+: 1373	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 2.48
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 45.92 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 45.98 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12352 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19566	Used time : 18108 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |    128 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12416 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19630	Used time : 18236 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |    128 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1344 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12480 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19694	Used time : 18334 s	Next ID: 7	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |    128 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1408 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12480 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19758	Used time : 18381 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |    128 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1408 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12544 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19822	Used time : 18446 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1795	fail_ct: 113	Time elapsed: 0.90
GA Iter: 0	Max score: 0.9800	Min score: 0.9660	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9818	Min score: 0.9728	#Pop: 128	#M+: 1394	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 3.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 52.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.22 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1776	fail_ct: 119	Time elapsed: 0.35
GA Iter: 0	Max score: 0.9765	Min score: 0.9675	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9822	Min score: 0.9730	#Pop: 128	#M+: 1386	#M-: 67
EvolutionarySearch		#s: 128	Time elapsed: 1.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************Time elapsed for measurement: 39.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 24.75 s
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |    128 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1408 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12608 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19886	Used time : 18541 s	Next ID: 12	

|  ID  |                       Task Description                        | Latency (ms) | Speed (GFLOPS) | Trials |
-----------------------------------------------------------------------------------------------------------------
|    0 |                                         vm_mod_fused_nn_lrn_1 |        0.083 |          27.12 |    448 |
|    1 |                                    vm_mod_fused_nn_max_pool2d |        0.013 |         190.30 |    128 |
|    2 |                           vm_mod_fused_nn_dense_add_nn_relu_1 |        0.027 |         309.70 |    192 |
|    3 |              vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu |        0.151 |        2242.97 |    768 |
|    4 |                                  vm_mod_fused_nn_max_pool2d_1 |        0.007 |          48.24 |     64 |
|    5 |                                       vm_mod_fused_nn_softmax |        0.006 |           0.68 |     64 |
|    6 |                                  vm_mod_fused_nn_max_pool2d_2 |        0.003 |          27.68 |     64 |
|    7 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 |        0.271 |        2835.31 |   1408 |
|    8 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 |        0.125 |        2715.78 |    640 |
|    9 |                                           vm_mod_fused_nn_lrn |        0.598 |          26.69 |   2048 |
|   10 |                                     vm_mod_fused_nn_dense_add |        0.010 |         195.42 |     64 |
|   11 |            vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 |        0.253 |        2686.68 |   2880 |
|   12 |                             vm_mod_fused_nn_dense_add_nn_relu |        2.511 |          60.14 |  12672 |
-----------------------------------------------------------------------------------------------------------------
Estimated total latency: 4.311 ms	Trials: 19950	Used time : 18604 s	Next ID: 12	

==== Task 0: vm_mod_fused_nn_lrn_1 (weight 1 key: ["0f353233a06b32a162590935e5014785", [1, 256, 25, 25], [1, 256, 25, 25]]) =====
placeholder = PLACEHOLDER [1, 256, 25, 25]
pad_data(ax0, ax1, ax2, ax3) = tir.if_then_else(((ax1 >= 2) && (ax1 < 258)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)
tensor(ax0, ax1, ax2, ax3) += (pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])
tensor(ax0, ax1, ax2, ax3) = tir.pow((2f + ((0.0005f*tensor[ax0, ax1, ax2, ax3])/5f)), 0.75f)
T_divide(ax0, ax1, ax2, ax3) = (placeholder[ax0, ax1, ax2, ax3]/tensor[ax0, ax1, ax2, ax3])


Trace for this task is: 
pad_data_ax0, pad_data_ax1, pad_data_ax2, pad_data_ax3 = tuple(pad_data.op.axis) + tuple(pad_data.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_rxs = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
T_divide_ax0, T_divide_ax1, T_divide_ax2, T_divide_ax3 = tuple(T_divide.op.axis) + tuple(T_divide.op.reduce_axis)
s[tensor].compute_inline()
s[tensor].compute_at(s[T_divide], T_divide_ax2)
s[pad_data].compute_at(s[tensor], tensor_ax1)
T_divide_ax0_ax1_fused_ax2_fused = s[T_divide].fuse(T_divide_ax0, T_divide_ax1, T_divide_ax2)
s[T_divide].parallel(T_divide_ax0_ax1_fused_ax2_fused)
s[tensor].pragma(tensor_ax0, "auto_unroll_max_step", 512)
s[tensor].pragma(tensor_ax0, "unroll_explicit", True)


The best replacement found is:
@main = primfn(placeholder_1: handle, T_divide_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [160000], []),
             T_divide: Buffer(T_divide_2: Pointer(float32), float32, [160000], [])}
  buffer_map = {placeholder_1: placeholder, T_divide_1: T_divide}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 256, 25, 25], []), T_divide_1: T_divide_3: Buffer(T_divide_2, float32, [1, 256, 25, 25], [])} {
  for (ax0.ax1.fused.ax2.fused: int32, 0, 6400) "parallel" {
    let cse_var_5: int32 = (ax0.ax1.fused.ax2.fused*25)
    let cse_var_4: bool = (ax0.ax1.fused.ax2.fused < 6375)
    let cse_var_3: bool = (ax0.ax1.fused.ax2.fused < 6350)
    let cse_var_2: bool = (50 <= ax0.ax1.fused.ax2.fused)
    let cse_var_1: bool = (25 <= ax0.ax1.fused.ax2.fused)
    allocate(pad_data: Pointer(global float32), float32, [125]), storage_scope = global;
    allocate(tensor: Pointer(global float32), float32, [25]), storage_scope = global {
      pad_data_1: Buffer(pad_data, float32, [125], [])[0] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1250)], 0f32, dtype=float32)
      pad_data_1[1] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1249)], 0f32, dtype=float32)
      pad_data_1[2] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1248)], 0f32, dtype=float32)
      pad_data_1[3] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1247)], 0f32, dtype=float32)
      pad_data_1[4] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1246)], 0f32, dtype=float32)
      pad_data_1[5] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1245)], 0f32, dtype=float32)
      pad_data_1[6] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1244)], 0f32, dtype=float32)
      pad_data_1[7] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1243)], 0f32, dtype=float32)
      pad_data_1[8] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1242)], 0f32, dtype=float32)
      pad_data_1[9] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1241)], 0f32, dtype=float32)
      pad_data_1[10] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1240)], 0f32, dtype=float32)
      pad_data_1[11] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1239)], 0f32, dtype=float32)
      pad_data_1[12] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1238)], 0f32, dtype=float32)
      pad_data_1[13] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1237)], 0f32, dtype=float32)
      pad_data_1[14] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1236)], 0f32, dtype=float32)
      pad_data_1[15] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1235)], 0f32, dtype=float32)
      pad_data_1[16] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1234)], 0f32, dtype=float32)
      pad_data_1[17] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1233)], 0f32, dtype=float32)
      pad_data_1[18] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1232)], 0f32, dtype=float32)
      pad_data_1[19] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1231)], 0f32, dtype=float32)
      pad_data_1[20] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1230)], 0f32, dtype=float32)
      pad_data_1[21] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1229)], 0f32, dtype=float32)
      pad_data_1[22] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1228)], 0f32, dtype=float32)
      pad_data_1[23] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1227)], 0f32, dtype=float32)
      pad_data_1[24] = @tir.if_then_else(cse_var_2, placeholder[(cse_var_5 - 1226)], 0f32, dtype=float32)
      pad_data_1[25] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 625)], 0f32, dtype=float32)
      pad_data_1[26] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 624)], 0f32, dtype=float32)
      pad_data_1[27] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 623)], 0f32, dtype=float32)
      pad_data_1[28] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 622)], 0f32, dtype=float32)
      pad_data_1[29] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 621)], 0f32, dtype=float32)
      pad_data_1[30] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 620)], 0f32, dtype=float32)
      pad_data_1[31] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 619)], 0f32, dtype=float32)
      pad_data_1[32] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 618)], 0f32, dtype=float32)
      pad_data_1[33] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 617)], 0f32, dtype=float32)
      pad_data_1[34] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 616)], 0f32, dtype=float32)
      pad_data_1[35] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 615)], 0f32, dtype=float32)
      pad_data_1[36] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 614)], 0f32, dtype=float32)
      pad_data_1[37] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 613)], 0f32, dtype=float32)
      pad_data_1[38] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 612)], 0f32, dtype=float32)
      pad_data_1[39] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 611)], 0f32, dtype=float32)
      pad_data_1[40] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 610)], 0f32, dtype=float32)
      pad_data_1[41] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 609)], 0f32, dtype=float32)
      pad_data_1[42] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 608)], 0f32, dtype=float32)
      pad_data_1[43] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 607)], 0f32, dtype=float32)
      pad_data_1[44] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 606)], 0f32, dtype=float32)
      pad_data_1[45] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 605)], 0f32, dtype=float32)
      pad_data_1[46] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 604)], 0f32, dtype=float32)
      pad_data_1[47] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 603)], 0f32, dtype=float32)
      pad_data_1[48] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 602)], 0f32, dtype=float32)
      pad_data_1[49] = @tir.if_then_else(cse_var_1, placeholder[(cse_var_5 - 601)], 0f32, dtype=float32)
      pad_data_1[50] = placeholder[cse_var_5]
      pad_data_1[51] = placeholder[(cse_var_5 + 1)]
      pad_data_1[52] = placeholder[(cse_var_5 + 2)]
      pad_data_1[53] = placeholder[(cse_var_5 + 3)]
      pad_data_1[54] = placeholder[(cse_var_5 + 4)]
      pad_data_1[55] = placeholder[(cse_var_5 + 5)]
      pad_data_1[56] = placeholder[(cse_var_5 + 6)]
      pad_data_1[57] = placeholder[(cse_var_5 + 7)]
      pad_data_1[58] = placeholder[(cse_var_5 + 8)]
      pad_data_1[59] = placeholder[(cse_var_5 + 9)]
      pad_data_1[60] = placeholder[(cse_var_5 + 10)]
      pad_data_1[61] = placeholder[(cse_var_5 + 11)]
      pad_data_1[62] = placeholder[(cse_var_5 + 12)]
      pad_data_1[63] = placeholder[(cse_var_5 + 13)]
      pad_data_1[64] = placeholder[(cse_var_5 + 14)]
      pad_data_1[65] = placeholder[(cse_var_5 + 15)]
      pad_data_1[66] = placeholder[(cse_var_5 + 16)]
      pad_data_1[67] = placeholder[(cse_var_5 + 17)]
      pad_data_1[68] = placeholder[(cse_var_5 + 18)]
      pad_data_1[69] = placeholder[(cse_var_5 + 19)]
      pad_data_1[70] = placeholder[(cse_var_5 + 20)]
      pad_data_1[71] = placeholder[(cse_var_5 + 21)]
      pad_data_1[72] = placeholder[(cse_var_5 + 22)]
      pad_data_1[73] = placeholder[(cse_var_5 + 23)]
      pad_data_1[74] = placeholder[(cse_var_5 + 24)]
      pad_data_1[75] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 625)], 0f32, dtype=float32)
      pad_data_1[76] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 626)], 0f32, dtype=float32)
      pad_data_1[77] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 627)], 0f32, dtype=float32)
      pad_data_1[78] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 628)], 0f32, dtype=float32)
      pad_data_1[79] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 629)], 0f32, dtype=float32)
      pad_data_1[80] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 630)], 0f32, dtype=float32)
      pad_data_1[81] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 631)], 0f32, dtype=float32)
      pad_data_1[82] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 632)], 0f32, dtype=float32)
      pad_data_1[83] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 633)], 0f32, dtype=float32)
      pad_data_1[84] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 634)], 0f32, dtype=float32)
      pad_data_1[85] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 635)], 0f32, dtype=float32)
      pad_data_1[86] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 636)], 0f32, dtype=float32)
      pad_data_1[87] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 637)], 0f32, dtype=float32)
      pad_data_1[88] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 638)], 0f32, dtype=float32)
      pad_data_1[89] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 639)], 0f32, dtype=float32)
      pad_data_1[90] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 640)], 0f32, dtype=float32)
      pad_data_1[91] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 641)], 0f32, dtype=float32)
      pad_data_1[92] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 642)], 0f32, dtype=float32)
      pad_data_1[93] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 643)], 0f32, dtype=float32)
      pad_data_1[94] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 644)], 0f32, dtype=float32)
      pad_data_1[95] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 645)], 0f32, dtype=float32)
      pad_data_1[96] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 646)], 0f32, dtype=float32)
      pad_data_1[97] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 647)], 0f32, dtype=float32)
      pad_data_1[98] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 648)], 0f32, dtype=float32)
      pad_data_1[99] = @tir.if_then_else(cse_var_4, placeholder[(cse_var_5 + 649)], 0f32, dtype=float32)
      pad_data_1[100] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1250)], 0f32, dtype=float32)
      pad_data_1[101] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1251)], 0f32, dtype=float32)
      pad_data_1[102] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1252)], 0f32, dtype=float32)
      pad_data_1[103] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1253)], 0f32, dtype=float32)
      pad_data_1[104] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1254)], 0f32, dtype=float32)
      pad_data_1[105] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1255)], 0f32, dtype=float32)
      pad_data_1[106] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1256)], 0f32, dtype=float32)
      pad_data_1[107] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1257)], 0f32, dtype=float32)
      pad_data_1[108] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1258)], 0f32, dtype=float32)
      pad_data_1[109] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1259)], 0f32, dtype=float32)
      pad_data_1[110] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1260)], 0f32, dtype=float32)
      pad_data_1[111] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1261)], 0f32, dtype=float32)
      pad_data_1[112] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1262)], 0f32, dtype=float32)
      pad_data_1[113] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1263)], 0f32, dtype=float32)
      pad_data_1[114] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1264)], 0f32, dtype=float32)
      pad_data_1[115] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1265)], 0f32, dtype=float32)
      pad_data_1[116] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1266)], 0f32, dtype=float32)
      pad_data_1[117] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1267)], 0f32, dtype=float32)
      pad_data_1[118] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1268)], 0f32, dtype=float32)
      pad_data_1[119] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1269)], 0f32, dtype=float32)
      pad_data_1[120] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1270)], 0f32, dtype=float32)
      pad_data_1[121] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1271)], 0f32, dtype=float32)
      pad_data_1[122] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1272)], 0f32, dtype=float32)
      pad_data_1[123] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1273)], 0f32, dtype=float32)
      pad_data_1[124] = @tir.if_then_else(cse_var_3, placeholder[(cse_var_5 + 1274)], 0f32, dtype=float32)
      tensor_1: Buffer(tensor, float32, [25], [], align=64)[0] = 0f32
      tensor_1[0] = (tensor_1[0] + (pad_data_1[0]*pad_data_1[0]))
      tensor_1[0] = (tensor_1[0] + (pad_data_1[25]*pad_data_1[25]))
      tensor_1[0] = (tensor_1[0] + (pad_data_1[50]*pad_data_1[50]))
      tensor_1[0] = (tensor_1[0] + (pad_data_1[75]*pad_data_1[75]))
      tensor_1[0] = (tensor_1[0] + (pad_data_1[100]*pad_data_1[100]))
      tensor_1[1] = 0f32
      tensor_1[1] = (tensor_1[1] + (pad_data_1[1]*pad_data_1[1]))
      tensor_1[1] = (tensor_1[1] + (pad_data_1[26]*pad_data_1[26]))
      tensor_1[1] = (tensor_1[1] + (pad_data_1[51]*pad_data_1[51]))
      tensor_1[1] = (tensor_1[1] + (pad_data_1[76]*pad_data_1[76]))
      tensor_1[1] = (tensor_1[1] + (pad_data_1[101]*pad_data_1[101]))
      tensor_1[2] = 0f32
      tensor_1[2] = (tensor_1[2] + (pad_data_1[2]*pad_data_1[2]))
      tensor_1[2] = (tensor_1[2] + (pad_data_1[27]*pad_data_1[27]))
      tensor_1[2] = (tensor_1[2] + (pad_data_1[52]*pad_data_1[52]))
      tensor_1[2] = (tensor_1[2] + (pad_data_1[77]*pad_data_1[77]))
      tensor_1[2] = (tensor_1[2] + (pad_data_1[102]*pad_data_1[102]))
      tensor_1[3] = 0f32
      tensor_1[3] = (tensor_1[3] + (pad_data_1[3]*pad_data_1[3]))
      tensor_1[3] = (tensor_1[3] + (pad_data_1[28]*pad_data_1[28]))
      tensor_1[3] = (tensor_1[3] + (pad_data_1[53]*pad_data_1[53]))
      tensor_1[3] = (tensor_1[3] + (pad_data_1[78]*pad_data_1[78]))
      tensor_1[3] = (tensor_1[3] + (pad_data_1[103]*pad_data_1[103]))
      tensor_1[4] = 0f32
      tensor_1[4] = (tensor_1[4] + (pad_data_1[4]*pad_data_1[4]))
      tensor_1[4] = (tensor_1[4] + (pad_data_1[29]*pad_data_1[29]))
      tensor_1[4] = (tensor_1[4] + (pad_data_1[54]*pad_data_1[54]))
      tensor_1[4] = (tensor_1[4] + (pad_data_1[79]*pad_data_1[79]))
      tensor_1[4] = (tensor_1[4] + (pad_data_1[104]*pad_data_1[104]))
      tensor_1[5] = 0f32
      tensor_1[5] = (tensor_1[5] + (pad_data_1[5]*pad_data_1[5]))
      tensor_1[5] = (tensor_1[5] + (pad_data_1[30]*pad_data_1[30]))
      tensor_1[5] = (tensor_1[5] + (pad_data_1[55]*pad_data_1[55]))
      tensor_1[5] = (tensor_1[5] + (pad_data_1[80]*pad_data_1[80]))
      tensor_1[5] = (tensor_1[5] + (pad_data_1[105]*pad_data_1[105]))
      tensor_1[6] = 0f32
      tensor_1[6] = (tensor_1[6] + (pad_data_1[6]*pad_data_1[6]))
      tensor_1[6] = (tensor_1[6] + (pad_data_1[31]*pad_data_1[31]))
      tensor_1[6] = (tensor_1[6] + (pad_data_1[56]*pad_data_1[56]))
      tensor_1[6] = (tensor_1[6] + (pad_data_1[81]*pad_data_1[81]))
      tensor_1[6] = (tensor_1[6] + (pad_data_1[106]*pad_data_1[106]))
      tensor_1[7] = 0f32
      tensor_1[7] = (tensor_1[7] + (pad_data_1[7]*pad_data_1[7]))
      tensor_1[7] = (tensor_1[7] + (pad_data_1[32]*pad_data_1[32]))
      tensor_1[7] = (tensor_1[7] + (pad_data_1[57]*pad_data_1[57]))
      tensor_1[7] = (tensor_1[7] + (pad_data_1[82]*pad_data_1[82]))
      tensor_1[7] = (tensor_1[7] + (pad_data_1[107]*pad_data_1[107]))
      tensor_1[8] = 0f32
      tensor_1[8] = (tensor_1[8] + (pad_data_1[8]*pad_data_1[8]))
      tensor_1[8] = (tensor_1[8] + (pad_data_1[33]*pad_data_1[33]))
      tensor_1[8] = (tensor_1[8] + (pad_data_1[58]*pad_data_1[58]))
      tensor_1[8] = (tensor_1[8] + (pad_data_1[83]*pad_data_1[83]))
      tensor_1[8] = (tensor_1[8] + (pad_data_1[108]*pad_data_1[108]))
      tensor_1[9] = 0f32
      tensor_1[9] = (tensor_1[9] + (pad_data_1[9]*pad_data_1[9]))
      tensor_1[9] = (tensor_1[9] + (pad_data_1[34]*pad_data_1[34]))
      tensor_1[9] = (tensor_1[9] + (pad_data_1[59]*pad_data_1[59]))
      tensor_1[9] = (tensor_1[9] + (pad_data_1[84]*pad_data_1[84]))
      tensor_1[9] = (tensor_1[9] + (pad_data_1[109]*pad_data_1[109]))
      tensor_1[10] = 0f32
      tensor_1[10] = (tensor_1[10] + (pad_data_1[10]*pad_data_1[10]))
      tensor_1[10] = (tensor_1[10] + (pad_data_1[35]*pad_data_1[35]))
      tensor_1[10] = (tensor_1[10] + (pad_data_1[60]*pad_data_1[60]))
      tensor_1[10] = (tensor_1[10] + (pad_data_1[85]*pad_data_1[85]))
      tensor_1[10] = (tensor_1[10] + (pad_data_1[110]*pad_data_1[110]))
      tensor_1[11] = 0f32
      tensor_1[11] = (tensor_1[11] + (pad_data_1[11]*pad_data_1[11]))
      tensor_1[11] = (tensor_1[11] + (pad_data_1[36]*pad_data_1[36]))
      tensor_1[11] = (tensor_1[11] + (pad_data_1[61]*pad_data_1[61]))
      tensor_1[11] = (tensor_1[11] + (pad_data_1[86]*pad_data_1[86]))
      tensor_1[11] = (tensor_1[11] + (pad_data_1[111]*pad_data_1[111]))
      tensor_1[12] = 0f32
      tensor_1[12] = (tensor_1[12] + (pad_data_1[12]*pad_data_1[12]))
      tensor_1[12] = (tensor_1[12] + (pad_data_1[37]*pad_data_1[37]))
      tensor_1[12] = (tensor_1[12] + (pad_data_1[62]*pad_data_1[62]))
      tensor_1[12] = (tensor_1[12] + (pad_data_1[87]*pad_data_1[87]))
      tensor_1[12] = (tensor_1[12] + (pad_data_1[112]*pad_data_1[112]))
      tensor_1[13] = 0f32
      tensor_1[13] = (tensor_1[13] + (pad_data_1[13]*pad_data_1[13]))
      tensor_1[13] = (tensor_1[13] + (pad_data_1[38]*pad_data_1[38]))
      tensor_1[13] = (tensor_1[13] + (pad_data_1[63]*pad_data_1[63]))
      tensor_1[13] = (tensor_1[13] + (pad_data_1[88]*pad_data_1[88]))
      tensor_1[13] = (tensor_1[13] + (pad_data_1[113]*pad_data_1[113]))
      tensor_1[14] = 0f32
      tensor_1[14] = (tensor_1[14] + (pad_data_1[14]*pad_data_1[14]))
      tensor_1[14] = (tensor_1[14] + (pad_data_1[39]*pad_data_1[39]))
      tensor_1[14] = (tensor_1[14] + (pad_data_1[64]*pad_data_1[64]))
      tensor_1[14] = (tensor_1[14] + (pad_data_1[89]*pad_data_1[89]))
      tensor_1[14] = (tensor_1[14] + (pad_data_1[114]*pad_data_1[114]))
      tensor_1[15] = 0f32
      tensor_1[15] = (tensor_1[15] + (pad_data_1[15]*pad_data_1[15]))
      tensor_1[15] = (tensor_1[15] + (pad_data_1[40]*pad_data_1[40]))
      tensor_1[15] = (tensor_1[15] + (pad_data_1[65]*pad_data_1[65]))
      tensor_1[15] = (tensor_1[15] + (pad_data_1[90]*pad_data_1[90]))
      tensor_1[15] = (tensor_1[15] + (pad_data_1[115]*pad_data_1[115]))
      tensor_1[16] = 0f32
      tensor_1[16] = (tensor_1[16] + (pad_data_1[16]*pad_data_1[16]))
      tensor_1[16] = (tensor_1[16] + (pad_data_1[41]*pad_data_1[41]))
      tensor_1[16] = (tensor_1[16] + (pad_data_1[66]*pad_data_1[66]))
      tensor_1[16] = (tensor_1[16] + (pad_data_1[91]*pad_data_1[91]))
      tensor_1[16] = (tensor_1[16] + (pad_data_1[116]*pad_data_1[116]))
      tensor_1[17] = 0f32
      tensor_1[17] = (tensor_1[17] + (pad_data_1[17]*pad_data_1[17]))
      tensor_1[17] = (tensor_1[17] + (pad_data_1[42]*pad_data_1[42]))
      tensor_1[17] = (tensor_1[17] + (pad_data_1[67]*pad_data_1[67]))
      tensor_1[17] = (tensor_1[17] + (pad_data_1[92]*pad_data_1[92]))
      tensor_1[17] = (tensor_1[17] + (pad_data_1[117]*pad_data_1[117]))
      tensor_1[18] = 0f32
      tensor_1[18] = (tensor_1[18] + (pad_data_1[18]*pad_data_1[18]))
      tensor_1[18] = (tensor_1[18] + (pad_data_1[43]*pad_data_1[43]))
      tensor_1[18] = (tensor_1[18] + (pad_data_1[68]*pad_data_1[68]))
      tensor_1[18] = (tensor_1[18] + (pad_data_1[93]*pad_data_1[93]))
      tensor_1[18] = (tensor_1[18] + (pad_data_1[118]*pad_data_1[118]))
      tensor_1[19] = 0f32
      tensor_1[19] = (tensor_1[19] + (pad_data_1[19]*pad_data_1[19]))
      tensor_1[19] = (tensor_1[19] + (pad_data_1[44]*pad_data_1[44]))
      tensor_1[19] = (tensor_1[19] + (pad_data_1[69]*pad_data_1[69]))
      tensor_1[19] = (tensor_1[19] + (pad_data_1[94]*pad_data_1[94]))
      tensor_1[19] = (tensor_1[19] + (pad_data_1[119]*pad_data_1[119]))
      tensor_1[20] = 0f32
      tensor_1[20] = (tensor_1[20] + (pad_data_1[20]*pad_data_1[20]))
      tensor_1[20] = (tensor_1[20] + (pad_data_1[45]*pad_data_1[45]))
      tensor_1[20] = (tensor_1[20] + (pad_data_1[70]*pad_data_1[70]))
      tensor_1[20] = (tensor_1[20] + (pad_data_1[95]*pad_data_1[95]))
      tensor_1[20] = (tensor_1[20] + (pad_data_1[120]*pad_data_1[120]))
      tensor_1[21] = 0f32
      tensor_1[21] = (tensor_1[21] + (pad_data_1[21]*pad_data_1[21]))
      tensor_1[21] = (tensor_1[21] + (pad_data_1[46]*pad_data_1[46]))
      tensor_1[21] = (tensor_1[21] + (pad_data_1[71]*pad_data_1[71]))
      tensor_1[21] = (tensor_1[21] + (pad_data_1[96]*pad_data_1[96]))
      tensor_1[21] = (tensor_1[21] + (pad_data_1[121]*pad_data_1[121]))
      tensor_1[22] = 0f32
      tensor_1[22] = (tensor_1[22] + (pad_data_1[22]*pad_data_1[22]))
      tensor_1[22] = (tensor_1[22] + (pad_data_1[47]*pad_data_1[47]))
      tensor_1[22] = (tensor_1[22] + (pad_data_1[72]*pad_data_1[72]))
      tensor_1[22] = (tensor_1[22] + (pad_data_1[97]*pad_data_1[97]))
      tensor_1[22] = (tensor_1[22] + (pad_data_1[122]*pad_data_1[122]))
      tensor_1[23] = 0f32
      tensor_1[23] = (tensor_1[23] + (pad_data_1[23]*pad_data_1[23]))
      tensor_1[23] = (tensor_1[23] + (pad_data_1[48]*pad_data_1[48]))
      tensor_1[23] = (tensor_1[23] + (pad_data_1[73]*pad_data_1[73]))
      tensor_1[23] = (tensor_1[23] + (pad_data_1[98]*pad_data_1[98]))
      tensor_1[23] = (tensor_1[23] + (pad_data_1[123]*pad_data_1[123]))
      tensor_1[24] = 0f32
      tensor_1[24] = (tensor_1[24] + (pad_data_1[24]*pad_data_1[24]))
      tensor_1[24] = (tensor_1[24] + (pad_data_1[49]*pad_data_1[49]))
      tensor_1[24] = (tensor_1[24] + (pad_data_1[74]*pad_data_1[74]))
      tensor_1[24] = (tensor_1[24] + (pad_data_1[99]*pad_data_1[99]))
      tensor_1[24] = (tensor_1[24] + (pad_data_1[124]*pad_data_1[124]))
      for (ax3: int32, 0, 25) {
        let cse_var_6: int32 = (cse_var_5 + ax3)
        T_divide[cse_var_6] = (placeholder[cse_var_6] / @tir.pow((2f32 + ((0.0005f32*tensor_1[ax3])*0.2f32)), 0.75f32, dtype=float32))
      }
    }
  }
}


==== Task 1: vm_mod_fused_nn_max_pool2d (weight 1 key: ["9abffad12b503cdcfdda685c0a0b65f2", [1, 96, 109, 109], [1, 96, 54, 54]]) =====
placeholder = PLACEHOLDER [1, 96, 109, 109]
tensor(ax0, ax1, ax2, ax3) max= placeholder[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1)]


Trace for this task is: 
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
tensor_ax0_ax1_fused = s[tensor].fuse(tensor_ax0, tensor_ax1)
s[tensor].parallel(tensor_ax0_ax1_fused)
s[tensor].pragma(tensor_ax0_ax1_fused, "auto_unroll_max_step", 16)
s[tensor].pragma(tensor_ax0_ax1_fused, "unroll_explicit", True)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [1140576], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [279936], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 96, 109, 109], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 96, 54, 54], [])} {
  for (ax0.ax1.fused: int32, 0, 96) "parallel" {
    for (ax2: int32, 0, 54) {
      for (ax3: int32, 0, 54) {
        let cse_var_2: int32 = (((ax0.ax1.fused*2916) + (ax2*54)) + ax3)
        let cse_var_1: int32 = (((ax0.ax1.fused*11881) + (ax2*218)) + (ax3*2))
         {
          tensor[cse_var_2] = -3.40282e+38f32
          tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[cse_var_1])
          tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_1 + 1)])
          tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_1 + 2)])
          tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_1 + 109)])
          tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_1 + 110)])
          tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_1 + 111)])
          tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_1 + 218)])
          tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_1 + 219)])
          tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_1 + 220)])
        }
      }
    }
  }
}


==== Task 2: vm_mod_fused_nn_dense_add_nn_relu_1 (weight 1 key: ["7c7999b7bbdaec23cf87b49ec0ce3a97", [1, 4096], [1024, 4096], [1, 1024], [1, 1024]]) =====
placeholder = PLACEHOLDER [1, 4096]
placeholder = PLACEHOLDER [1024, 4096]
T_matmul_NT(i, j) += (placeholder[i, k]*placeholder[j, k])
placeholder = PLACEHOLDER [1, 1024]
T_add(ax0, ax1) = (T_matmul_NT[ax0, ax1] + placeholder[ax0, ax1])
T_relu(ax0, ax1) = max(T_add[ax0, ax1], 0f)


Trace for this task is: 
T_matmul_NT_i, T_matmul_NT_j, T_matmul_NT_k = tuple(T_matmul_NT.op.axis) + tuple(T_matmul_NT.op.reduce_axis)
T_add_ax0, T_add_ax1 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
T_matmul_NT_i_o_i, T_matmul_NT_i_i = s[T_matmul_NT].split(T_matmul_NT_i, factor=1)
T_matmul_NT_i_o_o_i, T_matmul_NT_i_o_i = s[T_matmul_NT].split(T_matmul_NT_i_o_i, factor=1)
T_matmul_NT_i_o_o_o, T_matmul_NT_i_o_o_i = s[T_matmul_NT].split(T_matmul_NT_i_o_o_i, factor=1)
T_matmul_NT_j_o_i, T_matmul_NT_j_i = s[T_matmul_NT].split(T_matmul_NT_j, factor=64)
T_matmul_NT_j_o_o_i, T_matmul_NT_j_o_i = s[T_matmul_NT].split(T_matmul_NT_j_o_i, factor=1)
T_matmul_NT_j_o_o_o, T_matmul_NT_j_o_o_i = s[T_matmul_NT].split(T_matmul_NT_j_o_o_i, factor=8)
T_matmul_NT_k_o, T_matmul_NT_k_i = s[T_matmul_NT].split(T_matmul_NT_k, factor=8)
s[T_matmul_NT].reorder(T_matmul_NT_i_o_o_o, T_matmul_NT_j_o_o_o, T_matmul_NT_i_o_o_i, T_matmul_NT_j_o_o_i, T_matmul_NT_k_o, T_matmul_NT_i_o_i, T_matmul_NT_j_o_i, T_matmul_NT_k_i, T_matmul_NT_i_i, T_matmul_NT_j_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=64)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=8)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax0_i, T_relu_ax1_i)
s[T_matmul_NT].compute_at(s[T_relu], T_relu_ax1_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax0_o_i_fused_ax1_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax0_o_i_fused_ax1_o_i_fused)
s[T_matmul_NT].pragma(T_matmul_NT_i_o_o_o, "auto_unroll_max_step", 0)
s[T_matmul_NT].pragma(T_matmul_NT_i_o_o_o, "unroll_explicit", True)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [4096], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [4194304], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [1024], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [1024], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 4096], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [2, 8, 1, 1, 512, 1, 8, 64], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 1024], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 1024], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused: int32, 0, 16) "parallel" {
    allocate(T_matmul_NT: Pointer(global float32), float32, [64]), storage_scope = global {
      for (j.inner.init: int32, 0, 64) {
        T_matmul_NT_1: Buffer(T_matmul_NT, float32, [64], [])[j.inner.init] = 0f32
      }
      for (k.outer: int32, 0, 512) {
        for (k.inner: int32, 0, 8) {
          for (j.inner: int32, 0, 64) {
            T_matmul_NT_1[j.inner] = (T_matmul_NT_1[j.inner] + (placeholder[((k.outer*8) + k.inner)]*placeholder_1[((((ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused*262144) + (k.outer*512)) + (k.inner*64)) + j.inner)]))
          }
        }
      }
      for (ax1.inner: int32, 0, 64) {
        let cse_var_1: int32 = ((ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused*64) + ax1.inner)
        T_relu[cse_var_1] = max((T_matmul_NT_1[ax1.inner] + placeholder_2[cse_var_1]), 0f32)
      }
    }
  }
}


==== Task 3: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu (weight 1 key: ["01a6b9ff57444c5d506f411c1a32175c", [1, 1, 224, 224, 3], [6, 1, 7, 7, 3, 16], [1, 6, 1, 1, 16], [1, 6, 109, 109, 16]]) =====
placeholder = PLACEHOLDER [1, 1, 224, 224, 3]
placeholder = PLACEHOLDER [6, 1, 7, 7, 3, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 3), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 3)]*placeholder[oc_chunk, floordiv(ic, 3), kh, kw, floormod(ic, 3), oc_block])
placeholder = PLACEHOLDER [1, 6, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=3)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=1)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=109)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=1)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=1)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=7)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax1_o, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=3)
T_relu_ax2_o, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax3_o, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=109)
T_relu_ax4_o, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
s[T_relu].reorder(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o, T_relu_ax4_o, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o)
T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused = s[T_relu].fuse(T_relu_ax0_o, T_relu_ax1_o, T_relu_ax2_o, T_relu_ax3_o)
s[T_relu].parallel(T_relu_ax0_o_ax1_o_fused_ax2_o_fused_ax3_o_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [150528], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [14112], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [96], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [1140576], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 1, 224, 224, 3], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [6, 1, 7, 7, 3, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 6, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 6, 109, 109, 16], [])} {
  for (ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused: int32, 0, 218) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [327]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [327], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[109] = broadcast(0f32, 16)
      conv2d_NCHWc_1[218] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[110] = broadcast(0f32, 16)
      conv2d_NCHWc_1[219] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[111] = broadcast(0f32, 16)
      conv2d_NCHWc_1[220] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[112] = broadcast(0f32, 16)
      conv2d_NCHWc_1[221] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[113] = broadcast(0f32, 16)
      conv2d_NCHWc_1[222] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[114] = broadcast(0f32, 16)
      conv2d_NCHWc_1[223] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[115] = broadcast(0f32, 16)
      conv2d_NCHWc_1[224] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[116] = broadcast(0f32, 16)
      conv2d_NCHWc_1[225] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[117] = broadcast(0f32, 16)
      conv2d_NCHWc_1[226] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[118] = broadcast(0f32, 16)
      conv2d_NCHWc_1[227] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[119] = broadcast(0f32, 16)
      conv2d_NCHWc_1[228] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[120] = broadcast(0f32, 16)
      conv2d_NCHWc_1[229] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[121] = broadcast(0f32, 16)
      conv2d_NCHWc_1[230] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      conv2d_NCHWc_1[122] = broadcast(0f32, 16)
      conv2d_NCHWc_1[231] = broadcast(0f32, 16)
      conv2d_NCHWc_1[14] = broadcast(0f32, 16)
      conv2d_NCHWc_1[123] = broadcast(0f32, 16)
      conv2d_NCHWc_1[232] = broadcast(0f32, 16)
      conv2d_NCHWc_1[15] = broadcast(0f32, 16)
      conv2d_NCHWc_1[124] = broadcast(0f32, 16)
      conv2d_NCHWc_1[233] = broadcast(0f32, 16)
      conv2d_NCHWc_1[16] = broadcast(0f32, 16)
      conv2d_NCHWc_1[125] = broadcast(0f32, 16)
      conv2d_NCHWc_1[234] = broadcast(0f32, 16)
      conv2d_NCHWc_1[17] = broadcast(0f32, 16)
      conv2d_NCHWc_1[126] = broadcast(0f32, 16)
      conv2d_NCHWc_1[235] = broadcast(0f32, 16)
      conv2d_NCHWc_1[18] = broadcast(0f32, 16)
      conv2d_NCHWc_1[127] = broadcast(0f32, 16)
      conv2d_NCHWc_1[236] = broadcast(0f32, 16)
      conv2d_NCHWc_1[19] = broadcast(0f32, 16)
      conv2d_NCHWc_1[128] = broadcast(0f32, 16)
      conv2d_NCHWc_1[237] = broadcast(0f32, 16)
      conv2d_NCHWc_1[20] = broadcast(0f32, 16)
      conv2d_NCHWc_1[129] = broadcast(0f32, 16)
      conv2d_NCHWc_1[238] = broadcast(0f32, 16)
      conv2d_NCHWc_1[21] = broadcast(0f32, 16)
      conv2d_NCHWc_1[130] = broadcast(0f32, 16)
      conv2d_NCHWc_1[239] = broadcast(0f32, 16)
      conv2d_NCHWc_1[22] = broadcast(0f32, 16)
      conv2d_NCHWc_1[131] = broadcast(0f32, 16)
      conv2d_NCHWc_1[240] = broadcast(0f32, 16)
      conv2d_NCHWc_1[23] = broadcast(0f32, 16)
      conv2d_NCHWc_1[132] = broadcast(0f32, 16)
      conv2d_NCHWc_1[241] = broadcast(0f32, 16)
      conv2d_NCHWc_1[24] = broadcast(0f32, 16)
      conv2d_NCHWc_1[133] = broadcast(0f32, 16)
      conv2d_NCHWc_1[242] = broadcast(0f32, 16)
      conv2d_NCHWc_1[25] = broadcast(0f32, 16)
      conv2d_NCHWc_1[134] = broadcast(0f32, 16)
      conv2d_NCHWc_1[243] = broadcast(0f32, 16)
      conv2d_NCHWc_1[26] = broadcast(0f32, 16)
      conv2d_NCHWc_1[135] = broadcast(0f32, 16)
      conv2d_NCHWc_1[244] = broadcast(0f32, 16)
      conv2d_NCHWc_1[27] = broadcast(0f32, 16)
      conv2d_NCHWc_1[136] = broadcast(0f32, 16)
      conv2d_NCHWc_1[245] = broadcast(0f32, 16)
      conv2d_NCHWc_1[28] = broadcast(0f32, 16)
      conv2d_NCHWc_1[137] = broadcast(0f32, 16)
      conv2d_NCHWc_1[246] = broadcast(0f32, 16)
      conv2d_NCHWc_1[29] = broadcast(0f32, 16)
      conv2d_NCHWc_1[138] = broadcast(0f32, 16)
      conv2d_NCHWc_1[247] = broadcast(0f32, 16)
      conv2d_NCHWc_1[30] = broadcast(0f32, 16)
      conv2d_NCHWc_1[139] = broadcast(0f32, 16)
      conv2d_NCHWc_1[248] = broadcast(0f32, 16)
      conv2d_NCHWc_1[31] = broadcast(0f32, 16)
      conv2d_NCHWc_1[140] = broadcast(0f32, 16)
      conv2d_NCHWc_1[249] = broadcast(0f32, 16)
      conv2d_NCHWc_1[32] = broadcast(0f32, 16)
      conv2d_NCHWc_1[141] = broadcast(0f32, 16)
      conv2d_NCHWc_1[250] = broadcast(0f32, 16)
      conv2d_NCHWc_1[33] = broadcast(0f32, 16)
      conv2d_NCHWc_1[142] = broadcast(0f32, 16)
      conv2d_NCHWc_1[251] = broadcast(0f32, 16)
      conv2d_NCHWc_1[34] = broadcast(0f32, 16)
      conv2d_NCHWc_1[143] = broadcast(0f32, 16)
      conv2d_NCHWc_1[252] = broadcast(0f32, 16)
      conv2d_NCHWc_1[35] = broadcast(0f32, 16)
      conv2d_NCHWc_1[144] = broadcast(0f32, 16)
      conv2d_NCHWc_1[253] = broadcast(0f32, 16)
      conv2d_NCHWc_1[36] = broadcast(0f32, 16)
      conv2d_NCHWc_1[145] = broadcast(0f32, 16)
      conv2d_NCHWc_1[254] = broadcast(0f32, 16)
      conv2d_NCHWc_1[37] = broadcast(0f32, 16)
      conv2d_NCHWc_1[146] = broadcast(0f32, 16)
      conv2d_NCHWc_1[255] = broadcast(0f32, 16)
      conv2d_NCHWc_1[38] = broadcast(0f32, 16)
      conv2d_NCHWc_1[147] = broadcast(0f32, 16)
      conv2d_NCHWc_1[256] = broadcast(0f32, 16)
      conv2d_NCHWc_1[39] = broadcast(0f32, 16)
      conv2d_NCHWc_1[148] = broadcast(0f32, 16)
      conv2d_NCHWc_1[257] = broadcast(0f32, 16)
      conv2d_NCHWc_1[40] = broadcast(0f32, 16)
      conv2d_NCHWc_1[149] = broadcast(0f32, 16)
      conv2d_NCHWc_1[258] = broadcast(0f32, 16)
      conv2d_NCHWc_1[41] = broadcast(0f32, 16)
      conv2d_NCHWc_1[150] = broadcast(0f32, 16)
      conv2d_NCHWc_1[259] = broadcast(0f32, 16)
      conv2d_NCHWc_1[42] = broadcast(0f32, 16)
      conv2d_NCHWc_1[151] = broadcast(0f32, 16)
      conv2d_NCHWc_1[260] = broadcast(0f32, 16)
      conv2d_NCHWc_1[43] = broadcast(0f32, 16)
      conv2d_NCHWc_1[152] = broadcast(0f32, 16)
      conv2d_NCHWc_1[261] = broadcast(0f32, 16)
      conv2d_NCHWc_1[44] = broadcast(0f32, 16)
      conv2d_NCHWc_1[153] = broadcast(0f32, 16)
      conv2d_NCHWc_1[262] = broadcast(0f32, 16)
      conv2d_NCHWc_1[45] = broadcast(0f32, 16)
      conv2d_NCHWc_1[154] = broadcast(0f32, 16)
      conv2d_NCHWc_1[263] = broadcast(0f32, 16)
      conv2d_NCHWc_1[46] = broadcast(0f32, 16)
      conv2d_NCHWc_1[155] = broadcast(0f32, 16)
      conv2d_NCHWc_1[264] = broadcast(0f32, 16)
      conv2d_NCHWc_1[47] = broadcast(0f32, 16)
      conv2d_NCHWc_1[156] = broadcast(0f32, 16)
      conv2d_NCHWc_1[265] = broadcast(0f32, 16)
      conv2d_NCHWc_1[48] = broadcast(0f32, 16)
      conv2d_NCHWc_1[157] = broadcast(0f32, 16)
      conv2d_NCHWc_1[266] = broadcast(0f32, 16)
      conv2d_NCHWc_1[49] = broadcast(0f32, 16)
      conv2d_NCHWc_1[158] = broadcast(0f32, 16)
      conv2d_NCHWc_1[267] = broadcast(0f32, 16)
      conv2d_NCHWc_1[50] = broadcast(0f32, 16)
      conv2d_NCHWc_1[159] = broadcast(0f32, 16)
      conv2d_NCHWc_1[268] = broadcast(0f32, 16)
      conv2d_NCHWc_1[51] = broadcast(0f32, 16)
      conv2d_NCHWc_1[160] = broadcast(0f32, 16)
      conv2d_NCHWc_1[269] = broadcast(0f32, 16)
      conv2d_NCHWc_1[52] = broadcast(0f32, 16)
      conv2d_NCHWc_1[161] = broadcast(0f32, 16)
      conv2d_NCHWc_1[270] = broadcast(0f32, 16)
      conv2d_NCHWc_1[53] = broadcast(0f32, 16)
      conv2d_NCHWc_1[162] = broadcast(0f32, 16)
      conv2d_NCHWc_1[271] = broadcast(0f32, 16)
      conv2d_NCHWc_1[54] = broadcast(0f32, 16)
      conv2d_NCHWc_1[163] = broadcast(0f32, 16)
      conv2d_NCHWc_1[272] = broadcast(0f32, 16)
      conv2d_NCHWc_1[55] = broadcast(0f32, 16)
      conv2d_NCHWc_1[164] = broadcast(0f32, 16)
      conv2d_NCHWc_1[273] = broadcast(0f32, 16)
      conv2d_NCHWc_1[56] = broadcast(0f32, 16)
      conv2d_NCHWc_1[165] = broadcast(0f32, 16)
      conv2d_NCHWc_1[274] = broadcast(0f32, 16)
      conv2d_NCHWc_1[57] = broadcast(0f32, 16)
      conv2d_NCHWc_1[166] = broadcast(0f32, 16)
      conv2d_NCHWc_1[275] = broadcast(0f32, 16)
      conv2d_NCHWc_1[58] = broadcast(0f32, 16)
      conv2d_NCHWc_1[167] = broadcast(0f32, 16)
      conv2d_NCHWc_1[276] = broadcast(0f32, 16)
      conv2d_NCHWc_1[59] = broadcast(0f32, 16)
      conv2d_NCHWc_1[168] = broadcast(0f32, 16)
      conv2d_NCHWc_1[277] = broadcast(0f32, 16)
      conv2d_NCHWc_1[60] = broadcast(0f32, 16)
      conv2d_NCHWc_1[169] = broadcast(0f32, 16)
      conv2d_NCHWc_1[278] = broadcast(0f32, 16)
      conv2d_NCHWc_1[61] = broadcast(0f32, 16)
      conv2d_NCHWc_1[170] = broadcast(0f32, 16)
      conv2d_NCHWc_1[279] = broadcast(0f32, 16)
      conv2d_NCHWc_1[62] = broadcast(0f32, 16)
      conv2d_NCHWc_1[171] = broadcast(0f32, 16)
      conv2d_NCHWc_1[280] = broadcast(0f32, 16)
      conv2d_NCHWc_1[63] = broadcast(0f32, 16)
      conv2d_NCHWc_1[172] = broadcast(0f32, 16)
      conv2d_NCHWc_1[281] = broadcast(0f32, 16)
      conv2d_NCHWc_1[64] = broadcast(0f32, 16)
      conv2d_NCHWc_1[173] = broadcast(0f32, 16)
      conv2d_NCHWc_1[282] = broadcast(0f32, 16)
      conv2d_NCHWc_1[65] = broadcast(0f32, 16)
      conv2d_NCHWc_1[174] = broadcast(0f32, 16)
      conv2d_NCHWc_1[283] = broadcast(0f32, 16)
      conv2d_NCHWc_1[66] = broadcast(0f32, 16)
      conv2d_NCHWc_1[175] = broadcast(0f32, 16)
      conv2d_NCHWc_1[284] = broadcast(0f32, 16)
      conv2d_NCHWc_1[67] = broadcast(0f32, 16)
      conv2d_NCHWc_1[176] = broadcast(0f32, 16)
      conv2d_NCHWc_1[285] = broadcast(0f32, 16)
      conv2d_NCHWc_1[68] = broadcast(0f32, 16)
      conv2d_NCHWc_1[177] = broadcast(0f32, 16)
      conv2d_NCHWc_1[286] = broadcast(0f32, 16)
      conv2d_NCHWc_1[69] = broadcast(0f32, 16)
      conv2d_NCHWc_1[178] = broadcast(0f32, 16)
      conv2d_NCHWc_1[287] = broadcast(0f32, 16)
      conv2d_NCHWc_1[70] = broadcast(0f32, 16)
      conv2d_NCHWc_1[179] = broadcast(0f32, 16)
      conv2d_NCHWc_1[288] = broadcast(0f32, 16)
      conv2d_NCHWc_1[71] = broadcast(0f32, 16)
      conv2d_NCHWc_1[180] = broadcast(0f32, 16)
      conv2d_NCHWc_1[289] = broadcast(0f32, 16)
      conv2d_NCHWc_1[72] = broadcast(0f32, 16)
      conv2d_NCHWc_1[181] = broadcast(0f32, 16)
      conv2d_NCHWc_1[290] = broadcast(0f32, 16)
      conv2d_NCHWc_1[73] = broadcast(0f32, 16)
      conv2d_NCHWc_1[182] = broadcast(0f32, 16)
      conv2d_NCHWc_1[291] = broadcast(0f32, 16)
      conv2d_NCHWc_1[74] = broadcast(0f32, 16)
      conv2d_NCHWc_1[183] = broadcast(0f32, 16)
      conv2d_NCHWc_1[292] = broadcast(0f32, 16)
      conv2d_NCHWc_1[75] = broadcast(0f32, 16)
      conv2d_NCHWc_1[184] = broadcast(0f32, 16)
      conv2d_NCHWc_1[293] = broadcast(0f32, 16)
      conv2d_NCHWc_1[76] = broadcast(0f32, 16)
      conv2d_NCHWc_1[185] = broadcast(0f32, 16)
      conv2d_NCHWc_1[294] = broadcast(0f32, 16)
      conv2d_NCHWc_1[77] = broadcast(0f32, 16)
      conv2d_NCHWc_1[186] = broadcast(0f32, 16)
      conv2d_NCHWc_1[295] = broadcast(0f32, 16)
      conv2d_NCHWc_1[78] = broadcast(0f32, 16)
      conv2d_NCHWc_1[187] = broadcast(0f32, 16)
      conv2d_NCHWc_1[296] = broadcast(0f32, 16)
      conv2d_NCHWc_1[79] = broadcast(0f32, 16)
      conv2d_NCHWc_1[188] = broadcast(0f32, 16)
      conv2d_NCHWc_1[297] = broadcast(0f32, 16)
      conv2d_NCHWc_1[80] = broadcast(0f32, 16)
      conv2d_NCHWc_1[189] = broadcast(0f32, 16)
      conv2d_NCHWc_1[298] = broadcast(0f32, 16)
      conv2d_NCHWc_1[81] = broadcast(0f32, 16)
      conv2d_NCHWc_1[190] = broadcast(0f32, 16)
      conv2d_NCHWc_1[299] = broadcast(0f32, 16)
      conv2d_NCHWc_1[82] = broadcast(0f32, 16)
      conv2d_NCHWc_1[191] = broadcast(0f32, 16)
      conv2d_NCHWc_1[300] = broadcast(0f32, 16)
      conv2d_NCHWc_1[83] = broadcast(0f32, 16)
      conv2d_NCHWc_1[192] = broadcast(0f32, 16)
      conv2d_NCHWc_1[301] = broadcast(0f32, 16)
      conv2d_NCHWc_1[84] = broadcast(0f32, 16)
      conv2d_NCHWc_1[193] = broadcast(0f32, 16)
      conv2d_NCHWc_1[302] = broadcast(0f32, 16)
      conv2d_NCHWc_1[85] = broadcast(0f32, 16)
      conv2d_NCHWc_1[194] = broadcast(0f32, 16)
      conv2d_NCHWc_1[303] = broadcast(0f32, 16)
      conv2d_NCHWc_1[86] = broadcast(0f32, 16)
      conv2d_NCHWc_1[195] = broadcast(0f32, 16)
      conv2d_NCHWc_1[304] = broadcast(0f32, 16)
      conv2d_NCHWc_1[87] = broadcast(0f32, 16)
      conv2d_NCHWc_1[196] = broadcast(0f32, 16)
      conv2d_NCHWc_1[305] = broadcast(0f32, 16)
      conv2d_NCHWc_1[88] = broadcast(0f32, 16)
      conv2d_NCHWc_1[197] = broadcast(0f32, 16)
      conv2d_NCHWc_1[306] = broadcast(0f32, 16)
      conv2d_NCHWc_1[89] = broadcast(0f32, 16)
      conv2d_NCHWc_1[198] = broadcast(0f32, 16)
      conv2d_NCHWc_1[307] = broadcast(0f32, 16)
      conv2d_NCHWc_1[90] = broadcast(0f32, 16)
      conv2d_NCHWc_1[199] = broadcast(0f32, 16)
      conv2d_NCHWc_1[308] = broadcast(0f32, 16)
      conv2d_NCHWc_1[91] = broadcast(0f32, 16)
      conv2d_NCHWc_1[200] = broadcast(0f32, 16)
      conv2d_NCHWc_1[309] = broadcast(0f32, 16)
      conv2d_NCHWc_1[92] = broadcast(0f32, 16)
      conv2d_NCHWc_1[201] = broadcast(0f32, 16)
      conv2d_NCHWc_1[310] = broadcast(0f32, 16)
      conv2d_NCHWc_1[93] = broadcast(0f32, 16)
      conv2d_NCHWc_1[202] = broadcast(0f32, 16)
      conv2d_NCHWc_1[311] = broadcast(0f32, 16)
      conv2d_NCHWc_1[94] = broadcast(0f32, 16)
      conv2d_NCHWc_1[203] = broadcast(0f32, 16)
      conv2d_NCHWc_1[312] = broadcast(0f32, 16)
      conv2d_NCHWc_1[95] = broadcast(0f32, 16)
      conv2d_NCHWc_1[204] = broadcast(0f32, 16)
      conv2d_NCHWc_1[313] = broadcast(0f32, 16)
      conv2d_NCHWc_1[96] = broadcast(0f32, 16)
      conv2d_NCHWc_1[205] = broadcast(0f32, 16)
      conv2d_NCHWc_1[314] = broadcast(0f32, 16)
      conv2d_NCHWc_1[97] = broadcast(0f32, 16)
      conv2d_NCHWc_1[206] = broadcast(0f32, 16)
      conv2d_NCHWc_1[315] = broadcast(0f32, 16)
      conv2d_NCHWc_1[98] = broadcast(0f32, 16)
      conv2d_NCHWc_1[207] = broadcast(0f32, 16)
      conv2d_NCHWc_1[316] = broadcast(0f32, 16)
      conv2d_NCHWc_1[99] = broadcast(0f32, 16)
      conv2d_NCHWc_1[208] = broadcast(0f32, 16)
      conv2d_NCHWc_1[317] = broadcast(0f32, 16)
      conv2d_NCHWc_1[100] = broadcast(0f32, 16)
      conv2d_NCHWc_1[209] = broadcast(0f32, 16)
      conv2d_NCHWc_1[318] = broadcast(0f32, 16)
      conv2d_NCHWc_1[101] = broadcast(0f32, 16)
      conv2d_NCHWc_1[210] = broadcast(0f32, 16)
      conv2d_NCHWc_1[319] = broadcast(0f32, 16)
      conv2d_NCHWc_1[102] = broadcast(0f32, 16)
      conv2d_NCHWc_1[211] = broadcast(0f32, 16)
      conv2d_NCHWc_1[320] = broadcast(0f32, 16)
      conv2d_NCHWc_1[103] = broadcast(0f32, 16)
      conv2d_NCHWc_1[212] = broadcast(0f32, 16)
      conv2d_NCHWc_1[321] = broadcast(0f32, 16)
      conv2d_NCHWc_1[104] = broadcast(0f32, 16)
      conv2d_NCHWc_1[213] = broadcast(0f32, 16)
      conv2d_NCHWc_1[322] = broadcast(0f32, 16)
      conv2d_NCHWc_1[105] = broadcast(0f32, 16)
      conv2d_NCHWc_1[214] = broadcast(0f32, 16)
      conv2d_NCHWc_1[323] = broadcast(0f32, 16)
      conv2d_NCHWc_1[106] = broadcast(0f32, 16)
      conv2d_NCHWc_1[215] = broadcast(0f32, 16)
      conv2d_NCHWc_1[324] = broadcast(0f32, 16)
      conv2d_NCHWc_1[107] = broadcast(0f32, 16)
      conv2d_NCHWc_1[216] = broadcast(0f32, 16)
      conv2d_NCHWc_1[325] = broadcast(0f32, 16)
      conv2d_NCHWc_1[108] = broadcast(0f32, 16)
      conv2d_NCHWc_1[217] = broadcast(0f32, 16)
      conv2d_NCHWc_1[326] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 3) {
        for (kh.outer: int32, 0, 7) {
          for (ow.outer.inner: int32, 0, 109) {
            let cse_var_10: int32 = (ow.outer.inner + 218)
            let cse_var_9: int32 = (ow.outer.inner + 109)
            let cse_var_8: int32 = (((floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused, 109)*7056) + (kh.outer*336)) + (ic.outer*16))
            let cse_var_7: int32 = ((((floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused, 109)*1344) + (kh.outer*672)) + (ow.outer.inner*6)) + ic.outer)
            let cse_var_6: int32 = (cse_var_7 + 12)
            let cse_var_5: int32 = (cse_var_7 + 9)
            let cse_var_4: int32 = (cse_var_7 + 6)
            let cse_var_3: int32 = (cse_var_7 + 3)
            let cse_var_2: int32 = (cse_var_7 + 18)
            let cse_var_1: int32 = (cse_var_7 + 15)
             {
              conv2d_NCHWc_1[ow.outer.inner] = (conv2d_NCHWc_1[ow.outer.inner] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
              conv2d_NCHWc_1[cse_var_9] = (conv2d_NCHWc_1[cse_var_9] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp((cse_var_8 + 2352), 1, 16)]))
              conv2d_NCHWc_1[cse_var_10] = (conv2d_NCHWc_1[cse_var_10] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp((cse_var_8 + 4704), 1, 16)]))
              conv2d_NCHWc_1[ow.outer.inner] = (conv2d_NCHWc_1[ow.outer.inner] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp((cse_var_8 + 48), 1, 16)]))
              conv2d_NCHWc_1[cse_var_9] = (conv2d_NCHWc_1[cse_var_9] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp((cse_var_8 + 2400), 1, 16)]))
              conv2d_NCHWc_1[cse_var_10] = (conv2d_NCHWc_1[cse_var_10] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp((cse_var_8 + 4752), 1, 16)]))
              conv2d_NCHWc_1[ow.outer.inner] = (conv2d_NCHWc_1[ow.outer.inner] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp((cse_var_8 + 96), 1, 16)]))
              conv2d_NCHWc_1[cse_var_9] = (conv2d_NCHWc_1[cse_var_9] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp((cse_var_8 + 2448), 1, 16)]))
              conv2d_NCHWc_1[cse_var_10] = (conv2d_NCHWc_1[cse_var_10] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp((cse_var_8 + 4800), 1, 16)]))
              conv2d_NCHWc_1[ow.outer.inner] = (conv2d_NCHWc_1[ow.outer.inner] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp((cse_var_8 + 144), 1, 16)]))
              conv2d_NCHWc_1[cse_var_9] = (conv2d_NCHWc_1[cse_var_9] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp((cse_var_8 + 2496), 1, 16)]))
              conv2d_NCHWc_1[cse_var_10] = (conv2d_NCHWc_1[cse_var_10] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp((cse_var_8 + 4848), 1, 16)]))
              conv2d_NCHWc_1[ow.outer.inner] = (conv2d_NCHWc_1[ow.outer.inner] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp((cse_var_8 + 192), 1, 16)]))
              conv2d_NCHWc_1[cse_var_9] = (conv2d_NCHWc_1[cse_var_9] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp((cse_var_8 + 2544), 1, 16)]))
              conv2d_NCHWc_1[cse_var_10] = (conv2d_NCHWc_1[cse_var_10] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp((cse_var_8 + 4896), 1, 16)]))
              conv2d_NCHWc_1[ow.outer.inner] = (conv2d_NCHWc_1[ow.outer.inner] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp((cse_var_8 + 240), 1, 16)]))
              conv2d_NCHWc_1[cse_var_9] = (conv2d_NCHWc_1[cse_var_9] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp((cse_var_8 + 2592), 1, 16)]))
              conv2d_NCHWc_1[cse_var_10] = (conv2d_NCHWc_1[cse_var_10] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp((cse_var_8 + 4944), 1, 16)]))
              conv2d_NCHWc_1[ow.outer.inner] = (conv2d_NCHWc_1[ow.outer.inner] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp((cse_var_8 + 288), 1, 16)]))
              conv2d_NCHWc_1[cse_var_9] = (conv2d_NCHWc_1[cse_var_9] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp((cse_var_8 + 2640), 1, 16)]))
              conv2d_NCHWc_1[cse_var_10] = (conv2d_NCHWc_1[cse_var_10] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp((cse_var_8 + 4992), 1, 16)]))
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 3) {
        for (ax3.inner: int32, 0, 109) {
          let cse_var_11: int32 = floordiv(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused, 109)
          T_relu[ramp(((((cse_var_11*570288) + (ax1.inner*190096)) + (floormod(ax0.outer.ax1.outer.fused.ax2.outer.fused.ax3.outer.fused, 109)*1744)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*109) + ax3.inner)] + placeholder_2[ramp(((cse_var_11*48) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 4: vm_mod_fused_nn_max_pool2d_1 (weight 1 key: ["9abffad12b503cdcfdda685c0a0b65f2", [1, 256, 25, 25], [1, 256, 12, 12]]) =====
placeholder = PLACEHOLDER [1, 256, 25, 25]
tensor(ax0, ax1, ax2, ax3) max= placeholder[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1)]


Trace for this task is: 
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_root()
tensor_ax0_ax1_fused_ax2_fused_ax3_fused = s[tensor].fuse(tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3)
s[tensor].parallel(tensor_ax0_ax1_fused_ax2_fused_ax3_fused)
s[tensor].pragma(tensor_ax0_ax1_fused_ax2_fused_ax3_fused, "auto_unroll_max_step", 0)
s[tensor].pragma(tensor_ax0_ax1_fused_ax2_fused_ax3_fused, "unroll_explicit", True)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [160000], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [36864], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 256, 25, 25], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 256, 12, 12], [])} {
  for (ax0.ax1.fused.ax2.fused.ax3.fused: int32, 0, 36864) "parallel" {
    tensor[ax0.ax1.fused.ax2.fused.ax3.fused] = -3.40282e+38f32
    for (rv0: int32, 0, 3) {
      for (rv1: int32, 0, 3) {
        tensor[ax0.ax1.fused.ax2.fused.ax3.fused] = max(tensor[ax0.ax1.fused.ax2.fused.ax3.fused], placeholder[(((((floordiv(ax0.ax1.fused.ax2.fused.ax3.fused, 144)*625) + (floordiv(floormod(ax0.ax1.fused.ax2.fused.ax3.fused, 144), 12)*50)) + (rv0*25)) + (floormod(ax0.ax1.fused.ax2.fused.ax3.fused, 12)*2)) + rv1)])
      }
    }
  }
}


==== Task 5: vm_mod_fused_nn_softmax (weight 1 key: ["d7b65649a4dd54becea0a52aabbc5af5", [1, 1000], [1, 1000]]) =====
placeholder = PLACEHOLDER [1, 1000]
T_softmax_maxelem(i0) max= placeholder[i0, k]
T_softmax_exp(i0, i1) = tir.exp((placeholder[i0, i1] - T_softmax_maxelem[i0]))
T_softmax_expsum(i0) += T_softmax_exp[i0, k]
T_softmax_norm(i0, i1) = (T_softmax_exp[i0, i1]/T_softmax_expsum[i0])


Trace for this task is: 
T_softmax_maxelem_i0, T_softmax_maxelem_k = tuple(T_softmax_maxelem.op.axis) + tuple(T_softmax_maxelem.op.reduce_axis)
T_softmax_exp_i0, T_softmax_exp_i1 = tuple(T_softmax_exp.op.axis) + tuple(T_softmax_exp.op.reduce_axis)
T_softmax_expsum_i0, T_softmax_expsum_k = tuple(T_softmax_expsum.op.axis) + tuple(T_softmax_expsum.op.reduce_axis)
T_softmax_norm_i0, T_softmax_norm_i1 = tuple(T_softmax_norm.op.axis) + tuple(T_softmax_norm.op.reduce_axis)
T_softmax_expsum_k_o, T_softmax_expsum_k_i = s[T_softmax_expsum].split(T_softmax_expsum_k, factor=40)
T_softmax_expsum_rf = s.rfactor(T_softmax_expsum, k_i, 1)
T_softmax_expsum_rf_i0, T_softmax_expsum_rf_k_i, T_softmax_expsum_rf_k_o = tuple(T_softmax_expsum_rf.op.axis) + tuple(T_softmax_expsum_rf.op.reduce_axis)
T_softmax_expsum_repl_ax0, T_softmax_expsum_repl_k_i_v = tuple(s[T_softmax_expsum_repl].op.axis) + tuple(s[T_softmax_expsum_repl].op.reduce_axis)
s[T_softmax_expsum_rf].reorder(T_softmax_expsum_rf_i0, T_softmax_expsum_rf_k_o, T_softmax_expsum_rf_k_i)
T_softmax_maxelem_k_o, T_softmax_maxelem_k_i = s[T_softmax_maxelem].split(T_softmax_maxelem_k, factor=20)
T_softmax_maxelem_rf = s.rfactor(T_softmax_maxelem, k_i, 1)
T_softmax_maxelem_rf_i0, T_softmax_maxelem_rf_k_i, T_softmax_maxelem_rf_k_o = tuple(T_softmax_maxelem_rf.op.axis) + tuple(T_softmax_maxelem_rf.op.reduce_axis)
T_softmax_maxelem_repl_ax0, T_softmax_maxelem_repl_k_i_v = tuple(s[T_softmax_maxelem_repl].op.axis) + tuple(s[T_softmax_maxelem_repl].op.reduce_axis)
s[T_softmax_maxelem_rf].reorder(T_softmax_maxelem_rf_i0, T_softmax_maxelem_rf_k_o, T_softmax_maxelem_rf_k_i)
s[T_softmax_expsum_repl].compute_root()
s[T_softmax_exp].compute_root()
s[T_softmax_maxelem_rf].compute_root()
s[T_softmax_maxelem_rf].parallel(T_softmax_maxelem_rf_i0)
s[T_softmax_maxelem_repl].parallel(T_softmax_maxelem_repl_ax0)
T_softmax_exp_i0_i1_fused = s[T_softmax_exp].fuse(T_softmax_exp_i0, T_softmax_exp_i1)
s[T_softmax_exp].parallel(T_softmax_exp_i0_i1_fused)
s[T_softmax_expsum_rf].parallel(T_softmax_expsum_rf_i0)
s[T_softmax_expsum_repl].parallel(T_softmax_expsum_repl_ax0)
T_softmax_norm_i0_i1_fused = s[T_softmax_norm].fuse(T_softmax_norm_i0, T_softmax_norm_i1)
s[T_softmax_norm].parallel(T_softmax_norm_i0_i1_fused)
s[T_softmax_maxelem_rf].pragma(T_softmax_maxelem_rf_i0, "auto_unroll_max_step", 512)
s[T_softmax_maxelem_rf].pragma(T_softmax_maxelem_rf_i0, "unroll_explicit", True)
s[T_softmax_maxelem_repl].pragma(T_softmax_maxelem_repl_ax0, "auto_unroll_max_step", 16)
s[T_softmax_maxelem_repl].pragma(T_softmax_maxelem_repl_ax0, "unroll_explicit", True)
s[T_softmax_expsum_rf].pragma(T_softmax_expsum_rf_i0, "auto_unroll_max_step", 16)
s[T_softmax_expsum_rf].pragma(T_softmax_expsum_rf_i0, "unroll_explicit", True)
s[T_softmax_expsum_repl].pragma(T_softmax_expsum_repl_ax0, "auto_unroll_max_step", 0)
s[T_softmax_expsum_repl].pragma(T_softmax_expsum_repl_ax0, "unroll_explicit", True)
s[T_softmax_maxelem_rf].vectorize(T_softmax_maxelem_rf_k_i)


The best replacement found is:
@main = primfn(placeholder_1: handle, T_softmax_norm_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [1000], []),
             T_softmax_norm: Buffer(T_softmax_norm_2: Pointer(float32), float32, [1000], [])}
  buffer_map = {placeholder_1: placeholder, T_softmax_norm_1: T_softmax_norm}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 1000], []), T_softmax_norm_1: T_softmax_norm_3: Buffer(T_softmax_norm_2, float32, [1, 1000], [])} {
  allocate(T_softmax_maxelem.rf: Pointer(global float32), float32, [40]), storage_scope = global;
  allocate(T_softmax_maxelem: Pointer(global float32), float32, [1]), storage_scope = global;
  allocate(T_softmax_exp: Pointer(global float32), float32, [1000]), storage_scope = global;
  allocate(T_softmax_expsum: Pointer(global float32), float32, [1]), storage_scope = global {
    T_softmax_maxelem.rf_1: Buffer(T_softmax_maxelem.rf, float32, [20], [], align=64)[ramp(0, 1, 20)] = broadcast(-3.40282e+38f32, 20)
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(0, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(20, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(40, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(60, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(80, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(100, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(120, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(140, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(160, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(180, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(200, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(220, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(240, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(260, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(280, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(300, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(320, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(340, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(360, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(380, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(400, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(420, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(440, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(460, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(480, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(500, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(520, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(540, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(560, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(580, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(600, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(620, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(640, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(660, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(680, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(700, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(720, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(740, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(760, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(780, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(800, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(820, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(840, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(860, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(880, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(900, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(920, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(940, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(960, 1, 20)])
    T_softmax_maxelem.rf_1[ramp(0, 1, 20)] = max(T_softmax_maxelem.rf_1[ramp(0, 1, 20)], placeholder[ramp(980, 1, 20)])
    T_softmax_maxelem_1: Buffer(T_softmax_maxelem, float32, [1], [], align=4)[0] = -3.40282e+38f32
    for (k.inner.v: int32, 0, 20) {
      T_softmax_maxelem_1[0] = max(T_softmax_maxelem_1[0], T_softmax_maxelem.rf_1[k.inner.v])
    }
    for (i0.i1.fused: int32, 0, 1000) "parallel" {
      T_softmax_exp_1: Buffer(T_softmax_exp, float32, [1000], [])[i0.i1.fused] = @tir.exp((placeholder[i0.i1.fused] - T_softmax_maxelem_1[0]), dtype=float32)
    }
    for (k.inner.init: int32, 0, 40) {
      T_softmax_maxelem.rf_2: Buffer(T_softmax_maxelem.rf, float32, [40], [])[k.inner.init] = 0f32
    }
    for (k.outer: int32, 0, 25) {
      for (k.inner: int32, 0, 40) {
        T_softmax_maxelem.rf_2[k.inner] = (T_softmax_maxelem.rf_2[k.inner] + T_softmax_exp_1[((k.outer*40) + k.inner)])
      }
    }
    T_softmax_expsum_1: Buffer(T_softmax_expsum, float32, [1], [], align=4)[0] = 0f32
    for (k.inner.v_1: int32, 0, 40) {
      T_softmax_expsum_1[0] = (T_softmax_expsum_1[0] + T_softmax_maxelem.rf_2[k.inner.v_1])
    }
    for (i0.i1.fused_1: int32, 0, 1000) "parallel" {
      T_softmax_norm[i0.i1.fused_1] = (T_softmax_exp_1[i0.i1.fused_1] / T_softmax_expsum_1[0])
    }
  }
}


==== Task 6: vm_mod_fused_nn_max_pool2d_2 (weight 1 key: ["a02f874db93bbd6a17c0cfc6f9372f5a", [1, 32, 12, 12, 16], [1, 32, 6, 6, 16]]) =====
placeholder = PLACEHOLDER [1, 32, 12, 12, 16]
tensor(ax0, ax1, ax2, ax3, ax4) max= placeholder[ax0, ax1, ((ax2*2) + rv0), ((ax3*2) + rv1), ax4]


Trace for this task is: 
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_ax4, tensor_rv0, tensor_rv1 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
s[tensor].compute_root()
tensor_ax0_ax1_fused = s[tensor].fuse(tensor_ax0, tensor_ax1)
s[tensor].parallel(tensor_ax0_ax1_fused)
s[tensor].pragma(tensor_ax0_ax1_fused, "auto_unroll_max_step", 512)
s[tensor].pragma(tensor_ax0_ax1_fused, "unroll_explicit", True)


The best replacement found is:
@main = primfn(placeholder_1: handle, tensor_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [73728], []),
             tensor: Buffer(tensor_2: Pointer(float32), float32, [18432], [])}
  buffer_map = {placeholder_1: placeholder, tensor_1: tensor}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 32, 12, 12, 16], []), tensor_1: tensor_3: Buffer(tensor_2, float32, [1, 32, 6, 6, 16], [])} {
  for (ax0.ax1.fused: int32, 0, 32) "parallel" {
    for (ax2: int32, 0, 6) {
      let cse_var_97: int32 = ((ax0.ax1.fused*576) + (ax2*96))
      let cse_var_96: int32 = ((ax0.ax1.fused*2304) + (ax2*384))
      let cse_var_95: int32 = (cse_var_97 + 16)
      let cse_var_94: int32 = (cse_var_97 + 17)
      let cse_var_93: int32 = (cse_var_97 + 18)
      let cse_var_92: int32 = (cse_var_97 + 19)
      let cse_var_91: int32 = (cse_var_97 + 2)
      let cse_var_90: int32 = (cse_var_97 + 20)
      let cse_var_89: int32 = (cse_var_97 + 21)
      let cse_var_88: int32 = (cse_var_97 + 22)
      let cse_var_87: int32 = (cse_var_97 + 23)
      let cse_var_86: int32 = (cse_var_97 + 24)
      let cse_var_85: int32 = (cse_var_97 + 25)
      let cse_var_84: int32 = (cse_var_97 + 26)
      let cse_var_83: int32 = (cse_var_97 + 27)
      let cse_var_82: int32 = (cse_var_97 + 29)
      let cse_var_81: int32 = (cse_var_97 + 3)
      let cse_var_80: int32 = (cse_var_97 + 30)
      let cse_var_79: int32 = (cse_var_97 + 31)
      let cse_var_78: int32 = (cse_var_97 + 32)
      let cse_var_77: int32 = (cse_var_97 + 33)
      let cse_var_76: int32 = (cse_var_97 + 34)
      let cse_var_75: int32 = (cse_var_97 + 35)
      let cse_var_74: int32 = (cse_var_97 + 36)
      let cse_var_73: int32 = (cse_var_97 + 37)
      let cse_var_72: int32 = (cse_var_97 + 38)
      let cse_var_71: int32 = (cse_var_97 + 39)
      let cse_var_70: int32 = (cse_var_97 + 4)
      let cse_var_69: int32 = (cse_var_97 + 40)
      let cse_var_68: int32 = (cse_var_97 + 28)
      let cse_var_67: int32 = (cse_var_97 + 15)
      let cse_var_66: int32 = (cse_var_97 + 1)
      let cse_var_65: int32 = (cse_var_97 + 10)
      let cse_var_64: int32 = (cse_var_97 + 11)
      let cse_var_63: int32 = (cse_var_97 + 12)
      let cse_var_62: int32 = (cse_var_97 + 13)
      let cse_var_61: int32 = (cse_var_97 + 14)
      let cse_var_60: int32 = (cse_var_97 + 7)
      let cse_var_59: int32 = (cse_var_97 + 70)
      let cse_var_58: int32 = (cse_var_97 + 71)
      let cse_var_57: int32 = (cse_var_97 + 72)
      let cse_var_56: int32 = (cse_var_97 + 73)
      let cse_var_55: int32 = (cse_var_97 + 74)
      let cse_var_54: int32 = (cse_var_97 + 75)
      let cse_var_53: int32 = (cse_var_97 + 76)
      let cse_var_52: int32 = (cse_var_97 + 77)
      let cse_var_51: int32 = (cse_var_97 + 78)
      let cse_var_50: int32 = (cse_var_97 + 79)
      let cse_var_49: int32 = (cse_var_97 + 8)
      let cse_var_48: int32 = (cse_var_97 + 80)
      let cse_var_47: int32 = (cse_var_97 + 81)
      let cse_var_46: int32 = (cse_var_97 + 41)
      let cse_var_45: int32 = (cse_var_97 + 83)
      let cse_var_44: int32 = (cse_var_97 + 84)
      let cse_var_43: int32 = (cse_var_97 + 85)
      let cse_var_42: int32 = (cse_var_97 + 86)
      let cse_var_41: int32 = (cse_var_97 + 87)
      let cse_var_40: int32 = (cse_var_97 + 88)
      let cse_var_39: int32 = (cse_var_97 + 89)
      let cse_var_38: int32 = (cse_var_97 + 9)
      let cse_var_37: int32 = (cse_var_97 + 90)
      let cse_var_36: int32 = (cse_var_97 + 91)
      let cse_var_35: int32 = (cse_var_97 + 92)
      let cse_var_34: int32 = (cse_var_97 + 93)
      let cse_var_33: int32 = (cse_var_97 + 94)
      let cse_var_32: int32 = (cse_var_97 + 95)
      let cse_var_31: int32 = (cse_var_97 + 82)
      let cse_var_30: int32 = (cse_var_97 + 42)
      let cse_var_29: int32 = (cse_var_97 + 43)
      let cse_var_28: int32 = (cse_var_97 + 44)
      let cse_var_27: int32 = (cse_var_97 + 45)
      let cse_var_26: int32 = (cse_var_97 + 46)
      let cse_var_25: int32 = (cse_var_97 + 47)
      let cse_var_24: int32 = (cse_var_97 + 48)
      let cse_var_23: int32 = (cse_var_97 + 49)
      let cse_var_22: int32 = (cse_var_97 + 5)
      let cse_var_21: int32 = (cse_var_97 + 50)
      let cse_var_20: int32 = (cse_var_97 + 51)
      let cse_var_19: int32 = (cse_var_97 + 52)
      let cse_var_18: int32 = (cse_var_97 + 53)
      let cse_var_17: int32 = (cse_var_97 + 54)
      let cse_var_16: int32 = (cse_var_97 + 69)
      let cse_var_15: int32 = (cse_var_97 + 56)
      let cse_var_14: int32 = (cse_var_97 + 57)
      let cse_var_13: int32 = (cse_var_97 + 58)
      let cse_var_12: int32 = (cse_var_97 + 59)
      let cse_var_11: int32 = (cse_var_97 + 6)
      let cse_var_10: int32 = (cse_var_97 + 60)
      let cse_var_9: int32 = (cse_var_97 + 61)
      let cse_var_8: int32 = (cse_var_97 + 62)
      let cse_var_7: int32 = (cse_var_97 + 63)
      let cse_var_6: int32 = (cse_var_97 + 64)
      let cse_var_5: int32 = (cse_var_97 + 65)
      let cse_var_4: int32 = (cse_var_97 + 66)
      let cse_var_3: int32 = (cse_var_97 + 67)
      let cse_var_2: int32 = (cse_var_97 + 68)
      let cse_var_1: int32 = (cse_var_97 + 55)
       {
        tensor[cse_var_97] = -3.40282e+38f32
        tensor[cse_var_97] = max(tensor[cse_var_97], placeholder[cse_var_96])
        tensor[cse_var_97] = max(tensor[cse_var_97], placeholder[(cse_var_96 + 16)])
        tensor[cse_var_97] = max(tensor[cse_var_97], placeholder[(cse_var_96 + 192)])
        tensor[cse_var_97] = max(tensor[cse_var_97], placeholder[(cse_var_96 + 208)])
        tensor[cse_var_66] = -3.40282e+38f32
        tensor[cse_var_66] = max(tensor[cse_var_66], placeholder[(cse_var_96 + 1)])
        tensor[cse_var_66] = max(tensor[cse_var_66], placeholder[(cse_var_96 + 17)])
        tensor[cse_var_66] = max(tensor[cse_var_66], placeholder[(cse_var_96 + 193)])
        tensor[cse_var_66] = max(tensor[cse_var_66], placeholder[(cse_var_96 + 209)])
        tensor[cse_var_91] = -3.40282e+38f32
        tensor[cse_var_91] = max(tensor[cse_var_91], placeholder[(cse_var_96 + 2)])
        tensor[cse_var_91] = max(tensor[cse_var_91], placeholder[(cse_var_96 + 18)])
        tensor[cse_var_91] = max(tensor[cse_var_91], placeholder[(cse_var_96 + 194)])
        tensor[cse_var_91] = max(tensor[cse_var_91], placeholder[(cse_var_96 + 210)])
        tensor[cse_var_81] = -3.40282e+38f32
        tensor[cse_var_81] = max(tensor[cse_var_81], placeholder[(cse_var_96 + 3)])
        tensor[cse_var_81] = max(tensor[cse_var_81], placeholder[(cse_var_96 + 19)])
        tensor[cse_var_81] = max(tensor[cse_var_81], placeholder[(cse_var_96 + 195)])
        tensor[cse_var_81] = max(tensor[cse_var_81], placeholder[(cse_var_96 + 211)])
        tensor[cse_var_70] = -3.40282e+38f32
        tensor[cse_var_70] = max(tensor[cse_var_70], placeholder[(cse_var_96 + 4)])
        tensor[cse_var_70] = max(tensor[cse_var_70], placeholder[(cse_var_96 + 20)])
        tensor[cse_var_70] = max(tensor[cse_var_70], placeholder[(cse_var_96 + 196)])
        tensor[cse_var_70] = max(tensor[cse_var_70], placeholder[(cse_var_96 + 212)])
        tensor[cse_var_22] = -3.40282e+38f32
        tensor[cse_var_22] = max(tensor[cse_var_22], placeholder[(cse_var_96 + 5)])
        tensor[cse_var_22] = max(tensor[cse_var_22], placeholder[(cse_var_96 + 21)])
        tensor[cse_var_22] = max(tensor[cse_var_22], placeholder[(cse_var_96 + 197)])
        tensor[cse_var_22] = max(tensor[cse_var_22], placeholder[(cse_var_96 + 213)])
        tensor[cse_var_11] = -3.40282e+38f32
        tensor[cse_var_11] = max(tensor[cse_var_11], placeholder[(cse_var_96 + 6)])
        tensor[cse_var_11] = max(tensor[cse_var_11], placeholder[(cse_var_96 + 22)])
        tensor[cse_var_11] = max(tensor[cse_var_11], placeholder[(cse_var_96 + 198)])
        tensor[cse_var_11] = max(tensor[cse_var_11], placeholder[(cse_var_96 + 214)])
        tensor[cse_var_60] = -3.40282e+38f32
        tensor[cse_var_60] = max(tensor[cse_var_60], placeholder[(cse_var_96 + 7)])
        tensor[cse_var_60] = max(tensor[cse_var_60], placeholder[(cse_var_96 + 23)])
        tensor[cse_var_60] = max(tensor[cse_var_60], placeholder[(cse_var_96 + 199)])
        tensor[cse_var_60] = max(tensor[cse_var_60], placeholder[(cse_var_96 + 215)])
        tensor[cse_var_49] = -3.40282e+38f32
        tensor[cse_var_49] = max(tensor[cse_var_49], placeholder[(cse_var_96 + 8)])
        tensor[cse_var_49] = max(tensor[cse_var_49], placeholder[(cse_var_96 + 24)])
        tensor[cse_var_49] = max(tensor[cse_var_49], placeholder[(cse_var_96 + 200)])
        tensor[cse_var_49] = max(tensor[cse_var_49], placeholder[(cse_var_96 + 216)])
        tensor[cse_var_38] = -3.40282e+38f32
        tensor[cse_var_38] = max(tensor[cse_var_38], placeholder[(cse_var_96 + 9)])
        tensor[cse_var_38] = max(tensor[cse_var_38], placeholder[(cse_var_96 + 25)])
        tensor[cse_var_38] = max(tensor[cse_var_38], placeholder[(cse_var_96 + 201)])
        tensor[cse_var_38] = max(tensor[cse_var_38], placeholder[(cse_var_96 + 217)])
        tensor[cse_var_65] = -3.40282e+38f32
        tensor[cse_var_65] = max(tensor[cse_var_65], placeholder[(cse_var_96 + 10)])
        tensor[cse_var_65] = max(tensor[cse_var_65], placeholder[(cse_var_96 + 26)])
        tensor[cse_var_65] = max(tensor[cse_var_65], placeholder[(cse_var_96 + 202)])
        tensor[cse_var_65] = max(tensor[cse_var_65], placeholder[(cse_var_96 + 218)])
        tensor[cse_var_64] = -3.40282e+38f32
        tensor[cse_var_64] = max(tensor[cse_var_64], placeholder[(cse_var_96 + 11)])
        tensor[cse_var_64] = max(tensor[cse_var_64], placeholder[(cse_var_96 + 27)])
        tensor[cse_var_64] = max(tensor[cse_var_64], placeholder[(cse_var_96 + 203)])
        tensor[cse_var_64] = max(tensor[cse_var_64], placeholder[(cse_var_96 + 219)])
        tensor[cse_var_63] = -3.40282e+38f32
        tensor[cse_var_63] = max(tensor[cse_var_63], placeholder[(cse_var_96 + 12)])
        tensor[cse_var_63] = max(tensor[cse_var_63], placeholder[(cse_var_96 + 28)])
        tensor[cse_var_63] = max(tensor[cse_var_63], placeholder[(cse_var_96 + 204)])
        tensor[cse_var_63] = max(tensor[cse_var_63], placeholder[(cse_var_96 + 220)])
        tensor[cse_var_62] = -3.40282e+38f32
        tensor[cse_var_62] = max(tensor[cse_var_62], placeholder[(cse_var_96 + 13)])
        tensor[cse_var_62] = max(tensor[cse_var_62], placeholder[(cse_var_96 + 29)])
        tensor[cse_var_62] = max(tensor[cse_var_62], placeholder[(cse_var_96 + 205)])
        tensor[cse_var_62] = max(tensor[cse_var_62], placeholder[(cse_var_96 + 221)])
        tensor[cse_var_61] = -3.40282e+38f32
        tensor[cse_var_61] = max(tensor[cse_var_61], placeholder[(cse_var_96 + 14)])
        tensor[cse_var_61] = max(tensor[cse_var_61], placeholder[(cse_var_96 + 30)])
        tensor[cse_var_61] = max(tensor[cse_var_61], placeholder[(cse_var_96 + 206)])
        tensor[cse_var_61] = max(tensor[cse_var_61], placeholder[(cse_var_96 + 222)])
        tensor[cse_var_67] = -3.40282e+38f32
        tensor[cse_var_67] = max(tensor[cse_var_67], placeholder[(cse_var_96 + 15)])
        tensor[cse_var_67] = max(tensor[cse_var_67], placeholder[(cse_var_96 + 31)])
        tensor[cse_var_67] = max(tensor[cse_var_67], placeholder[(cse_var_96 + 207)])
        tensor[cse_var_67] = max(tensor[cse_var_67], placeholder[(cse_var_96 + 223)])
        tensor[cse_var_95] = -3.40282e+38f32
        tensor[cse_var_95] = max(tensor[cse_var_95], placeholder[(cse_var_96 + 32)])
        tensor[cse_var_95] = max(tensor[cse_var_95], placeholder[(cse_var_96 + 48)])
        tensor[cse_var_95] = max(tensor[cse_var_95], placeholder[(cse_var_96 + 224)])
        tensor[cse_var_95] = max(tensor[cse_var_95], placeholder[(cse_var_96 + 240)])
        tensor[cse_var_94] = -3.40282e+38f32
        tensor[cse_var_94] = max(tensor[cse_var_94], placeholder[(cse_var_96 + 33)])
        tensor[cse_var_94] = max(tensor[cse_var_94], placeholder[(cse_var_96 + 49)])
        tensor[cse_var_94] = max(tensor[cse_var_94], placeholder[(cse_var_96 + 225)])
        tensor[cse_var_94] = max(tensor[cse_var_94], placeholder[(cse_var_96 + 241)])
        tensor[cse_var_93] = -3.40282e+38f32
        tensor[cse_var_93] = max(tensor[cse_var_93], placeholder[(cse_var_96 + 34)])
        tensor[cse_var_93] = max(tensor[cse_var_93], placeholder[(cse_var_96 + 50)])
        tensor[cse_var_93] = max(tensor[cse_var_93], placeholder[(cse_var_96 + 226)])
        tensor[cse_var_93] = max(tensor[cse_var_93], placeholder[(cse_var_96 + 242)])
        tensor[cse_var_92] = -3.40282e+38f32
        tensor[cse_var_92] = max(tensor[cse_var_92], placeholder[(cse_var_96 + 35)])
        tensor[cse_var_92] = max(tensor[cse_var_92], placeholder[(cse_var_96 + 51)])
        tensor[cse_var_92] = max(tensor[cse_var_92], placeholder[(cse_var_96 + 227)])
        tensor[cse_var_92] = max(tensor[cse_var_92], placeholder[(cse_var_96 + 243)])
        tensor[cse_var_90] = -3.40282e+38f32
        tensor[cse_var_90] = max(tensor[cse_var_90], placeholder[(cse_var_96 + 36)])
        tensor[cse_var_90] = max(tensor[cse_var_90], placeholder[(cse_var_96 + 52)])
        tensor[cse_var_90] = max(tensor[cse_var_90], placeholder[(cse_var_96 + 228)])
        tensor[cse_var_90] = max(tensor[cse_var_90], placeholder[(cse_var_96 + 244)])
        tensor[cse_var_89] = -3.40282e+38f32
        tensor[cse_var_89] = max(tensor[cse_var_89], placeholder[(cse_var_96 + 37)])
        tensor[cse_var_89] = max(tensor[cse_var_89], placeholder[(cse_var_96 + 53)])
        tensor[cse_var_89] = max(tensor[cse_var_89], placeholder[(cse_var_96 + 229)])
        tensor[cse_var_89] = max(tensor[cse_var_89], placeholder[(cse_var_96 + 245)])
        tensor[cse_var_88] = -3.40282e+38f32
        tensor[cse_var_88] = max(tensor[cse_var_88], placeholder[(cse_var_96 + 38)])
        tensor[cse_var_88] = max(tensor[cse_var_88], placeholder[(cse_var_96 + 54)])
        tensor[cse_var_88] = max(tensor[cse_var_88], placeholder[(cse_var_96 + 230)])
        tensor[cse_var_88] = max(tensor[cse_var_88], placeholder[(cse_var_96 + 246)])
        tensor[cse_var_87] = -3.40282e+38f32
        tensor[cse_var_87] = max(tensor[cse_var_87], placeholder[(cse_var_96 + 39)])
        tensor[cse_var_87] = max(tensor[cse_var_87], placeholder[(cse_var_96 + 55)])
        tensor[cse_var_87] = max(tensor[cse_var_87], placeholder[(cse_var_96 + 231)])
        tensor[cse_var_87] = max(tensor[cse_var_87], placeholder[(cse_var_96 + 247)])
        tensor[cse_var_86] = -3.40282e+38f32
        tensor[cse_var_86] = max(tensor[cse_var_86], placeholder[(cse_var_96 + 40)])
        tensor[cse_var_86] = max(tensor[cse_var_86], placeholder[(cse_var_96 + 56)])
        tensor[cse_var_86] = max(tensor[cse_var_86], placeholder[(cse_var_96 + 232)])
        tensor[cse_var_86] = max(tensor[cse_var_86], placeholder[(cse_var_96 + 248)])
        tensor[cse_var_85] = -3.40282e+38f32
        tensor[cse_var_85] = max(tensor[cse_var_85], placeholder[(cse_var_96 + 41)])
        tensor[cse_var_85] = max(tensor[cse_var_85], placeholder[(cse_var_96 + 57)])
        tensor[cse_var_85] = max(tensor[cse_var_85], placeholder[(cse_var_96 + 233)])
        tensor[cse_var_85] = max(tensor[cse_var_85], placeholder[(cse_var_96 + 249)])
        tensor[cse_var_84] = -3.40282e+38f32
        tensor[cse_var_84] = max(tensor[cse_var_84], placeholder[(cse_var_96 + 42)])
        tensor[cse_var_84] = max(tensor[cse_var_84], placeholder[(cse_var_96 + 58)])
        tensor[cse_var_84] = max(tensor[cse_var_84], placeholder[(cse_var_96 + 234)])
        tensor[cse_var_84] = max(tensor[cse_var_84], placeholder[(cse_var_96 + 250)])
        tensor[cse_var_83] = -3.40282e+38f32
        tensor[cse_var_83] = max(tensor[cse_var_83], placeholder[(cse_var_96 + 43)])
        tensor[cse_var_83] = max(tensor[cse_var_83], placeholder[(cse_var_96 + 59)])
        tensor[cse_var_83] = max(tensor[cse_var_83], placeholder[(cse_var_96 + 235)])
        tensor[cse_var_83] = max(tensor[cse_var_83], placeholder[(cse_var_96 + 251)])
        tensor[cse_var_68] = -3.40282e+38f32
        tensor[cse_var_68] = max(tensor[cse_var_68], placeholder[(cse_var_96 + 44)])
        tensor[cse_var_68] = max(tensor[cse_var_68], placeholder[(cse_var_96 + 60)])
        tensor[cse_var_68] = max(tensor[cse_var_68], placeholder[(cse_var_96 + 236)])
        tensor[cse_var_68] = max(tensor[cse_var_68], placeholder[(cse_var_96 + 252)])
        tensor[cse_var_82] = -3.40282e+38f32
        tensor[cse_var_82] = max(tensor[cse_var_82], placeholder[(cse_var_96 + 45)])
        tensor[cse_var_82] = max(tensor[cse_var_82], placeholder[(cse_var_96 + 61)])
        tensor[cse_var_82] = max(tensor[cse_var_82], placeholder[(cse_var_96 + 237)])
        tensor[cse_var_82] = max(tensor[cse_var_82], placeholder[(cse_var_96 + 253)])
        tensor[cse_var_80] = -3.40282e+38f32
        tensor[cse_var_80] = max(tensor[cse_var_80], placeholder[(cse_var_96 + 46)])
        tensor[cse_var_80] = max(tensor[cse_var_80], placeholder[(cse_var_96 + 62)])
        tensor[cse_var_80] = max(tensor[cse_var_80], placeholder[(cse_var_96 + 238)])
        tensor[cse_var_80] = max(tensor[cse_var_80], placeholder[(cse_var_96 + 254)])
        tensor[cse_var_79] = -3.40282e+38f32
        tensor[cse_var_79] = max(tensor[cse_var_79], placeholder[(cse_var_96 + 47)])
        tensor[cse_var_79] = max(tensor[cse_var_79], placeholder[(cse_var_96 + 63)])
        tensor[cse_var_79] = max(tensor[cse_var_79], placeholder[(cse_var_96 + 239)])
        tensor[cse_var_79] = max(tensor[cse_var_79], placeholder[(cse_var_96 + 255)])
        tensor[cse_var_78] = -3.40282e+38f32
        tensor[cse_var_78] = max(tensor[cse_var_78], placeholder[(cse_var_96 + 64)])
        tensor[cse_var_78] = max(tensor[cse_var_78], placeholder[(cse_var_96 + 80)])
        tensor[cse_var_78] = max(tensor[cse_var_78], placeholder[(cse_var_96 + 256)])
        tensor[cse_var_78] = max(tensor[cse_var_78], placeholder[(cse_var_96 + 272)])
        tensor[cse_var_77] = -3.40282e+38f32
        tensor[cse_var_77] = max(tensor[cse_var_77], placeholder[(cse_var_96 + 65)])
        tensor[cse_var_77] = max(tensor[cse_var_77], placeholder[(cse_var_96 + 81)])
        tensor[cse_var_77] = max(tensor[cse_var_77], placeholder[(cse_var_96 + 257)])
        tensor[cse_var_77] = max(tensor[cse_var_77], placeholder[(cse_var_96 + 273)])
        tensor[cse_var_76] = -3.40282e+38f32
        tensor[cse_var_76] = max(tensor[cse_var_76], placeholder[(cse_var_96 + 66)])
        tensor[cse_var_76] = max(tensor[cse_var_76], placeholder[(cse_var_96 + 82)])
        tensor[cse_var_76] = max(tensor[cse_var_76], placeholder[(cse_var_96 + 258)])
        tensor[cse_var_76] = max(tensor[cse_var_76], placeholder[(cse_var_96 + 274)])
        tensor[cse_var_75] = -3.40282e+38f32
        tensor[cse_var_75] = max(tensor[cse_var_75], placeholder[(cse_var_96 + 67)])
        tensor[cse_var_75] = max(tensor[cse_var_75], placeholder[(cse_var_96 + 83)])
        tensor[cse_var_75] = max(tensor[cse_var_75], placeholder[(cse_var_96 + 259)])
        tensor[cse_var_75] = max(tensor[cse_var_75], placeholder[(cse_var_96 + 275)])
        tensor[cse_var_74] = -3.40282e+38f32
        tensor[cse_var_74] = max(tensor[cse_var_74], placeholder[(cse_var_96 + 68)])
        tensor[cse_var_74] = max(tensor[cse_var_74], placeholder[(cse_var_96 + 84)])
        tensor[cse_var_74] = max(tensor[cse_var_74], placeholder[(cse_var_96 + 260)])
        tensor[cse_var_74] = max(tensor[cse_var_74], placeholder[(cse_var_96 + 276)])
        tensor[cse_var_73] = -3.40282e+38f32
        tensor[cse_var_73] = max(tensor[cse_var_73], placeholder[(cse_var_96 + 69)])
        tensor[cse_var_73] = max(tensor[cse_var_73], placeholder[(cse_var_96 + 85)])
        tensor[cse_var_73] = max(tensor[cse_var_73], placeholder[(cse_var_96 + 261)])
        tensor[cse_var_73] = max(tensor[cse_var_73], placeholder[(cse_var_96 + 277)])
        tensor[cse_var_72] = -3.40282e+38f32
        tensor[cse_var_72] = max(tensor[cse_var_72], placeholder[(cse_var_96 + 70)])
        tensor[cse_var_72] = max(tensor[cse_var_72], placeholder[(cse_var_96 + 86)])
        tensor[cse_var_72] = max(tensor[cse_var_72], placeholder[(cse_var_96 + 262)])
        tensor[cse_var_72] = max(tensor[cse_var_72], placeholder[(cse_var_96 + 278)])
        tensor[cse_var_71] = -3.40282e+38f32
        tensor[cse_var_71] = max(tensor[cse_var_71], placeholder[(cse_var_96 + 71)])
        tensor[cse_var_71] = max(tensor[cse_var_71], placeholder[(cse_var_96 + 87)])
        tensor[cse_var_71] = max(tensor[cse_var_71], placeholder[(cse_var_96 + 263)])
        tensor[cse_var_71] = max(tensor[cse_var_71], placeholder[(cse_var_96 + 279)])
        tensor[cse_var_69] = -3.40282e+38f32
        tensor[cse_var_69] = max(tensor[cse_var_69], placeholder[(cse_var_96 + 72)])
        tensor[cse_var_69] = max(tensor[cse_var_69], placeholder[(cse_var_96 + 88)])
        tensor[cse_var_69] = max(tensor[cse_var_69], placeholder[(cse_var_96 + 264)])
        tensor[cse_var_69] = max(tensor[cse_var_69], placeholder[(cse_var_96 + 280)])
        tensor[cse_var_46] = -3.40282e+38f32
        tensor[cse_var_46] = max(tensor[cse_var_46], placeholder[(cse_var_96 + 73)])
        tensor[cse_var_46] = max(tensor[cse_var_46], placeholder[(cse_var_96 + 89)])
        tensor[cse_var_46] = max(tensor[cse_var_46], placeholder[(cse_var_96 + 265)])
        tensor[cse_var_46] = max(tensor[cse_var_46], placeholder[(cse_var_96 + 281)])
        tensor[cse_var_30] = -3.40282e+38f32
        tensor[cse_var_30] = max(tensor[cse_var_30], placeholder[(cse_var_96 + 74)])
        tensor[cse_var_30] = max(tensor[cse_var_30], placeholder[(cse_var_96 + 90)])
        tensor[cse_var_30] = max(tensor[cse_var_30], placeholder[(cse_var_96 + 266)])
        tensor[cse_var_30] = max(tensor[cse_var_30], placeholder[(cse_var_96 + 282)])
        tensor[cse_var_29] = -3.40282e+38f32
        tensor[cse_var_29] = max(tensor[cse_var_29], placeholder[(cse_var_96 + 75)])
        tensor[cse_var_29] = max(tensor[cse_var_29], placeholder[(cse_var_96 + 91)])
        tensor[cse_var_29] = max(tensor[cse_var_29], placeholder[(cse_var_96 + 267)])
        tensor[cse_var_29] = max(tensor[cse_var_29], placeholder[(cse_var_96 + 283)])
        tensor[cse_var_28] = -3.40282e+38f32
        tensor[cse_var_28] = max(tensor[cse_var_28], placeholder[(cse_var_96 + 76)])
        tensor[cse_var_28] = max(tensor[cse_var_28], placeholder[(cse_var_96 + 92)])
        tensor[cse_var_28] = max(tensor[cse_var_28], placeholder[(cse_var_96 + 268)])
        tensor[cse_var_28] = max(tensor[cse_var_28], placeholder[(cse_var_96 + 284)])
        tensor[cse_var_27] = -3.40282e+38f32
        tensor[cse_var_27] = max(tensor[cse_var_27], placeholder[(cse_var_96 + 77)])
        tensor[cse_var_27] = max(tensor[cse_var_27], placeholder[(cse_var_96 + 93)])
        tensor[cse_var_27] = max(tensor[cse_var_27], placeholder[(cse_var_96 + 269)])
        tensor[cse_var_27] = max(tensor[cse_var_27], placeholder[(cse_var_96 + 285)])
        tensor[cse_var_26] = -3.40282e+38f32
        tensor[cse_var_26] = max(tensor[cse_var_26], placeholder[(cse_var_96 + 78)])
        tensor[cse_var_26] = max(tensor[cse_var_26], placeholder[(cse_var_96 + 94)])
        tensor[cse_var_26] = max(tensor[cse_var_26], placeholder[(cse_var_96 + 270)])
        tensor[cse_var_26] = max(tensor[cse_var_26], placeholder[(cse_var_96 + 286)])
        tensor[cse_var_25] = -3.40282e+38f32
        tensor[cse_var_25] = max(tensor[cse_var_25], placeholder[(cse_var_96 + 79)])
        tensor[cse_var_25] = max(tensor[cse_var_25], placeholder[(cse_var_96 + 95)])
        tensor[cse_var_25] = max(tensor[cse_var_25], placeholder[(cse_var_96 + 271)])
        tensor[cse_var_25] = max(tensor[cse_var_25], placeholder[(cse_var_96 + 287)])
        tensor[cse_var_24] = -3.40282e+38f32
        tensor[cse_var_24] = max(tensor[cse_var_24], placeholder[(cse_var_96 + 96)])
        tensor[cse_var_24] = max(tensor[cse_var_24], placeholder[(cse_var_96 + 112)])
        tensor[cse_var_24] = max(tensor[cse_var_24], placeholder[(cse_var_96 + 288)])
        tensor[cse_var_24] = max(tensor[cse_var_24], placeholder[(cse_var_96 + 304)])
        tensor[cse_var_23] = -3.40282e+38f32
        tensor[cse_var_23] = max(tensor[cse_var_23], placeholder[(cse_var_96 + 97)])
        tensor[cse_var_23] = max(tensor[cse_var_23], placeholder[(cse_var_96 + 113)])
        tensor[cse_var_23] = max(tensor[cse_var_23], placeholder[(cse_var_96 + 289)])
        tensor[cse_var_23] = max(tensor[cse_var_23], placeholder[(cse_var_96 + 305)])
        tensor[cse_var_21] = -3.40282e+38f32
        tensor[cse_var_21] = max(tensor[cse_var_21], placeholder[(cse_var_96 + 98)])
        tensor[cse_var_21] = max(tensor[cse_var_21], placeholder[(cse_var_96 + 114)])
        tensor[cse_var_21] = max(tensor[cse_var_21], placeholder[(cse_var_96 + 290)])
        tensor[cse_var_21] = max(tensor[cse_var_21], placeholder[(cse_var_96 + 306)])
        tensor[cse_var_20] = -3.40282e+38f32
        tensor[cse_var_20] = max(tensor[cse_var_20], placeholder[(cse_var_96 + 99)])
        tensor[cse_var_20] = max(tensor[cse_var_20], placeholder[(cse_var_96 + 115)])
        tensor[cse_var_20] = max(tensor[cse_var_20], placeholder[(cse_var_96 + 291)])
        tensor[cse_var_20] = max(tensor[cse_var_20], placeholder[(cse_var_96 + 307)])
        tensor[cse_var_19] = -3.40282e+38f32
        tensor[cse_var_19] = max(tensor[cse_var_19], placeholder[(cse_var_96 + 100)])
        tensor[cse_var_19] = max(tensor[cse_var_19], placeholder[(cse_var_96 + 116)])
        tensor[cse_var_19] = max(tensor[cse_var_19], placeholder[(cse_var_96 + 292)])
        tensor[cse_var_19] = max(tensor[cse_var_19], placeholder[(cse_var_96 + 308)])
        tensor[cse_var_18] = -3.40282e+38f32
        tensor[cse_var_18] = max(tensor[cse_var_18], placeholder[(cse_var_96 + 101)])
        tensor[cse_var_18] = max(tensor[cse_var_18], placeholder[(cse_var_96 + 117)])
        tensor[cse_var_18] = max(tensor[cse_var_18], placeholder[(cse_var_96 + 293)])
        tensor[cse_var_18] = max(tensor[cse_var_18], placeholder[(cse_var_96 + 309)])
        tensor[cse_var_17] = -3.40282e+38f32
        tensor[cse_var_17] = max(tensor[cse_var_17], placeholder[(cse_var_96 + 102)])
        tensor[cse_var_17] = max(tensor[cse_var_17], placeholder[(cse_var_96 + 118)])
        tensor[cse_var_17] = max(tensor[cse_var_17], placeholder[(cse_var_96 + 294)])
        tensor[cse_var_17] = max(tensor[cse_var_17], placeholder[(cse_var_96 + 310)])
        tensor[cse_var_1] = -3.40282e+38f32
        tensor[cse_var_1] = max(tensor[cse_var_1], placeholder[(cse_var_96 + 103)])
        tensor[cse_var_1] = max(tensor[cse_var_1], placeholder[(cse_var_96 + 119)])
        tensor[cse_var_1] = max(tensor[cse_var_1], placeholder[(cse_var_96 + 295)])
        tensor[cse_var_1] = max(tensor[cse_var_1], placeholder[(cse_var_96 + 311)])
        tensor[cse_var_15] = -3.40282e+38f32
        tensor[cse_var_15] = max(tensor[cse_var_15], placeholder[(cse_var_96 + 104)])
        tensor[cse_var_15] = max(tensor[cse_var_15], placeholder[(cse_var_96 + 120)])
        tensor[cse_var_15] = max(tensor[cse_var_15], placeholder[(cse_var_96 + 296)])
        tensor[cse_var_15] = max(tensor[cse_var_15], placeholder[(cse_var_96 + 312)])
        tensor[cse_var_14] = -3.40282e+38f32
        tensor[cse_var_14] = max(tensor[cse_var_14], placeholder[(cse_var_96 + 105)])
        tensor[cse_var_14] = max(tensor[cse_var_14], placeholder[(cse_var_96 + 121)])
        tensor[cse_var_14] = max(tensor[cse_var_14], placeholder[(cse_var_96 + 297)])
        tensor[cse_var_14] = max(tensor[cse_var_14], placeholder[(cse_var_96 + 313)])
        tensor[cse_var_13] = -3.40282e+38f32
        tensor[cse_var_13] = max(tensor[cse_var_13], placeholder[(cse_var_96 + 106)])
        tensor[cse_var_13] = max(tensor[cse_var_13], placeholder[(cse_var_96 + 122)])
        tensor[cse_var_13] = max(tensor[cse_var_13], placeholder[(cse_var_96 + 298)])
        tensor[cse_var_13] = max(tensor[cse_var_13], placeholder[(cse_var_96 + 314)])
        tensor[cse_var_12] = -3.40282e+38f32
        tensor[cse_var_12] = max(tensor[cse_var_12], placeholder[(cse_var_96 + 107)])
        tensor[cse_var_12] = max(tensor[cse_var_12], placeholder[(cse_var_96 + 123)])
        tensor[cse_var_12] = max(tensor[cse_var_12], placeholder[(cse_var_96 + 299)])
        tensor[cse_var_12] = max(tensor[cse_var_12], placeholder[(cse_var_96 + 315)])
        tensor[cse_var_10] = -3.40282e+38f32
        tensor[cse_var_10] = max(tensor[cse_var_10], placeholder[(cse_var_96 + 108)])
        tensor[cse_var_10] = max(tensor[cse_var_10], placeholder[(cse_var_96 + 124)])
        tensor[cse_var_10] = max(tensor[cse_var_10], placeholder[(cse_var_96 + 300)])
        tensor[cse_var_10] = max(tensor[cse_var_10], placeholder[(cse_var_96 + 316)])
        tensor[cse_var_9] = -3.40282e+38f32
        tensor[cse_var_9] = max(tensor[cse_var_9], placeholder[(cse_var_96 + 109)])
        tensor[cse_var_9] = max(tensor[cse_var_9], placeholder[(cse_var_96 + 125)])
        tensor[cse_var_9] = max(tensor[cse_var_9], placeholder[(cse_var_96 + 301)])
        tensor[cse_var_9] = max(tensor[cse_var_9], placeholder[(cse_var_96 + 317)])
        tensor[cse_var_8] = -3.40282e+38f32
        tensor[cse_var_8] = max(tensor[cse_var_8], placeholder[(cse_var_96 + 110)])
        tensor[cse_var_8] = max(tensor[cse_var_8], placeholder[(cse_var_96 + 126)])
        tensor[cse_var_8] = max(tensor[cse_var_8], placeholder[(cse_var_96 + 302)])
        tensor[cse_var_8] = max(tensor[cse_var_8], placeholder[(cse_var_96 + 318)])
        tensor[cse_var_7] = -3.40282e+38f32
        tensor[cse_var_7] = max(tensor[cse_var_7], placeholder[(cse_var_96 + 111)])
        tensor[cse_var_7] = max(tensor[cse_var_7], placeholder[(cse_var_96 + 127)])
        tensor[cse_var_7] = max(tensor[cse_var_7], placeholder[(cse_var_96 + 303)])
        tensor[cse_var_7] = max(tensor[cse_var_7], placeholder[(cse_var_96 + 319)])
        tensor[cse_var_6] = -3.40282e+38f32
        tensor[cse_var_6] = max(tensor[cse_var_6], placeholder[(cse_var_96 + 128)])
        tensor[cse_var_6] = max(tensor[cse_var_6], placeholder[(cse_var_96 + 144)])
        tensor[cse_var_6] = max(tensor[cse_var_6], placeholder[(cse_var_96 + 320)])
        tensor[cse_var_6] = max(tensor[cse_var_6], placeholder[(cse_var_96 + 336)])
        tensor[cse_var_5] = -3.40282e+38f32
        tensor[cse_var_5] = max(tensor[cse_var_5], placeholder[(cse_var_96 + 129)])
        tensor[cse_var_5] = max(tensor[cse_var_5], placeholder[(cse_var_96 + 145)])
        tensor[cse_var_5] = max(tensor[cse_var_5], placeholder[(cse_var_96 + 321)])
        tensor[cse_var_5] = max(tensor[cse_var_5], placeholder[(cse_var_96 + 337)])
        tensor[cse_var_4] = -3.40282e+38f32
        tensor[cse_var_4] = max(tensor[cse_var_4], placeholder[(cse_var_96 + 130)])
        tensor[cse_var_4] = max(tensor[cse_var_4], placeholder[(cse_var_96 + 146)])
        tensor[cse_var_4] = max(tensor[cse_var_4], placeholder[(cse_var_96 + 322)])
        tensor[cse_var_4] = max(tensor[cse_var_4], placeholder[(cse_var_96 + 338)])
        tensor[cse_var_3] = -3.40282e+38f32
        tensor[cse_var_3] = max(tensor[cse_var_3], placeholder[(cse_var_96 + 131)])
        tensor[cse_var_3] = max(tensor[cse_var_3], placeholder[(cse_var_96 + 147)])
        tensor[cse_var_3] = max(tensor[cse_var_3], placeholder[(cse_var_96 + 323)])
        tensor[cse_var_3] = max(tensor[cse_var_3], placeholder[(cse_var_96 + 339)])
        tensor[cse_var_2] = -3.40282e+38f32
        tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_96 + 132)])
        tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_96 + 148)])
        tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_96 + 324)])
        tensor[cse_var_2] = max(tensor[cse_var_2], placeholder[(cse_var_96 + 340)])
        tensor[cse_var_16] = -3.40282e+38f32
        tensor[cse_var_16] = max(tensor[cse_var_16], placeholder[(cse_var_96 + 133)])
        tensor[cse_var_16] = max(tensor[cse_var_16], placeholder[(cse_var_96 + 149)])
        tensor[cse_var_16] = max(tensor[cse_var_16], placeholder[(cse_var_96 + 325)])
        tensor[cse_var_16] = max(tensor[cse_var_16], placeholder[(cse_var_96 + 341)])
        tensor[cse_var_59] = -3.40282e+38f32
        tensor[cse_var_59] = max(tensor[cse_var_59], placeholder[(cse_var_96 + 134)])
        tensor[cse_var_59] = max(tensor[cse_var_59], placeholder[(cse_var_96 + 150)])
        tensor[cse_var_59] = max(tensor[cse_var_59], placeholder[(cse_var_96 + 326)])
        tensor[cse_var_59] = max(tensor[cse_var_59], placeholder[(cse_var_96 + 342)])
        tensor[cse_var_58] = -3.40282e+38f32
        tensor[cse_var_58] = max(tensor[cse_var_58], placeholder[(cse_var_96 + 135)])
        tensor[cse_var_58] = max(tensor[cse_var_58], placeholder[(cse_var_96 + 151)])
        tensor[cse_var_58] = max(tensor[cse_var_58], placeholder[(cse_var_96 + 327)])
        tensor[cse_var_58] = max(tensor[cse_var_58], placeholder[(cse_var_96 + 343)])
        tensor[cse_var_57] = -3.40282e+38f32
        tensor[cse_var_57] = max(tensor[cse_var_57], placeholder[(cse_var_96 + 136)])
        tensor[cse_var_57] = max(tensor[cse_var_57], placeholder[(cse_var_96 + 152)])
        tensor[cse_var_57] = max(tensor[cse_var_57], placeholder[(cse_var_96 + 328)])
        tensor[cse_var_57] = max(tensor[cse_var_57], placeholder[(cse_var_96 + 344)])
        tensor[cse_var_56] = -3.40282e+38f32
        tensor[cse_var_56] = max(tensor[cse_var_56], placeholder[(cse_var_96 + 137)])
        tensor[cse_var_56] = max(tensor[cse_var_56], placeholder[(cse_var_96 + 153)])
        tensor[cse_var_56] = max(tensor[cse_var_56], placeholder[(cse_var_96 + 329)])
        tensor[cse_var_56] = max(tensor[cse_var_56], placeholder[(cse_var_96 + 345)])
        tensor[cse_var_55] = -3.40282e+38f32
        tensor[cse_var_55] = max(tensor[cse_var_55], placeholder[(cse_var_96 + 138)])
        tensor[cse_var_55] = max(tensor[cse_var_55], placeholder[(cse_var_96 + 154)])
        tensor[cse_var_55] = max(tensor[cse_var_55], placeholder[(cse_var_96 + 330)])
        tensor[cse_var_55] = max(tensor[cse_var_55], placeholder[(cse_var_96 + 346)])
        tensor[cse_var_54] = -3.40282e+38f32
        tensor[cse_var_54] = max(tensor[cse_var_54], placeholder[(cse_var_96 + 139)])
        tensor[cse_var_54] = max(tensor[cse_var_54], placeholder[(cse_var_96 + 155)])
        tensor[cse_var_54] = max(tensor[cse_var_54], placeholder[(cse_var_96 + 331)])
        tensor[cse_var_54] = max(tensor[cse_var_54], placeholder[(cse_var_96 + 347)])
        tensor[cse_var_53] = -3.40282e+38f32
        tensor[cse_var_53] = max(tensor[cse_var_53], placeholder[(cse_var_96 + 140)])
        tensor[cse_var_53] = max(tensor[cse_var_53], placeholder[(cse_var_96 + 156)])
        tensor[cse_var_53] = max(tensor[cse_var_53], placeholder[(cse_var_96 + 332)])
        tensor[cse_var_53] = max(tensor[cse_var_53], placeholder[(cse_var_96 + 348)])
        tensor[cse_var_52] = -3.40282e+38f32
        tensor[cse_var_52] = max(tensor[cse_var_52], placeholder[(cse_var_96 + 141)])
        tensor[cse_var_52] = max(tensor[cse_var_52], placeholder[(cse_var_96 + 157)])
        tensor[cse_var_52] = max(tensor[cse_var_52], placeholder[(cse_var_96 + 333)])
        tensor[cse_var_52] = max(tensor[cse_var_52], placeholder[(cse_var_96 + 349)])
        tensor[cse_var_51] = -3.40282e+38f32
        tensor[cse_var_51] = max(tensor[cse_var_51], placeholder[(cse_var_96 + 142)])
        tensor[cse_var_51] = max(tensor[cse_var_51], placeholder[(cse_var_96 + 158)])
        tensor[cse_var_51] = max(tensor[cse_var_51], placeholder[(cse_var_96 + 334)])
        tensor[cse_var_51] = max(tensor[cse_var_51], placeholder[(cse_var_96 + 350)])
        tensor[cse_var_50] = -3.40282e+38f32
        tensor[cse_var_50] = max(tensor[cse_var_50], placeholder[(cse_var_96 + 143)])
        tensor[cse_var_50] = max(tensor[cse_var_50], placeholder[(cse_var_96 + 159)])
        tensor[cse_var_50] = max(tensor[cse_var_50], placeholder[(cse_var_96 + 335)])
        tensor[cse_var_50] = max(tensor[cse_var_50], placeholder[(cse_var_96 + 351)])
        tensor[cse_var_48] = -3.40282e+38f32
        tensor[cse_var_48] = max(tensor[cse_var_48], placeholder[(cse_var_96 + 160)])
        tensor[cse_var_48] = max(tensor[cse_var_48], placeholder[(cse_var_96 + 176)])
        tensor[cse_var_48] = max(tensor[cse_var_48], placeholder[(cse_var_96 + 352)])
        tensor[cse_var_48] = max(tensor[cse_var_48], placeholder[(cse_var_96 + 368)])
        tensor[cse_var_47] = -3.40282e+38f32
        tensor[cse_var_47] = max(tensor[cse_var_47], placeholder[(cse_var_96 + 161)])
        tensor[cse_var_47] = max(tensor[cse_var_47], placeholder[(cse_var_96 + 177)])
        tensor[cse_var_47] = max(tensor[cse_var_47], placeholder[(cse_var_96 + 353)])
        tensor[cse_var_47] = max(tensor[cse_var_47], placeholder[(cse_var_96 + 369)])
        tensor[cse_var_31] = -3.40282e+38f32
        tensor[cse_var_31] = max(tensor[cse_var_31], placeholder[(cse_var_96 + 162)])
        tensor[cse_var_31] = max(tensor[cse_var_31], placeholder[(cse_var_96 + 178)])
        tensor[cse_var_31] = max(tensor[cse_var_31], placeholder[(cse_var_96 + 354)])
        tensor[cse_var_31] = max(tensor[cse_var_31], placeholder[(cse_var_96 + 370)])
        tensor[cse_var_45] = -3.40282e+38f32
        tensor[cse_var_45] = max(tensor[cse_var_45], placeholder[(cse_var_96 + 163)])
        tensor[cse_var_45] = max(tensor[cse_var_45], placeholder[(cse_var_96 + 179)])
        tensor[cse_var_45] = max(tensor[cse_var_45], placeholder[(cse_var_96 + 355)])
        tensor[cse_var_45] = max(tensor[cse_var_45], placeholder[(cse_var_96 + 371)])
        tensor[cse_var_44] = -3.40282e+38f32
        tensor[cse_var_44] = max(tensor[cse_var_44], placeholder[(cse_var_96 + 164)])
        tensor[cse_var_44] = max(tensor[cse_var_44], placeholder[(cse_var_96 + 180)])
        tensor[cse_var_44] = max(tensor[cse_var_44], placeholder[(cse_var_96 + 356)])
        tensor[cse_var_44] = max(tensor[cse_var_44], placeholder[(cse_var_96 + 372)])
        tensor[cse_var_43] = -3.40282e+38f32
        tensor[cse_var_43] = max(tensor[cse_var_43], placeholder[(cse_var_96 + 165)])
        tensor[cse_var_43] = max(tensor[cse_var_43], placeholder[(cse_var_96 + 181)])
        tensor[cse_var_43] = max(tensor[cse_var_43], placeholder[(cse_var_96 + 357)])
        tensor[cse_var_43] = max(tensor[cse_var_43], placeholder[(cse_var_96 + 373)])
        tensor[cse_var_42] = -3.40282e+38f32
        tensor[cse_var_42] = max(tensor[cse_var_42], placeholder[(cse_var_96 + 166)])
        tensor[cse_var_42] = max(tensor[cse_var_42], placeholder[(cse_var_96 + 182)])
        tensor[cse_var_42] = max(tensor[cse_var_42], placeholder[(cse_var_96 + 358)])
        tensor[cse_var_42] = max(tensor[cse_var_42], placeholder[(cse_var_96 + 374)])
        tensor[cse_var_41] = -3.40282e+38f32
        tensor[cse_var_41] = max(tensor[cse_var_41], placeholder[(cse_var_96 + 167)])
        tensor[cse_var_41] = max(tensor[cse_var_41], placeholder[(cse_var_96 + 183)])
        tensor[cse_var_41] = max(tensor[cse_var_41], placeholder[(cse_var_96 + 359)])
        tensor[cse_var_41] = max(tensor[cse_var_41], placeholder[(cse_var_96 + 375)])
        tensor[cse_var_40] = -3.40282e+38f32
        tensor[cse_var_40] = max(tensor[cse_var_40], placeholder[(cse_var_96 + 168)])
        tensor[cse_var_40] = max(tensor[cse_var_40], placeholder[(cse_var_96 + 184)])
        tensor[cse_var_40] = max(tensor[cse_var_40], placeholder[(cse_var_96 + 360)])
        tensor[cse_var_40] = max(tensor[cse_var_40], placeholder[(cse_var_96 + 376)])
        tensor[cse_var_39] = -3.40282e+38f32
        tensor[cse_var_39] = max(tensor[cse_var_39], placeholder[(cse_var_96 + 169)])
        tensor[cse_var_39] = max(tensor[cse_var_39], placeholder[(cse_var_96 + 185)])
        tensor[cse_var_39] = max(tensor[cse_var_39], placeholder[(cse_var_96 + 361)])
        tensor[cse_var_39] = max(tensor[cse_var_39], placeholder[(cse_var_96 + 377)])
        tensor[cse_var_37] = -3.40282e+38f32
        tensor[cse_var_37] = max(tensor[cse_var_37], placeholder[(cse_var_96 + 170)])
        tensor[cse_var_37] = max(tensor[cse_var_37], placeholder[(cse_var_96 + 186)])
        tensor[cse_var_37] = max(tensor[cse_var_37], placeholder[(cse_var_96 + 362)])
        tensor[cse_var_37] = max(tensor[cse_var_37], placeholder[(cse_var_96 + 378)])
        tensor[cse_var_36] = -3.40282e+38f32
        tensor[cse_var_36] = max(tensor[cse_var_36], placeholder[(cse_var_96 + 171)])
        tensor[cse_var_36] = max(tensor[cse_var_36], placeholder[(cse_var_96 + 187)])
        tensor[cse_var_36] = max(tensor[cse_var_36], placeholder[(cse_var_96 + 363)])
        tensor[cse_var_36] = max(tensor[cse_var_36], placeholder[(cse_var_96 + 379)])
        tensor[cse_var_35] = -3.40282e+38f32
        tensor[cse_var_35] = max(tensor[cse_var_35], placeholder[(cse_var_96 + 172)])
        tensor[cse_var_35] = max(tensor[cse_var_35], placeholder[(cse_var_96 + 188)])
        tensor[cse_var_35] = max(tensor[cse_var_35], placeholder[(cse_var_96 + 364)])
        tensor[cse_var_35] = max(tensor[cse_var_35], placeholder[(cse_var_96 + 380)])
        tensor[cse_var_34] = -3.40282e+38f32
        tensor[cse_var_34] = max(tensor[cse_var_34], placeholder[(cse_var_96 + 173)])
        tensor[cse_var_34] = max(tensor[cse_var_34], placeholder[(cse_var_96 + 189)])
        tensor[cse_var_34] = max(tensor[cse_var_34], placeholder[(cse_var_96 + 365)])
        tensor[cse_var_34] = max(tensor[cse_var_34], placeholder[(cse_var_96 + 381)])
        tensor[cse_var_33] = -3.40282e+38f32
        tensor[cse_var_33] = max(tensor[cse_var_33], placeholder[(cse_var_96 + 174)])
        tensor[cse_var_33] = max(tensor[cse_var_33], placeholder[(cse_var_96 + 190)])
        tensor[cse_var_33] = max(tensor[cse_var_33], placeholder[(cse_var_96 + 366)])
        tensor[cse_var_33] = max(tensor[cse_var_33], placeholder[(cse_var_96 + 382)])
        tensor[cse_var_32] = -3.40282e+38f32
        tensor[cse_var_32] = max(tensor[cse_var_32], placeholder[(cse_var_96 + 175)])
        tensor[cse_var_32] = max(tensor[cse_var_32], placeholder[(cse_var_96 + 191)])
        tensor[cse_var_32] = max(tensor[cse_var_32], placeholder[(cse_var_96 + 367)])
        tensor[cse_var_32] = max(tensor[cse_var_32], placeholder[(cse_var_96 + 383)])
      }
    }
  }
}


==== Task 7: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1 (weight 1 key: ["218f348ca19713d944f219d28361e292", [1, 6, 54, 54, 16], [16, 6, 5, 5, 16, 16], [1, 16, 1, 1, 16], [1, 16, 25, 25, 16]]) =====
placeholder = PLACEHOLDER [1, 6, 54, 54, 16]
placeholder = PLACEHOLDER [16, 6, 5, 5, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (placeholder[n, floordiv(ic, 16), ((oh*2) + kh), ((ow*2) + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 16, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=1)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=1)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=5)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=5)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=1)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=1)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=5)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [279936], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [614400], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [256], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [160000], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 6, 54, 54, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [16, 6, 5, 5, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 16, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 16, 25, 25, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused: int32, 0, 1000) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [10]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [10], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 6) {
        for (kw.outer: int32, 0, 5) {
          for (ic.inner: int32, 0, 16) {
            let cse_var_35: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused, 125)*76800) + (ic.outer*6400)) + (kw.outer*256)) + (ic.inner*16))
            let cse_var_34: int32 = (cse_var_35 + 1280)
            let cse_var_33: int32 = (cse_var_35 + 2560)
            let cse_var_32: int32 = (cse_var_35 + 38400)
            let cse_var_31: int32 = (cse_var_35 + 39680)
            let cse_var_30: int32 = (cse_var_35 + 40960)
            let cse_var_29: int32 = (cse_var_35 + 42240)
            let cse_var_28: int32 = (cse_var_35 + 43520)
            let cse_var_27: int32 = (cse_var_35 + 5120)
            let cse_var_26: int32 = (cse_var_35 + 3840)
            let cse_var_25: int32 = (((((ic.outer*46656) + (floordiv(floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused, 125), 5)*1728)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused, 5)*160)) + (kw.outer*16)) + ic.inner)
            let cse_var_24: int32 = (cse_var_25 + 2592)
            let cse_var_23: int32 = (cse_var_25 + 3456)
            let cse_var_22: int32 = (cse_var_25 + 2720)
            let cse_var_21: int32 = (cse_var_25 + 2688)
            let cse_var_20: int32 = (cse_var_25 + 2656)
            let cse_var_19: int32 = (cse_var_25 + 2624)
            let cse_var_18: int32 = (cse_var_25 + 1856)
            let cse_var_17: int32 = (cse_var_25 + 1824)
            let cse_var_16: int32 = (cse_var_25 + 1792)
            let cse_var_15: int32 = (cse_var_25 + 1760)
            let cse_var_14: int32 = (cse_var_25 + 128)
            let cse_var_13: int32 = (cse_var_25 + 32)
            let cse_var_12: int32 = (cse_var_25 + 3488)
            let cse_var_11: int32 = (cse_var_25 + 3520)
            let cse_var_10: int32 = (cse_var_25 + 3552)
            let cse_var_9: int32 = (cse_var_25 + 3584)
            let cse_var_8: int32 = (cse_var_25 + 64)
            let cse_var_7: int32 = (cse_var_25 + 864)
            let cse_var_6: int32 = (cse_var_25 + 896)
            let cse_var_5: int32 = (cse_var_25 + 928)
            let cse_var_4: int32 = (cse_var_25 + 96)
            let cse_var_3: int32 = (cse_var_25 + 960)
            let cse_var_2: int32 = (cse_var_25 + 992)
            let cse_var_1: int32 = (cse_var_25 + 1728)
             {
              conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
              conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
              conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
              conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
              conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_35, 1, 16)]))
              conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_25], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
              conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_13], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
              conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_8], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
              conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_4], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
              conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_14], 16)*placeholder_1[ramp(cse_var_32, 1, 16)]))
              conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
              conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
              conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
              conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
              conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_34, 1, 16)]))
              conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_7], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
              conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_6], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
              conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_5], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
              conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_3], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
              conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_2], 16)*placeholder_1[ramp(cse_var_31, 1, 16)]))
              conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
              conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
              conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
              conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
              conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_33, 1, 16)]))
              conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_1], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
              conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_15], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
              conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_16], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
              conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_17], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
              conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_18], 16)*placeholder_1[ramp(cse_var_30, 1, 16)]))
              conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
              conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
              conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
              conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
              conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_26, 1, 16)]))
              conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_24], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
              conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_19], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
              conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_20], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
              conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_21], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
              conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_22], 16)*placeholder_1[ramp(cse_var_29, 1, 16)]))
              conv2d_NCHWc_1[0] = (conv2d_NCHWc_1[0] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
              conv2d_NCHWc_1[1] = (conv2d_NCHWc_1[1] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
              conv2d_NCHWc_1[2] = (conv2d_NCHWc_1[2] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
              conv2d_NCHWc_1[3] = (conv2d_NCHWc_1[3] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
              conv2d_NCHWc_1[4] = (conv2d_NCHWc_1[4] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_27, 1, 16)]))
              conv2d_NCHWc_1[5] = (conv2d_NCHWc_1[5] + (broadcast(placeholder[cse_var_23], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
              conv2d_NCHWc_1[6] = (conv2d_NCHWc_1[6] + (broadcast(placeholder[cse_var_12], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
              conv2d_NCHWc_1[7] = (conv2d_NCHWc_1[7] + (broadcast(placeholder[cse_var_11], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
              conv2d_NCHWc_1[8] = (conv2d_NCHWc_1[8] + (broadcast(placeholder[cse_var_10], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
              conv2d_NCHWc_1[9] = (conv2d_NCHWc_1[9] + (broadcast(placeholder[cse_var_9], 16)*placeholder_1[ramp(cse_var_28, 1, 16)]))
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax3.inner: int32, 0, 5) {
          let cse_var_36: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused, 125)
          T_relu[ramp(((((cse_var_36*20000) + (ax1.inner*10000)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused, 125)*80)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[((ax1.inner*5) + ax3.inner)] + placeholder_2[ramp(((cse_var_36*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
        }
      }
    }
  }
}


==== Task 8: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2 (weight 1 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 16, 12, 12, 16], [32, 16, 3, 3, 16, 16], [1, 32, 1, 1, 16], [1, 32, 12, 12, 16]]) =====
placeholder = PLACEHOLDER [1, 16, 12, 12, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 13)) && (i3 >= 1)) && (i3 < 13)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [32, 16, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 32, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=16)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=2)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=6)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=4)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=1)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=3)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=16)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=12)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=4)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=3)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_ic_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused_ax1_o_i_fused_ax2_o_i_fused_ax3_o_i_fused_ax4_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 64)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [36864], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [1179648], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [512], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [73728], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 16, 12, 12, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [32, 16, 3, 3, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 32, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 32, 12, 12, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused: int32, 0, 48) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [96]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [1344]), storage_scope = global {
      for (oh.outer.inner.init: int32, 0, 6) {
        let cse_var_1: int32 = (oh.outer.inner.init*8)
         {
          conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [96], [])[cse_var_1] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 1)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 2)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 3)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 4)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 5)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 6)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 7)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 48)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 49)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 50)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 51)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 52)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 53)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 54)] = broadcast(0f32, 16)
          conv2d_NCHWc_1[(cse_var_1 + 55)] = broadcast(0f32, 16)
        }
      }
      for (ic.outer: int32, 0, 16) {
        for (i2: int32, 0, 14) {
          let cse_var_5: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 3)
          let cse_var_4: int32 = (i2*96)
          let cse_var_3: bool = ((1 <= i2) && (i2 < 13))
          let cse_var_2: int32 = (((ic.outer*2304) + (i2*192)) + (cse_var_5*64))
           {
            data_pad_1: Buffer(data_pad, float32, [1344], [])[ramp(cse_var_4, 1, 16)] = @tir.if_then_else((cse_var_3 && (1 <= cse_var_5)), placeholder[ramp((cse_var_2 - 208), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp((cse_var_4 + 16), 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 - 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp((cse_var_4 + 32), 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 - 176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp((cse_var_4 + 48), 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 - 160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp((cse_var_4 + 64), 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_2 - 144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
            data_pad_1[ramp((cse_var_4 + 80), 1, 16)] = @tir.if_then_else((cse_var_3 && (cse_var_5 < 2)), placeholder[ramp((cse_var_2 - 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          }
        }
        for (oh.outer.inner: int32, 0, 6) {
          for (ic.inner: int32, 0, 16) {
            for (kh.inner: int32, 0, 3) {
              let cse_var_39: int32 = (oh.outer.inner*8)
              let cse_var_38: int32 = (cse_var_39 + 7)
              let cse_var_37: int32 = (cse_var_39 + 6)
              let cse_var_36: int32 = (cse_var_39 + 55)
              let cse_var_35: int32 = (cse_var_39 + 54)
              let cse_var_34: int32 = (cse_var_39 + 53)
              let cse_var_33: int32 = (cse_var_39 + 52)
              let cse_var_32: int32 = (cse_var_39 + 51)
              let cse_var_31: int32 = (cse_var_39 + 50)
              let cse_var_30: int32 = (cse_var_39 + 5)
              let cse_var_29: int32 = (cse_var_39 + 49)
              let cse_var_28: int32 = (cse_var_39 + 48)
              let cse_var_27: int32 = (cse_var_39 + 4)
              let cse_var_26: int32 = (cse_var_39 + 3)
              let cse_var_25: int32 = (cse_var_39 + 2)
              let cse_var_24: int32 = (cse_var_39 + 1)
              let cse_var_23: int32 = (((oh.outer.inner*192) + (kh.inner*96)) + ic.inner)
              let cse_var_22: int32 = (cse_var_23 + 96)
              let cse_var_21: int32 = (cse_var_23 + 80)
              let cse_var_20: int32 = (cse_var_23 + 64)
              let cse_var_19: int32 = (cse_var_23 + 48)
              let cse_var_18: int32 = (cse_var_23 + 32)
              let cse_var_17: int32 = (cse_var_23 + 176)
              let cse_var_16: int32 = (cse_var_23 + 160)
              let cse_var_15: int32 = (cse_var_23 + 16)
              let cse_var_14: int32 = (cse_var_23 + 144)
              let cse_var_13: int32 = (cse_var_23 + 128)
              let cse_var_12: int32 = (cse_var_23 + 112)
              let cse_var_11: int32 = ((((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 3)*73728) + (ic.outer*2304)) + (kh.inner*768)) + (ic.inner*16))
              let cse_var_10: int32 = (cse_var_11 + 37120)
              let cse_var_9: int32 = (cse_var_11 + 37376)
              let cse_var_8: int32 = (cse_var_11 + 512)
              let cse_var_7: int32 = (cse_var_11 + 256)
              let cse_var_6: int32 = (cse_var_11 + 36864)
               {
                conv2d_NCHWc_1[cse_var_39] = (conv2d_NCHWc_1[cse_var_39] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[cse_var_24] = (conv2d_NCHWc_1[cse_var_24] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[cse_var_25] = (conv2d_NCHWc_1[cse_var_25] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[cse_var_26] = (conv2d_NCHWc_1[cse_var_26] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[cse_var_27] = (conv2d_NCHWc_1[cse_var_27] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[cse_var_30] = (conv2d_NCHWc_1[cse_var_30] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[cse_var_37] = (conv2d_NCHWc_1[cse_var_37] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[cse_var_38] = (conv2d_NCHWc_1[cse_var_38] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                conv2d_NCHWc_1[cse_var_28] = (conv2d_NCHWc_1[cse_var_28] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[cse_var_29] = (conv2d_NCHWc_1[cse_var_29] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[cse_var_31] = (conv2d_NCHWc_1[cse_var_31] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[cse_var_32] = (conv2d_NCHWc_1[cse_var_32] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[cse_var_33] = (conv2d_NCHWc_1[cse_var_33] + (broadcast(data_pad_1[cse_var_22], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[cse_var_34] = (conv2d_NCHWc_1[cse_var_34] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[cse_var_35] = (conv2d_NCHWc_1[cse_var_35] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[cse_var_36] = (conv2d_NCHWc_1[cse_var_36] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                conv2d_NCHWc_1[cse_var_39] = (conv2d_NCHWc_1[cse_var_39] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[cse_var_24] = (conv2d_NCHWc_1[cse_var_24] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[cse_var_25] = (conv2d_NCHWc_1[cse_var_25] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[cse_var_26] = (conv2d_NCHWc_1[cse_var_26] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[cse_var_27] = (conv2d_NCHWc_1[cse_var_27] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[cse_var_30] = (conv2d_NCHWc_1[cse_var_30] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[cse_var_37] = (conv2d_NCHWc_1[cse_var_37] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[cse_var_38] = (conv2d_NCHWc_1[cse_var_38] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                conv2d_NCHWc_1[cse_var_28] = (conv2d_NCHWc_1[cse_var_28] + (broadcast(data_pad_1[cse_var_15], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[cse_var_29] = (conv2d_NCHWc_1[cse_var_29] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[cse_var_31] = (conv2d_NCHWc_1[cse_var_31] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[cse_var_32] = (conv2d_NCHWc_1[cse_var_32] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[cse_var_33] = (conv2d_NCHWc_1[cse_var_33] + (broadcast(data_pad_1[cse_var_12], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[cse_var_34] = (conv2d_NCHWc_1[cse_var_34] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[cse_var_35] = (conv2d_NCHWc_1[cse_var_35] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[cse_var_36] = (conv2d_NCHWc_1[cse_var_36] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                conv2d_NCHWc_1[cse_var_39] = (conv2d_NCHWc_1[cse_var_39] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[cse_var_24] = (conv2d_NCHWc_1[cse_var_24] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[cse_var_25] = (conv2d_NCHWc_1[cse_var_25] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[cse_var_26] = (conv2d_NCHWc_1[cse_var_26] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[cse_var_27] = (conv2d_NCHWc_1[cse_var_27] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[cse_var_30] = (conv2d_NCHWc_1[cse_var_30] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[cse_var_37] = (conv2d_NCHWc_1[cse_var_37] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[cse_var_38] = (conv2d_NCHWc_1[cse_var_38] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                conv2d_NCHWc_1[cse_var_28] = (conv2d_NCHWc_1[cse_var_28] + (broadcast(data_pad_1[cse_var_18], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[cse_var_29] = (conv2d_NCHWc_1[cse_var_29] + (broadcast(data_pad_1[cse_var_19], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[cse_var_31] = (conv2d_NCHWc_1[cse_var_31] + (broadcast(data_pad_1[cse_var_20], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[cse_var_32] = (conv2d_NCHWc_1[cse_var_32] + (broadcast(data_pad_1[cse_var_21], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[cse_var_33] = (conv2d_NCHWc_1[cse_var_33] + (broadcast(data_pad_1[cse_var_13], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[cse_var_34] = (conv2d_NCHWc_1[cse_var_34] + (broadcast(data_pad_1[cse_var_14], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[cse_var_35] = (conv2d_NCHWc_1[cse_var_35] + (broadcast(data_pad_1[cse_var_16], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                conv2d_NCHWc_1[cse_var_36] = (conv2d_NCHWc_1[cse_var_36] + (broadcast(data_pad_1[cse_var_17], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 12) {
          for (ax3.inner: int32, 0, 4) {
            let cse_var_40: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 3)
            T_relu[ramp((((((cse_var_40*4608) + (ax1.inner*2304)) + (ax2.inner*192)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused.ax2.outer.inner.fused.ax3.outer.inner.fused.ax4.outer.inner.fused, 3)*64)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[(((ax1.inner*48) + (ax2.inner*4)) + ax3.inner)] + placeholder_2[ramp(((cse_var_40*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
          }
        }
      }
    }
  }
}


==== Task 9: vm_mod_fused_nn_lrn (weight 1 key: ["0f353233a06b32a162590935e5014785", [1, 96, 109, 109], [1, 96, 109, 109]]) =====
placeholder = PLACEHOLDER [1, 96, 109, 109]
pad_data(ax0, ax1, ax2, ax3) = tir.if_then_else(((ax1 >= 2) && (ax1 < 98)), placeholder[ax0, (ax1 - 2), ax2, ax3], 0f)
tensor(ax0, ax1, ax2, ax3) += (pad_data[ax0, (ax1 + rxs), ax2, ax3]*pad_data[ax0, (ax1 + rxs), ax2, ax3])
tensor(ax0, ax1, ax2, ax3) = tir.pow((2f + ((0.0005f*tensor[ax0, ax1, ax2, ax3])/5f)), 0.75f)
T_divide(ax0, ax1, ax2, ax3) = (placeholder[ax0, ax1, ax2, ax3]/tensor[ax0, ax1, ax2, ax3])


Trace for this task is: 
pad_data_ax0, pad_data_ax1, pad_data_ax2, pad_data_ax3 = tuple(pad_data.op.axis) + tuple(pad_data.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3, tensor_rxs = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
tensor_ax0, tensor_ax1, tensor_ax2, tensor_ax3 = tuple(tensor.op.axis) + tuple(tensor.op.reduce_axis)
T_divide_ax0, T_divide_ax1, T_divide_ax2, T_divide_ax3 = tuple(T_divide.op.axis) + tuple(T_divide.op.reduce_axis)
s[tensor].compute_inline()
s[tensor].compute_root()
s[pad_data].compute_at(s[tensor], tensor_ax3)
tensor_ax0_ax1_fused_ax2_fused = s[tensor].fuse(tensor_ax0, tensor_ax1, tensor_ax2)
s[tensor].parallel(tensor_ax0_ax1_fused_ax2_fused)
T_divide_ax0_ax1_fused_ax2_fused_ax3_fused = s[T_divide].fuse(T_divide_ax0, T_divide_ax1, T_divide_ax2, T_divide_ax3)
s[T_divide].parallel(T_divide_ax0_ax1_fused_ax2_fused_ax3_fused)
s[tensor].pragma(tensor_ax0_ax1_fused_ax2_fused, "auto_unroll_max_step", 512)
s[tensor].pragma(tensor_ax0_ax1_fused_ax2_fused, "unroll_explicit", True)
pad_data_ax2_ax3_fused = s[pad_data].fuse(pad_data_ax2, pad_data_ax3)
s[pad_data].vectorize(pad_data_ax2_ax3_fused)


The best replacement found is:
@main = primfn(placeholder_1: handle, T_divide_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_2: Pointer(float32), float32, [1140576], []),
             T_divide: Buffer(T_divide_2: Pointer(float32), float32, [1140576], [])}
  buffer_map = {placeholder_1: placeholder, T_divide_1: T_divide}
  preflattened_buffer_map = {placeholder_1: placeholder_3: Buffer(placeholder_2, float32, [1, 96, 109, 109], []), T_divide_1: T_divide_3: Buffer(T_divide_2, float32, [1, 96, 109, 109], [])} {
  allocate(tensor: Pointer(global float32), float32, [1140576]), storage_scope = global {
    for (ax0.ax1.fused.ax2.fused: int32, 0, 10464) "parallel" {
      allocate(pad_data: Pointer(global float32), float32, [5]), storage_scope = global;
      for (ax3: int32, 0, 109) {
        let cse_var_1: int32 = ((ax0.ax1.fused.ax2.fused*109) + ax3)
         {
          pad_data_1: Buffer(pad_data, float32, [5], [], align=16)[0] = @tir.if_then_else((218 <= ax0.ax1.fused.ax2.fused), placeholder[(cse_var_1 - 23762)], 0f32, dtype=float32)
          pad_data_1[1] = @tir.if_then_else((109 <= ax0.ax1.fused.ax2.fused), placeholder[(cse_var_1 - 11881)], 0f32, dtype=float32)
          pad_data_1[2] = placeholder[cse_var_1]
          pad_data_1[3] = @tir.if_then_else((ax0.ax1.fused.ax2.fused < 10355), placeholder[(cse_var_1 + 11881)], 0f32, dtype=float32)
          pad_data_1[4] = @tir.if_then_else((ax0.ax1.fused.ax2.fused < 10246), placeholder[(cse_var_1 + 23762)], 0f32, dtype=float32)
          tensor_1: Buffer(tensor, float32, [1140576], [])[cse_var_1] = 0f32
          tensor_1[cse_var_1] = (tensor_1[cse_var_1] + (pad_data_1[0]*pad_data_1[0]))
          tensor_1[cse_var_1] = (tensor_1[cse_var_1] + (pad_data_1[1]*pad_data_1[1]))
          tensor_1[cse_var_1] = (tensor_1[cse_var_1] + (pad_data_1[2]*pad_data_1[2]))
          tensor_1[cse_var_1] = (tensor_1[cse_var_1] + (pad_data_1[3]*pad_data_1[3]))
          tensor_1[cse_var_1] = (tensor_1[cse_var_1] + (pad_data_1[4]*pad_data_1[4]))
        }
      }
    }
    for (ax0.ax1.fused.ax2.fused.ax3.fused: int32, 0, 1140576) "parallel" {
      T_divide[ax0.ax1.fused.ax2.fused.ax3.fused] = (placeholder[ax0.ax1.fused.ax2.fused.ax3.fused] / @tir.pow((2f32 + ((0.0005f32*tensor_1[ax0.ax1.fused.ax2.fused.ax3.fused])*0.2f32)), 0.75f32, dtype=float32))
    }
  }
}


==== Task 10: vm_mod_fused_nn_dense_add (weight 1 key: ["7d44c6e3c81cd80f61ff2265b2bae89a", [1, 1024], [1000, 1024], [1, 1000], [1, 1000]]) =====
placeholder = PLACEHOLDER [1, 1024]
placeholder = PLACEHOLDER [1000, 1024]
T_matmul_NT(i, j) += (placeholder[i, k]*placeholder[j, k])
placeholder = PLACEHOLDER [1, 1000]
T_add(ax0, ax1) = (T_matmul_NT[ax0, ax1] + placeholder[ax0, ax1])


Trace for this task is: 
T_matmul_NT_i, T_matmul_NT_j, T_matmul_NT_k = tuple(T_matmul_NT.op.axis) + tuple(T_matmul_NT.op.reduce_axis)
T_add_ax0, T_add_ax1 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_matmul_NT_i_o_i, T_matmul_NT_i_i = s[T_matmul_NT].split(T_matmul_NT_i, factor=1)
T_matmul_NT_i_o_o_i, T_matmul_NT_i_o_i = s[T_matmul_NT].split(T_matmul_NT_i_o_i, factor=1)
T_matmul_NT_i_o_o_o, T_matmul_NT_i_o_o_i = s[T_matmul_NT].split(T_matmul_NT_i_o_o_i, factor=1)
T_matmul_NT_j_o_i, T_matmul_NT_j_i = s[T_matmul_NT].split(T_matmul_NT_j, factor=50)
T_matmul_NT_j_o_o_i, T_matmul_NT_j_o_i = s[T_matmul_NT].split(T_matmul_NT_j_o_i, factor=1)
T_matmul_NT_j_o_o_o, T_matmul_NT_j_o_o_i = s[T_matmul_NT].split(T_matmul_NT_j_o_o_i, factor=2)
T_matmul_NT_k_o, T_matmul_NT_k_i = s[T_matmul_NT].split(T_matmul_NT_k, factor=16)
s[T_matmul_NT].reorder(T_matmul_NT_i_o_o_o, T_matmul_NT_j_o_o_o, T_matmul_NT_i_o_o_i, T_matmul_NT_j_o_o_i, T_matmul_NT_k_o, T_matmul_NT_i_o_i, T_matmul_NT_j_o_i, T_matmul_NT_k_i, T_matmul_NT_i_i, T_matmul_NT_j_i)
T_add_ax0_o_i, T_add_ax0_i = s[T_add].split(T_add_ax0, factor=1)
T_add_ax0_o_o, T_add_ax0_o_i = s[T_add].split(T_add_ax0_o_i, factor=1)
T_add_ax1_o_i, T_add_ax1_i = s[T_add].split(T_add_ax1, factor=50)
T_add_ax1_o_o, T_add_ax1_o_i = s[T_add].split(T_add_ax1_o_i, factor=2)
s[T_add].reorder(T_add_ax0_o_o, T_add_ax1_o_o, T_add_ax0_o_i, T_add_ax1_o_i, T_add_ax0_i, T_add_ax1_i)
s[T_matmul_NT].compute_at(s[T_add], T_add_ax1_o_i)
T_add_ax0_o_o_ax1_o_o_fused_ax0_o_i_fused_ax1_o_i_fused = s[T_add].fuse(T_add_ax0_o_o, T_add_ax1_o_o, T_add_ax0_o_i, T_add_ax1_o_i)
s[T_add].parallel(T_add_ax0_o_o_ax1_o_o_fused_ax0_o_i_fused_ax1_o_i_fused)
s[T_matmul_NT].pragma(T_matmul_NT_i_o_o_o, "auto_unroll_max_step", 512)
s[T_matmul_NT].pragma(T_matmul_NT_i_o_o_o, "unroll_explicit", True)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_add_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [1024], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [1024000], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [1000], []),
             T_add: Buffer(T_add_2: Pointer(float32), float32, [1000], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_add_1: T_add}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 1024], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [10, 2, 1, 1, 64, 1, 16, 50], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 1000], []), T_add_1: T_add_3: Buffer(T_add_2, float32, [1, 1000], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused: int32, 0, 20) "parallel" {
    allocate(T_matmul_NT: Pointer(global float32), float32, [50]), storage_scope = global {
      T_matmul_NT_1: Buffer(T_matmul_NT, float32, [50], [])[0] = 0f32
      T_matmul_NT_1[1] = 0f32
      T_matmul_NT_1[2] = 0f32
      T_matmul_NT_1[3] = 0f32
      T_matmul_NT_1[4] = 0f32
      T_matmul_NT_1[5] = 0f32
      T_matmul_NT_1[6] = 0f32
      T_matmul_NT_1[7] = 0f32
      T_matmul_NT_1[8] = 0f32
      T_matmul_NT_1[9] = 0f32
      T_matmul_NT_1[10] = 0f32
      T_matmul_NT_1[11] = 0f32
      T_matmul_NT_1[12] = 0f32
      T_matmul_NT_1[13] = 0f32
      T_matmul_NT_1[14] = 0f32
      T_matmul_NT_1[15] = 0f32
      T_matmul_NT_1[16] = 0f32
      T_matmul_NT_1[17] = 0f32
      T_matmul_NT_1[18] = 0f32
      T_matmul_NT_1[19] = 0f32
      T_matmul_NT_1[20] = 0f32
      T_matmul_NT_1[21] = 0f32
      T_matmul_NT_1[22] = 0f32
      T_matmul_NT_1[23] = 0f32
      T_matmul_NT_1[24] = 0f32
      T_matmul_NT_1[25] = 0f32
      T_matmul_NT_1[26] = 0f32
      T_matmul_NT_1[27] = 0f32
      T_matmul_NT_1[28] = 0f32
      T_matmul_NT_1[29] = 0f32
      T_matmul_NT_1[30] = 0f32
      T_matmul_NT_1[31] = 0f32
      T_matmul_NT_1[32] = 0f32
      T_matmul_NT_1[33] = 0f32
      T_matmul_NT_1[34] = 0f32
      T_matmul_NT_1[35] = 0f32
      T_matmul_NT_1[36] = 0f32
      T_matmul_NT_1[37] = 0f32
      T_matmul_NT_1[38] = 0f32
      T_matmul_NT_1[39] = 0f32
      T_matmul_NT_1[40] = 0f32
      T_matmul_NT_1[41] = 0f32
      T_matmul_NT_1[42] = 0f32
      T_matmul_NT_1[43] = 0f32
      T_matmul_NT_1[44] = 0f32
      T_matmul_NT_1[45] = 0f32
      T_matmul_NT_1[46] = 0f32
      T_matmul_NT_1[47] = 0f32
      T_matmul_NT_1[48] = 0f32
      T_matmul_NT_1[49] = 0f32
      for (k.outer: int32, 0, 64) {
        for (k.inner: int32, 0, 16) {
          let cse_var_2: int32 = ((k.outer*16) + k.inner)
          let cse_var_1: int32 = (((ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused*51200) + (k.outer*800)) + (k.inner*50))
           {
            T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_2]*placeholder_1[cse_var_1]))
            T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 1)]))
            T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 2)]))
            T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 3)]))
            T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 4)]))
            T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 5)]))
            T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 6)]))
            T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 7)]))
            T_matmul_NT_1[8] = (T_matmul_NT_1[8] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 8)]))
            T_matmul_NT_1[9] = (T_matmul_NT_1[9] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 9)]))
            T_matmul_NT_1[10] = (T_matmul_NT_1[10] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 10)]))
            T_matmul_NT_1[11] = (T_matmul_NT_1[11] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 11)]))
            T_matmul_NT_1[12] = (T_matmul_NT_1[12] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 12)]))
            T_matmul_NT_1[13] = (T_matmul_NT_1[13] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 13)]))
            T_matmul_NT_1[14] = (T_matmul_NT_1[14] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 14)]))
            T_matmul_NT_1[15] = (T_matmul_NT_1[15] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 15)]))
            T_matmul_NT_1[16] = (T_matmul_NT_1[16] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 16)]))
            T_matmul_NT_1[17] = (T_matmul_NT_1[17] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 17)]))
            T_matmul_NT_1[18] = (T_matmul_NT_1[18] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 18)]))
            T_matmul_NT_1[19] = (T_matmul_NT_1[19] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 19)]))
            T_matmul_NT_1[20] = (T_matmul_NT_1[20] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 20)]))
            T_matmul_NT_1[21] = (T_matmul_NT_1[21] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 21)]))
            T_matmul_NT_1[22] = (T_matmul_NT_1[22] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 22)]))
            T_matmul_NT_1[23] = (T_matmul_NT_1[23] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 23)]))
            T_matmul_NT_1[24] = (T_matmul_NT_1[24] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 24)]))
            T_matmul_NT_1[25] = (T_matmul_NT_1[25] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 25)]))
            T_matmul_NT_1[26] = (T_matmul_NT_1[26] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 26)]))
            T_matmul_NT_1[27] = (T_matmul_NT_1[27] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 27)]))
            T_matmul_NT_1[28] = (T_matmul_NT_1[28] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 28)]))
            T_matmul_NT_1[29] = (T_matmul_NT_1[29] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 29)]))
            T_matmul_NT_1[30] = (T_matmul_NT_1[30] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 30)]))
            T_matmul_NT_1[31] = (T_matmul_NT_1[31] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 31)]))
            T_matmul_NT_1[32] = (T_matmul_NT_1[32] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 32)]))
            T_matmul_NT_1[33] = (T_matmul_NT_1[33] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 33)]))
            T_matmul_NT_1[34] = (T_matmul_NT_1[34] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 34)]))
            T_matmul_NT_1[35] = (T_matmul_NT_1[35] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 35)]))
            T_matmul_NT_1[36] = (T_matmul_NT_1[36] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 36)]))
            T_matmul_NT_1[37] = (T_matmul_NT_1[37] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 37)]))
            T_matmul_NT_1[38] = (T_matmul_NT_1[38] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 38)]))
            T_matmul_NT_1[39] = (T_matmul_NT_1[39] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 39)]))
            T_matmul_NT_1[40] = (T_matmul_NT_1[40] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 40)]))
            T_matmul_NT_1[41] = (T_matmul_NT_1[41] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 41)]))
            T_matmul_NT_1[42] = (T_matmul_NT_1[42] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 42)]))
            T_matmul_NT_1[43] = (T_matmul_NT_1[43] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 43)]))
            T_matmul_NT_1[44] = (T_matmul_NT_1[44] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 44)]))
            T_matmul_NT_1[45] = (T_matmul_NT_1[45] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 45)]))
            T_matmul_NT_1[46] = (T_matmul_NT_1[46] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 46)]))
            T_matmul_NT_1[47] = (T_matmul_NT_1[47] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 47)]))
            T_matmul_NT_1[48] = (T_matmul_NT_1[48] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 48)]))
            T_matmul_NT_1[49] = (T_matmul_NT_1[49] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 49)]))
          }
        }
      }
      for (ax1.inner: int32, 0, 50) {
        let cse_var_3: int32 = ((ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused.ax1.outer.inner.fused*50) + ax1.inner)
        T_add[cse_var_3] = (T_matmul_NT_1[ax1.inner] + placeholder_2[cse_var_3])
      }
    }
  }
}


==== Task 11: vm_mod_fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3 (weight 2 key: ["ce1b4a245fb9b3a0526fcd7e77d29d3f", [1, 32, 12, 12, 16], [32, 32, 3, 3, 16, 16], [1, 32, 1, 1, 16], [1, 32, 12, 12, 16]]) =====
placeholder = PLACEHOLDER [1, 32, 12, 12, 16]
data_pad(i0, i1, i2, i3, i4) = tir.if_then_else(((((i2 >= 1) && (i2 < 13)) && (i3 >= 1)) && (i3 < 13)), placeholder[i0, i1, (i2 - 1), (i3 - 1), i4], 0f)
placeholder = PLACEHOLDER [32, 32, 3, 3, 16, 16]
conv2d_NCHWc(n, oc_chunk, oh, ow, oc_block) += (data_pad[n, floordiv(ic, 16), (oh + kh), (ow + kw), floormod(ic, 16)]*placeholder[oc_chunk, floordiv(ic, 16), kh, kw, floormod(ic, 16), oc_block])
placeholder = PLACEHOLDER [1, 32, 1, 1, 16]
T_add(ax0, ax1, ax2, ax3, ax4) = (conv2d_NCHWc[ax0, ax1, ax2, ax3, ax4] + placeholder[ax0, ax1, 0, 0, ax4])
T_relu(ax0, ax1, ax2, ax3, ax4) = max(T_add[ax0, ax1, ax2, ax3, ax4], 0f)


Trace for this task is: 
data_pad_i0, data_pad_i1, data_pad_i2, data_pad_i3, data_pad_i4 = tuple(data_pad.op.axis) + tuple(data_pad.op.reduce_axis)
conv2d_NCHWc_n, conv2d_NCHWc_oc_chunk, conv2d_NCHWc_oh, conv2d_NCHWc_ow, conv2d_NCHWc_oc_block, conv2d_NCHWc_ic, conv2d_NCHWc_kh, conv2d_NCHWc_kw = tuple(conv2d_NCHWc.op.axis) + tuple(conv2d_NCHWc.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3, T_add_ax4 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1, T_relu_ax2, T_relu_ax3, T_relu_ax4 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
conv2d_NCHWc_n_o_i, conv2d_NCHWc_n_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n, factor=1)
conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_n_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_i, factor=1)
conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_n_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_n_o_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oc_chunk_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk, factor=2)
conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oc_chunk_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_i, factor=1)
conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oc_chunk_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_chunk_o_o_i, factor=1)
conv2d_NCHWc_oh_o_i, conv2d_NCHWc_oh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh, factor=2)
conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_oh_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_i, factor=2)
conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_oh_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oh_o_o_i, factor=1)
conv2d_NCHWc_ow_o_i, conv2d_NCHWc_ow_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow, factor=4)
conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_ow_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_i, factor=3)
conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_ow_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ow_o_o_i, factor=1)
conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_oc_block_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block, factor=16)
conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_oc_block_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_i, factor=1)
conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_oc_block_o_o_i = s[conv2d_NCHWc].split(conv2d_NCHWc_oc_block_o_o_i, factor=1)
conv2d_NCHWc_ic_o, conv2d_NCHWc_ic_i = s[conv2d_NCHWc].split(conv2d_NCHWc_ic, factor=16)
conv2d_NCHWc_kh_o, conv2d_NCHWc_kh_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kh, factor=3)
conv2d_NCHWc_kw_o, conv2d_NCHWc_kw_i = s[conv2d_NCHWc].split(conv2d_NCHWc_kw, factor=3)
s[conv2d_NCHWc].reorder(conv2d_NCHWc_n_o_o_o, conv2d_NCHWc_oc_chunk_o_o_o, conv2d_NCHWc_oh_o_o_o, conv2d_NCHWc_ow_o_o_o, conv2d_NCHWc_oc_block_o_o_o, conv2d_NCHWc_n_o_o_i, conv2d_NCHWc_oc_chunk_o_o_i, conv2d_NCHWc_oh_o_o_i, conv2d_NCHWc_ow_o_o_i, conv2d_NCHWc_oc_block_o_o_i, conv2d_NCHWc_ic_o, conv2d_NCHWc_kh_o, conv2d_NCHWc_kw_o, conv2d_NCHWc_n_o_i, conv2d_NCHWc_oc_chunk_o_i, conv2d_NCHWc_oh_o_i, conv2d_NCHWc_ow_o_i, conv2d_NCHWc_oc_block_o_i, conv2d_NCHWc_ic_i, conv2d_NCHWc_kh_i, conv2d_NCHWc_kw_i, conv2d_NCHWc_n_i, conv2d_NCHWc_oc_chunk_i, conv2d_NCHWc_oh_i, conv2d_NCHWc_ow_i, conv2d_NCHWc_oc_block_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=2)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=1)
T_relu_ax2_o_i, T_relu_ax2_i = s[T_relu].split(T_relu_ax2, factor=4)
T_relu_ax2_o_o, T_relu_ax2_o_i = s[T_relu].split(T_relu_ax2_o_i, factor=1)
T_relu_ax3_o_i, T_relu_ax3_i = s[T_relu].split(T_relu_ax3, factor=12)
T_relu_ax3_o_o, T_relu_ax3_o_i = s[T_relu].split(T_relu_ax3_o_i, factor=1)
T_relu_ax4_o_i, T_relu_ax4_i = s[T_relu].split(T_relu_ax4, factor=16)
T_relu_ax4_o_o, T_relu_ax4_o_i = s[T_relu].split(T_relu_ax4_o_i, factor=1)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax2_o_i, T_relu_ax3_o_i, T_relu_ax4_o_i, T_relu_ax0_i, T_relu_ax1_i, T_relu_ax2_i, T_relu_ax3_i, T_relu_ax4_i)
s[conv2d_NCHWc].compute_at(s[T_relu], T_relu_ax4_o_i)
s[data_pad].compute_at(s[conv2d_NCHWc], conv2d_NCHWc_ic_o)
T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax2_o_o, T_relu_ax3_o_o, T_relu_ax4_o_o, T_relu_ax0_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax2_o_o_fused_ax3_o_o_fused_ax4_o_o_fused_ax0_o_i_fused)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "auto_unroll_max_step", 512)
s[conv2d_NCHWc].pragma(conv2d_NCHWc_n_o_o_o, "unroll_explicit", True)
s[data_pad].vectorize(data_pad_i4)
s[conv2d_NCHWc].vectorize(conv2d_NCHWc_oc_block_i)
s[T_relu].vectorize(T_relu_ax4_i)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [73728], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [2359296], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [512], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [73728], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 32, 12, 12, 16], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [32, 32, 3, 3, 16, 16], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 32, 1, 1, 16], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 32, 12, 12, 16], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused: int32, 0, 48) "parallel" {
    allocate(conv2d_NCHWc: Pointer(global float32x16), float32x16, [96]), storage_scope = global;
    allocate(data_pad: Pointer(global float32), float32, [1344]), storage_scope = global {
      conv2d_NCHWc_1: Buffer(conv2d_NCHWc, float32x16, [96], [])[0] = broadcast(0f32, 16)
      conv2d_NCHWc_1[1] = broadcast(0f32, 16)
      conv2d_NCHWc_1[2] = broadcast(0f32, 16)
      conv2d_NCHWc_1[3] = broadcast(0f32, 16)
      conv2d_NCHWc_1[12] = broadcast(0f32, 16)
      conv2d_NCHWc_1[13] = broadcast(0f32, 16)
      conv2d_NCHWc_1[14] = broadcast(0f32, 16)
      conv2d_NCHWc_1[15] = broadcast(0f32, 16)
      conv2d_NCHWc_1[48] = broadcast(0f32, 16)
      conv2d_NCHWc_1[49] = broadcast(0f32, 16)
      conv2d_NCHWc_1[50] = broadcast(0f32, 16)
      conv2d_NCHWc_1[51] = broadcast(0f32, 16)
      conv2d_NCHWc_1[60] = broadcast(0f32, 16)
      conv2d_NCHWc_1[61] = broadcast(0f32, 16)
      conv2d_NCHWc_1[62] = broadcast(0f32, 16)
      conv2d_NCHWc_1[63] = broadcast(0f32, 16)
      conv2d_NCHWc_1[4] = broadcast(0f32, 16)
      conv2d_NCHWc_1[5] = broadcast(0f32, 16)
      conv2d_NCHWc_1[6] = broadcast(0f32, 16)
      conv2d_NCHWc_1[7] = broadcast(0f32, 16)
      conv2d_NCHWc_1[16] = broadcast(0f32, 16)
      conv2d_NCHWc_1[17] = broadcast(0f32, 16)
      conv2d_NCHWc_1[18] = broadcast(0f32, 16)
      conv2d_NCHWc_1[19] = broadcast(0f32, 16)
      conv2d_NCHWc_1[52] = broadcast(0f32, 16)
      conv2d_NCHWc_1[53] = broadcast(0f32, 16)
      conv2d_NCHWc_1[54] = broadcast(0f32, 16)
      conv2d_NCHWc_1[55] = broadcast(0f32, 16)
      conv2d_NCHWc_1[64] = broadcast(0f32, 16)
      conv2d_NCHWc_1[65] = broadcast(0f32, 16)
      conv2d_NCHWc_1[66] = broadcast(0f32, 16)
      conv2d_NCHWc_1[67] = broadcast(0f32, 16)
      conv2d_NCHWc_1[8] = broadcast(0f32, 16)
      conv2d_NCHWc_1[9] = broadcast(0f32, 16)
      conv2d_NCHWc_1[10] = broadcast(0f32, 16)
      conv2d_NCHWc_1[11] = broadcast(0f32, 16)
      conv2d_NCHWc_1[20] = broadcast(0f32, 16)
      conv2d_NCHWc_1[21] = broadcast(0f32, 16)
      conv2d_NCHWc_1[22] = broadcast(0f32, 16)
      conv2d_NCHWc_1[23] = broadcast(0f32, 16)
      conv2d_NCHWc_1[56] = broadcast(0f32, 16)
      conv2d_NCHWc_1[57] = broadcast(0f32, 16)
      conv2d_NCHWc_1[58] = broadcast(0f32, 16)
      conv2d_NCHWc_1[59] = broadcast(0f32, 16)
      conv2d_NCHWc_1[68] = broadcast(0f32, 16)
      conv2d_NCHWc_1[69] = broadcast(0f32, 16)
      conv2d_NCHWc_1[70] = broadcast(0f32, 16)
      conv2d_NCHWc_1[71] = broadcast(0f32, 16)
      conv2d_NCHWc_1[24] = broadcast(0f32, 16)
      conv2d_NCHWc_1[25] = broadcast(0f32, 16)
      conv2d_NCHWc_1[26] = broadcast(0f32, 16)
      conv2d_NCHWc_1[27] = broadcast(0f32, 16)
      conv2d_NCHWc_1[36] = broadcast(0f32, 16)
      conv2d_NCHWc_1[37] = broadcast(0f32, 16)
      conv2d_NCHWc_1[38] = broadcast(0f32, 16)
      conv2d_NCHWc_1[39] = broadcast(0f32, 16)
      conv2d_NCHWc_1[72] = broadcast(0f32, 16)
      conv2d_NCHWc_1[73] = broadcast(0f32, 16)
      conv2d_NCHWc_1[74] = broadcast(0f32, 16)
      conv2d_NCHWc_1[75] = broadcast(0f32, 16)
      conv2d_NCHWc_1[84] = broadcast(0f32, 16)
      conv2d_NCHWc_1[85] = broadcast(0f32, 16)
      conv2d_NCHWc_1[86] = broadcast(0f32, 16)
      conv2d_NCHWc_1[87] = broadcast(0f32, 16)
      conv2d_NCHWc_1[28] = broadcast(0f32, 16)
      conv2d_NCHWc_1[29] = broadcast(0f32, 16)
      conv2d_NCHWc_1[30] = broadcast(0f32, 16)
      conv2d_NCHWc_1[31] = broadcast(0f32, 16)
      conv2d_NCHWc_1[40] = broadcast(0f32, 16)
      conv2d_NCHWc_1[41] = broadcast(0f32, 16)
      conv2d_NCHWc_1[42] = broadcast(0f32, 16)
      conv2d_NCHWc_1[43] = broadcast(0f32, 16)
      conv2d_NCHWc_1[76] = broadcast(0f32, 16)
      conv2d_NCHWc_1[77] = broadcast(0f32, 16)
      conv2d_NCHWc_1[78] = broadcast(0f32, 16)
      conv2d_NCHWc_1[79] = broadcast(0f32, 16)
      conv2d_NCHWc_1[88] = broadcast(0f32, 16)
      conv2d_NCHWc_1[89] = broadcast(0f32, 16)
      conv2d_NCHWc_1[90] = broadcast(0f32, 16)
      conv2d_NCHWc_1[91] = broadcast(0f32, 16)
      conv2d_NCHWc_1[32] = broadcast(0f32, 16)
      conv2d_NCHWc_1[33] = broadcast(0f32, 16)
      conv2d_NCHWc_1[34] = broadcast(0f32, 16)
      conv2d_NCHWc_1[35] = broadcast(0f32, 16)
      conv2d_NCHWc_1[44] = broadcast(0f32, 16)
      conv2d_NCHWc_1[45] = broadcast(0f32, 16)
      conv2d_NCHWc_1[46] = broadcast(0f32, 16)
      conv2d_NCHWc_1[47] = broadcast(0f32, 16)
      conv2d_NCHWc_1[80] = broadcast(0f32, 16)
      conv2d_NCHWc_1[81] = broadcast(0f32, 16)
      conv2d_NCHWc_1[82] = broadcast(0f32, 16)
      conv2d_NCHWc_1[83] = broadcast(0f32, 16)
      conv2d_NCHWc_1[92] = broadcast(0f32, 16)
      conv2d_NCHWc_1[93] = broadcast(0f32, 16)
      conv2d_NCHWc_1[94] = broadcast(0f32, 16)
      conv2d_NCHWc_1[95] = broadcast(0f32, 16)
      for (ic.outer: int32, 0, 32) {
        let cse_var_4: int32 = floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused, 3)
        let cse_var_3: bool = (cse_var_4 < 2)
        let cse_var_2: bool = (1 <= cse_var_4)
        let cse_var_1: int32 = ((ic.outer*2304) + (cse_var_4*768))
         {
          data_pad_1: Buffer(data_pad, float32, [1344], [])[ramp(0, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(16, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 192), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(32, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 176), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(48, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 160), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(64, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 144), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(80, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 128), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(96, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 112), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(112, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 96), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(128, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 80), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(144, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 64), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(160, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 48), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(176, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 32), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(192, 1, 16)] = @tir.if_then_else(cse_var_2, placeholder[ramp((cse_var_1 - 16), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(208, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(224, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(240, 1, 16)] = placeholder[ramp(cse_var_1, 1, 16)]
          data_pad_1[ramp(256, 1, 16)] = placeholder[ramp((cse_var_1 + 16), 1, 16)]
          data_pad_1[ramp(272, 1, 16)] = placeholder[ramp((cse_var_1 + 32), 1, 16)]
          data_pad_1[ramp(288, 1, 16)] = placeholder[ramp((cse_var_1 + 48), 1, 16)]
          data_pad_1[ramp(304, 1, 16)] = placeholder[ramp((cse_var_1 + 64), 1, 16)]
          data_pad_1[ramp(320, 1, 16)] = placeholder[ramp((cse_var_1 + 80), 1, 16)]
          data_pad_1[ramp(336, 1, 16)] = placeholder[ramp((cse_var_1 + 96), 1, 16)]
          data_pad_1[ramp(352, 1, 16)] = placeholder[ramp((cse_var_1 + 112), 1, 16)]
          data_pad_1[ramp(368, 1, 16)] = placeholder[ramp((cse_var_1 + 128), 1, 16)]
          data_pad_1[ramp(384, 1, 16)] = placeholder[ramp((cse_var_1 + 144), 1, 16)]
          data_pad_1[ramp(400, 1, 16)] = placeholder[ramp((cse_var_1 + 160), 1, 16)]
          data_pad_1[ramp(416, 1, 16)] = placeholder[ramp((cse_var_1 + 176), 1, 16)]
          data_pad_1[ramp(432, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(448, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(464, 1, 16)] = placeholder[ramp((cse_var_1 + 192), 1, 16)]
          data_pad_1[ramp(480, 1, 16)] = placeholder[ramp((cse_var_1 + 208), 1, 16)]
          data_pad_1[ramp(496, 1, 16)] = placeholder[ramp((cse_var_1 + 224), 1, 16)]
          data_pad_1[ramp(512, 1, 16)] = placeholder[ramp((cse_var_1 + 240), 1, 16)]
          data_pad_1[ramp(528, 1, 16)] = placeholder[ramp((cse_var_1 + 256), 1, 16)]
          data_pad_1[ramp(544, 1, 16)] = placeholder[ramp((cse_var_1 + 272), 1, 16)]
          data_pad_1[ramp(560, 1, 16)] = placeholder[ramp((cse_var_1 + 288), 1, 16)]
          data_pad_1[ramp(576, 1, 16)] = placeholder[ramp((cse_var_1 + 304), 1, 16)]
          data_pad_1[ramp(592, 1, 16)] = placeholder[ramp((cse_var_1 + 320), 1, 16)]
          data_pad_1[ramp(608, 1, 16)] = placeholder[ramp((cse_var_1 + 336), 1, 16)]
          data_pad_1[ramp(624, 1, 16)] = placeholder[ramp((cse_var_1 + 352), 1, 16)]
          data_pad_1[ramp(640, 1, 16)] = placeholder[ramp((cse_var_1 + 368), 1, 16)]
          data_pad_1[ramp(656, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(672, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(688, 1, 16)] = placeholder[ramp((cse_var_1 + 384), 1, 16)]
          data_pad_1[ramp(704, 1, 16)] = placeholder[ramp((cse_var_1 + 400), 1, 16)]
          data_pad_1[ramp(720, 1, 16)] = placeholder[ramp((cse_var_1 + 416), 1, 16)]
          data_pad_1[ramp(736, 1, 16)] = placeholder[ramp((cse_var_1 + 432), 1, 16)]
          data_pad_1[ramp(752, 1, 16)] = placeholder[ramp((cse_var_1 + 448), 1, 16)]
          data_pad_1[ramp(768, 1, 16)] = placeholder[ramp((cse_var_1 + 464), 1, 16)]
          data_pad_1[ramp(784, 1, 16)] = placeholder[ramp((cse_var_1 + 480), 1, 16)]
          data_pad_1[ramp(800, 1, 16)] = placeholder[ramp((cse_var_1 + 496), 1, 16)]
          data_pad_1[ramp(816, 1, 16)] = placeholder[ramp((cse_var_1 + 512), 1, 16)]
          data_pad_1[ramp(832, 1, 16)] = placeholder[ramp((cse_var_1 + 528), 1, 16)]
          data_pad_1[ramp(848, 1, 16)] = placeholder[ramp((cse_var_1 + 544), 1, 16)]
          data_pad_1[ramp(864, 1, 16)] = placeholder[ramp((cse_var_1 + 560), 1, 16)]
          data_pad_1[ramp(880, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(896, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(912, 1, 16)] = placeholder[ramp((cse_var_1 + 576), 1, 16)]
          data_pad_1[ramp(928, 1, 16)] = placeholder[ramp((cse_var_1 + 592), 1, 16)]
          data_pad_1[ramp(944, 1, 16)] = placeholder[ramp((cse_var_1 + 608), 1, 16)]
          data_pad_1[ramp(960, 1, 16)] = placeholder[ramp((cse_var_1 + 624), 1, 16)]
          data_pad_1[ramp(976, 1, 16)] = placeholder[ramp((cse_var_1 + 640), 1, 16)]
          data_pad_1[ramp(992, 1, 16)] = placeholder[ramp((cse_var_1 + 656), 1, 16)]
          data_pad_1[ramp(1008, 1, 16)] = placeholder[ramp((cse_var_1 + 672), 1, 16)]
          data_pad_1[ramp(1024, 1, 16)] = placeholder[ramp((cse_var_1 + 688), 1, 16)]
          data_pad_1[ramp(1040, 1, 16)] = placeholder[ramp((cse_var_1 + 704), 1, 16)]
          data_pad_1[ramp(1056, 1, 16)] = placeholder[ramp((cse_var_1 + 720), 1, 16)]
          data_pad_1[ramp(1072, 1, 16)] = placeholder[ramp((cse_var_1 + 736), 1, 16)]
          data_pad_1[ramp(1088, 1, 16)] = placeholder[ramp((cse_var_1 + 752), 1, 16)]
          data_pad_1[ramp(1104, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(1120, 1, 16)] = broadcast(0f32, 16)
          data_pad_1[ramp(1136, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 768), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1152, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 784), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1168, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 800), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1184, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 816), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1200, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 832), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1216, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 848), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1232, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 864), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1248, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 880), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1264, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 896), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1280, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 912), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1296, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 928), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1312, 1, 16)] = @tir.if_then_else(cse_var_3, placeholder[ramp((cse_var_1 + 944), 1, 16)], broadcast(0f32, 16), dtype=float32x16)
          data_pad_1[ramp(1328, 1, 16)] = broadcast(0f32, 16)
          for (oh.outer.inner: int32, 0, 2) {
            for (ow.outer.inner: int32, 0, 3) {
              for (ic.inner: int32, 0, 16) {
                let cse_var_62: int32 = ((oh.outer.inner*24) + (ow.outer.inner*4))
                let cse_var_61: int32 = (cse_var_62 + 1)
                let cse_var_60: int32 = (cse_var_62 + 12)
                let cse_var_59: int32 = (cse_var_62 + 14)
                let cse_var_58: int32 = (cse_var_62 + 15)
                let cse_var_57: int32 = (cse_var_62 + 2)
                let cse_var_56: int32 = (cse_var_62 + 3)
                let cse_var_55: int32 = (cse_var_62 + 48)
                let cse_var_54: int32 = (cse_var_62 + 49)
                let cse_var_53: int32 = (cse_var_62 + 50)
                let cse_var_52: int32 = (cse_var_62 + 51)
                let cse_var_51: int32 = (cse_var_62 + 60)
                let cse_var_50: int32 = (cse_var_62 + 61)
                let cse_var_49: int32 = (cse_var_62 + 62)
                let cse_var_48: int32 = (cse_var_62 + 13)
                let cse_var_47: int32 = (cse_var_62 + 63)
                let cse_var_46: int32 = (((oh.outer.inner*448) + (ow.outer.inner*64)) + ic.inner)
                let cse_var_45: int32 = (cse_var_46 + 464)
                let cse_var_44: int32 = (cse_var_46 + 448)
                let cse_var_43: int32 = (cse_var_46 + 32)
                let cse_var_42: int32 = (cse_var_46 + 304)
                let cse_var_41: int32 = (cse_var_46 + 288)
                let cse_var_40: int32 = (cse_var_46 + 272)
                let cse_var_39: int32 = (cse_var_46 + 256)
                let cse_var_38: int32 = (cse_var_46 + 240)
                let cse_var_37: int32 = (cse_var_46 + 224)
                let cse_var_36: int32 = (cse_var_46 + 16)
                let cse_var_35: int32 = (cse_var_46 + 480)
                let cse_var_34: int32 = (cse_var_46 + 48)
                let cse_var_33: int32 = (cse_var_46 + 512)
                let cse_var_32: int32 = (cse_var_46 + 528)
                let cse_var_31: int32 = (cse_var_46 + 64)
                let cse_var_30: int32 = (cse_var_46 + 672)
                let cse_var_29: int32 = (cse_var_46 + 688)
                let cse_var_28: int32 = (cse_var_46 + 704)
                let cse_var_27: int32 = (cse_var_46 + 720)
                let cse_var_26: int32 = (cse_var_46 + 736)
                let cse_var_25: int32 = (cse_var_46 + 752)
                let cse_var_24: int32 = (cse_var_46 + 80)
                let cse_var_23: int32 = (cse_var_46 + 496)
                let cse_var_22: int32 = (((floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused, 3)*147456) + (ic.outer*2304)) + (ic.inner*16))
                let cse_var_21: int32 = (cse_var_22 + 73984)
                let cse_var_20: int32 = (cse_var_22 + 512)
                let cse_var_19: int32 = (cse_var_22 + 256)
                let cse_var_18: int32 = (cse_var_22 + 2048)
                let cse_var_17: int32 = (cse_var_22 + 1792)
                let cse_var_16: int32 = (cse_var_22 + 1536)
                let cse_var_15: int32 = (cse_var_22 + 1280)
                let cse_var_14: int32 = (cse_var_22 + 73728)
                let cse_var_13: int32 = (cse_var_22 + 74240)
                let cse_var_12: int32 = (cse_var_22 + 74496)
                let cse_var_11: int32 = (cse_var_22 + 74752)
                let cse_var_10: int32 = (cse_var_22 + 75008)
                let cse_var_9: int32 = (cse_var_22 + 75264)
                let cse_var_8: int32 = (cse_var_22 + 75776)
                let cse_var_7: int32 = (cse_var_22 + 768)
                let cse_var_6: int32 = (cse_var_22 + 1024)
                let cse_var_5: int32 = (cse_var_22 + 75520)
                 {
                  conv2d_NCHWc_1[cse_var_62] = (conv2d_NCHWc_1[cse_var_62] + (broadcast(data_pad_1[cse_var_46], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_61] = (conv2d_NCHWc_1[cse_var_61] + (broadcast(data_pad_1[cse_var_36], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_57] = (conv2d_NCHWc_1[cse_var_57] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_56] = (conv2d_NCHWc_1[cse_var_56] + (broadcast(data_pad_1[cse_var_34], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_60] = (conv2d_NCHWc_1[cse_var_60] + (broadcast(data_pad_1[cse_var_37], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_48] = (conv2d_NCHWc_1[cse_var_48] + (broadcast(data_pad_1[cse_var_38], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_59] = (conv2d_NCHWc_1[cse_var_59] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_58] = (conv2d_NCHWc_1[cse_var_58] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_22, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_55] = (conv2d_NCHWc_1[cse_var_55] + (broadcast(data_pad_1[cse_var_46], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_54] = (conv2d_NCHWc_1[cse_var_54] + (broadcast(data_pad_1[cse_var_36], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_53] = (conv2d_NCHWc_1[cse_var_53] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_52] = (conv2d_NCHWc_1[cse_var_52] + (broadcast(data_pad_1[cse_var_34], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_51] = (conv2d_NCHWc_1[cse_var_51] + (broadcast(data_pad_1[cse_var_37], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_50] = (conv2d_NCHWc_1[cse_var_50] + (broadcast(data_pad_1[cse_var_38], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_49] = (conv2d_NCHWc_1[cse_var_49] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_47] = (conv2d_NCHWc_1[cse_var_47] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_14, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_62] = (conv2d_NCHWc_1[cse_var_62] + (broadcast(data_pad_1[cse_var_36], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_61] = (conv2d_NCHWc_1[cse_var_61] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_57] = (conv2d_NCHWc_1[cse_var_57] + (broadcast(data_pad_1[cse_var_34], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_56] = (conv2d_NCHWc_1[cse_var_56] + (broadcast(data_pad_1[cse_var_31], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_60] = (conv2d_NCHWc_1[cse_var_60] + (broadcast(data_pad_1[cse_var_38], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_48] = (conv2d_NCHWc_1[cse_var_48] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_59] = (conv2d_NCHWc_1[cse_var_59] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_58] = (conv2d_NCHWc_1[cse_var_58] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_19, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_55] = (conv2d_NCHWc_1[cse_var_55] + (broadcast(data_pad_1[cse_var_36], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_54] = (conv2d_NCHWc_1[cse_var_54] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_53] = (conv2d_NCHWc_1[cse_var_53] + (broadcast(data_pad_1[cse_var_34], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_52] = (conv2d_NCHWc_1[cse_var_52] + (broadcast(data_pad_1[cse_var_31], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_51] = (conv2d_NCHWc_1[cse_var_51] + (broadcast(data_pad_1[cse_var_38], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_50] = (conv2d_NCHWc_1[cse_var_50] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_49] = (conv2d_NCHWc_1[cse_var_49] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_47] = (conv2d_NCHWc_1[cse_var_47] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_21, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_62] = (conv2d_NCHWc_1[cse_var_62] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_61] = (conv2d_NCHWc_1[cse_var_61] + (broadcast(data_pad_1[cse_var_34], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_57] = (conv2d_NCHWc_1[cse_var_57] + (broadcast(data_pad_1[cse_var_31], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_56] = (conv2d_NCHWc_1[cse_var_56] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_60] = (conv2d_NCHWc_1[cse_var_60] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_48] = (conv2d_NCHWc_1[cse_var_48] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_59] = (conv2d_NCHWc_1[cse_var_59] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_58] = (conv2d_NCHWc_1[cse_var_58] + (broadcast(data_pad_1[cse_var_42], 16)*placeholder_1[ramp(cse_var_20, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_55] = (conv2d_NCHWc_1[cse_var_55] + (broadcast(data_pad_1[cse_var_43], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_54] = (conv2d_NCHWc_1[cse_var_54] + (broadcast(data_pad_1[cse_var_34], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_53] = (conv2d_NCHWc_1[cse_var_53] + (broadcast(data_pad_1[cse_var_31], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_52] = (conv2d_NCHWc_1[cse_var_52] + (broadcast(data_pad_1[cse_var_24], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_51] = (conv2d_NCHWc_1[cse_var_51] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_50] = (conv2d_NCHWc_1[cse_var_50] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_49] = (conv2d_NCHWc_1[cse_var_49] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_47] = (conv2d_NCHWc_1[cse_var_47] + (broadcast(data_pad_1[cse_var_42], 16)*placeholder_1[ramp(cse_var_13, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_62] = (conv2d_NCHWc_1[cse_var_62] + (broadcast(data_pad_1[cse_var_37], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_61] = (conv2d_NCHWc_1[cse_var_61] + (broadcast(data_pad_1[cse_var_38], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_57] = (conv2d_NCHWc_1[cse_var_57] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_56] = (conv2d_NCHWc_1[cse_var_56] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_60] = (conv2d_NCHWc_1[cse_var_60] + (broadcast(data_pad_1[cse_var_44], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_48] = (conv2d_NCHWc_1[cse_var_48] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_59] = (conv2d_NCHWc_1[cse_var_59] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_58] = (conv2d_NCHWc_1[cse_var_58] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_7, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_55] = (conv2d_NCHWc_1[cse_var_55] + (broadcast(data_pad_1[cse_var_37], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_54] = (conv2d_NCHWc_1[cse_var_54] + (broadcast(data_pad_1[cse_var_38], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_53] = (conv2d_NCHWc_1[cse_var_53] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_52] = (conv2d_NCHWc_1[cse_var_52] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_51] = (conv2d_NCHWc_1[cse_var_51] + (broadcast(data_pad_1[cse_var_44], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_50] = (conv2d_NCHWc_1[cse_var_50] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_49] = (conv2d_NCHWc_1[cse_var_49] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_47] = (conv2d_NCHWc_1[cse_var_47] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_12, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_62] = (conv2d_NCHWc_1[cse_var_62] + (broadcast(data_pad_1[cse_var_38], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_61] = (conv2d_NCHWc_1[cse_var_61] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_57] = (conv2d_NCHWc_1[cse_var_57] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_56] = (conv2d_NCHWc_1[cse_var_56] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_60] = (conv2d_NCHWc_1[cse_var_60] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_48] = (conv2d_NCHWc_1[cse_var_48] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_59] = (conv2d_NCHWc_1[cse_var_59] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_58] = (conv2d_NCHWc_1[cse_var_58] + (broadcast(data_pad_1[cse_var_33], 16)*placeholder_1[ramp(cse_var_6, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_55] = (conv2d_NCHWc_1[cse_var_55] + (broadcast(data_pad_1[cse_var_38], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_54] = (conv2d_NCHWc_1[cse_var_54] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_53] = (conv2d_NCHWc_1[cse_var_53] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_52] = (conv2d_NCHWc_1[cse_var_52] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_51] = (conv2d_NCHWc_1[cse_var_51] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_50] = (conv2d_NCHWc_1[cse_var_50] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_49] = (conv2d_NCHWc_1[cse_var_49] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_47] = (conv2d_NCHWc_1[cse_var_47] + (broadcast(data_pad_1[cse_var_33], 16)*placeholder_1[ramp(cse_var_11, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_62] = (conv2d_NCHWc_1[cse_var_62] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_61] = (conv2d_NCHWc_1[cse_var_61] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_57] = (conv2d_NCHWc_1[cse_var_57] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_56] = (conv2d_NCHWc_1[cse_var_56] + (broadcast(data_pad_1[cse_var_42], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_60] = (conv2d_NCHWc_1[cse_var_60] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_48] = (conv2d_NCHWc_1[cse_var_48] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_59] = (conv2d_NCHWc_1[cse_var_59] + (broadcast(data_pad_1[cse_var_33], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_58] = (conv2d_NCHWc_1[cse_var_58] + (broadcast(data_pad_1[cse_var_32], 16)*placeholder_1[ramp(cse_var_15, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_55] = (conv2d_NCHWc_1[cse_var_55] + (broadcast(data_pad_1[cse_var_39], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_54] = (conv2d_NCHWc_1[cse_var_54] + (broadcast(data_pad_1[cse_var_40], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_53] = (conv2d_NCHWc_1[cse_var_53] + (broadcast(data_pad_1[cse_var_41], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_52] = (conv2d_NCHWc_1[cse_var_52] + (broadcast(data_pad_1[cse_var_42], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_51] = (conv2d_NCHWc_1[cse_var_51] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_50] = (conv2d_NCHWc_1[cse_var_50] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_49] = (conv2d_NCHWc_1[cse_var_49] + (broadcast(data_pad_1[cse_var_33], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_47] = (conv2d_NCHWc_1[cse_var_47] + (broadcast(data_pad_1[cse_var_32], 16)*placeholder_1[ramp(cse_var_10, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_62] = (conv2d_NCHWc_1[cse_var_62] + (broadcast(data_pad_1[cse_var_44], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_61] = (conv2d_NCHWc_1[cse_var_61] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_57] = (conv2d_NCHWc_1[cse_var_57] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_56] = (conv2d_NCHWc_1[cse_var_56] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_60] = (conv2d_NCHWc_1[cse_var_60] + (broadcast(data_pad_1[cse_var_30], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_48] = (conv2d_NCHWc_1[cse_var_48] + (broadcast(data_pad_1[cse_var_29], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_59] = (conv2d_NCHWc_1[cse_var_59] + (broadcast(data_pad_1[cse_var_28], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_58] = (conv2d_NCHWc_1[cse_var_58] + (broadcast(data_pad_1[cse_var_27], 16)*placeholder_1[ramp(cse_var_16, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_55] = (conv2d_NCHWc_1[cse_var_55] + (broadcast(data_pad_1[cse_var_44], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_54] = (conv2d_NCHWc_1[cse_var_54] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_53] = (conv2d_NCHWc_1[cse_var_53] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_52] = (conv2d_NCHWc_1[cse_var_52] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_51] = (conv2d_NCHWc_1[cse_var_51] + (broadcast(data_pad_1[cse_var_30], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_50] = (conv2d_NCHWc_1[cse_var_50] + (broadcast(data_pad_1[cse_var_29], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_49] = (conv2d_NCHWc_1[cse_var_49] + (broadcast(data_pad_1[cse_var_28], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_47] = (conv2d_NCHWc_1[cse_var_47] + (broadcast(data_pad_1[cse_var_27], 16)*placeholder_1[ramp(cse_var_9, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_62] = (conv2d_NCHWc_1[cse_var_62] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_61] = (conv2d_NCHWc_1[cse_var_61] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_57] = (conv2d_NCHWc_1[cse_var_57] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_56] = (conv2d_NCHWc_1[cse_var_56] + (broadcast(data_pad_1[cse_var_33], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_60] = (conv2d_NCHWc_1[cse_var_60] + (broadcast(data_pad_1[cse_var_29], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_48] = (conv2d_NCHWc_1[cse_var_48] + (broadcast(data_pad_1[cse_var_28], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_59] = (conv2d_NCHWc_1[cse_var_59] + (broadcast(data_pad_1[cse_var_27], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_58] = (conv2d_NCHWc_1[cse_var_58] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_17, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_55] = (conv2d_NCHWc_1[cse_var_55] + (broadcast(data_pad_1[cse_var_45], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_54] = (conv2d_NCHWc_1[cse_var_54] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_53] = (conv2d_NCHWc_1[cse_var_53] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_52] = (conv2d_NCHWc_1[cse_var_52] + (broadcast(data_pad_1[cse_var_33], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_51] = (conv2d_NCHWc_1[cse_var_51] + (broadcast(data_pad_1[cse_var_29], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_50] = (conv2d_NCHWc_1[cse_var_50] + (broadcast(data_pad_1[cse_var_28], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_49] = (conv2d_NCHWc_1[cse_var_49] + (broadcast(data_pad_1[cse_var_27], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_47] = (conv2d_NCHWc_1[cse_var_47] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_5, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_62] = (conv2d_NCHWc_1[cse_var_62] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_61] = (conv2d_NCHWc_1[cse_var_61] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_57] = (conv2d_NCHWc_1[cse_var_57] + (broadcast(data_pad_1[cse_var_33], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_56] = (conv2d_NCHWc_1[cse_var_56] + (broadcast(data_pad_1[cse_var_32], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_60] = (conv2d_NCHWc_1[cse_var_60] + (broadcast(data_pad_1[cse_var_28], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_48] = (conv2d_NCHWc_1[cse_var_48] + (broadcast(data_pad_1[cse_var_27], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_59] = (conv2d_NCHWc_1[cse_var_59] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_58] = (conv2d_NCHWc_1[cse_var_58] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_18, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_55] = (conv2d_NCHWc_1[cse_var_55] + (broadcast(data_pad_1[cse_var_35], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_54] = (conv2d_NCHWc_1[cse_var_54] + (broadcast(data_pad_1[cse_var_23], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_53] = (conv2d_NCHWc_1[cse_var_53] + (broadcast(data_pad_1[cse_var_33], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_52] = (conv2d_NCHWc_1[cse_var_52] + (broadcast(data_pad_1[cse_var_32], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_51] = (conv2d_NCHWc_1[cse_var_51] + (broadcast(data_pad_1[cse_var_28], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_50] = (conv2d_NCHWc_1[cse_var_50] + (broadcast(data_pad_1[cse_var_27], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_49] = (conv2d_NCHWc_1[cse_var_49] + (broadcast(data_pad_1[cse_var_26], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                  conv2d_NCHWc_1[cse_var_47] = (conv2d_NCHWc_1[cse_var_47] + (broadcast(data_pad_1[cse_var_25], 16)*placeholder_1[ramp(cse_var_8, 1, 16)]))
                }
              }
            }
          }
        }
      }
      for (ax1.inner: int32, 0, 2) {
        for (ax2.inner: int32, 0, 4) {
          for (ax3.inner: int32, 0, 12) {
            let cse_var_63: int32 = floordiv(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused, 3)
            T_relu[ramp((((((cse_var_63*4608) + (ax1.inner*2304)) + (floormod(ax0.outer.outer.ax1.outer.outer.fused.ax2.outer.outer.fused.ax3.outer.outer.fused.ax4.outer.outer.fused.ax0.outer.inner.fused, 3)*768)) + (ax2.inner*192)) + (ax3.inner*16)), 1, 16)] = max((conv2d_NCHWc_1[(((ax1.inner*48) + (ax2.inner*12)) + ax3.inner)] + placeholder_2[ramp(((cse_var_63*32) + (ax1.inner*16)), 1, 16)]), broadcast(0f32, 16))
          }
        }
      }
    }
  }
}


==== Task 12: vm_mod_fused_nn_dense_add_nn_relu (weight 1 key: ["7c7999b7bbdaec23cf87b49ec0ce3a97", [1, 18432], [4096, 18432], [1, 4096], [1, 4096]]) =====
placeholder = PLACEHOLDER [1, 18432]
placeholder = PLACEHOLDER [4096, 18432]
T_matmul_NT(i, j) += (placeholder[i, k]*placeholder[j, k])
placeholder = PLACEHOLDER [1, 4096]
T_add(ax0, ax1) = (T_matmul_NT[ax0, ax1] + placeholder[ax0, ax1])
T_relu(ax0, ax1) = max(T_add[ax0, ax1], 0f)


Trace for this task is: 
T_matmul_NT_i, T_matmul_NT_j, T_matmul_NT_k = tuple(T_matmul_NT.op.axis) + tuple(T_matmul_NT.op.reduce_axis)
T_add_ax0, T_add_ax1 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
T_relu_ax0, T_relu_ax1 = tuple(T_relu.op.axis) + tuple(T_relu.op.reduce_axis)
s[T_add].compute_inline()
T_matmul_NT_i_o_i, T_matmul_NT_i_i = s[T_matmul_NT].split(T_matmul_NT_i, factor=1)
T_matmul_NT_i_o_o_i, T_matmul_NT_i_o_i = s[T_matmul_NT].split(T_matmul_NT_i_o_i, factor=1)
T_matmul_NT_i_o_o_o, T_matmul_NT_i_o_o_i = s[T_matmul_NT].split(T_matmul_NT_i_o_o_i, factor=1)
T_matmul_NT_j_o_i, T_matmul_NT_j_i = s[T_matmul_NT].split(T_matmul_NT_j, factor=8)
T_matmul_NT_j_o_o_i, T_matmul_NT_j_o_i = s[T_matmul_NT].split(T_matmul_NT_j_o_i, factor=1)
T_matmul_NT_j_o_o_o, T_matmul_NT_j_o_o_i = s[T_matmul_NT].split(T_matmul_NT_j_o_o_i, factor=32)
T_matmul_NT_k_o, T_matmul_NT_k_i = s[T_matmul_NT].split(T_matmul_NT_k, factor=64)
s[T_matmul_NT].reorder(T_matmul_NT_i_o_o_o, T_matmul_NT_j_o_o_o, T_matmul_NT_i_o_o_i, T_matmul_NT_j_o_o_i, T_matmul_NT_k_o, T_matmul_NT_i_o_i, T_matmul_NT_j_o_i, T_matmul_NT_k_i, T_matmul_NT_i_i, T_matmul_NT_j_i)
T_relu_ax0_o_i, T_relu_ax0_i = s[T_relu].split(T_relu_ax0, factor=1)
T_relu_ax0_o_o, T_relu_ax0_o_i = s[T_relu].split(T_relu_ax0_o_i, factor=1)
T_relu_ax1_o_i, T_relu_ax1_i = s[T_relu].split(T_relu_ax1, factor=8)
T_relu_ax1_o_o, T_relu_ax1_o_i = s[T_relu].split(T_relu_ax1_o_i, factor=32)
s[T_relu].reorder(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax0_o_i, T_relu_ax1_o_i, T_relu_ax0_i, T_relu_ax1_i)
s[T_matmul_NT].compute_at(s[T_relu], T_relu_ax1_o_i)
T_relu_ax0_o_o_ax1_o_o_fused_ax0_o_i_fused = s[T_relu].fuse(T_relu_ax0_o_o, T_relu_ax1_o_o, T_relu_ax0_o_i)
s[T_relu].parallel(T_relu_ax0_o_o_ax1_o_o_fused_ax0_o_i_fused)
s[T_matmul_NT].pragma(T_matmul_NT_i_o_o_o, "auto_unroll_max_step", 512)
s[T_matmul_NT].pragma(T_matmul_NT_i_o_o_o, "unroll_explicit", True)


The best replacement found is:
@main = primfn(placeholder_3: handle, placeholder_4: handle, placeholder_5: handle, T_relu_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_6: Pointer(float32), float32, [18432], []),
             placeholder_1: Buffer(placeholder_7: Pointer(float32), float32, [75497472], []),
             placeholder_2: Buffer(placeholder_8: Pointer(float32), float32, [4096], []),
             T_relu: Buffer(T_relu_2: Pointer(float32), float32, [4096], [])}
  buffer_map = {placeholder_3: placeholder, placeholder_4: placeholder_1, placeholder_5: placeholder_2, T_relu_1: T_relu}
  preflattened_buffer_map = {placeholder_3: placeholder_9: Buffer(placeholder_6, float32, [1, 18432], []), placeholder_4: placeholder_10: Buffer(placeholder_7, float32, [16, 32, 1, 1, 288, 1, 64, 8], []), placeholder_5: placeholder_11: Buffer(placeholder_8, float32, [1, 4096], []), T_relu_1: T_relu_3: Buffer(T_relu_2, float32, [1, 4096], [])} {
  for (ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused: int32, 0, 16) "parallel" {
    allocate(T_matmul_NT: Pointer(global float32), float32, [8]), storage_scope = global;
    for (ax1.outer.inner: int32, 0, 32) {
      T_matmul_NT_1: Buffer(T_matmul_NT, float32, [8], [], align=32)[0] = 0f32
      T_matmul_NT_1[1] = 0f32
      T_matmul_NT_1[2] = 0f32
      T_matmul_NT_1[3] = 0f32
      T_matmul_NT_1[4] = 0f32
      T_matmul_NT_1[5] = 0f32
      T_matmul_NT_1[6] = 0f32
      T_matmul_NT_1[7] = 0f32
      for (k.outer: int32, 0, 288) {
        let cse_var_65: int32 = (k.outer*64)
        let cse_var_64: int32 = (cse_var_65 + 38)
        let cse_var_63: int32 = (cse_var_65 + 36)
        let cse_var_62: int32 = (cse_var_65 + 35)
        let cse_var_61: int32 = (cse_var_65 + 34)
        let cse_var_60: int32 = (cse_var_65 + 33)
        let cse_var_59: int32 = (cse_var_65 + 32)
        let cse_var_58: int32 = (cse_var_65 + 31)
        let cse_var_57: int32 = (cse_var_65 + 30)
        let cse_var_56: int32 = (cse_var_65 + 3)
        let cse_var_55: int32 = (cse_var_65 + 29)
        let cse_var_54: int32 = (cse_var_65 + 28)
        let cse_var_53: int32 = (cse_var_65 + 27)
        let cse_var_52: int32 = (cse_var_65 + 26)
        let cse_var_51: int32 = (cse_var_65 + 25)
        let cse_var_50: int32 = (cse_var_65 + 24)
        let cse_var_49: int32 = (cse_var_65 + 23)
        let cse_var_48: int32 = (cse_var_65 + 22)
        let cse_var_47: int32 = (cse_var_65 + 21)
        let cse_var_46: int32 = (cse_var_65 + 20)
        let cse_var_45: int32 = (cse_var_65 + 2)
        let cse_var_44: int32 = (cse_var_65 + 19)
        let cse_var_43: int32 = (cse_var_65 + 18)
        let cse_var_42: int32 = (cse_var_65 + 17)
        let cse_var_41: int32 = (cse_var_65 + 16)
        let cse_var_40: int32 = (cse_var_65 + 15)
        let cse_var_39: int32 = (cse_var_65 + 14)
        let cse_var_38: int32 = (cse_var_65 + 13)
        let cse_var_37: int32 = (cse_var_65 + 12)
        let cse_var_36: int32 = (cse_var_65 + 11)
        let cse_var_35: int32 = (cse_var_65 + 10)
        let cse_var_34: int32 = (cse_var_65 + 37)
        let cse_var_33: int32 = (cse_var_65 + 1)
        let cse_var_32: int32 = (cse_var_65 + 9)
        let cse_var_31: int32 = (cse_var_65 + 8)
        let cse_var_30: int32 = (cse_var_65 + 7)
        let cse_var_29: int32 = (cse_var_65 + 63)
        let cse_var_28: int32 = (cse_var_65 + 62)
        let cse_var_27: int32 = (cse_var_65 + 61)
        let cse_var_26: int32 = (cse_var_65 + 60)
        let cse_var_25: int32 = (cse_var_65 + 6)
        let cse_var_24: int32 = (cse_var_65 + 59)
        let cse_var_23: int32 = (cse_var_65 + 58)
        let cse_var_22: int32 = (cse_var_65 + 57)
        let cse_var_21: int32 = (cse_var_65 + 56)
        let cse_var_20: int32 = (cse_var_65 + 55)
        let cse_var_19: int32 = (cse_var_65 + 54)
        let cse_var_18: int32 = (cse_var_65 + 53)
        let cse_var_17: int32 = (cse_var_65 + 39)
        let cse_var_16: int32 = (cse_var_65 + 4)
        let cse_var_15: int32 = (cse_var_65 + 40)
        let cse_var_14: int32 = (cse_var_65 + 41)
        let cse_var_13: int32 = (cse_var_65 + 42)
        let cse_var_12: int32 = (cse_var_65 + 43)
        let cse_var_11: int32 = (cse_var_65 + 44)
        let cse_var_10: int32 = (cse_var_65 + 45)
        let cse_var_9: int32 = (cse_var_65 + 46)
        let cse_var_8: int32 = (cse_var_65 + 47)
        let cse_var_7: int32 = (cse_var_65 + 48)
        let cse_var_6: int32 = (cse_var_65 + 49)
        let cse_var_5: int32 = (cse_var_65 + 5)
        let cse_var_4: int32 = (cse_var_65 + 50)
        let cse_var_3: int32 = (cse_var_65 + 51)
        let cse_var_2: int32 = (cse_var_65 + 52)
        let cse_var_1: int32 = (((ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused*4718592) + (ax1.outer.inner*147456)) + (k.outer*512))
         {
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_65]*placeholder_1[cse_var_1]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_65]*placeholder_1[(cse_var_1 + 1)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_65]*placeholder_1[(cse_var_1 + 2)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_65]*placeholder_1[(cse_var_1 + 3)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_65]*placeholder_1[(cse_var_1 + 4)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_65]*placeholder_1[(cse_var_1 + 5)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_65]*placeholder_1[(cse_var_1 + 6)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_65]*placeholder_1[(cse_var_1 + 7)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_33]*placeholder_1[(cse_var_1 + 8)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_33]*placeholder_1[(cse_var_1 + 9)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_33]*placeholder_1[(cse_var_1 + 10)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_33]*placeholder_1[(cse_var_1 + 11)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_33]*placeholder_1[(cse_var_1 + 12)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_33]*placeholder_1[(cse_var_1 + 13)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_33]*placeholder_1[(cse_var_1 + 14)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_33]*placeholder_1[(cse_var_1 + 15)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_45]*placeholder_1[(cse_var_1 + 16)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_45]*placeholder_1[(cse_var_1 + 17)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_45]*placeholder_1[(cse_var_1 + 18)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_45]*placeholder_1[(cse_var_1 + 19)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_45]*placeholder_1[(cse_var_1 + 20)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_45]*placeholder_1[(cse_var_1 + 21)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_45]*placeholder_1[(cse_var_1 + 22)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_45]*placeholder_1[(cse_var_1 + 23)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_56]*placeholder_1[(cse_var_1 + 24)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_56]*placeholder_1[(cse_var_1 + 25)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_56]*placeholder_1[(cse_var_1 + 26)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_56]*placeholder_1[(cse_var_1 + 27)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_56]*placeholder_1[(cse_var_1 + 28)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_56]*placeholder_1[(cse_var_1 + 29)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_56]*placeholder_1[(cse_var_1 + 30)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_56]*placeholder_1[(cse_var_1 + 31)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_16]*placeholder_1[(cse_var_1 + 32)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_16]*placeholder_1[(cse_var_1 + 33)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_16]*placeholder_1[(cse_var_1 + 34)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_16]*placeholder_1[(cse_var_1 + 35)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_16]*placeholder_1[(cse_var_1 + 36)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_16]*placeholder_1[(cse_var_1 + 37)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_16]*placeholder_1[(cse_var_1 + 38)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_16]*placeholder_1[(cse_var_1 + 39)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_5]*placeholder_1[(cse_var_1 + 40)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_5]*placeholder_1[(cse_var_1 + 41)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_5]*placeholder_1[(cse_var_1 + 42)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_5]*placeholder_1[(cse_var_1 + 43)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_5]*placeholder_1[(cse_var_1 + 44)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_5]*placeholder_1[(cse_var_1 + 45)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_5]*placeholder_1[(cse_var_1 + 46)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_5]*placeholder_1[(cse_var_1 + 47)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_25]*placeholder_1[(cse_var_1 + 48)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_25]*placeholder_1[(cse_var_1 + 49)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_25]*placeholder_1[(cse_var_1 + 50)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_25]*placeholder_1[(cse_var_1 + 51)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_25]*placeholder_1[(cse_var_1 + 52)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_25]*placeholder_1[(cse_var_1 + 53)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_25]*placeholder_1[(cse_var_1 + 54)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_25]*placeholder_1[(cse_var_1 + 55)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_30]*placeholder_1[(cse_var_1 + 56)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_30]*placeholder_1[(cse_var_1 + 57)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_30]*placeholder_1[(cse_var_1 + 58)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_30]*placeholder_1[(cse_var_1 + 59)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_30]*placeholder_1[(cse_var_1 + 60)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_30]*placeholder_1[(cse_var_1 + 61)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_30]*placeholder_1[(cse_var_1 + 62)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_30]*placeholder_1[(cse_var_1 + 63)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_31]*placeholder_1[(cse_var_1 + 64)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_31]*placeholder_1[(cse_var_1 + 65)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_31]*placeholder_1[(cse_var_1 + 66)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_31]*placeholder_1[(cse_var_1 + 67)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_31]*placeholder_1[(cse_var_1 + 68)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_31]*placeholder_1[(cse_var_1 + 69)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_31]*placeholder_1[(cse_var_1 + 70)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_31]*placeholder_1[(cse_var_1 + 71)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_32]*placeholder_1[(cse_var_1 + 72)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_32]*placeholder_1[(cse_var_1 + 73)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_32]*placeholder_1[(cse_var_1 + 74)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_32]*placeholder_1[(cse_var_1 + 75)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_32]*placeholder_1[(cse_var_1 + 76)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_32]*placeholder_1[(cse_var_1 + 77)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_32]*placeholder_1[(cse_var_1 + 78)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_32]*placeholder_1[(cse_var_1 + 79)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_35]*placeholder_1[(cse_var_1 + 80)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_35]*placeholder_1[(cse_var_1 + 81)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_35]*placeholder_1[(cse_var_1 + 82)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_35]*placeholder_1[(cse_var_1 + 83)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_35]*placeholder_1[(cse_var_1 + 84)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_35]*placeholder_1[(cse_var_1 + 85)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_35]*placeholder_1[(cse_var_1 + 86)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_35]*placeholder_1[(cse_var_1 + 87)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_36]*placeholder_1[(cse_var_1 + 88)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_36]*placeholder_1[(cse_var_1 + 89)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_36]*placeholder_1[(cse_var_1 + 90)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_36]*placeholder_1[(cse_var_1 + 91)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_36]*placeholder_1[(cse_var_1 + 92)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_36]*placeholder_1[(cse_var_1 + 93)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_36]*placeholder_1[(cse_var_1 + 94)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_36]*placeholder_1[(cse_var_1 + 95)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_37]*placeholder_1[(cse_var_1 + 96)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_37]*placeholder_1[(cse_var_1 + 97)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_37]*placeholder_1[(cse_var_1 + 98)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_37]*placeholder_1[(cse_var_1 + 99)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_37]*placeholder_1[(cse_var_1 + 100)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_37]*placeholder_1[(cse_var_1 + 101)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_37]*placeholder_1[(cse_var_1 + 102)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_37]*placeholder_1[(cse_var_1 + 103)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_38]*placeholder_1[(cse_var_1 + 104)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_38]*placeholder_1[(cse_var_1 + 105)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_38]*placeholder_1[(cse_var_1 + 106)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_38]*placeholder_1[(cse_var_1 + 107)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_38]*placeholder_1[(cse_var_1 + 108)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_38]*placeholder_1[(cse_var_1 + 109)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_38]*placeholder_1[(cse_var_1 + 110)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_38]*placeholder_1[(cse_var_1 + 111)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_39]*placeholder_1[(cse_var_1 + 112)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_39]*placeholder_1[(cse_var_1 + 113)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_39]*placeholder_1[(cse_var_1 + 114)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_39]*placeholder_1[(cse_var_1 + 115)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_39]*placeholder_1[(cse_var_1 + 116)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_39]*placeholder_1[(cse_var_1 + 117)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_39]*placeholder_1[(cse_var_1 + 118)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_39]*placeholder_1[(cse_var_1 + 119)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_40]*placeholder_1[(cse_var_1 + 120)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_40]*placeholder_1[(cse_var_1 + 121)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_40]*placeholder_1[(cse_var_1 + 122)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_40]*placeholder_1[(cse_var_1 + 123)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_40]*placeholder_1[(cse_var_1 + 124)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_40]*placeholder_1[(cse_var_1 + 125)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_40]*placeholder_1[(cse_var_1 + 126)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_40]*placeholder_1[(cse_var_1 + 127)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_41]*placeholder_1[(cse_var_1 + 128)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_41]*placeholder_1[(cse_var_1 + 129)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_41]*placeholder_1[(cse_var_1 + 130)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_41]*placeholder_1[(cse_var_1 + 131)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_41]*placeholder_1[(cse_var_1 + 132)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_41]*placeholder_1[(cse_var_1 + 133)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_41]*placeholder_1[(cse_var_1 + 134)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_41]*placeholder_1[(cse_var_1 + 135)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_42]*placeholder_1[(cse_var_1 + 136)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_42]*placeholder_1[(cse_var_1 + 137)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_42]*placeholder_1[(cse_var_1 + 138)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_42]*placeholder_1[(cse_var_1 + 139)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_42]*placeholder_1[(cse_var_1 + 140)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_42]*placeholder_1[(cse_var_1 + 141)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_42]*placeholder_1[(cse_var_1 + 142)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_42]*placeholder_1[(cse_var_1 + 143)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_43]*placeholder_1[(cse_var_1 + 144)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_43]*placeholder_1[(cse_var_1 + 145)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_43]*placeholder_1[(cse_var_1 + 146)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_43]*placeholder_1[(cse_var_1 + 147)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_43]*placeholder_1[(cse_var_1 + 148)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_43]*placeholder_1[(cse_var_1 + 149)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_43]*placeholder_1[(cse_var_1 + 150)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_43]*placeholder_1[(cse_var_1 + 151)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_44]*placeholder_1[(cse_var_1 + 152)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_44]*placeholder_1[(cse_var_1 + 153)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_44]*placeholder_1[(cse_var_1 + 154)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_44]*placeholder_1[(cse_var_1 + 155)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_44]*placeholder_1[(cse_var_1 + 156)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_44]*placeholder_1[(cse_var_1 + 157)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_44]*placeholder_1[(cse_var_1 + 158)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_44]*placeholder_1[(cse_var_1 + 159)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_46]*placeholder_1[(cse_var_1 + 160)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_46]*placeholder_1[(cse_var_1 + 161)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_46]*placeholder_1[(cse_var_1 + 162)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_46]*placeholder_1[(cse_var_1 + 163)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_46]*placeholder_1[(cse_var_1 + 164)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_46]*placeholder_1[(cse_var_1 + 165)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_46]*placeholder_1[(cse_var_1 + 166)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_46]*placeholder_1[(cse_var_1 + 167)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_47]*placeholder_1[(cse_var_1 + 168)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_47]*placeholder_1[(cse_var_1 + 169)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_47]*placeholder_1[(cse_var_1 + 170)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_47]*placeholder_1[(cse_var_1 + 171)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_47]*placeholder_1[(cse_var_1 + 172)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_47]*placeholder_1[(cse_var_1 + 173)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_47]*placeholder_1[(cse_var_1 + 174)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_47]*placeholder_1[(cse_var_1 + 175)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_48]*placeholder_1[(cse_var_1 + 176)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_48]*placeholder_1[(cse_var_1 + 177)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_48]*placeholder_1[(cse_var_1 + 178)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_48]*placeholder_1[(cse_var_1 + 179)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_48]*placeholder_1[(cse_var_1 + 180)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_48]*placeholder_1[(cse_var_1 + 181)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_48]*placeholder_1[(cse_var_1 + 182)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_48]*placeholder_1[(cse_var_1 + 183)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_49]*placeholder_1[(cse_var_1 + 184)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_49]*placeholder_1[(cse_var_1 + 185)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_49]*placeholder_1[(cse_var_1 + 186)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_49]*placeholder_1[(cse_var_1 + 187)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_49]*placeholder_1[(cse_var_1 + 188)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_49]*placeholder_1[(cse_var_1 + 189)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_49]*placeholder_1[(cse_var_1 + 190)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_49]*placeholder_1[(cse_var_1 + 191)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_50]*placeholder_1[(cse_var_1 + 192)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_50]*placeholder_1[(cse_var_1 + 193)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_50]*placeholder_1[(cse_var_1 + 194)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_50]*placeholder_1[(cse_var_1 + 195)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_50]*placeholder_1[(cse_var_1 + 196)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_50]*placeholder_1[(cse_var_1 + 197)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_50]*placeholder_1[(cse_var_1 + 198)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_50]*placeholder_1[(cse_var_1 + 199)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_51]*placeholder_1[(cse_var_1 + 200)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_51]*placeholder_1[(cse_var_1 + 201)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_51]*placeholder_1[(cse_var_1 + 202)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_51]*placeholder_1[(cse_var_1 + 203)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_51]*placeholder_1[(cse_var_1 + 204)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_51]*placeholder_1[(cse_var_1 + 205)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_51]*placeholder_1[(cse_var_1 + 206)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_51]*placeholder_1[(cse_var_1 + 207)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_52]*placeholder_1[(cse_var_1 + 208)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_52]*placeholder_1[(cse_var_1 + 209)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_52]*placeholder_1[(cse_var_1 + 210)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_52]*placeholder_1[(cse_var_1 + 211)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_52]*placeholder_1[(cse_var_1 + 212)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_52]*placeholder_1[(cse_var_1 + 213)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_52]*placeholder_1[(cse_var_1 + 214)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_52]*placeholder_1[(cse_var_1 + 215)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_53]*placeholder_1[(cse_var_1 + 216)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_53]*placeholder_1[(cse_var_1 + 217)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_53]*placeholder_1[(cse_var_1 + 218)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_53]*placeholder_1[(cse_var_1 + 219)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_53]*placeholder_1[(cse_var_1 + 220)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_53]*placeholder_1[(cse_var_1 + 221)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_53]*placeholder_1[(cse_var_1 + 222)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_53]*placeholder_1[(cse_var_1 + 223)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_54]*placeholder_1[(cse_var_1 + 224)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_54]*placeholder_1[(cse_var_1 + 225)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_54]*placeholder_1[(cse_var_1 + 226)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_54]*placeholder_1[(cse_var_1 + 227)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_54]*placeholder_1[(cse_var_1 + 228)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_54]*placeholder_1[(cse_var_1 + 229)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_54]*placeholder_1[(cse_var_1 + 230)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_54]*placeholder_1[(cse_var_1 + 231)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_55]*placeholder_1[(cse_var_1 + 232)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_55]*placeholder_1[(cse_var_1 + 233)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_55]*placeholder_1[(cse_var_1 + 234)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_55]*placeholder_1[(cse_var_1 + 235)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_55]*placeholder_1[(cse_var_1 + 236)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_55]*placeholder_1[(cse_var_1 + 237)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_55]*placeholder_1[(cse_var_1 + 238)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_55]*placeholder_1[(cse_var_1 + 239)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_57]*placeholder_1[(cse_var_1 + 240)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_57]*placeholder_1[(cse_var_1 + 241)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_57]*placeholder_1[(cse_var_1 + 242)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_57]*placeholder_1[(cse_var_1 + 243)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_57]*placeholder_1[(cse_var_1 + 244)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_57]*placeholder_1[(cse_var_1 + 245)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_57]*placeholder_1[(cse_var_1 + 246)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_57]*placeholder_1[(cse_var_1 + 247)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_58]*placeholder_1[(cse_var_1 + 248)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_58]*placeholder_1[(cse_var_1 + 249)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_58]*placeholder_1[(cse_var_1 + 250)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_58]*placeholder_1[(cse_var_1 + 251)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_58]*placeholder_1[(cse_var_1 + 252)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_58]*placeholder_1[(cse_var_1 + 253)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_58]*placeholder_1[(cse_var_1 + 254)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_58]*placeholder_1[(cse_var_1 + 255)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_59]*placeholder_1[(cse_var_1 + 256)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_59]*placeholder_1[(cse_var_1 + 257)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_59]*placeholder_1[(cse_var_1 + 258)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_59]*placeholder_1[(cse_var_1 + 259)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_59]*placeholder_1[(cse_var_1 + 260)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_59]*placeholder_1[(cse_var_1 + 261)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_59]*placeholder_1[(cse_var_1 + 262)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_59]*placeholder_1[(cse_var_1 + 263)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_60]*placeholder_1[(cse_var_1 + 264)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_60]*placeholder_1[(cse_var_1 + 265)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_60]*placeholder_1[(cse_var_1 + 266)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_60]*placeholder_1[(cse_var_1 + 267)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_60]*placeholder_1[(cse_var_1 + 268)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_60]*placeholder_1[(cse_var_1 + 269)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_60]*placeholder_1[(cse_var_1 + 270)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_60]*placeholder_1[(cse_var_1 + 271)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_61]*placeholder_1[(cse_var_1 + 272)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_61]*placeholder_1[(cse_var_1 + 273)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_61]*placeholder_1[(cse_var_1 + 274)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_61]*placeholder_1[(cse_var_1 + 275)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_61]*placeholder_1[(cse_var_1 + 276)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_61]*placeholder_1[(cse_var_1 + 277)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_61]*placeholder_1[(cse_var_1 + 278)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_61]*placeholder_1[(cse_var_1 + 279)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_62]*placeholder_1[(cse_var_1 + 280)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_62]*placeholder_1[(cse_var_1 + 281)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_62]*placeholder_1[(cse_var_1 + 282)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_62]*placeholder_1[(cse_var_1 + 283)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_62]*placeholder_1[(cse_var_1 + 284)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_62]*placeholder_1[(cse_var_1 + 285)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_62]*placeholder_1[(cse_var_1 + 286)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_62]*placeholder_1[(cse_var_1 + 287)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_63]*placeholder_1[(cse_var_1 + 288)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_63]*placeholder_1[(cse_var_1 + 289)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_63]*placeholder_1[(cse_var_1 + 290)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_63]*placeholder_1[(cse_var_1 + 291)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_63]*placeholder_1[(cse_var_1 + 292)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_63]*placeholder_1[(cse_var_1 + 293)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_63]*placeholder_1[(cse_var_1 + 294)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_63]*placeholder_1[(cse_var_1 + 295)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_34]*placeholder_1[(cse_var_1 + 296)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_34]*placeholder_1[(cse_var_1 + 297)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_34]*placeholder_1[(cse_var_1 + 298)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_34]*placeholder_1[(cse_var_1 + 299)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_34]*placeholder_1[(cse_var_1 + 300)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_34]*placeholder_1[(cse_var_1 + 301)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_34]*placeholder_1[(cse_var_1 + 302)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_34]*placeholder_1[(cse_var_1 + 303)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_64]*placeholder_1[(cse_var_1 + 304)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_64]*placeholder_1[(cse_var_1 + 305)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_64]*placeholder_1[(cse_var_1 + 306)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_64]*placeholder_1[(cse_var_1 + 307)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_64]*placeholder_1[(cse_var_1 + 308)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_64]*placeholder_1[(cse_var_1 + 309)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_64]*placeholder_1[(cse_var_1 + 310)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_64]*placeholder_1[(cse_var_1 + 311)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_17]*placeholder_1[(cse_var_1 + 312)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_17]*placeholder_1[(cse_var_1 + 313)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_17]*placeholder_1[(cse_var_1 + 314)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_17]*placeholder_1[(cse_var_1 + 315)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_17]*placeholder_1[(cse_var_1 + 316)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_17]*placeholder_1[(cse_var_1 + 317)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_17]*placeholder_1[(cse_var_1 + 318)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_17]*placeholder_1[(cse_var_1 + 319)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_15]*placeholder_1[(cse_var_1 + 320)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_15]*placeholder_1[(cse_var_1 + 321)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_15]*placeholder_1[(cse_var_1 + 322)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_15]*placeholder_1[(cse_var_1 + 323)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_15]*placeholder_1[(cse_var_1 + 324)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_15]*placeholder_1[(cse_var_1 + 325)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_15]*placeholder_1[(cse_var_1 + 326)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_15]*placeholder_1[(cse_var_1 + 327)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_14]*placeholder_1[(cse_var_1 + 328)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_14]*placeholder_1[(cse_var_1 + 329)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_14]*placeholder_1[(cse_var_1 + 330)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_14]*placeholder_1[(cse_var_1 + 331)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_14]*placeholder_1[(cse_var_1 + 332)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_14]*placeholder_1[(cse_var_1 + 333)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_14]*placeholder_1[(cse_var_1 + 334)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_14]*placeholder_1[(cse_var_1 + 335)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_13]*placeholder_1[(cse_var_1 + 336)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_13]*placeholder_1[(cse_var_1 + 337)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_13]*placeholder_1[(cse_var_1 + 338)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_13]*placeholder_1[(cse_var_1 + 339)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_13]*placeholder_1[(cse_var_1 + 340)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_13]*placeholder_1[(cse_var_1 + 341)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_13]*placeholder_1[(cse_var_1 + 342)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_13]*placeholder_1[(cse_var_1 + 343)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_12]*placeholder_1[(cse_var_1 + 344)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_12]*placeholder_1[(cse_var_1 + 345)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_12]*placeholder_1[(cse_var_1 + 346)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_12]*placeholder_1[(cse_var_1 + 347)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_12]*placeholder_1[(cse_var_1 + 348)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_12]*placeholder_1[(cse_var_1 + 349)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_12]*placeholder_1[(cse_var_1 + 350)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_12]*placeholder_1[(cse_var_1 + 351)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_11]*placeholder_1[(cse_var_1 + 352)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_11]*placeholder_1[(cse_var_1 + 353)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_11]*placeholder_1[(cse_var_1 + 354)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_11]*placeholder_1[(cse_var_1 + 355)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_11]*placeholder_1[(cse_var_1 + 356)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_11]*placeholder_1[(cse_var_1 + 357)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_11]*placeholder_1[(cse_var_1 + 358)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_11]*placeholder_1[(cse_var_1 + 359)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_10]*placeholder_1[(cse_var_1 + 360)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_10]*placeholder_1[(cse_var_1 + 361)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_10]*placeholder_1[(cse_var_1 + 362)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_10]*placeholder_1[(cse_var_1 + 363)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_10]*placeholder_1[(cse_var_1 + 364)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_10]*placeholder_1[(cse_var_1 + 365)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_10]*placeholder_1[(cse_var_1 + 366)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_10]*placeholder_1[(cse_var_1 + 367)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_9]*placeholder_1[(cse_var_1 + 368)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_9]*placeholder_1[(cse_var_1 + 369)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_9]*placeholder_1[(cse_var_1 + 370)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_9]*placeholder_1[(cse_var_1 + 371)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_9]*placeholder_1[(cse_var_1 + 372)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_9]*placeholder_1[(cse_var_1 + 373)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_9]*placeholder_1[(cse_var_1 + 374)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_9]*placeholder_1[(cse_var_1 + 375)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_8]*placeholder_1[(cse_var_1 + 376)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_8]*placeholder_1[(cse_var_1 + 377)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_8]*placeholder_1[(cse_var_1 + 378)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_8]*placeholder_1[(cse_var_1 + 379)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_8]*placeholder_1[(cse_var_1 + 380)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_8]*placeholder_1[(cse_var_1 + 381)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_8]*placeholder_1[(cse_var_1 + 382)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_8]*placeholder_1[(cse_var_1 + 383)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_7]*placeholder_1[(cse_var_1 + 384)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_7]*placeholder_1[(cse_var_1 + 385)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_7]*placeholder_1[(cse_var_1 + 386)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_7]*placeholder_1[(cse_var_1 + 387)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_7]*placeholder_1[(cse_var_1 + 388)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_7]*placeholder_1[(cse_var_1 + 389)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_7]*placeholder_1[(cse_var_1 + 390)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_7]*placeholder_1[(cse_var_1 + 391)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_6]*placeholder_1[(cse_var_1 + 392)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_6]*placeholder_1[(cse_var_1 + 393)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_6]*placeholder_1[(cse_var_1 + 394)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_6]*placeholder_1[(cse_var_1 + 395)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_6]*placeholder_1[(cse_var_1 + 396)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_6]*placeholder_1[(cse_var_1 + 397)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_6]*placeholder_1[(cse_var_1 + 398)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_6]*placeholder_1[(cse_var_1 + 399)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_4]*placeholder_1[(cse_var_1 + 400)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_4]*placeholder_1[(cse_var_1 + 401)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_4]*placeholder_1[(cse_var_1 + 402)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_4]*placeholder_1[(cse_var_1 + 403)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_4]*placeholder_1[(cse_var_1 + 404)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_4]*placeholder_1[(cse_var_1 + 405)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_4]*placeholder_1[(cse_var_1 + 406)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_4]*placeholder_1[(cse_var_1 + 407)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_3]*placeholder_1[(cse_var_1 + 408)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_3]*placeholder_1[(cse_var_1 + 409)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_3]*placeholder_1[(cse_var_1 + 410)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_3]*placeholder_1[(cse_var_1 + 411)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_3]*placeholder_1[(cse_var_1 + 412)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_3]*placeholder_1[(cse_var_1 + 413)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_3]*placeholder_1[(cse_var_1 + 414)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_3]*placeholder_1[(cse_var_1 + 415)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 416)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 417)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 418)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 419)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 420)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 421)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 422)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_2]*placeholder_1[(cse_var_1 + 423)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_18]*placeholder_1[(cse_var_1 + 424)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_18]*placeholder_1[(cse_var_1 + 425)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_18]*placeholder_1[(cse_var_1 + 426)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_18]*placeholder_1[(cse_var_1 + 427)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_18]*placeholder_1[(cse_var_1 + 428)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_18]*placeholder_1[(cse_var_1 + 429)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_18]*placeholder_1[(cse_var_1 + 430)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_18]*placeholder_1[(cse_var_1 + 431)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_19]*placeholder_1[(cse_var_1 + 432)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_19]*placeholder_1[(cse_var_1 + 433)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_19]*placeholder_1[(cse_var_1 + 434)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_19]*placeholder_1[(cse_var_1 + 435)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_19]*placeholder_1[(cse_var_1 + 436)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_19]*placeholder_1[(cse_var_1 + 437)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_19]*placeholder_1[(cse_var_1 + 438)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_19]*placeholder_1[(cse_var_1 + 439)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_20]*placeholder_1[(cse_var_1 + 440)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_20]*placeholder_1[(cse_var_1 + 441)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_20]*placeholder_1[(cse_var_1 + 442)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_20]*placeholder_1[(cse_var_1 + 443)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_20]*placeholder_1[(cse_var_1 + 444)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_20]*placeholder_1[(cse_var_1 + 445)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_20]*placeholder_1[(cse_var_1 + 446)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_20]*placeholder_1[(cse_var_1 + 447)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_21]*placeholder_1[(cse_var_1 + 448)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_21]*placeholder_1[(cse_var_1 + 449)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_21]*placeholder_1[(cse_var_1 + 450)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_21]*placeholder_1[(cse_var_1 + 451)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_21]*placeholder_1[(cse_var_1 + 452)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_21]*placeholder_1[(cse_var_1 + 453)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_21]*placeholder_1[(cse_var_1 + 454)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_21]*placeholder_1[(cse_var_1 + 455)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_22]*placeholder_1[(cse_var_1 + 456)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_22]*placeholder_1[(cse_var_1 + 457)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_22]*placeholder_1[(cse_var_1 + 458)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_22]*placeholder_1[(cse_var_1 + 459)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_22]*placeholder_1[(cse_var_1 + 460)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_22]*placeholder_1[(cse_var_1 + 461)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_22]*placeholder_1[(cse_var_1 + 462)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_22]*placeholder_1[(cse_var_1 + 463)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_23]*placeholder_1[(cse_var_1 + 464)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_23]*placeholder_1[(cse_var_1 + 465)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_23]*placeholder_1[(cse_var_1 + 466)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_23]*placeholder_1[(cse_var_1 + 467)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_23]*placeholder_1[(cse_var_1 + 468)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_23]*placeholder_1[(cse_var_1 + 469)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_23]*placeholder_1[(cse_var_1 + 470)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_23]*placeholder_1[(cse_var_1 + 471)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_24]*placeholder_1[(cse_var_1 + 472)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_24]*placeholder_1[(cse_var_1 + 473)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_24]*placeholder_1[(cse_var_1 + 474)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_24]*placeholder_1[(cse_var_1 + 475)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_24]*placeholder_1[(cse_var_1 + 476)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_24]*placeholder_1[(cse_var_1 + 477)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_24]*placeholder_1[(cse_var_1 + 478)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_24]*placeholder_1[(cse_var_1 + 479)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_26]*placeholder_1[(cse_var_1 + 480)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_26]*placeholder_1[(cse_var_1 + 481)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_26]*placeholder_1[(cse_var_1 + 482)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_26]*placeholder_1[(cse_var_1 + 483)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_26]*placeholder_1[(cse_var_1 + 484)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_26]*placeholder_1[(cse_var_1 + 485)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_26]*placeholder_1[(cse_var_1 + 486)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_26]*placeholder_1[(cse_var_1 + 487)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_27]*placeholder_1[(cse_var_1 + 488)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_27]*placeholder_1[(cse_var_1 + 489)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_27]*placeholder_1[(cse_var_1 + 490)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_27]*placeholder_1[(cse_var_1 + 491)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_27]*placeholder_1[(cse_var_1 + 492)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_27]*placeholder_1[(cse_var_1 + 493)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_27]*placeholder_1[(cse_var_1 + 494)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_27]*placeholder_1[(cse_var_1 + 495)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_28]*placeholder_1[(cse_var_1 + 496)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_28]*placeholder_1[(cse_var_1 + 497)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_28]*placeholder_1[(cse_var_1 + 498)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_28]*placeholder_1[(cse_var_1 + 499)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_28]*placeholder_1[(cse_var_1 + 500)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_28]*placeholder_1[(cse_var_1 + 501)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_28]*placeholder_1[(cse_var_1 + 502)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_28]*placeholder_1[(cse_var_1 + 503)]))
          T_matmul_NT_1[0] = (T_matmul_NT_1[0] + (placeholder[cse_var_29]*placeholder_1[(cse_var_1 + 504)]))
          T_matmul_NT_1[1] = (T_matmul_NT_1[1] + (placeholder[cse_var_29]*placeholder_1[(cse_var_1 + 505)]))
          T_matmul_NT_1[2] = (T_matmul_NT_1[2] + (placeholder[cse_var_29]*placeholder_1[(cse_var_1 + 506)]))
          T_matmul_NT_1[3] = (T_matmul_NT_1[3] + (placeholder[cse_var_29]*placeholder_1[(cse_var_1 + 507)]))
          T_matmul_NT_1[4] = (T_matmul_NT_1[4] + (placeholder[cse_var_29]*placeholder_1[(cse_var_1 + 508)]))
          T_matmul_NT_1[5] = (T_matmul_NT_1[5] + (placeholder[cse_var_29]*placeholder_1[(cse_var_1 + 509)]))
          T_matmul_NT_1[6] = (T_matmul_NT_1[6] + (placeholder[cse_var_29]*placeholder_1[(cse_var_1 + 510)]))
          T_matmul_NT_1[7] = (T_matmul_NT_1[7] + (placeholder[cse_var_29]*placeholder_1[(cse_var_1 + 511)]))
        }
      }
      for (ax1.inner: int32, 0, 8) {
        let cse_var_66: int32 = (((ax0.outer.outer.ax1.outer.outer.fused.ax0.outer.inner.fused*256) + (ax1.outer.inner*8)) + ax1.inner)
        T_relu[cse_var_66] = max((T_matmul_NT_1[ax1.inner] + placeholder_2[cse_var_66]), 0f32)
      }
    }
  }
}

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ubuntu/anaconda3/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/tune_relay_auto_scheduler.py", line 244, in <module>
    main()
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/tune_relay_auto_scheduler.py", line 234, in main
    run_module_via_rpc(
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/custom_builder_runner.py", line 170, in run_module_via_rpc
    return continuation(rt_mod, dev, args)
  File "/home/ubuntu/tvm/python/tvm/meta_schedule/testing/tune_relay_auto_scheduler.py", line 223, in f_per_layer
    mod = create(graph, rt_mod, dev)
  File "/home/ubuntu/tvm/python/tvm/contrib/debugger/debug_executor.py", line 73, in create
    gmod = GraphModuleDebug(func_obj, dev, graph_json_str, dump_root)
  File "/home/ubuntu/tvm/python/tvm/contrib/debugger/debug_executor.py", line 116, in __init__
    self._run_individual_node = module["run_individual_node"]
  File "/home/ubuntu/tvm/python/tvm/runtime/module.py", line 169, in __getitem__
    return self.get_function(name)
  File "/home/ubuntu/tvm/python/tvm/runtime/module.py", line 153, in get_function
    raise AttributeError("Module has no function '%s'" % name)
AttributeError: Module has no function 'run_individual_node'

Running time in time_evaluator:  [5.604321177777778, 5.608890622222223, 5.610323788888889]
Avg running time: 5.607845196296296
